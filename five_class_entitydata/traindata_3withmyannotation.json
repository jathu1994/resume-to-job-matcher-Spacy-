{"content": "Abhishek Das\n\nMobile: 7411570615                             Email: abhishekdas.nitc@gmail.com\n                               Github: https://github.com/abhishekdas105\n\tLinkedIn: https://www.linkedin.com/in/abhishek-das-6bab9644/\n                                   \nCareer Summary:\n\n1.9 years of experience in Data Science and Analytics.\n6+ years of experience in Global service delivery industry as System Administrator.\n\nKey Skills:\n\n* Data Science and Analysis Tools: Python, SPSS Modeler, R.\n* Visualization and Dash-boarding Tools: Watson Analytics, TABLEAU, Excel.\n* System Admin Tools: TADDM, ITM, Maximo, ISM Dispatching Tool, TIVOLI Console and Job Workload Scheduler.\n\nCertification:\n* ITIL V3 foundation certified.\n\nWork Profile:\n\nDuration: April 2016 to Present.                            \t\t\tCompany: IBM India Pvt Ltd.\nRole: Data Science Engineer                                              \t\tLocation: Bangalore\n\nSkills Learned:\n \nUndertaken training in Data Science under the mentorship of ITOA GTS-Labs Lead Architect, Shekhar S. Jadhav to learn different statistical modeling, machine learning techniques and its applications.\n\nTools and Applications: Python, TABLEAU, Watson Analytics, SPSS Modeler, R.\n\nROLES AND RESPONSIBILITIES:\n\n* Analyze datasets to provide strategic direction to the account management.\n* Perform quantitative analysis of data to recommend efficient staffing solutions.\n* Develop forecasting models based on incident data to predict demands and risks.\n* Utilize analytical tools to identify trends and relationships between different pieces of raw data and draw appropriate conclusions.\n* Translate analytical findings into business insights.\n* Create and interpret analysis into visualizations to provide a detailed view to a diverse set of senior management.\n\n\n\nProjects:\n\nKP : CLUSTERING INDICENTS on INCIDENTS\n\nDesigned and implemented Clustering Modeling techniques on incident log data to identify and create relevant groups on the basis of their summaries.\n\nModel: Clustering\nAlgorithm: Hierarchical Clustering\nTools and Language: Python\nLibraries: pandas, numpy, matplotlib, nltk, sklearn, scipy, xlswriter\n\n* Developed pre-processing techniques to clean the raw data using tokenizers, regular expressions, stop-words and lemmatizers.\n* Implemented vectorization methods using sklearn libraries tf-idf and CountVectorizer to transform the cleaned data to sparse matrix.\n* Applied distanced-based (Hierarchical) clustering method using cosine similarity and ward method to classify the data-points in to separate clusters.\n* Analyzed and tested the connectivity model using dendrograms from scipy library on different thresholds to obtain an optimum set of clusters. \n\nRESEARCH PAPER on NLP Approach to CLUSTER LABEL naming and summarization:\n\nAs an extension to the previous project, I have designed a new technique and implemented the algorithm that aids in providing a detailed view of the cluster insights and appropriately labels each cluster. The technique is under testing phase following which will be filed for patent.\n\nROGERS : TIME SERIES FORECASTING OF INCIDENTS\n\nResponsible for providing an efficient staffing solution to account management team based on volume of incidents raised.\n\nModel: Time-series\nAlgorithm: Moving Average, EWMA, ARIMA\nTools and Language: Python, TABLEAU\nLibraries and modules: pandas, numpy, matplotlib, statsmodel, xlswriter\n\n* Analyzed various data fields to conduct data preparation and outlier detection.\n* Interpreted and visualized the relevant fields to provide a basic understanding of the volume distribution using TABLEAU.\n* Created time-series forecasting models using EWMA, Moving Average and ARIMA from statsmodel library and tested the model using MAPE to test the accuracy.\n* Provided an interface using TkInter library that allows the user to enter ARIMA parameters manually during run-time.\n\n\nAPMM: TREND ANALYSIS OF SCAN FAILURES\n\nResponsible for providing a behavioral insight to Configuration Management Team for faster resolution of application scan failures and improve overall scan success SLO.\n\nModel: Descriptive Analysis\nAlgorithm: Distribution\nTools and Language: SPSS modeler, Python\nLibraries and modules: pandas, numpy, matplotlib, seaborn, xlswriter\n\n* Analyzed the raw scan logs to identify parameters such as environment, priority and type of the scan failure issues to provide insight on.\n* Created a statistical model to visualize and interpret the trend and dependencies at each level of scan window for the majorly contributing scan failure applications.\n* Provided insights, corrective measures and preventive measures to help achieve higher scan success SLO.\n\nDYNAMIC VISUALIZATION OF TnT CAPABILITIES:\n\nThis project aims at capturing and visualizing the different capabilities and pain-points related to transition team data. It is currently in transition. The project is being implemented in TABLEAU.\n\n\n\nDuration: Aug 2012 to Present.                            Company: IBM India Pvt Ltd.\nRole: System Administrator.                                  Bangalore: Bangalore\n\n  Job Responsibility: \n\n* Perform/Monitor/Schedule TADDM discoveries\n* Create/Modify Scopes in TADDM\n* Create/Modify Access List in TADDM\n* Report on Discovery Health and Discoveries to Configuration management team\n* Resolve Discovery issues\n* Troubleshoot Anchor and Gateway related problems E-CMDB Sync problems. Maintain and Modify collation. Properties based on requirement and need.\n* Co-ordinate with Platform / Oracle / Application teams for discovery and database related issues; Ensure backups are successful with the platform team.\n* Create Reports based on customer requirement. Creating Scripts to collect custom information about various systems. Pay close attention to detail and ability to follow through with open issues until resolved\n* Work successfully in a cross-functional environment including development, networking, operating systems, database, and application servers.  in a team environment, handle multiple tasks simultaneously and adapt quickly to changes.\n* Good communication skills to work with IT personnel to build Application and Business Service models in TADDM and the CMDB.\n* Work with data gathering architects to guide them to get information they need to be successful.\n\n\n\n\nProject Details:\n\nIGA and NAB: TADDM\n\nResponsibilities:\n* Perform/Monitor/Schedule TADDM discoveries\n* Create/Modify Scopes in TADDM\n* Create/Modify Access List in TADDM\n* Report on Discovery Health and Discoveries to Configuration management team\n* Resolve Discovery issues\n* Troubleshoot Anchor and Gateway related problems E-CMDB Sync problems. Maintain and Modify collation. Properties based on requirement and need.\n* Co-ordinate with Platform / Oracle / Application teams for discovery and database related issues; Ensure backups are successful with the platform team.\n* Maintain and troubleshoot Id related issues across several domains of IGA.\n\n\nMiller Coors:  ISM Maximo\n\nResponsibilities:\n* Manage and customize CCMDB data according to customer requirement.\n* Run scripts to capture logs on a daily basis.  \n* Updating servers Inventory DB.\n* Study and Analysis of the Business requirements.\n* Work on ISM Change management process.\n\n\nWork Profile:\n\nDesignation: Senior Systems Engineer (Project Lead)\nCompany: IBM India Pvt. Ltd. (on contract)\nTenure: 22nd February 2011- 30th May 2012.\n\n\n\nProject Details: \n\n\nProject Description: Transport for London is a job Scheduling and Application Support in a Batch and Console in Unix Environment. Billing Servers are continuously and rigorously supported on 24*7 basis to provide output at the Client Location. The Portal also includes Regular Health CheckUps and performing Operations such as Checking the Database Logs for Errors and resolving them. Maximo is used as the ticketing tool to resolve the issues faced.\n\n\nJob Profile(Roles and Responsibilities) :\no Remote Server Support and Administration of high end mission critical production Servers\no Support Production Middleware Servers & Production Applications.\no Batch/Jobs/Activities Scheduling & Monitoring etc (Tivoli Workload Scheduler).\no Change Initialization - Unlink Services, Application Shutdowns, Holding Jobs etc.\no Support & Maintains the Billing Servers for London remotely from India through 24x7.\no Schedule and execute the process of validation, pricing, archiving and backup of Call Detail Records (CDRs) of Local and Roaming customers.\no Schedule the jobs & schedules as per users requests (3rd party Billing Dept.), Schedule and Run the required Bill cycle.\no Monitoring of Unix system stability and performance (disk, CPU , Handler )\no Debug & rerun the failed jobs, Monitoring and Maintaining space issues in the servers by running cleanup scripts.\no Continuous interaction with onsite staff, to inform them for any hardware failure and their prompt solution.\no Handle Change Requests and incidents.( Maximo)\no Change Implementation and tracking the change that is performed as required during Servers up gradation.\no Rights of cold reboots on servers for issue where it could be resolved.\no Raise Hardware Calls through chat for Servers Maintenance/Fault. \no Monitoring alerts of the servers such as Fatal, Critical, Warning and Harmless\no Perform First Level Problem Determination if server goes down.\no Ensure that all the problems we attended did not miss SLA\no Assist to the Onsite support if any Hardware problem is there in the server.\n\n\n\n\n\n\n EDUCATIONAL QUALIFICATIONS\n\nCourse\nYear\nUniversity/Board\nCGPA/Percentage\n Class X(ICSE)\n2003\nSt. Augustine�s Day School    \nKolkata.\n79.4%\n      Class XII (ISC)  \n2005\nSt. Augustine�s Day School     \nKolkata. \n74%\nB.Tech (Computer Science  & Engineering).\n2010\nNational Institute of Technology, Calicut.\n5.63\n\n\nPersonal Details :\nName\t\t\t\t: ABHISHEK DAS\nSex\t\t\t           \t: Male\nDate of Birth\t\t           \t: 21st July 1986.\nMarital status\t\t\t: Married\nNationality\t\t\t: Indian\nLanguages I can speak\t\t: Hindi, English, Bengali. \nDeclaration:\n\nI here by declare that all the details furnished above are true to the best of my knowledge.\n\nDate:\t9th November 2017                                                                                               Abhishek Das","annotation":[{"label":["Name"],"points":[{"start":10253,"end":10264,"text":"Abhishek Das"}]},{"label":["Education"],"points":[{"start":9717,"end":9722,"text":"B.Tech"}]},{"label":["Skills"],"points":[{"start":9145,"end":9145,"text":"R"}]},{"label":["Skills"],"points":[{"start":9071,"end":9071,"text":"R"}]},{"label":["Skills"],"points":[{"start":8929,"end":8929,"text":"R"}]},{"label":["Skills"],"points":[{"start":8580,"end":8580,"text":"R"}]},{"label":["Skills"],"points":[{"start":8467,"end":8467,"text":"R"}]},{"label":["Skills"],"points":[{"start":8450,"end":8450,"text":"R"}]},{"label":["Skills"],"points":[{"start":8439,"end":8439,"text":"R"}]},{"label":["Skills"],"points":[{"start":7936,"end":7936,"text":"R"}]},{"label":["Skills"],"points":[{"start":7914,"end":7914,"text":"R"}]},{"label":["Skills"],"points":[{"start":7904,"end":7904,"text":"R"}]},{"label":["Skills"],"points":[{"start":7708,"end":7708,"text":"R"}]},{"label":["Skills"],"points":[{"start":7088,"end":7088,"text":"R"}]},{"label":["Skills"],"points":[{"start":6999,"end":6999,"text":"R"}]},{"label":["Skills"],"points":[{"start":6568,"end":6568,"text":"R"}]},{"label":["Skills"],"points":[{"start":6490,"end":6490,"text":"R"}]},{"label":["Skills"],"points":[{"start":6482,"end":6486,"text":"TADDM"}]},{"label":["Skills"],"points":[{"start":6445,"end":6449,"text":"TADDM"}]},{"label":["Skills"],"points":[{"start":6401,"end":6405,"text":"TADDM"}]},{"label":["Skills"],"points":[{"start":6356,"end":6356,"text":"R"}]},{"label":["Skills"],"points":[{"start":6349,"end":6353,"text":"TADDM"}]},{"label":["Skills"],"points":[{"start":6195,"end":6199,"text":"TADDM"}]},{"label":["Skills"],"points":[{"start":5654,"end":5654,"text":"R"}]},{"label":["Skills"],"points":[{"start":5320,"end":5320,"text":"R"}]},{"label":["Skills"],"points":[{"start":5242,"end":5242,"text":"R"}]},{"label":["Skills"],"points":[{"start":5234,"end":5238,"text":"TADDM"}]},{"label":["Skills"],"points":[{"start":5197,"end":5201,"text":"TADDM"}]},{"label":["Skills"],"points":[{"start":5153,"end":5157,"text":"TADDM"}]},{"label":["Skills"],"points":[{"start":5108,"end":5108,"text":"R"}]},{"label":["Skills"],"points":[{"start":5019,"end":5019,"text":"R"}]},{"label":["Skills"],"points":[{"start":4921,"end":4927,"text":"TABLEAU"}]},{"label":["Skills"],"points":[{"start":4192,"end":4198,"text":" Python"}]},{"label":["Skills"],"points":[{"start":3937,"end":3937,"text":"R"}]},{"label":["Skills"],"points":[{"start":3932,"end":3932,"text":"R"}]},{"label":["Skills"],"points":[{"start":3905,"end":3905,"text":"R"}]},{"label":["Skills"],"points":[{"start":3854,"end":3854,"text":"R"}]},{"label":["Skills"],"points":[{"start":3694,"end":3694,"text":"R"}]},{"label":["Skills"],"points":[{"start":3612,"end":3618,"text":"TABLEAU"}]},{"label":["Skills"],"points":[{"start":3334,"end":3340,"text":"TABLEAU"}]},{"label":["Skills"],"points":[{"start":3325,"end":3331,"text":" Python"}]},{"label":["Skills"],"points":[{"start":3301,"end":3301,"text":"R"}]},{"label":["Skills"],"points":[{"start":3126,"end":3126,"text":"R"}]},{"label":["Skills"],"points":[{"start":3102,"end":3102,"text":"R"}]},{"label":["Skills"],"points":[{"start":3095,"end":3095,"text":"R"}]},{"label":["Skills"],"points":[{"start":3083,"end":3083,"text":"R"}]},{"label":["Skills"],"points":[{"start":3079,"end":3079,"text":"R"}]},{"label":["Skills"],"points":[{"start":2759,"end":2759,"text":"R"}]},{"label":["Skills"],"points":[{"start":2732,"end":2732,"text":"R"}]},{"label":["Skills"],"points":[{"start":2724,"end":2724,"text":"R"}]},{"label":["Skills"],"points":[{"start":2719,"end":2719,"text":"R"}]},{"label":["Skills"],"points":[{"start":2080,"end":2086,"text":" Python"}]},{"label":["Skills"],"points":[{"start":1829,"end":1829,"text":"R"}]},{"label":["Skills"],"points":[{"start":1234,"end":1234,"text":"R"}]},{"label":["Skills"],"points":[{"start":1224,"end":1224,"text":"R"}]},{"label":["Skills"],"points":[{"start":1220,"end":1220,"text":"R"}]},{"label":["Skills"],"points":[{"start":1206,"end":1217,"text":"SPSS Modeler"}]},{"label":["Skills"],"points":[{"start":1188,"end":1203,"text":"Watson Analytics"}]},{"label":["Skills"],"points":[{"start":1179,"end":1185,"text":"TABLEAU"}]},{"label":["Skills"],"points":[{"start":1170,"end":1176,"text":" Python"}]},{"label":["Skills"],"points":[{"start":833,"end":833,"text":"R"}]},{"label":["Skills"],"points":[{"start":555,"end":561,"text":"TABLEAU"}]},{"label":["Skills"],"points":[{"start":537,"end":552,"text":"Watson Analytics"}]},{"label":["Skills"],"points":[{"start":493,"end":493,"text":"R"}]},{"label":["Skills"],"points":[{"start":479,"end":490,"text":"SPSS Modeler"}]},{"label":["Skills"],"points":[{"start":470,"end":476,"text":" Python"}]},{"label":["Name"],"points":[{"start":0,"end":11,"text":"Abhishek Das"}]}],"extras":null,"metadata":{"first_done_at":1532694208000,"last_updated_at":1532694208000,"sec_taken":104,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "ABITH S GANADAHOLE\nBangalore, KA |+919986441793�|�abith.gs@gmail.com\nProfile\n* Senior Software Engineer with 5+ years of experience building cognitive and enterprise solutions.\n* Experience working with IBM Watson services, building Machine learning applications and NLP models.\n* IBM Certified Watson developer � V3\n* 2 years of On-Site experience working in Copenhagen, Denmark with client A.P. Moller�Maersk providing solutions and developing various custom applications for Business-critical processes under the Travel &Transportation domain.\n* Known for excellent troubleshooting and analytical skills�� able to analyze code and engineer well-researched, cost-effective and responsive solutions.\nTechnical Skills\nJava, Spring Framework, Restful API, Hibernate, Cloudant NoSQL, Node JS, Strongloop , IBM Watson Services, Bash Scripting, Python, Pandas, Scikit-learn, Seaborn, MatplotLib , SQL, PL SQL, C#, C++,Oracle , WebSphere MQ, PySpark\nProfessional Experience\nSR. SOFTWARE ENGINEER | IBM GLOBAL BUSINESS SERVICES |10/2012 � PRESENT\n\nClient: IGA PricingIQ � eProcurement(US)\nProject Description: PricingIQ provides business users with insights of opportunity for savings and market conditions to deliver competitive advantage to the company. PricingIQ provides insights from market sentiment to inform the bid decisions, future prices and projected spend, Speed in Fair Value decisions, easy interaction to customer.\nTechnologies: Watson, Java, Node JS, Spring MVC, Loopback, RESTful API, Bluemix, Cloudant NoSQL, Git, Pandas, IBM Data Science Experience\nResponsibilities:\n* Working part of IBM AIS - Application innovation services team, experience in developing cognitive solutions and REST microservices with IBM Watson and Bluemix Cloud(PaaS)\n* Development of Time Series ARIMA Predictive Models for various procurement business councils with python on IBM Data Science Experience.\n* Market sentiment model creation sourcing various news articles and websites crawled with WCA(Watson Content analytics)\n* Development of NLP ChatBot integrating IBM Watson- Conversation Service to provide Analytical procurement data to business users.\n* Designing and implementing WebCrawler�s through Watson Content Analytics studio and Apache UMMI to transform Unstructured data for market sentiment analytics.\n* Experience working with Cloudant NoSQL DB for content analytics and developing basic Map reduce functions for data analysis.\nClient: AP Moller Maersk (Denmark)\nProject Description: Global manifest System(GMS) is a global customs compliance application. It compiles the vessel manifest information, validating it against a country's standards, transmitting the data to the customs via the Advance Message Processing System (AMPS), while tracking customs responses. \nTechnologies: Java, Spring MVC, Oracle , SQL, Clearcase , Websphere MQ \nResponsibilities:\n* Part of Agile scrum team involved in developing and designing of Spring MVC web application.\n* Working with onsite client and offshore teams to track status and issues in delivery, conducting reviews of codes and test cases, analyzing requirements and enhancements. \n\nProject Description: GCSS (Global Customer Service System) is a booking and order handling system of Maersk Line. To create opportunities in global commerce, GCSS is a key element in offering second to none transportation solution. It also helps to increase the efficiency of the order handling\nprocess. \n\nTechnologies: C++, Oracle , SQL, Clearcase , Websphere MQ ,Python, Bash Scripting\n* Handling development including design and troubleshooting of core business critical applications for Maersk line.\n* Played the role of onsite coordinator interacting with Client and Business process owners for solutioning and design of upcoming Business requirements.\n* Generated and implemented new ideas as part of continuous service improvements by developing new scripts and tools which automated and simplified business pain points and in turn generate revenue for IBM.\n* SME in the field with in-depth functional knowledge and deep understanding of Client business processes under Travel and Transportation domain.\nEducation\nBACHELOR OF ENGINEERING |�2012�|�VISHWESHWARAIAH TECHNOLOGY UNIVERSITY\n* College: KSIT\n* Major: Computer Science","annotation":[{"label":["Education"],"points":[{"start":4156,"end":4178,"text":"BACHELOR OF ENGINEERING"}]},{"label":["Skills"],"points":[{"start":3508,"end":3521,"text":"Bash Scripting"}]},{"label":["Skills"],"points":[{"start":3500,"end":3505,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3486,"end":3497,"text":"Websphere MQ"}]},{"label":["Skills"],"points":[{"start":3474,"end":3483,"text":"Clearcase "}]},{"label":["Skills"],"points":[{"start":3469,"end":3471,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":3460,"end":3465,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":3455,"end":3457,"text":"C++"}]},{"label":["Skills"],"points":[{"start":2833,"end":2844,"text":"Websphere MQ"}]},{"label":["Skills"],"points":[{"start":2821,"end":2830,"text":"Clearcase "}]},{"label":["Skills"],"points":[{"start":2816,"end":2818,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":2816,"end":2817,"text":"SQ"}]},{"label":["Skills"],"points":[{"start":2807,"end":2812,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":2345,"end":2347,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":2345,"end":2346,"text":"SQ"}]},{"label":["Skills"],"points":[{"start":2056,"end":2065,"text":"IBM Watson"}]},{"label":["Skills"],"points":[{"start":1720,"end":1729,"text":"IBM Watson"}]},{"label":["Skills"],"points":[{"start":1517,"end":1519,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1517,"end":1518,"text":"SQ"}]},{"label":["Skills"],"points":[{"start":914,"end":919,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":910,"end":912,"text":"C++"}]},{"label":["Skills"],"points":[{"start":901,"end":903,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":901,"end":902,"text":"SQ"}]},{"label":["Skills"],"points":[{"start":893,"end":895,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":893,"end":894,"text":"SQ"}]},{"label":["Skills"],"points":[{"start":841,"end":846,"text":"Python"}]},{"label":["Skills"],"points":[{"start":825,"end":838,"text":"Bash Scripting"}]},{"label":["Skills"],"points":[{"start":804,"end":813,"text":"IBM Watson"}]},{"label":["Skills"],"points":[{"start":777,"end":779,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":777,"end":778,"text":"SQ"}]},{"label":["Skills"],"points":[{"start":203,"end":212,"text":"IBM Watson"}]},{"label":["Location"],"points":[{"start":19,"end":27,"text":"Bangalore"}]},{"label":["Name"],"points":[{"start":0,"end":17,"text":"ABITH S GANADAHOLE"}]}],"extras":null,"metadata":{"first_done_at":1532674968000,"last_updated_at":1532674968000,"sec_taken":257,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Ajay Kumar Soma\nTechnical Architect\n9676116650\nAjaykumar.career@gmail.com\n\n\nSummary\n\n3+ years of experience in Machine Learning, Deep Learning, Data/Text Mining, NLP, Decision Trees, Adaptive Decision Algorithms, Neural Networks\n\nExcellent Knowledge and hand-on experience in Deep Learning family of machine learning methods.\n\nGood knowledge in Deep learning architectures such as \n\tDeep Convolutional Nural Network\n\tReccurant Neural networks\n\tDeep Reccurant neural networks\n\nWorked in the following areas of Deep learning applications\n\tNatural language processing (NLP)\n\tAutomatic speech recognition\n\tRecommendation systems\n\tImage recognition\n    Customer relationship management\n\tBioinformatics\n\tMobile advertising\n\tComputer Vison\n\nGood knowledge and hand-on experience in following Deep Learning frameworks\nTensorflow, Microsoft Cognitive Toolkit(CNTK), Keras, Torch, PyTorch, MXNet, \ndeeplearn.js, BigDL\n\n Technical skills: \nI have full stack technical skills and experience necessary to develop, deploy and maintain a full scale application from business requirement.\nProficient in:\nProficient in code versioning tools (Git, Mercurial or SVN)\nStrong programming experience in Python, \nDesign and develop software as scalable architectures, components, API's and systems.\n\nPopular python libraries for Machine Learning - numpy, Scipy, SciKit-Learn, Pandas, matplotlib, NLTK, NLP\nData/Text Mining\nExcellent experience in webscraping using Selenium and Python. Very useful for data mining.\nGood experience and knowledge in Android app development.\nWeb application development experience in Python using WebSocket protocol\nProficient in NodeJS\nExcellent experience and knowledge in building RESTful web services\nStrong programming experience in R Programming\nOptimization Algorithms, Data science\nHTML5, JavaScript, Angular JS, ionic framework\nExperience on statsmodel, OpenCV(cv2.ml), matplotlib\nStrong knowledge in OOPS in Python\nWorked on advanced topics like iterators, generators, regular expressions in Python.\nStrong hold in Data Structures and Algorithm.\nDatabase\nOracle, MySQL, MongoDB, CouchDB\n Professional summary\n> Worked as Senior Systems Engineer in Infosys Technologies Pvt. Ltd, from SEP 2006 to Dec 31st 2010.\n> Working as Lead Consultant in Headstrong Technologies Pvt. Ltd, from May 2016 to till date.\n> Working as Technical Architect in TCS, from June 2016 to till date.\n\n\nWork Experience\n\nExperience on modern deep learning approaches to NLP: word/paragraph embeddings, representation learning, text/sentiment classification, disambiguation.\n\nExperience in the following areas: entity/relation extraction, normalization, summarization, semantic search, word/paragraph/document embedding, ranking, ontology-aware IR, question answering.\n\nExpertise related to applying deep learning, convolutional neural networks (CNNs) and related techniques for computer vision, object detection, object classifications and related problems.\n\n\n\nIn the current project I am responsible for building Deep Learning models to solve specific problems. Workflow would look as follows: \n1) Define Problem Statement (input -> output) \n2) Preprocess Data \n3) Build DL model \n4) Test on different datasets using Transfer Learning \n5) Parameter Tuning \n6) Deployment to production\n\nResponsibilities \nUsing data mining to uncover actionable insights\nCommunicate insights clearly to business and product management\nInfluence business decisions using data\nPartner with engineering to spot opportunities and build solutions for improving data driven decision making and consumer experience\n\nSome of the applications we have built are given below.\n\nDetecting diabetic eye disease with machine learning\n\nDiabetic retinopathy � an eye condition that affects people with diabetes � is the fastest growing cause of blindness, with nearly 415 million diabetic patients at risk worldwide. The disease can be treated if detected early, but if not, it can lead to irreversible blindness.\n\nOne of the most common ways to detect diabetic eye disease is to have a specialist examine pictures of the back of the eye and determine whether there are signs of the disease, and if so, how severe it is.\n\nOur client who is a leading hospital in china, provided us a dataset of 128,000 images and used them to train a deep neural network to detect diabetic retinopathy. \n\nWe have used deep learning platform CNTK and Microsoft azure to build the model.\nWe then compared our algorithm�s performance to another set of images examined by a panel of board-certified ophthalmologists. Our algorithm performs on par with the ophthalmologists, achieving both high sensitivity and specificity. \n\n\nCredit card fraud detection\n\n\nAlthough there are several fraud detection technology exist based on Data mining, Knowledge Discovery and Expert System etc. but all these are not capable enough to detect the fraud at the time when fraudulent transaction are in progress due to very less chance of a transaction being fraudulent . We have used deep learning platform TensorFlow to built a model which is saving around 5000$ every day for the customer.\n\n\n\nPrior to this I was working in IBM AS400 as a developer.\n\nNotice period\nActual notice is 1-2 months but it is negotiable.\n\n Educational Details\n\nCourse\nBoard/University\nYear of Passing\nAggregate\nB. Tech(ECE)\nJNTU, Hyderabad\nApril,2006\n80%\nIntermediate\nBoard of Intermediate ,AP\nMarch,2002\n96%\nSSC\nSecondary School Board ,AP\nMarch,2000\n83.33%\n \n Personal Details\n\nDate of Birth    \t\t:\tMay 10th, 1984\n\t\n\n\n3","annotation":[{"label":["Education"],"points":[{"start":5309,"end":5320,"text":"B. Tech(ECE)"}]},{"label":["Skills"],"points":[{"start":3004,"end":3017,"text":" Deep Learning"}]},{"label":["Skills"],"points":[{"start":1383,"end":1398,"text":"Data/Text Mining"}]},{"label":["Skills"],"points":[{"start":1306,"end":1321,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":784,"end":797,"text":" Deep Learning"}]},{"label":["Skills"],"points":[{"start":275,"end":288,"text":" Deep Learning"}]},{"label":["Skills"],"points":[{"start":144,"end":159,"text":"Data/Text Mining"}]},{"label":["Skills"],"points":[{"start":129,"end":141,"text":"Deep Learning"}]},{"label":["Skills"],"points":[{"start":111,"end":126,"text":"Machine Learning"}]},{"label":["Name"],"points":[{"start":0,"end":14,"text":"Ajay Kumar Soma"}]}],"extras":null,"metadata":{"first_done_at":1532684249000,"last_updated_at":1532684249000,"sec_taken":249,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Ajaya Kumar Muduli\n\n\nMobile: +91-9901722250/9036030401\n    E-Mail: ajayamuduli@gmail.com\n\n\n\nObjective\n\nTo learn and share knowledge in every step enhancing my current skills and efficiency of the company and to contribute to the highest potential to achieve the objective of organization that will impact company�s growth. \n\nSummary:\n\n* Ability to coordinate with team members.\n* 7.11 years of experience in software development and maintenance with 4.5 years in C, C++ and UNIX/LINUX and 3.5 years in Python, REST API, Django, Machine learning in Telecom ,Networking ,digital TV and Embedded domain.\n* Working knowledge in Shell Scripting and Python.\n* Working knowledge in protocols like TCP/IP, UDP.\n* Working knowledge in tools likes GCC, GDB, MAKE, CVS, ASTACH Community, Jude Community CPP UNIT, Rational Rose, Perforce, PUTTY, and VMWARE, CSCOPE, Beyond Compare, Source Insight, PC Lint, Google Test, CPP Unit, Val grind, WIRESHARK, WINSCP, GIT.  \n* Working knowledge in Pycharm, Anaconda, Numpy and Pandas.             \n* Working knowledge in Design Pattern and UML design.\n* Working knowledge in Data Structures.\n* Working knowledge in Socket programming, Multithreading and interprocess communication (IPC).\n* Working knowledge in SQL and PL/SQL.\n* Working Knowledge Oracle SQL developer.\n* Working knowledge in BOOST.\n* Working knowledge in STL (Standard Template Library).\n* Good expertise in SDLC like software design, development and implementation of software.\n\nWork Experience:\n\nPresently working as a Senior Software Engineer with Accenture Pvt Ltd from July 2014 to till-date.\nPreviously Worked with TechMahindra   from July 2013 to June 2014 as Senior Software Engineer.\nPreviously worked with HCL Technology from Jan 2010 to June 2013 as a software Engineer in Bangalore.\n\n\n\n\n\n\n\n\nTechnical Skill Profile:\n\nLanguage\t\t: C, C++\nProtocol \t\t: TCP/IP, UDP\nNetworking\t\t: Socket programming, IPC, Multithreading\nDatabases\t\t: Oracle 10g\nScripting Language\t: Shell Scripting, Python\nTools\t\t\t: GDB 3.3, GCC 3.2, CVS, MAKE 3.79, Perforce.\nOperating System   : Linux, Windows 10,Ubuntu16.04\n\nProfessional Experience:\n\n\n#1 Title: NBNCO (National Broadband Network Company) \n\nOrganization  : Accenture Bangalore\nTeam Size     : 10\nClient            : NBNCO, Australian Telecom Client\nDuration        : July 2014 to till date.\n\nSpatialNet is the product used to manage the PNI (Physical Network Inventory) for communicationservices. It includes Planning/Operation/Design/Maintenance and Management for Telecommunications ServiceProviders. It is build to support different telecommunication services Fiber, Copper, HFC, Satellite etc.Activities: Development of the service accessibility for different telecom & network technologies, written python code to post the request and generate the report if the boundary is serviceable. Configured metadata to identify the area is serviceable or not for different technologies.\n\nSolution Environment: Python, Windows, Linux, Restful API, Spatial NET, XML, Oracle, AUTO CAD, GIT, Jenkin, Pycharm ,Django.\nResponsibility:\n* Strong Independent contributor (Giving support to the customers) as well as leading the Freshers.\n* Design development and enhancement work.\n* Coding,Code review,Testing.\n* Doing POC and providing to client.\n* Analysis of  specifications provided by the clients\n* Communicating with the customer.\n\n\n#2 Title: HACC (High Availably Control component) \n\nOrganization   : Tech Mahindra Bangalore\nTeam Size      : 8\nClient             : PTC, USA.\nDuration         : June 2013 July 2014.\n\nThe ITC PTC system relies on messages transmitted by WIU�s. Multiple locomotives in the area receive these messages and PTC application uses them as part of its operation. Since more than one locomotive may be interested in a WIU�s message, the status message is sent in a broadcast mode at the radio level. The PTC application on the locomotive needs the message a specified distance ahead of the wayside location. This poses some unique challenges such as:-\nWayside 220 radios may not cover the needed distance of track. And, parts or the entire 220 MHz radio network may fail and the wayside currently has no ability to leverage locomotive�s wireless IP networks.\nHACC as an application solves the above challenges through:-220MHz Radio Base Station relay & failover � which improves 220 Network reliability and track coverage.  On    demand dynamic subscriptions,   where by wayside status messages can be delivered by WSRS to locomotive over any available network � to mitigate failures in the 220 radio network. Ability to accept Wayside status messages by WSRS over IP network paths � to mitigate failures on the wayside radio. Additionally, WSRS provides following capabilities:-Raise alerts when destination(s) are unreachable Provides Audit reports of type 30day sliding on WIUs, Relays and Subscriptions\n\nSolution Environment: C++, C,BOOST,Linux,VI Editor,CVS, Shell Scripting, Design pattern , IPC, STL, UML,Socket,Multithreading,TCP/IP,UDP,GDB,POCO,eclipse.\n\nResponsibility:\n* Strong Independent contributor (Giving support to the customers) as well as leading the Freshers.\n* Design development and enhancement work.\n* Coding,Code review,Testing.\n* Doing POC and providing to client.\n* Sometimes   writing UT using Google test.\n* Analysis of  specifications provided by the clients\n* Communicating with the customer.\n\n\n\n\n\n#3 Title: Broadcast Middleware and Application Development \n\nOrganization   : HCL Technology Bangalore\nTeam Size      : 10\nClient             : Leading Consumer Electronics & IT Products in the world.\nDuration         : Jan 2010 to June 2013.\nDescription:\nDigital television (DTV) is the transmission of audio and video by digitally is a way of receiving television signal in a digital format. It is an innovative service that represents a significant evolution in television technology. DTV has enabled broadcasters to offer television with better picture and sound quality. It also offers multiple programming choices, called multicasting and interactive capabilities. It allows users to access further information by entering menus and interacting with the television. The various features present in TV are activated used by the Menu control of the TV.\nApplication Development is about the User Interface design of the menu and various applications and interacting with varios layers for data prcessing and Prohibit conditions according to a specific operator/Country selected by the user; prohibit conditions according to a specific model of the TV; Operating the lower layer�s features to process a request from the user, etc. \n\nSolution Environment: C++, C, Linux, Source Insight, Perforce, Shell Scripting, Design pattern , IPC, STL, UML,Socket,Multithreading,UDP.\nPosition: Lead Engineer\nRole: Team Member\nTools: Teraterm, Perforce, XML, GDB, VI Editor, Hudson,Jenkin.\nResponsibility:\n* Complete responsibility of requirement analysis, software design and development.\n* Delivered strong sustainable product with design/implementation & workflow optimization.\n* Designed and developed many challenging features like MBD.\n* Designing the UI layout and developing API to interact with Lower layer and HAL.\n* Bug fixing and root cause analysis. Providing solution for the issue with proper risk analysis.\n* Functional and Integration testing for various modules handled.\n* Review of Design, Coding and Test cases for both LLR and HLR.\n* Prepared Requirement analysis document, Refactoring document and IT sheet.\n* Interact with Clients (through email and Voice) for their new and change in requirements.\n* Mentoring new members within the Team.\n\nEducation:\n\nM.C.A (Master of Computer Application) from Berhampur University, Odisha with 84% in 2006.\nB.C.A (Bachelor in Computer Application) from Berhampur University, Odisha with 82% in 2003.\n\nPersonal Details:\n\nName: Ajaya Kumar Muduli\nFather�s Name: Shri Ranka Muduli.\nSex: Male\nMarital Status: Married\nPassport No: G7673211\nDate Of Issue: 13-05-2008\nDate Of Expire: 12-05-2018       \n\n\n                                                                                        Ajaya Kumar Muduli","annotation":[{"label":["Name"],"points":[{"start":8119,"end":8136,"text":"Ajaya Kumar Muduli"}]},{"label":["Name"],"points":[{"start":7860,"end":7877,"text":"Ajaya Kumar Muduli"}]},{"label":["Skills"],"points":[{"start":7760,"end":7760,"text":"C"}]},{"label":["Skills"],"points":[{"start":7760,"end":7760,"text":"C"}]},{"label":["Skills"],"points":[{"start":7743,"end":7743,"text":"C"}]},{"label":["Skills"],"points":[{"start":7743,"end":7743,"text":"C"}]},{"label":["Skills"],"points":[{"start":7667,"end":7667,"text":"C"}]},{"label":["Skills"],"points":[{"start":7667,"end":7667,"text":"C"}]},{"label":["Skills"],"points":[{"start":7652,"end":7652,"text":"C"}]},{"label":["Skills"],"points":[{"start":7652,"end":7652,"text":"C"}]},{"label":["Education"],"points":[{"start":7650,"end":7655,"text":"M.C.A "}]},{"label":["Skills"],"points":[{"start":7520,"end":7520,"text":"C"}]},{"label":["Skills"],"points":[{"start":7520,"end":7520,"text":"C"}]},{"label":["Skills"],"points":[{"start":7383,"end":7383,"text":"C"}]},{"label":["Skills"],"points":[{"start":7383,"end":7383,"text":"C"}]},{"label":["Skills"],"points":[{"start":6882,"end":6882,"text":"C"}]},{"label":["Skills"],"points":[{"start":6882,"end":6882,"text":"C"}]},{"label":["Skills"],"points":[{"start":6720,"end":6720,"text":"C"}]},{"label":["Skills"],"points":[{"start":6720,"end":6720,"text":"C"}]},{"label":["Skills"],"points":[{"start":6648,"end":6648,"text":"C"}]},{"label":["Skills"],"points":[{"start":6648,"end":6648,"text":"C"}]},{"label":["Skills"],"points":[{"start":6643,"end":6645,"text":"C++"}]},{"label":["Skills"],"points":[{"start":6643,"end":6643,"text":"C"}]},{"label":["Skills"],"points":[{"start":6643,"end":6643,"text":"C"}]},{"label":["Skills"],"points":[{"start":6450,"end":6450,"text":"C"}]},{"label":["Skills"],"points":[{"start":6450,"end":6450,"text":"C"}]},{"label":["Skills"],"points":[{"start":5538,"end":5538,"text":"C"}]},{"label":["Skills"],"points":[{"start":5538,"end":5538,"text":"C"}]},{"label":["Skills"],"points":[{"start":5509,"end":5509,"text":"C"}]},{"label":["Skills"],"points":[{"start":5509,"end":5509,"text":"C"}]},{"label":["Location"],"points":[{"start":5479,"end":5487,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":5465,"end":5465,"text":"C"}]},{"label":["Skills"],"points":[{"start":5465,"end":5465,"text":"C"}]},{"label":["Skills"],"points":[{"start":5348,"end":5348,"text":"C"}]},{"label":["Skills"],"points":[{"start":5348,"end":5348,"text":"C"}]},{"label":["Skills"],"points":[{"start":5221,"end":5221,"text":"C"}]},{"label":["Skills"],"points":[{"start":5221,"end":5221,"text":"C"}]},{"label":["Skills"],"points":[{"start":5190,"end":5190,"text":"C"}]},{"label":["Skills"],"points":[{"start":5190,"end":5190,"text":"C"}]},{"label":["Skills"],"points":[{"start":5183,"end":5183,"text":"C"}]},{"label":["Skills"],"points":[{"start":5183,"end":5183,"text":"C"}]},{"label":["Skills"],"points":[{"start":5009,"end":5009,"text":"C"}]},{"label":["Skills"],"points":[{"start":5009,"end":5009,"text":"C"}]},{"label":["Skills"],"points":[{"start":4993,"end":4993,"text":"C"}]},{"label":["Skills"],"points":[{"start":4993,"end":4993,"text":"C"}]},{"label":["Skills"],"points":[{"start":4958,"end":4958,"text":"C"}]},{"label":["Skills"],"points":[{"start":4958,"end":4958,"text":"C"}]},{"label":["Skills"],"points":[{"start":4917,"end":4917,"text":"C"}]},{"label":["Skills"],"points":[{"start":4917,"end":4917,"text":"C"}]},{"label":["Skills"],"points":[{"start":4893,"end":4893,"text":"C"}]},{"label":["Skills"],"points":[{"start":4893,"end":4893,"text":"C"}]},{"label":["Skills"],"points":[{"start":4888,"end":4890,"text":"C++"}]},{"label":["Skills"],"points":[{"start":4888,"end":4888,"text":"C"}]},{"label":["Skills"],"points":[{"start":4888,"end":4888,"text":"C"}]},{"label":["Skills"],"points":[{"start":4220,"end":4220,"text":"C"}]},{"label":["Skills"],"points":[{"start":4220,"end":4220,"text":"C"}]},{"label":["Skills"],"points":[{"start":4219,"end":4219,"text":"C"}]},{"label":["Skills"],"points":[{"start":4219,"end":4219,"text":"C"}]},{"label":["Skills"],"points":[{"start":3864,"end":3864,"text":"C"}]},{"label":["Skills"],"points":[{"start":3864,"end":3864,"text":"C"}]},{"label":["Skills"],"points":[{"start":3672,"end":3672,"text":"C"}]},{"label":["Skills"],"points":[{"start":3672,"end":3672,"text":"C"}]},{"label":["Skills"],"points":[{"start":3560,"end":3560,"text":"C"}]},{"label":["Skills"],"points":[{"start":3560,"end":3560,"text":"C"}]},{"label":["Skills"],"points":[{"start":3556,"end":3556,"text":"C"}]},{"label":["Skills"],"points":[{"start":3556,"end":3556,"text":"C"}]},{"label":["Skills"],"points":[{"start":3501,"end":3501,"text":"C"}]},{"label":["Skills"],"points":[{"start":3501,"end":3501,"text":"C"}]},{"label":["Skills"],"points":[{"start":3478,"end":3478,"text":"C"}]},{"label":["Skills"],"points":[{"start":3478,"end":3478,"text":"C"}]},{"label":["Location"],"points":[{"start":3449,"end":3457,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":3397,"end":3397,"text":"C"}]},{"label":["Skills"],"points":[{"start":3397,"end":3397,"text":"C"}]},{"label":["Skills"],"points":[{"start":3379,"end":3379,"text":"C"}]},{"label":["Skills"],"points":[{"start":3379,"end":3379,"text":"C"}]},{"label":["Skills"],"points":[{"start":3378,"end":3378,"text":"C"}]},{"label":["Skills"],"points":[{"start":3378,"end":3378,"text":"C"}]},{"label":["Skills"],"points":[{"start":3331,"end":3331,"text":"C"}]},{"label":["Skills"],"points":[{"start":3331,"end":3331,"text":"C"}]},{"label":["Skills"],"points":[{"start":3248,"end":3248,"text":"C"}]},{"label":["Skills"],"points":[{"start":3248,"end":3248,"text":"C"}]},{"label":["Skills"],"points":[{"start":3217,"end":3217,"text":"C"}]},{"label":["Skills"],"points":[{"start":3217,"end":3217,"text":"C"}]},{"label":["Skills"],"points":[{"start":3210,"end":3210,"text":"C"}]},{"label":["Skills"],"points":[{"start":3210,"end":3210,"text":"C"}]},{"label":["Skills"],"points":[{"start":3041,"end":3046,"text":"Django"}]},{"label":["Skills"],"points":[{"start":3014,"end":3014,"text":"C"}]},{"label":["Skills"],"points":[{"start":3014,"end":3014,"text":"C"}]},{"label":["Skills"],"points":[{"start":2946,"end":2951,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2832,"end":2832,"text":"C"}]},{"label":["Skills"],"points":[{"start":2832,"end":2832,"text":"C"}]},{"label":["Skills"],"points":[{"start":2620,"end":2620,"text":"C"}]},{"label":["Skills"],"points":[{"start":2620,"end":2620,"text":"C"}]},{"label":["Skills"],"points":[{"start":2610,"end":2610,"text":"C"}]},{"label":["Skills"],"points":[{"start":2610,"end":2610,"text":"C"}]},{"label":["Skills"],"points":[{"start":2282,"end":2282,"text":"C"}]},{"label":["Skills"],"points":[{"start":2282,"end":2282,"text":"C"}]},{"label":["Skills"],"points":[{"start":2259,"end":2259,"text":"C"}]},{"label":["Skills"],"points":[{"start":2259,"end":2259,"text":"C"}]},{"label":["Skills"],"points":[{"start":2236,"end":2236,"text":"C"}]},{"label":["Skills"],"points":[{"start":2236,"end":2236,"text":"C"}]},{"label":["Location"],"points":[{"start":2207,"end":2215,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":2139,"end":2139,"text":"C"}]},{"label":["Skills"],"points":[{"start":2139,"end":2139,"text":"C"}]},{"label":["Skills"],"points":[{"start":2021,"end":2021,"text":"C"}]},{"label":["Skills"],"points":[{"start":2021,"end":2021,"text":"C"}]},{"label":["Skills"],"points":[{"start":2014,"end":2014,"text":"C"}]},{"label":["Skills"],"points":[{"start":2014,"end":2014,"text":"C"}]},{"label":["Skills"],"points":[{"start":2013,"end":2013,"text":"C"}]},{"label":["Skills"],"points":[{"start":2013,"end":2013,"text":"C"}]},{"label":["Skills"],"points":[{"start":1986,"end":1991,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1906,"end":1906,"text":"C"}]},{"label":["Skills"],"points":[{"start":1906,"end":1906,"text":"C"}]},{"label":["Skills"],"points":[{"start":1859,"end":1859,"text":"C"}]},{"label":["Skills"],"points":[{"start":1859,"end":1859,"text":"C"}]},{"label":["Skills"],"points":[{"start":1841,"end":1843,"text":"C++"}]},{"label":["Skills"],"points":[{"start":1841,"end":1841,"text":"C"}]},{"label":["Skills"],"points":[{"start":1841,"end":1841,"text":"C"}]},{"label":["Skills"],"points":[{"start":1838,"end":1838,"text":"C"}]},{"label":["Skills"],"points":[{"start":1838,"end":1838,"text":"C"}]},{"label":["Location"],"points":[{"start":1781,"end":1789,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":1714,"end":1714,"text":"C"}]},{"label":["Skills"],"points":[{"start":1714,"end":1714,"text":"C"}]},{"label":["Skills"],"points":[{"start":1408,"end":1408,"text":"C"}]},{"label":["Skills"],"points":[{"start":1408,"end":1408,"text":"C"}]},{"label":["Skills"],"points":[{"start":1214,"end":1214,"text":"C"}]},{"label":["Skills"],"points":[{"start":1214,"end":1214,"text":"C"}]},{"label":["Skills"],"points":[{"start":944,"end":944,"text":"C"}]},{"label":["Skills"],"points":[{"start":944,"end":944,"text":"C"}]},{"label":["Skills"],"points":[{"start":908,"end":908,"text":"C"}]},{"label":["Skills"],"points":[{"start":908,"end":908,"text":"C"}]},{"label":["Skills"],"points":[{"start":887,"end":887,"text":"C"}]},{"label":["Skills"],"points":[{"start":887,"end":887,"text":"C"}]},{"label":["Skills"],"points":[{"start":861,"end":861,"text":"C"}]},{"label":["Skills"],"points":[{"start":861,"end":861,"text":"C"}]},{"label":["Skills"],"points":[{"start":846,"end":846,"text":"C"}]},{"label":["Skills"],"points":[{"start":846,"end":846,"text":"C"}]},{"label":["Skills"],"points":[{"start":792,"end":792,"text":"C"}]},{"label":["Skills"],"points":[{"start":792,"end":792,"text":"C"}]},{"label":["Skills"],"points":[{"start":782,"end":782,"text":"C"}]},{"label":["Skills"],"points":[{"start":782,"end":782,"text":"C"}]},{"label":["Skills"],"points":[{"start":766,"end":766,"text":"C"}]},{"label":["Skills"],"points":[{"start":766,"end":766,"text":"C"}]},{"label":["Skills"],"points":[{"start":763,"end":763,"text":"C"}]},{"label":["Skills"],"points":[{"start":763,"end":763,"text":"C"}]},{"label":["Skills"],"points":[{"start":754,"end":754,"text":"C"}]},{"label":["Skills"],"points":[{"start":754,"end":754,"text":"C"}]},{"label":["Skills"],"points":[{"start":740,"end":740,"text":"C"}]},{"label":["Skills"],"points":[{"start":740,"end":740,"text":"C"}]},{"label":["Skills"],"points":[{"start":644,"end":649,"text":"Python"}]},{"label":["Skills"],"points":[{"start":528,"end":543,"text":"Machine learning"}]},{"label":["Skills"],"points":[{"start":520,"end":525,"text":"Django"}]},{"label":["Skills"],"points":[{"start":510,"end":517,"text":"REST API"}]},{"label":["Skills"],"points":[{"start":502,"end":507,"text":"Python"}]},{"label":["Skills"],"points":[{"start":479,"end":483,"text":"LINUX"}]},{"label":["Skills"],"points":[{"start":474,"end":477,"text":"UNIX"}]},{"label":["Skills"],"points":[{"start":466,"end":468,"text":"C++"}]},{"label":["Name"],"points":[{"start":0,"end":17,"text":"Ajaya Kumar Muduli"}]}],"extras":null,"metadata":{"first_done_at":1532667859000,"last_updated_at":1532667859000,"sec_taken":197,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "R E S U M E\nNAME:-Akshy Kumar\nMobile: +91- 9620124620\nEmail: akkygr84u@gmail.com\n\nSUMMARY\n\n* 5.6 years of total experience working on Data Science , Machine Learning  and Web application  using python(SciKit- Learn, Flask, Numpy, Panda) and java/j2ee. \n* Basics of Deep Learning using Tensorflow. \n* Completed MCA (Master in Computer Application) with 7.93 CGPA.\nWORK EXPERIENCE\n\n* Currently  working  with Century link India as Senior Software Engineer  from   March 2016.\n* Worked in  Accenture as a Senior  Analyst  from  May 2015 to Dec 2015.\n\n* Worked in Schneider Electric India as a  Analyst from May 2014 to May 2015\n\n* Worked as Software Engineer in Liferay India Pvt. Ltd. from  Feb  2012 to May 2014\n\nSKILLS\nTools & Technology\n\n\nIDE\nPython, Scikit-Learn, Numpy, Pandas, Flask,\nNLTK, Spacy, Seaborn, Matplotlib, Java/J2ee\n\nEclipse, PyCharm, Ipython Notebook.\nProject Management  Skills   \nDatabase Known\nSVN, Jenkins, Putty,  Maven, WinSCP.\nOracle, MySQL\nOperating System\nWindows, Linux\n\nPROJECT  DETAILS \n(1)Century link Technology:- Worked on Predictive and Prescriptive Analytics in Telecom sector.\nKey Models developed using statistical and machine learning knowledge.\nCustomer Churn Modeling :- Models to identify customers with high risk of churn. \nProspects conversion model: -Build Model to identify  prospects with maximum chances of conversion.\nCustomer Segmentation:- Develop Model to identify group and their interests within groups.\nEmployee Retention:- Identify employee who is going to leave organization in near future.\nML methods: Logistic Regression, Decision Tree and Random Forest ,SVM, Bagging and Boosting Techniques.\nAbility to handle Imbalance data.\nCluster Analysis: K-Means, DBSCAN, Hierarchical Clustering and Dendrograms.\nNLP: spaCy, Logistic Regression.\nDimensionality reduction : PCA\n\n\n\n\n(1) Company :    Accenture India\nProject: Insurance Policy Lapse\nInsurance Industry predicting the state of a Life Insurance Policy with a purpose of predicting the lapse state. Focus on target customers and accordingly take actions / precautions. \n\nDevelop model using Decision Tree, Kaplan-Meier estimator(To estimate the time (months) it will take for a policy to Lapse.)\n\n\n\n\n\n(2) Company:  Schneider Electric India\nProject:  GIP(Global Internal Project)\nClient:  Schneider Electric India\t\n\nSentiment Analysis:-For new portal  launch ,Naive-Bayes, NLTK, Python, Scikit-Learn.\n\nTechnology:- java,j2ee,Spring\nProject Overview:  It is internal project for their internal employee. User can get information about internal activities and get mail notification after subscription. \n\n\n\n (3) Company:    Liferay India  Pvt. Ltd.\nClient:   HP(HEWLETT  PACKARD, Tata motor finance, Reliance power)\t\nWorked as product consultant with various companies on portal framework and java/je22 technologies.","annotation":[{"label":["Education"],"points":[{"start":310,"end":312,"text":"MCA"}]},{"label":["Skills"],"points":[{"start":265,"end":277,"text":"Deep Learning"}]},{"label":["Skills"],"points":[{"start":149,"end":164,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":134,"end":145,"text":"Data Science"}]},{"label":["Name"],"points":[{"start":18,"end":28,"text":"Akshy Kumar"}]}],"extras":null,"metadata":{"first_done_at":1532680204000,"last_updated_at":1532680204000,"sec_taken":60,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Amandeep Singh Saini\nS/O Sh. Harbhajan Singh Saini\nVill-Daburji Sham Singh\nP/O-  Dinanagar Distt-Gurdaspur\nPunjab(143531)\nPhone: (M) 09703632800. \nEmail: er.amandeep007@gmail.com. \nDate of birth: 3rd Sep 1989\n\n\n\nObjective\nTo work in a challenging work environment that facilitates growth & learning while being resourceful and flexible.\n\n\nTechnical Proficiencies:\n\nCertification: AWS Developer Associate Certified\n\nDomain: IOT, Telecommunication, Retail.\n\nCore Languages: Java, C++.\n\nPlatform: Windows (XP, 7, 8,10), Linux, Mac OS.\n\nTools:\tEclipse, ASCF,Netbeans, Maven, TOAD,SQL Developer,Titanium studio, XCode.\n\nTechnical Skills:\n\n* Cloud : MicroSoft Azure, AWS , IBM Cloud\n* MDM Tools: Informatica MDM (Siperian MDM) \n* Language Specific: Android, IOS (ipad,iphone).\n* Middlewares: PhoneGap, SFDC, Titanium.\n* Web- based : HTML5, CSS3, JSF, JSP,JPA,Swings, Spring,Hibernate\n* Databases: MYSql, Sqlite3,Oracle11g,Postgres, SQL Server, NoSQL(Cloudant,DocumentDb)\n* Microservices : REST\n\n\n\nWork Experience\t\t\t\t\t\t\t\t         5Yrs 11 Months\n* HCL Technologies Noida( March, 2016 � Till Now)    \no Project:\nIOT-WORKS (Technical Lead)\nWorker Safety\nSolution for safety of worker working in the Mines. I was involved in designing and developing Microservice based solution for worker safety. In this solution data is captured from helmet and send to IBM Cloud. We have built Springboot Microservices and Web application for User interaction and data representation.\nTechnologies involved MicroServices, SpringBoot, Java, IBM Cloud(IOT Watson, CloudantDb, ),  PostgreSQ and .Google Map ApIs\nTrack&Trace\nResponsible for building strategic solution for a US based medical equipment   manufacturer. The objective of this project was to track and trace the medical equipment leveraging cloud technologies. He has performed requirement analysis, solution design, coding and testing during the course of the project.  \nSonoco\nI worked on critical mission project for development and deployment of strategic solution for a manufacturing customer. This project was aimed at maintenance cost reduction by capturing data of the boilers to assess their efficiency. Results of the assessment were then to be considered by the customer for arriving at their strategic decisions. During the course of this project, he has utilized Java (Hibernate and Spring), Java Script and also has employed his sound knowledge and understanding on the offerings provided by Microsoft Azure Cloud (IOT-HUB, Stream Analytics, Cosmos DB, Service Bus, Power BI, Event Hub, Notification Hub, App Service).\nAs a part of the project team, I as performed application systems development tasks which include working with users to define system needs, analysis and revision application design, creation and review of Technical/Functional documents, flowcharts and diagrams creation to illustrate logical use case sequence, translation of logic diagrams into program statements using cloud components, design logical database modeler, automate deployment & build process. Cloud Components, design logical database modeler, automate deployment & build process. \n\n* Amdocs Pvt Ltd Pune ( Aug, 2014 � March, 2016)  \t\t\t\t\t 1Yrs 6 Months\no Project:\n* OMS(Ordering Management System)\nResponsible for enhancing the existing OMS for clients to support the capturing of order from customer till delivered. This enhancement also includes the development of GUI integration with server side implementation. Amdocs OMS is product that is integrated with CRM and Billing to provide complete solution to Telecommunication industry. This Application uses core java, swings and Oracle Database using Amdocs Business Process.\n\n\n\n* Infosys Ltd. Hyderabad ( Feb, 2012 � Jul, 2014 )\t\t\t\t\t 2Yrs 6 Months\n\no Projects: \n* Nordstrom(Customer Rewards Service)\nResponsible for enhancing the existing Customer and Salesperson MDM database for Nordstrom to support new tables, views and functions intended for data from a new source system.  This enhancement also includes development of custom Java web services to support the systems which use master data (Update/Retrive data supporting different types of searches).\n\n* Android Transformer:\nDeveloped an android based application which can convert a picture into text and this text can be translated to any preferred language.  The application has both options either to select the image from the gallery or can be taken from the camera. This application can extensively be used by the tourists, as they can translate any regional text overlaid at the images to their desired language. Technologies used in the Application were PhoneGap, Android, HTML5, Web services and Java.\n\n\n\n* Field Force:\nA native IOS Application designed to cater the requirements of an organization that manages a large no of employees in field while providing door to door services to the client. My role was to prepare a dashboard which can track the location of the employees in field, as well as their work. Technologies used in the application were Objective C, Web Services, Core Data with Sqlite3, and Maps Toolkit. \n\n\n\n\no Training: 6 Months\n\n* In-house training from Infosys - Incorporating refresher courses on C/C++ & RDBMS and extensive domain specific training on fundamentals of Java and Android.\n\n* Developed a web based java application �e-Garage� which could be used as an online garage management tool using JSF.\n\n6 Months Industrial Training:\n\no Interface For Live Streaming:\n The project was an aiding element to the Radio Live Streaming. My role was to create an interface that helps the Radio controllers to watch the status graphically of the live stream the operator can set the values of the streaming parameters to be taken care during streaming.  Alerts are generated in case of any streaming error. Technologies used were Java, and JSP.\n\n\n\n\nEducation\n\n2007 to 2011\tBachelor's in Information Technology       \t                                 74.0%\n\t\t\tBaba Banda Singh Bahadur engineering College, PTU\n\n2006 to 2007 \tClass 12 ( Non-Medical )\t\t\t\t\t        67.0%\n\t\t\tArya Senior Secondary School,Dinanagar\n\n2004 to 2005\tClass 10\t\t\t\t\t\t\t       78.6%\n\t\t\tLittle  Flower  Convent School,Dinanagar\n\n\nAchievements:\n\n* 2015: Awarded one of the good innovators of Amdocs in Hackathon event. \n* 2011: Awarded the 1st prize in the Java in debugging code event in college tech fest Techmanthan-11.\n* 2011: Awarded the 2nd prize in the Java programming event �an eve with java� in a tech fest organized by Rayat institute of engineering and Information Technology, Ropar, Punjab.\n* 2010: Awarded the 2nd prize in the C\\C++ coding event �CodeMad�, in college tech fest Techmanthan-10\n* 2009: Awarded the 1st prize in the algorithm making competition �Go wid Algo�, in college techfest Techmanthan-09\n\n\n\nExtra-Curricular:\n\n* Active Member Football and Cricket team of OMS unit.\n* Active member of a club IMS(�Infy Model School� run by Infosys Hyderabad) which provides education in govt. schools and poor children\n\n* Active member of the Dance Club at Infosys Ltd.\n* Fest Manager of the College Technical Fest �Techmanthan-11� in year 2011.\n\n* Active member of Devnet (the Technical Club of BBSBEC) during the year 2007-11.\n\n* Active member of the Pryas Foundation (a social club run by BBSBEC for teaching slum children and arranging funds for their schooling).\n\n* Event Manager of the HackFest event (Ethical hacking event) organized during 2010 in college.\n\n* Player of college Cricket team during 2008-2011.\n\n\n\nHobbies:\n* Listening to music.\n* Playing Cricket\n\n\n\n\nAmandeep Singh Saini","annotation":[{"label":["Name"],"points":[{"start":7528,"end":7547,"text":"Amandeep Singh Saini"}]},{"label":["Skills"],"points":[{"start":6581,"end":6583,"text":"C++"}]},{"label":["Skills"],"points":[{"start":6398,"end":6401,"text":"Java"}]},{"label":["Skills"],"points":[{"start":6295,"end":6298,"text":"Java"}]},{"label":["Skills"],"points":[{"start":5802,"end":5805,"text":"Java"}]},{"label":["Skills"],"points":[{"start":5245,"end":5248,"text":"Java"}]},{"label":["Skills"],"points":[{"start":5175,"end":5177,"text":"C++"}]},{"label":["Skills"],"points":[{"start":4649,"end":4652,"text":"Java"}]},{"label":["Skills"],"points":[{"start":4020,"end":4023,"text":"Java"}]},{"label":["Skills"],"points":[{"start":2339,"end":2342,"text":"Java"}]},{"label":["Skills"],"points":[{"start":2310,"end":2313,"text":"Java"}]},{"label":["Skills"],"points":[{"start":1515,"end":1523,"text":"IBM Cloud"}]},{"label":["Skills"],"points":[{"start":1509,"end":1512,"text":"Java"}]},{"label":["Skills"],"points":[{"start":1344,"end":1352,"text":"IBM Cloud"}]},{"label":["Location"],"points":[{"start":1057,"end":1061,"text":"Noida"}]},{"label":["Skills"],"points":[{"start":667,"end":675,"text":"IBM Cloud"}]},{"label":["Skills"],"points":[{"start":661,"end":663,"text":"AWS"}]},{"label":["Skills"],"points":[{"start":644,"end":658,"text":"MicroSoft Azure"}]},{"label":["Skills"],"points":[{"start":478,"end":480,"text":"C++"}]},{"label":["Skills"],"points":[{"start":472,"end":475,"text":"Java"}]},{"label":["Skills"],"points":[{"start":380,"end":382,"text":"AWS"}]},{"label":["Name"],"points":[{"start":0,"end":19,"text":"Amandeep Singh Saini"}]}],"extras":null,"metadata":{"first_done_at":1532669241000,"last_updated_at":1532669241000,"sec_taken":107,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "CURRICULUM VITAE\n\n\nAmit Baswa\n\nE-mail:   amitb2050@gmail.com\nPhone:  +91-8080846691\n\t\t\t\t\t\t\t     \n  \n CAREER OBJECTIVES\n* A challenging position in I.T offering responsibility and opportunities for advancement.\n* To come up with new ideas such that work pressure can be minimized.\nCAREER SUMMARY\nOver 5.2 years of experience in Storage and Investment Banking domains, core development in Python and their frameworks along with contributed experience in Machine Learning projects, past experience in ASP.Net, C Sharp and VB script with good exposure on SQL DB�s. Currently working in Bank of America as a Senior Software Engineer on Market Risk Suite (MRS) set of strategic projects. Wish to continue pursuing challenging work in an environment which offers active participation, team oriented tasks, challenges and career opportunity.\nMAJOR ASSIGNMENTS ON PROJECTS\n* Consolidated P&L Risk and Trade (CPRT) Applications (Since Feb 2017): The project scope was to centralize all the Market Risk Suite feed processing structure as per bank regulatory. Although this is a huge framework, the major responsibility was to work on different set of Modules such as extraction of different LOBS feeds from upstream and Recon tools that will help in seamless integration of this Framework in MRS.\nSKILLS USED: Linux, Python, SQLite, Netezza.\n* Position Reconciliation Application (March 2016 � Jan 2017): The project scope was to automate the feed processing and generating the reports for the Reconciliation of Market Risk Suite Positions and Book Level data with that of Front Office Sub Leaguer Report. The core responsibility was to interact with BA�s and user to understand the requirements and deliver the same with-in a stringent time lines.\nSKILLS USED: Python, Netezza, Sybase.\n* Virtual Hierarchy Tool (VHT) Management (Jan 2016 � March 2016): The project scope was to understand the thousands of Books and their Millions of hierarchy management under Risk Market Suite. The major responsibility was to fix issues raise by users and integrate the new feature to make the application more robust and reliable.\nSKILLS USED: Linux, Python, Flask, Netezza, Sybase.\n* ELECOM NAS Cloud Storage Solutions (Oct 2015 � Nov 2015): The project scope involves providing effective and robust product development services that should have capabilities of backing up PCs and Mac computers on your network while simultaneously sharing digital assets, multimedia files and documents. The major responsibility was to work on upcoming modules and features in ELECOM product. Modules that were worked upon are Active Directory Server integration and SSL network integration.\nSKILLS USED: Linux, Python, PyCharm, Django, MySQL, Server specific tools such as Samba, Active Directory, LDAP, etc.\n* VPLEX Escalation Engineering (July 2013 � Sept 2015): The project scope involves providing effective Engineering service to protect and recover vital information from DU/DL outages for all EMC VPLEX customers along with detailed root cause analysis for issues which caused significant business impact to the customers. Development and testing of Automation and Customize Tools for VPLEX product such as FMAR Automation Tool, LDAP UI, etc.\nSKILLS USED: Linux, Python.\n* Plastemart � Android Application (Jan 2013 � March 2013): The objectives of this project are to make mobile application for Plastemart.Com. The task of this application is to provide latest update on Machine products detail, Articles, News from Plastemart.Com live.\nSKILLS USED: Android Studio, Java, HTML, CSS, JS, etc.\n* Mass Mailer (Dec 2012 � Jan 2013): This project was developed to send mass mailing to Plastemart clients.\nSKILLS USED: Visual Studio 2010, C Sharp, ASP.Net, HTML, CSS, JS, etc.\n* Plastemart website Dev & Support (Aug 2012 � Jan 2013): This project is to solve errors occur in coding; add any new features/ Changes to be made in applications.\nSKILLS USED: Visual Studio 2010, C Sharp, ASP.Net, HTML, CSS, JS, etc.\nCONTIBUTION ON PROJECTS\n* Chat-bot application (July 2017 � September 2017): I�ve been worked as a part of core team member in contribution to developing a Chat-bot that will automatically reply to the human messages sent via Skype, email and web portal.\nSKILLS USED: Linux, Python, ML specific libraries such as Natural Language Toolkit (NLTK), Numpy, Pandas, etc.\n* Process Dashboard (May 2017 � June 2017): I was a contributor in this project to consolidate the different processes of applications, SQL�s, etc and show in a single portal to analyze the predictable load time during spikes.\nSKILLS USED: Linux, Python, Pandas, etc.\nWORK EXPERIENCE\n* Currently working as Senior Software Engineer in B A Continuum (Non-banking subsidiary of Bank of America) since Dec 2015. The major responsibility is to understand the Investment Banking domain for various Market Risk Suite management applications. Understand strategic projects from BA�s, work on development and maintenance.\n* Worked as a Senior Software Engineer in IGATE Global Solutions Limited from March 2013 till Sept 2015. The major role was to work on Storage Specific Business Unit for client EMC Corporation on VPLEX product. Development of Automation and customized tools in Python. Check code, find out resolutions, review fixed codes, test and present to the team for awareness.\n* Worked as a Software Developer in Smartech Global Solution Private Limited from Aug 2012 till March 2013. The responsibility was to maintain (Error solving, adding new features, etc.) the existing application/ Websites. Maintenance of plastemart.com, jobs.plastemart.com, plastics-polymers.com. Work on new projects, such as PlastIndia and Grescasa Mass Mailer, Exhibitions websites.\nACHIEVEMENTS\n* Received TWO Gold Award (May 2017 and Aug 2017) from �Bank of America� in appreciation of alone managing the Position Reconciliation and CPRT Recon Tool projects globally, for building trust with BA�s, clients and users of application and building robust application in shortest time span.\n* Received Silver Award (April 2017) from �Bank of America� in appreciation of contribution and being a part of Core team to an initiative called Code@Thon. To successfully complete Process Dashboard Application Phase 2 module by efficiently and effectively managing the underlying team and delivering robust product.\n* Received TWO Gold Award�s (in April 2016 and Sept 2016) from �Bank of America� in appreciation of working smartly and sincerely on QZ - Position Reconciliation & CPDM (Consolidate Positions Data Model). To extremely impress USA Line manager and team mates by dedication and commitment towards taking complete ownership of QZ Position Reconciliation trough the self-learning route. To actively interacting with Risk Data Validation BAs; and understanding the functional aspects of Recons sent to them. For simultaneously executing work on aligned CPDM application as well within a short span. On efforts that have resulted in more strategic work coming our way in CPDM QZ-Re-Engineering.\n* Received IEVOLVE Kaizen (Aug 2015) and Silver Star Award (Jan 2015) from client company �EMC Corporation� in appreciation of taking the responsibility of learning Python, creating the framework of FMAR Automation tool and automating all the checks for the FMAR analysis, which was approximately taking 2 man days to complete, with the help of this tool, now the checks could be completed in 2 hours.\n* Received Pat on the Back Award (Jan 2014) from �IGATE Global Solution Private Ltd� in appreciation of dedication and excellence in fixing the issues and upgrading Watch4Net setup in lab and subsequent knowledge sharing on same topic.\n* Scored 100% in M.S.C.I.T (2008) and declared first in Maharashtra.\nTECHNICAL SKILLS\nOperating Systems\n:\nWindows, Linux\nStorage Domain & Products\n:\nSAN, NAS, RAID Concept, Virtualization, VPLEX, CLARiiON, etc\nScript Knowledge\n:\nPython, VBA\nWeb Technologies\n:\nASP.NET, Flask, Django, HTML, CSS, JavaScript.\nSQL Database\n:\nNetezza, Sybase, SQL Server, MySQL Basic\nNOSQL Database\n:\nMongoDB basics\nProgramming Languages\n:\nCore Java, C#\nEDUCATIONAL QUALIFICATION\nQUALIFICATIONS\nBOARD/ UNIVERSITY\nYEAR OF PASSING\nRESULTS\nB.Sc.I.T\nMumbai University\n2012\n65.00%\nH.S.C\nMaharashtra State Board\n2009\n61.67%\nS.S.C\nMaharashtra State Board\n2007\n72.46%\nADDITIONAL CERTIFICATIONS \n* Information Storage and Management Associate (EMCISA) v2 (Scored 80% marks in year Aug 2015)\n* MS-CIT Course (Scored 100% marks in year 2008).\n* Certificated in Adobe Photoshop, Coral Draw, Page Maker in 2008.\nPERSONAL SKILLS \n* Communication: Ability to deal with Internal and External clients.\n* Problem solving: Resolve client queries to find appropriate resolutions, efficiencies and high level of quality.\n* Planning & Organizing:  Refined planning and organizational skills that balance work, team support and ad-hoc responsibilities in a timely and professional manner.\nSTRENGTHS \n* Positive Thinking Attitude,\n* Punctual,\n* Honest to My Work,\n* Quick Learner.\nPERSONNAL PROFILE DETAILS \n      Date of Birth\n:\n21th  November  1991\n      Gender\n:\nMale\n      Marital Status\n:\nSingle\n      Nationality\n:\nIndian\n      Permanent Address\n:\n14 Shitlaprasad Pandey Chawl, S.S Brahmanwadi, Anand Nagar, Jogeshwari - East, Mumbai, Maharashtra, India - 400060.\nDECLARATION \n       I, Amit Baswa declare that the above information is true and correct to the best of my knowledge and nothing has been concealed or distorted.\n\nYours Sincerely,\nAmit Baswa\n4 | Page","annotation":[{"label":["Name"],"points":[{"start":9467,"end":9477,"text":"Amit Baswa\n"}]},{"label":["Location"],"points":[{"start":9250,"end":9255,"text":"Mumbai"}]},{"label":["Location"],"points":[{"start":8187,"end":8192,"text":"Mumbai"}]},{"label":["Education"],"points":[{"start":7678,"end":7688,"text":" M.S.C.I.T "}]},{"label":["Skills"],"points":[{"start":7188,"end":7194,"text":" Python"}]},{"label":["Skills"],"points":[{"start":5219,"end":5225,"text":" Python"}]},{"label":["Skills"],"points":[{"start":4591,"end":4597,"text":" Python"}]},{"label":["Skills"],"points":[{"start":4253,"end":4259,"text":" Python"}]},{"label":["Skills"],"points":[{"start":3950,"end":3956,"text":"ASP.Net"}]},{"label":["Skills"],"points":[{"start":3940,"end":3947,"text":" C Sharp"}]},{"label":["Skills"],"points":[{"start":3714,"end":3720,"text":"ASP.Net"}]},{"label":["Skills"],"points":[{"start":3704,"end":3711,"text":" C Sharp"}]},{"label":["Skills"],"points":[{"start":3232,"end":3238,"text":" Python"}]},{"label":["Skills"],"points":[{"start":2673,"end":2679,"text":" Python"}]},{"label":["Skills"],"points":[{"start":2127,"end":2133,"text":" Python"}]},{"label":["Skills"],"points":[{"start":1750,"end":1756,"text":" Python"}]},{"label":["Skills"],"points":[{"start":1305,"end":1311,"text":" Python"}]},{"label":["Skills"],"points":[{"start":551,"end":556,"text":"SQL DB"}]},{"label":["Skills"],"points":[{"start":519,"end":527,"text":"VB script"}]},{"label":["Skills"],"points":[{"start":506,"end":513,"text":" C Sharp"}]},{"label":["Skills"],"points":[{"start":498,"end":504,"text":"ASP.Net"}]},{"label":["Skills"],"points":[{"start":452,"end":468,"text":"Machine Learning "}]},{"label":["Skills"],"points":[{"start":386,"end":392,"text":" Python"}]},{"label":["Name"],"points":[{"start":19,"end":29,"text":"Amit Baswa\n"}]}],"extras":null,"metadata":{"first_done_at":1532692049000,"last_updated_at":1532692049000,"sec_taken":77,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Amit Kumar\n                                    E-mail: timacs12@gmail.com \n                                    Mobile No.: +91 9163057166\n\n\n\nSummary \n\n\n* 5 years and 7 months of experience in JAVA/J2EE/IBM Cloud application development.\n* Oracle Certified Associate Java 8 Programmer.\n* IBM certified Cloud Application Developer\n* Experience in developing microservice using IBM cloud platform Bluemix.\n* Experienced in software development in Web application,Mobile Application.\n* Gained valuable exposure during developing application, conducting testing.\n* Gained valuable exposure while interfacing with client and working under stipulated timeframe. \n* Acquired valuable knowledge and understanding of the following subjects:\n1. Core Java, Collections frameworks, OOAD and Design patterns, Servlet .\n2. Restful(JAX-RS) Webservices.\n3. Kafka,ElasticSearch,Single Sign On,JWT,No Sql DB\n4. Real time usages and implementation of J2EE,Struts,Hibernate, Data Structures and Algorithms.\n5. Client side technology such as Angular JS,Node JS ,JSP and Javascript\n6. Familiar with Web and Application servers like Websphere  and Apache tomcat.\n7. Practiced Waterfall and Agile/Scrum development methodologies..\n* A through professional with strong academic foundation backed by acumen and zeal to excel in the software development.\n* Possess analytical bent of mind to grasp new concepts easily and quickly.\n\nTechnical Skills:\n\n* Core Java, Collection framework,JDBC, Data Structures and Algorithms, Design Patterns, OOAD concepts.\n* IBM cloud platform Bluemix.\n* Kafka,ElasticSearch,SSO\n* Apache,Websphere,RAD,Eclipse,Jenkins\n* JSP,Struts,Servlet,Hibernate JUnit,.\n* SQL, Maven,Log4j\n\nWeb Services\nRestful (JAX-RS)\nORM tool\nHibernate,JPA\nWeb / Application Servers\nWebsphere,  Apache/Tomcat\nDatabase\nOracle ,DB2, Cloudant No Sql DB\nTools\nEclipse, RAD, SQL Developer,Jenkins\n\nEducational Qualification :\n\nB.Tech\n(Graduation)\nComputer Science & Engineering,\nFrom Cochin University Of Science and Technology, Kochi, Kerala. with 79%.\n\nAwards and Recognition :\n* Received recognition  �TCS  KUDOS� award .\n* One of the best performer of the year (IBM).\n* Manager Choice Award (IBM).\n* IBM Certified Application Developer Cloud Platform V1.\n* Oracle Certified associate, Java SE 8 Programmer.\n\nWork Experience\n\nIBM India Pvt Ltd (November 2014 � Present)\nDesignation: Application Developer Cloud.Java\n\n* Worked on microservice deveploment using IBM cloud platform bluemix.\n* Designed and developed Rest webservice using java,jpa,db2.\n* Build and deploy project in development environment and release coordination for other upper environments.\n* Implemented Single sign on using identity provider okta.\n* Implemented the application framework using factory and singleton design patterns.\n* Implemented modules using core java api�s , java collection , xml and integrating the modules.\n* Used Redis as a high speed cache.\n* Used Jira,RTC for defect management.\n* Used Log4j to generate system information and debug messages.\n* Used Junit for unit testing.\n* Created xml configuration file for database connectivity.\n* Worked on developing data models by configuring hibernate persistence layer, mapping java classes with database using hibernate/hibernate query language(hql).\n* Participated in design and code review.\n* Interact with other team members to incorporate their innovations and vice versa.\n* Worked for different clients like jabil,uk post office,cocacola,g&k services and psai.\n  \n      \n\n\nTata Consultancy Services Pvt Ltd (July 2012  � November 2014)\nDesignation: System Engineer \n\n* Developed business components in java/java ee  and involved in various phase of software development life cycle.\n* Used eclipse for creating required classes and xml.\n* Used Jira,RTC for defect management.\n* Used Log4j to generate system information and debug messages.\n* Used Junit for unit testing.\n* Implemented the application framework using factory and singleton design patterns.\n* Designed and developed several servlets and hibernate components.\n* Implemented modules using core java api�s , java collection , xml and integrating the modules.\n* Used hibernate to store the persistence data into the database and wrote hql to access the data from db.\n* Interact with other team members to incorporate their innovations and vice versa.\n* Worked for Citibank client.\n\n  \n      \n\n\n\n\n       \n    \n       \n\t\t\t\t\t\t\t\t                           \n\n\n\t\t   Amit Kumar\n\n\n\n2","annotation":[{"label":["Name"],"points":[{"start":4439,"end":4448,"text":"Amit Kumar"}]},{"label":["Education"],"points":[{"start":1899,"end":1904,"text":"B.Tech"}]},{"label":["Skills"],"points":[{"start":1861,"end":1867,"text":"Jenkins"}]},{"label":["Skills"],"points":[{"start":1842,"end":1844,"text":"RAD"}]},{"label":["Skills"],"points":[{"start":1833,"end":1839,"text":"Eclipse"}]},{"label":["Skills"],"points":[{"start":1772,"end":1777,"text":"Apache"}]},{"label":["Skills"],"points":[{"start":1760,"end":1768,"text":"Websphere"}]},{"label":["Skills"],"points":[{"start":1614,"end":1620,"text":"Jenkins"}]},{"label":["Skills"],"points":[{"start":1606,"end":1612,"text":"Eclipse"}]},{"label":["Skills"],"points":[{"start":1602,"end":1604,"text":"RAD"}]},{"label":["Skills"],"points":[{"start":1592,"end":1600,"text":"Websphere"}]},{"label":["Skills"],"points":[{"start":1585,"end":1590,"text":"Apache"}]},{"label":["Skills"],"points":[{"start":1124,"end":1129,"text":"Apache"}]},{"label":["Skills"],"points":[{"start":1109,"end":1117,"text":"Websphere"}]},{"label":["Skills"],"points":[{"start":193,"end":210,"text":"AVA/J2EE/IBM Cloud"}]},{"label":["Name"],"points":[{"start":0,"end":9,"text":"Amit Kumar"}]}],"extras":null,"metadata":{"first_done_at":1532680142000,"last_updated_at":1532680142000,"sec_taken":92,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Ankita Mahasaheb\nData Scientist\nMobile No.: 9880244437/9421274688\nE-Mail:ankitamahasaheb@ymail.com\n\n\nTo be a part of a firm offering opportunity for career advancement and Professional growth. \nPython: 4/5\nR: 3/5 \nMachine Learning: 3/5 \nNP: Immediately\n\n\nSynopsis\n\n\nChemical Engineer by education, data scientist by training, and a highly numerate individual, maneuvered the career into data science with passion and interest in data driven analysis and decision making. Always curious to learn new things. Adept at converting a business/technical problem into data science problem.\nRich exposure in�Consultancy and Technical Service Department & had worked on Chemical, Petrochemical & Oil-gas facilities projects. Assisted in preparation of Basic Engineering Package involving P&ID, PFD for� Equipment, hydraulic calculation such as line sizing, control valve sizing, Pump hydraulics, PSV sizing, involved in troubleshooting, technical services & operation, Process Simulation for basic operations using ASPEN+ / UNISIM / H.T.R.I.\n\nExperience\n\nGE, Bengaluru�August 2013 � Till date\n> M&D Migration: Lead a team to create the Migration Dashboard to track the real-time migration efforts. Developed automated validation process to compare the results. Assisted in creating the analytic framework.\n> Production Ready Analytics: Refactored power analytics and made it production ready. Automated this process for new analytics.\n> Analytic Catalogue Predix: As part of 6-member team, refactored 220+ predictive and prognostic analytics to monitor and diagnose faults and failures in GE Power equipment\n> Smart Signal for Reliance: Got in-house/on-job training on SmartSignals and assisted in retuning few units for Reliance and maintained the predictive alarming capabilty.\n> Gasification:Worked on Gasification Process Design Package(PDP) execution. Activities involved were Critical Equipment sizing(Syngas Scrubber),Tanks,PumpsVessels,Heat Exchanger PDS, P&ID and line sizing. Received an ERD Award for one of the Project for customer fullfilment. \n\nJacobs Engineering Pvt. Ltd, Mumbai�March 2011 - August 2013\n> Exxon Mobil:Worked as a process engineer on Rotterdam Aromatics plant. Activities involved were Line list, Control Valve calculation, preparation of Instrument/CV datasheet, Equipment datasheet, Tie-in list.\n> DuPont: Worked as a process engineer for DuPont Project. Activities involved were PFDs, P&ID development, Management of change on P&ID,�line list, IPDS and preparation of Pressure Relief Device packages.\n> BP��ETP�UPGRADE PROJECT:�Worked as a process engineer for�ETP�Upgrade. Activities involved were Updation of PFDs, P&IDs, Line list,�PDS, IPDS, Line sizing calculation & Control valve calculation.\n> �BP�CARSON: �Worked as a process engineer for BP Carson Concern Validation Report preparation for Pressure relief system.\n\nDeepak Nitrite. Ltd, Corporate Office, Pune�1st Sept 2010 � 11th March 2011\n> HYDROGENATION OF ORTHO NITRO TOLUENE:�Worked as a process engineer for Hydrogenation of�ONT, Plant Capacity 30 TPD. Activities involved were Preparation of PFDs, P&IDs, Equipment list, Line list, Instrument List,�PDS, IPDS, Line sizing calculation etc.\n> �STEAM REFORMING OF NATURAL�GAS�TO PRODUCE HYDROGEN:Worked as a process engineer for Hydrogen Production, Plant Capacity 1560 Nm3/hr. Activities involved were Preparation of PFDs, Equipment list, Instrument List etc.\n\nAcademia\n\n* B.Tech. (Chemical) from Vishwakarma Institute of Technology, Pune,Pune University, in 2010. Secured 81%\n* 12thfrom Saraswati Bhuvhan College,Aurangabad, in 2006. Secured 83.17%\n* 10thfrom Ideal English School, Beed, Maharashtra State Board in 2004. Secured 83.47%\n\n* Other Details:\n* Diploma in Process Engineering Design from Maharashtra Institute of Technology, Pune in 2011.\n* Academic Projects Crude Oil Distillation, Manufacturing Dextrin, Hydrogenation of Aromatic Compounds\n\t\t\nEnvironment & Skills (Blend of Data Science and Domain Expertise)\n\n* Programming- Python, R, Matlab\n* Others- SmartSignals, Scrum, Statistics, Machine Learning,Timeseries Data analysis and cleaning, H.T.R.I,  HYSIS, Aspen+, AutoCAD\n\nPersonal Dossier\n\nDate of Birth\t\t\t:\t\t\t\t\t\t9th November, 1988\nLanguages Known\t\t:\t\t\t\t\t\tEnglish, Hindi and Marathi\nPresent address\t\t:\t\t\t\t\t\tSwavalambi, Nagar, Nagpur � 440022 (MH)\t\nPermanent address\t:\t\t\t\t\t\tShri Swami Samarth Nagar, Georai, Dist � Beed,431127 (MH)\t\nVisa                           :\t\t\t\t        B1 Visa holder","annotation":[{"label":["Location"],"points":[{"start":4372,"end":4375,"text":"Beed"}]},{"label":["Skills"],"points":[{"start":4100,"end":4100,"text":"R"}]},{"label":["Skills"],"points":[{"start":4040,"end":4055,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":3990,"end":3995,"text":"Matlab"}]},{"label":["Skills"],"points":[{"start":3987,"end":3987,"text":"R"}]},{"label":["Skills"],"points":[{"start":3979,"end":3984,"text":"Python"}]},{"label":["Location"],"points":[{"start":3623,"end":3626,"text":"Beed"}]},{"label":["Skills"],"points":[{"start":3229,"end":3229,"text":"R"}]},{"label":["Skills"],"points":[{"start":3219,"end":3219,"text":"R"}]},{"label":["Skills"],"points":[{"start":3207,"end":3207,"text":"R"}]},{"label":["Skills"],"points":[{"start":3194,"end":3194,"text":"R"}]},{"label":["Skills"],"points":[{"start":3190,"end":3190,"text":"R"}]},{"label":["Skills"],"points":[{"start":2954,"end":2954,"text":"R"}]},{"label":["Skills"],"points":[{"start":2946,"end":2946,"text":"R"}]},{"label":["Skills"],"points":[{"start":2931,"end":2931,"text":"R"}]},{"label":["Skills"],"points":[{"start":2802,"end":2802,"text":"R"}]},{"label":["Skills"],"points":[{"start":2733,"end":2733,"text":"R"}]},{"label":["Skills"],"points":[{"start":2546,"end":2546,"text":"R"}]},{"label":["Skills"],"points":[{"start":2540,"end":2540,"text":"R"}]},{"label":["Skills"],"points":[{"start":2503,"end":2503,"text":"R"}]},{"label":["Skills"],"points":[{"start":2157,"end":2157,"text":"R"}]},{"label":["Skills"],"points":[{"start":1990,"end":1990,"text":"R"}]},{"label":["Skills"],"points":[{"start":1977,"end":1977,"text":"R"}]},{"label":["Skills"],"points":[{"start":1712,"end":1712,"text":"R"}]},{"label":["Skills"],"points":[{"start":1618,"end":1618,"text":"R"}]},{"label":["Skills"],"points":[{"start":1327,"end":1327,"text":"R"}]},{"label":["Skills"],"points":[{"start":1310,"end":1310,"text":"R"}]},{"label":["Skills"],"points":[{"start":1028,"end":1028,"text":"R"}]},{"label":["Skills"],"points":[{"start":583,"end":583,"text":"R"}]},{"label":["Skills"],"points":[{"start":214,"end":229,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":206,"end":206,"text":"R"}]},{"label":["Skills"],"points":[{"start":194,"end":199,"text":"Python"}]},{"label":["Name"],"points":[{"start":0,"end":15,"text":"Ankita Mahasaheb"}]}],"extras":null,"metadata":{"first_done_at":1532666380000,"last_updated_at":1532666380000,"sec_taken":0,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Udaya Laxmi Ch\n\nEmail : laxmi.udaya@gmail.com\n\n\t\n\n\tPhone: -9740606990\n\t\n\n\n\tSummary\n\n\t· 9.5 years of experience in Software Development.\n· 3.5 years of experience in Machine Learning\n· Primary Skills – Machine Learning, R programming, Lotus Notes.\n· Presently working for Wipro Technologies, Bangalore.\n· Experience in planning, estimation, design, development, and testing object oriented applications.\n· Experience in preparing various technical documents like Functional Specs, HLD, LLD, Flowcharts and Test cases.\n· Sound Knowledge in Object Oriented Design Principles\n· Have Team Handling experience.\n· Domain experience of Manufacturing and Finance.\n· Have Experience in Scrum Agile Model\n· Understand business requirements from clients\n\n\n\n\tTechnical Skills\n\n\tKey skills: \n\tMachine Learning,R Programming, MySQL, PostgreSQL, Microsoft Access, SQL Server, FileMaker, Oracle, RDBMS, dBASE, Clipper, FoxPro, Firebase, Mongodb, Python,  ava, J2EE, Oracle Fusion,Oracle Cloud, Salesforce, Devops Android, Business Analyst, UI Developer, DBAs, Embedded Systems, .NET, Hadoop, SQL Developer, Big Data, Tableau, Networking, Etl, Informatica, Ios, Quality Analyst, Project Manager, Python, Data Science, Python, Machine Learning, SAS, Java, Scala, Hadoop, Hive, Bigdata, Programming, SQL server reporting, Msbi Ssis, Ssrs, Msbi, Sql Reporting, Artificial Intelligence, Pandas, Pyspark, Sklearn, Flask, Django, Map Reduce, Parametric Design, Modeling, Regression, Patterns, Data Mining, Text Mining, Oops, Deep Learning, Web Analytics, Time Series, Regression, Tensorflow, Azure, Linear Regression, Logistic Regression, Decision Tree, Random Forest, Data Structure, Computer Vision, IHS, WAS, Java EE, SQL Server, .NET core, C#, ASP.NET, Rdlc, Linq, Sql, Web Api, Mvc, Javascript, Web Services, Oracle, MS SQL, PHP, Laravel, CodeIgniter, Symfony, Zend, Phalcon, CakePHP, Yii, FuelPHP, React, Vue, Angular, Ember, Backbone, Lotus Notes\n\n\tAlgorithms:\n\tNaïve Bayes, K means clustering,Word Cloud\n\n\tDatabases: \n\tMicrosoft SQL, Mongo DB\n\n\tWeb Technologies: \n\tXML, XSLT, HTML,  JavaScript,  AJAX, JQuery\n\n\tIDE:\n\tR studio,Pycharm\n\n\n\tProfessional Experience\n\n\tCurrent Employer :\n\tWipro Technologies., Bangalore  – (Oct  2010  to till date) – Technical Lead/Data Scientist\n\n\tPrevious Employers :\n\tHSBC Software development , Hyderabad (June  2008  to Sep 2010)  - SE\n\n\n\tQualification\n\n\tDegree\n\tCollege\n\tUniversity/Board\n\tYear\n\tPercentage (%)\n\n\tMCA\n\tNizam College, Basheerbagh,Hyderabad\n\tOsmania University\n\t2008\n\t75\n\n\n\tProject Experience \n\n\tProject 1 : Exploratory Data Analysis:\n\nProject Description:   Performed EDA analysis to analyze the Purchase frequency of vehicles which occurred over past 3 years and try to predict the frequency occurring in the future.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Performed EDA analysis to find the insights of the data. Observed the summary of each and every variable to understand the variables.\n\n· Performed the feature selection using hypothesis testing.\n\n· Identified the outliers using box plot.\n\n· Identified the trend in the purchases using histogram.\n\n\n\n\tProject 2: Word Cloud Analysis:\n\nProject Description:   Performed Word cloud and Sentimental Analysis of the customer feedbacks. Graphically represented the most frequently occurred words through Word cloud. Through sentimental analysis we identified whether a user-generated text expresses positive, negative or neutral opinion.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Created a Corpus using TM package and performed pre-processing of data.\n\n· Removed the punctuations, stemming and stop words which are of no analytical value.\n\n· Built a Document term matrix and identified the most frequently occurring words\n\n· Graphically represented it using  RColorbrewer Package\n\n\n\tProject 3: Sentimental Analysis:\n\nProject Description: Performed Sentimental Analysis of customer feedbacks through Naïve Bayes. Used “e1071” Package for implementing naïve Bayes method.\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· The DTM created using TM package was an input to the Naive Bayes Model.\n\n· As Naive Bayes classifier is typically trained on data with categorical features. We have converted the count of the words into a factor variable that indicates Yes or No whether the word is present or not.\n\n\tProject 4: Clustering Analysis:\n\nProject Description: Classified the customers on the basis of their purchases whether they have purchased low variant or high variant trucks. It in turn helped in building the right customer strategies.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Performed data preparation and Normalization of data using min-max method.\n\n· As K-means algorithm groups a dataset into a user-specified number (k) of clusters. Identified the initial cluster centroids as 3.\n\n· K clusters are creating by associating every observation with the nearest mean.\n\n· Used elbow method to validate the number of clusters such that within-cluster sum of square(wss) is minimized.\n\n\n\n\tProject 5 : Inter Connection Management Tool\nProject Description: Inter-connection Management (IMT) is prototype being developed for Engineering and Sales department to handle customizations of an existing product based on the customer's requirement. Users from engineering department will identify the items, which need to be customized out of the entire product design.\nRole\n\n       : Module Lead\n\nEnvironment\n       : Python, Mongo DB, jQuery\n\nTasks handled:\n\n· Gathering Requirements and providing Project Plan and Effort Estimation details.\n\n· Understanding business requirements and preparing SoU (Statement of Understanding) and Functional/Technical Specification documents.\n\n· Providing Effort & Resource estimations\n\n· Planning for application development and deployment\n\n· Writing and executing Test Cases and Test scenarios\n\n· Creating design elements using Technical Specification.\n\n· Performing Unit testing & Peer Reviews\n\n· Work Allocation and mentoring the team\n\n· Providing Technical guidance to the team. \n\n\tProject 6\n: cvdAEI Application\n\nProject Description\n     : CVDAEI is a web based multilingual application developed for handling the Change Management process in Truck division of Daimler. The change request flows through different phases mainly Initialization, Evaluation, Decision and Conclusion. This application has a configurable workflow where the request flow and the responsible persons can be configured easily at any point of time. \n\nRole\n\n    : Developer/Tester\n\nEnvironment\n     : Lotus Notes, Java, HTML, XML, Java Script, JQuery\n\nTasks handled:\n\n· Gathering Requirements and providing Project Plan and Effort Estimation details.\n\n· Understanding business requirements and preparing SoU (Statement of Understanding) and Functional/Technical Specification documents.\n\n· Providing Effort & Resource estimations\n\n· Planning for application development and deployment\n\n· Writing and executing Test Cases and Test scenarios\n\n· Creating design elements using Technical Specification.\n\n· Performing Unit testing & Peer Reviews\n\n· Work Allocation and mentoring the team\n\n· Providing Technical guidance to the team. \n\n\n\n\tProject Title: Project Management Office \nProject Description: The purpose of this system is to enable the Project Management Office to manage and execute the IT Applications and Operations driven project tasks in  more systematic manner. It will also enable them to efficiently perform a role as a facilitator to coordinate various IT Operations teams and to ensure that project activity enters the department through one common interface. The project tasks will subsequently be dealt with in a common format and in a consistent and appropriate manner, ensuring open and regular communication between all involved parties.\n\nRole\n\n    : Developer/Tester\n\nEnvironment\n     : Lotus Notes, Java, HTML, XML, Java Script, JQuery\n\nTasks Handled :\n\n· Writing and Executing Test cases in client server based environment\n· Individually provided application support","annotation":[{"label":["Skills"],"points":[{"start":7951,"end":7956,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":7938,"end":7948,"text":"Java Script"}]},{"label":["Skills"],"points":[{"start":7933,"end":7935,"text":"XML"}]},{"label":["Skills"],"points":[{"start":7927,"end":7930,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":7921,"end":7924,"text":"Java"}]},{"label":["Skills"],"points":[{"start":7908,"end":7918,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":6645,"end":6650,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":6632,"end":6642,"text":"Java Script"}]},{"label":["Skills"],"points":[{"start":6627,"end":6629,"text":"XML"}]},{"label":["Skills"],"points":[{"start":6621,"end":6624,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":6615,"end":6618,"text":"Java"}]},{"label":["Skills"],"points":[{"start":6602,"end":6612,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":5522,"end":5527,"text":"jQuery"}]},{"label":["Skills"],"points":[{"start":5512,"end":5519,"text":"Mongo DB"}]},{"label":["Skills"],"points":[{"start":5504,"end":5509,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4645,"end":4652,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":4054,"end":4061,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":3941,"end":3951,"text":"Naïve Bayes"}]},{"label":["Skills"],"points":[{"start":3494,"end":3501,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":3132,"end":3141,"text":"Word Cloud"}]},{"label":["Skills"],"points":[{"start":2793,"end":2800,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":2110,"end":2116,"text":"Pycharm"}]},{"label":["Skills"],"points":[{"start":2101,"end":2108,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":2086,"end":2091,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":2080,"end":2083,"text":"AJAX"}]},{"label":["Skills"],"points":[{"start":2067,"end":2076,"text":"JavaScript"}]},{"label":["Skills"],"points":[{"start":2060,"end":2063,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":2054,"end":2057,"text":"XSLT"}]},{"label":["Skills"],"points":[{"start":2049,"end":2051,"text":"XML"}]},{"label":["Skills"],"points":[{"start":2018,"end":2025,"text":"Mongo DB"}]},{"label":["Skills"],"points":[{"start":2003,"end":2015,"text":"Microsoft SQL"}]},{"label":["Skills"],"points":[{"start":1977,"end":1986,"text":"Word Cloud"}]},{"label":["Skills"],"points":[{"start":1958,"end":1975,"text":"K means clustering"}]},{"label":["Skills"],"points":[{"start":1945,"end":1955,"text":"Naïve Bayes"}]},{"label":["Skills"],"points":[{"start":1918,"end":1928,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":1908,"end":1915,"text":"Backbone"}]},{"label":["Skills"],"points":[{"start":1901,"end":1905,"text":"Ember"}]},{"label":["Skills"],"points":[{"start":1892,"end":1898,"text":"Angular"}]},{"label":["Skills"],"points":[{"start":1887,"end":1889,"text":"Vue"}]},{"label":["Skills"],"points":[{"start":1880,"end":1884,"text":"React"}]},{"label":["Skills"],"points":[{"start":1871,"end":1877,"text":"FuelPHP"}]},{"label":["Skills"],"points":[{"start":1866,"end":1868,"text":"Yii"}]},{"label":["Skills"],"points":[{"start":1857,"end":1863,"text":"CakePHP"}]},{"label":["Skills"],"points":[{"start":1848,"end":1854,"text":"Phalcon"}]},{"label":["Skills"],"points":[{"start":1842,"end":1845,"text":"Zend"}]},{"label":["Skills"],"points":[{"start":1833,"end":1839,"text":"Symfony"}]},{"label":["Skills"],"points":[{"start":1820,"end":1830,"text":"CodeIgniter"}]},{"label":["Skills"],"points":[{"start":1811,"end":1817,"text":"Laravel"}]},{"label":["Skills"],"points":[{"start":1806,"end":1808,"text":"PHP"}]},{"label":["Skills"],"points":[{"start":1798,"end":1803,"text":"MS SQL"}]},{"label":["Skills"],"points":[{"start":1790,"end":1795,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":1776,"end":1787,"text":"Web Services"}]},{"label":["Skills"],"points":[{"start":1764,"end":1773,"text":"Javascript"}]},{"label":["Skills"],"points":[{"start":1759,"end":1761,"text":"Mvc"}]},{"label":["Skills"],"points":[{"start":1750,"end":1756,"text":"Web Api"}]},{"label":["Skills"],"points":[{"start":1745,"end":1747,"text":"Sql"}]},{"label":["Skills"],"points":[{"start":1739,"end":1742,"text":"Linq"}]},{"label":["Skills"],"points":[{"start":1733,"end":1736,"text":"Rdlc"}]},{"label":["Skills"],"points":[{"start":1724,"end":1730,"text":"ASP.NET"}]},{"label":["Skills"],"points":[{"start":1720,"end":1721,"text":"C#"}]},{"label":["Skills"],"points":[{"start":1709,"end":1717,"text":".NET core"}]},{"label":["Skills"],"points":[{"start":1697,"end":1706,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":1688,"end":1694,"text":"Java EE"}]},{"label":["Skills"],"points":[{"start":1683,"end":1685,"text":"WAS"}]},{"label":["Skills"],"points":[{"start":1678,"end":1680,"text":"IHS"}]},{"label":["Skills"],"points":[{"start":1661,"end":1675,"text":"Computer Vision"}]},{"label":["Skills"],"points":[{"start":1645,"end":1658,"text":"Data Structure"}]},{"label":["Skills"],"points":[{"start":1630,"end":1642,"text":"Random Forest"}]},{"label":["Skills"],"points":[{"start":1615,"end":1627,"text":"Decision Tree"}]},{"label":["Skills"],"points":[{"start":1594,"end":1612,"text":"Logistic Regression"}]},{"label":["Skills"],"points":[{"start":1575,"end":1591,"text":"Linear Regression"}]},{"label":["Skills"],"points":[{"start":1568,"end":1572,"text":"Azure"}]},{"label":["Skills"],"points":[{"start":1556,"end":1565,"text":"Tensorflow"}]},{"label":["Skills"],"points":[{"start":1544,"end":1553,"text":"Regression"}]},{"label":["Skills"],"points":[{"start":1531,"end":1541,"text":"Time Series"}]},{"label":["Skills"],"points":[{"start":1516,"end":1528,"text":"Web Analytics"}]},{"label":["Skills"],"points":[{"start":1501,"end":1513,"text":"Deep Learning"}]},{"label":["Skills"],"points":[{"start":1495,"end":1498,"text":"Oops"}]},{"label":["Skills"],"points":[{"start":1482,"end":1492,"text":"Text Mining"}]},{"label":["Skills"],"points":[{"start":1469,"end":1479,"text":"Data Mining"}]},{"label":["Skills"],"points":[{"start":1459,"end":1466,"text":"Patterns"}]},{"label":["Skills"],"points":[{"start":1447,"end":1456,"text":"Regression"}]},{"label":["Skills"],"points":[{"start":1437,"end":1444,"text":"Modeling"}]},{"label":["Skills"],"points":[{"start":1418,"end":1434,"text":"Parametric Design"}]},{"label":["Skills"],"points":[{"start":1406,"end":1415,"text":"Map Reduce"}]},{"label":["Skills"],"points":[{"start":1398,"end":1403,"text":"Django"}]},{"label":["Skills"],"points":[{"start":1391,"end":1395,"text":"Flask"}]},{"label":["Skills"],"points":[{"start":1382,"end":1388,"text":"Sklearn"}]},{"label":["Skills"],"points":[{"start":1373,"end":1379,"text":"Pyspark"}]},{"label":["Skills"],"points":[{"start":1365,"end":1370,"text":"Pandas"}]},{"label":["Skills"],"points":[{"start":1340,"end":1362,"text":"Artificial Intelligence"}]},{"label":["Skills"],"points":[{"start":1325,"end":1337,"text":"Sql Reporting"}]},{"label":["Skills"],"points":[{"start":1325,"end":1327,"text":"Sql"}]},{"label":["Skills"],"points":[{"start":1319,"end":1322,"text":"Msbi"}]},{"label":["Skills"],"points":[{"start":1313,"end":1316,"text":"Ssrs"}]},{"label":["Skills"],"points":[{"start":1302,"end":1310,"text":"Msbi Ssis"}]},{"label":["Skills"],"points":[{"start":1302,"end":1305,"text":"Msbi"}]},{"label":["Skills"],"points":[{"start":1280,"end":1299,"text":"SQL server reporting"}]},{"label":["Skills"],"points":[{"start":1267,"end":1277,"text":"Programming"}]},{"label":["Skills"],"points":[{"start":1258,"end":1264,"text":"Bigdata"}]},{"label":["Skills"],"points":[{"start":1252,"end":1255,"text":"Hive"}]},{"label":["Skills"],"points":[{"start":1244,"end":1249,"text":"Hadoop"}]},{"label":["Skills"],"points":[{"start":1237,"end":1241,"text":"Scala"}]},{"label":["Skills"],"points":[{"start":1231,"end":1234,"text":"Java"}]},{"label":["Skills"],"points":[{"start":1226,"end":1228,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1208,"end":1223,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1200,"end":1205,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1186,"end":1197,"text":"Data Science"}]},{"label":["Skills"],"points":[{"start":1178,"end":1183,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1161,"end":1175,"text":"Project Manager"}]},{"label":["Skills"],"points":[{"start":1144,"end":1158,"text":"Quality Analyst"}]},{"label":["Skills"],"points":[{"start":1139,"end":1141,"text":"Ios"}]},{"label":["Skills"],"points":[{"start":1126,"end":1136,"text":"Informatica"}]},{"label":["Skills"],"points":[{"start":1121,"end":1123,"text":"Etl"}]},{"label":["Skills"],"points":[{"start":1109,"end":1118,"text":"Networking"}]},{"label":["Skills"],"points":[{"start":1100,"end":1106,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":1090,"end":1097,"text":"Big Data"}]},{"label":["Skills"],"points":[{"start":1075,"end":1087,"text":"SQL Developer"}]},{"label":["Skills"],"points":[{"start":1067,"end":1072,"text":"Hadoop"}]},{"label":["Skills"],"points":[{"start":1061,"end":1064,"text":".NET"}]},{"label":["Skills"],"points":[{"start":1043,"end":1058,"text":"Embedded Systems"}]},{"label":["Skills"],"points":[{"start":1037,"end":1040,"text":"DBAs"}]},{"label":["Skills"],"points":[{"start":1023,"end":1034,"text":"UI Developer"}]},{"label":["Skills"],"points":[{"start":1005,"end":1020,"text":"Business Analyst"}]},{"label":["Skills"],"points":[{"start":989,"end":1002,"text":"Devops Android"}]},{"label":["Skills"],"points":[{"start":977,"end":986,"text":"Salesforce"}]},{"label":["Skills"],"points":[{"start":963,"end":974,"text":"Oracle Cloud"}]},{"label":["Skills"],"points":[{"start":949,"end":961,"text":"Oracle Fusion"}]},{"label":["Skills"],"points":[{"start":943,"end":946,"text":"J2EE"}]},{"label":["Skills"],"points":[{"start":929,"end":934,"text":"Python"}]},{"label":["Skills"],"points":[{"start":920,"end":926,"text":"Mongodb"}]},{"label":["Skills"],"points":[{"start":910,"end":917,"text":"Firebase"}]},{"label":["Skills"],"points":[{"start":902,"end":907,"text":"FoxPro"}]},{"label":["Skills"],"points":[{"start":893,"end":899,"text":"Clipper"}]},{"label":["Skills"],"points":[{"start":886,"end":890,"text":"dBASE"}]},{"label":["Skills"],"points":[{"start":879,"end":883,"text":"RDBMS"}]},{"label":["Skills"],"points":[{"start":871,"end":876,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":860,"end":868,"text":"FileMaker"}]},{"label":["Skills"],"points":[{"start":848,"end":857,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":830,"end":845,"text":"Microsoft Access"}]},{"label":["Skills"],"points":[{"start":818,"end":827,"text":"PostgreSQL"}]},{"label":["Skills"],"points":[{"start":811,"end":815,"text":"MySQL"}]},{"label":["Skills"],"points":[{"start":798,"end":808,"text":"Programming"}]},{"label":["Skills"],"points":[{"start":796,"end":808,"text":"R Programming"}]},{"label":["Skills"],"points":[{"start":779,"end":794,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":234,"end":244,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":219,"end":231,"text":"R programming"}]},{"label":["Skills"],"points":[{"start":201,"end":216,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":165,"end":180,"text":"Machine Learning"}]},{"label":["Name"],"points":[{"start":0,"end":13,"text":"Udaya Laxmi Ch"}]}],"extras":null,"metadata":{"first_done_at":1579625576000,"last_updated_at":1579626369000,"sec_taken":0,"last_updated_by":"aJOmJy1lvpOYFetVNuqLvFo9Vx42","status":"done","evaluation":"NONE"}}
{"content": "Aravinda U.S\n\n\n\n\nSummary\n\n\n\n\n\n\nEducation\n\n\nTechnical Skills\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExperience\n\nSourcebits Pvt.Ltd(Dec 30th 2015 - Mar-2017)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAchumen Technologies Pvt.Ltd(Nov 5th 2012 �)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSaaranga Infotech LLP (15th November 2010 � 7th October -2012)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNyku Systems : Feb-2009-July-2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrainings Taken\n\n\n\n\n\n\n\n\n\n\n\nPersonal Details\n\nAssociate Technical Lead \n#72,�Mandara�,3rd Cross, 6th Main, 1st Block, Narayana  Nagar ,Bengaluru-560062 \narvind.aithal@gmail.com\n(+91)9901835835\nOverall 7.7 Years of IT Experience in Opensource Frontend Web Application Development, Integration and Deployment  in Linux servers.Working experience under integration of  Business Intelligence tool, CMS website integration, Application Deployment  in Cloud, Dedicated and Shared Servers. \n\nB.E. in computer Science ,VTU(2007)\n\n\nLanguages\nPython,PHP,HTML,CSS,Jquery,Javascript\n\nFramework\nDjango, Codeigniter, Drupal(CMS)\n\nDatabase\nPostgres, MySQL\n\nBI Tool\nJasper soft\n\nDeployment\nAWS(Cloud),Ubuntu and Debian (Dedicated Servers), Shared Servers.\n\n\n\n\nAssociate Technical Lead, Lemeno(Jun-2016- Mar-2017)\n? Backend Development using Django(Python Framework) with Postgres as Backend\n? REST API�s using django for Mobile platforms.\n? Hosted applications in AWS, RDS, Elasticache, S3.\n\n\nAssociate Technical Lead, HeyBnB (Jan-2016-Jun-2016)\n\n? Integration and development of REST API�s for Mobile Platforms \n? Backend with Yii Framework and MySql.\n? AWS server setup for the application hosting\n\n\n\nSenior Software Engineer, Saaramsha - Achumen Technologies, Jan 2014-Dec-15\n? Business Intelligence tool on cloud report creations and data capabilities.\n? Front end development in Codeigniter with MySql, with UI designed in HTML, CSS.\n? Integration of Jasper soft for BI capabilities.\n? Hosting on AWS cloud server and AWS Redshift\n\n\nSoftware Engineer, Dataconnect Online � Achumen Technologies, August-2013-Jan-2014\n? Online Advertising Management System allows users and franchise to earn money by posting ads.\n? Front end development in Codeigniter with MySql, HTML, CSS\n? Involved in Integration of Payment Gateway into the system.\n? Deployment  in Windows Server.  \n\nSoftware Engineer, MyOp � Achumen Technlogies Feb-2013-July-2013\n? Application is mainly based on customer service experience and  feedback system. System  built on Django with Mysql.\n? Involved in development of modules regarding moderation\n? Involved in hosting on AWS cloud server.\n\nSoftware Engineer, VTR Travels � Achumen Technologies\n? A travel website built on Drupal content management System.\n? Involved in integration  and deployment of  website.\n\nSoftware Engineer, Simple Learning � Achumen technologies\n? Website which has been developed for consulting organization which involves client size in the fields of Manufacturing, Retail, IT and ITES.\n? Technologies involved in development are : Drupal 7, Html 5 and CSS 3\n\n\nAssociate Software Engineer \n\n? Worked with integrating and developing Content Management System of version Drupal 6 and Drupal.\n? Sites for non profit organisations like United Way, Unity, American Redcross ,Humane Society , CFC etc.for several local and national chapters of United States and global chapters.\n? Built websites on multisite environment running in Linux with PHP5, MySql in dedicated servers of Debian and Ubuntu.\n? Given time to time Technical Support and maintenance for the issues raised by customers.\n? Integrated CiviCRM 3.4.8 to 4.2.2 version for most of the non profit organizations.\n? Integrated Secure Pages for serveral chapters of the United Way, Unity, Humane Society.\n? Integrated Ubercart module for several chapters of United Way and Unity.\n? Worked with the Drupal CMS system to build sites for clients of all sizes, including\n? eCommerce site, Non profits, Social networking sites like sampada, mysoreassociation , graam\n? Integrated SSL for several sites mainly for CiviCRM and Ubercart.\n? Experience includes Drupal 6/7, integrating theme using Zen, Omega, experience with CCK,Views and more.\n? Worked on migration of sites from server to server, installing new sites.\n? Worked integrating UI for android mobile application development.\n? Experience includes the knowledge of views, intents etc. in android application development.\n                  Sample sites are http://unitedwaytoledo.org/ http://cfcvp.org etc\n\n\nJanjeevan Foundation � Software Engineer\n? This website is an application for the children medical foundation. Features incorporated �mailing option� for the donors who helps the children having rare\n disorder and for the children education foundation.\n? �Member login facility� for the members to get the details and solutions of disorders from\n? doctors.\n? Involved in development through PHP, web page design through Html and CSS.\n Managed development, uploading site in server and maintenance.\n\nVideo memories - Software Engineer\n\n? Video memories is a site for uploading and downloading videos.\n? Involved in functionality testing, also included form validation and CSS issues.\n\nIP@Web - Software Engineer\n? Website is a personal profile of a politician called TM Umesh.\n? Involved in developing this project through Drupal 5, and Mysql using PHPMyadmin.\n? Features involved are Gallery integration, content creation using CCK etc.\n? Involved in site maintenance and support.Worked this project in WAMP environment\n\nTPSET � Php developer\n\n? Internal Application TPSET is a tool developed for employees of TPS organisation which contains the Employee details, Employee work status and leave management.\n? Involved in integrating and developing this through PHP, Mysql.Worked this project in WAMP environment.\n\n\n? VXL instruments - 2008  Internship for 3months\n\n? NIIT Jayanagar - 2010 3 months Diploma in dot net training includes, C# 3.5,ASP.net and MSSQL.\nProject undertaken here was to make a web portal using C#,Asp.net and MsSQL to create  online test application for the students UI included with HTML, Javascript and Jquery. \n? Master skills - 2010  1 month Android Application Development.\n\n\n\nDOB : 24-08-1984","annotation":[{"label":["Skills"],"points":[{"start":6064,"end":6069,"text":"Jquery"}]},{"label":["Skills"],"points":[{"start":6049,"end":6058,"text":"Javascript"}]},{"label":["Skills"],"points":[{"start":6043,"end":6046,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":5697,"end":5699,"text":"PHP"}]},{"label":["Skills"],"points":[{"start":5284,"end":5286,"text":"PHP"}]},{"label":["Skills"],"points":[{"start":5107,"end":5109,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":4865,"end":4867,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":4827,"end":4829,"text":"PHP"}]},{"label":["Skills"],"points":[{"start":3358,"end":3360,"text":"PHP"}]},{"label":["Skills"],"points":[{"start":2974,"end":2976,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":2516,"end":2518,"text":"AWS"}]},{"label":["Skills"],"points":[{"start":2147,"end":2149,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":2141,"end":2144,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":1896,"end":1898,"text":"AWS"}]},{"label":["Skills"],"points":[{"start":1875,"end":1877,"text":"AWS"}]},{"label":["Skills"],"points":[{"start":1807,"end":1809,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":1801,"end":1804,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":1528,"end":1530,"text":"AWS"}]},{"label":["Skills"],"points":[{"start":1359,"end":1361,"text":" S3"}]},{"label":["Skills"],"points":[{"start":1347,"end":1357,"text":"Elasticache"}]},{"label":["Skills"],"points":[{"start":1341,"end":1344,"text":" RDS"}]},{"label":["Skills"],"points":[{"start":1337,"end":1339,"text":"AWS"}]},{"label":["Skills"],"points":[{"start":1221,"end":1226,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1063,"end":1065,"text":"AWS"}]},{"label":["Skills"],"points":[{"start":949,"end":958,"text":"Javascript"}]},{"label":["Skills"],"points":[{"start":942,"end":947,"text":"Jquery"}]},{"label":["Skills"],"points":[{"start":938,"end":940,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":933,"end":936,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":929,"end":931,"text":"PHP"}]},{"label":["Skills"],"points":[{"start":922,"end":927,"text":"Python"}]},{"label":["Education"],"points":[{"start":874,"end":876,"text":"B.E"}]},{"label":["Location"],"points":[{"start":524,"end":532,"text":"Bengaluru"}]},{"label":["Name"],"points":[{"start":0,"end":11,"text":"Aravinda U.S"}]}],"extras":null,"metadata":{"first_done_at":1532679346000,"last_updated_at":1532679346000,"sec_taken":139,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Ashok Bole\nEmail: ashok.bole7@gmail.com\t\t          Mobile:- +91-9742888783\nCareer objective\t\n\nA challenging position in data analytics and machine learning, providing an effective and efficient solution that will assist organization to get the finest solutions to the business problems which could increase productivity and delight\nCustomers as well as enhance my data science skills.\nSummary\n\n* Software Engineer with 3.7 years of overall Experience, with 2+ years of experience in Analytics Domain.\n* Exposure to statistical concepts like univariate, bivariate, multivariate analysis, Hypothesis, P value, Central Limit theorem, Inferential ,predictive and descriptive statistics. \n* Exposure to data cleansing techniques like outlier treatment, missing value treatment etc.\n* Exposure in Multivariate Analysis Techniques (Linear & Logistic Regression, SVM, Decision trees, Random Forest Principal component Analysis and Associate rule Learning).\n* Proficiency in R programming and R packages.\n* Exposure to data visualization using various visualization charts like scatterplots, barplots, histograms,Shiny.ino ggplots etc.\n* Exposure to importing data from external files, external databases into R environment.\n* A team player with the strong communication and interpersonal skills. Contributed effectively to the achievement of team goals.\n* A quick learner with the ability to work under pressure and meet deadlines.\n* Ability to work independently and cross functions in a timely manner.\n* Good presentation skills with distinguished abilities of team building and taking initiatives; self-motivated, fast learner, coordinate effectively across levels/ multi-location teams.\n* High capability to quickly learn new technology and adapt to a new environment.\n* Proven ability to manage multiple projects with excellent organization skills.\n\nProfessional Experience\nSoftware Engineer                                              CGI Bangalore                                         Jan 2015 � Till date\n1. Insurance policy purchase prediction:\nClient: Leading Insurance Company\nPOC Description:\nThe main goal of this project is to predict the exact car insurance options purchased by individual customers. And using customer�s shopping history; we need to predict what policy a new customer will end up choosing.\nRole Description:\n* Involved in Data Exploration and Visualization.\n* Feature Engineering on the data set and created new additional features using transformations or combinations of features.\n* Involved in creating data visualization charts.\n* Clustering on featured data set to find out the different patterns in the data.\n* Presenting the Analysis and insights to client in weekly calls and enhanced the analysis and Insights generation based on Change Request.\n* Developed logistic regression model for predicting which customers would change from their final quote.\n* Developed a RandomForest model to find out which car insurance options and coverage information a customer will end up choosing.\nTools Used:  R, Machine Learning Algorithms � Logistic regression, Multinomial logistic regression, Random Forest.\n2. Car Insurance Campaign:\nClient: Leading Insurance Company\nProject Description: OP organizes regular campaigns to attract new clients. The bank has potential customers� data, and bank�s employees call them for advertising available car insurance options. They have provided with general information about clients as well as more specific information about the current insurance sell campaign (communication, last contact day) and previous campaigns. The main goal of this project is to predict for the customers who were contacted during the current campaign, whether they will buy car insurance or not.\nRole Description:\nDeveloped a Decision tree model whether they will buy car insurance or not, and did Statistical significance testing using R. \n3. Employee attrition:\nPOC Description: Employee turnover (attrition) is a major cost to an organization, and predicting turnover is at the forefront of needs of Human Resources (HR) in the organization. Some costs are tangible such as training expenses and the time it takes from when an employee starts to when they become a productive member. So with advances in machine learning and data science, predicted the employee attrition by understanding the key variables that influence turnover.�\nRole Description:\n* Importing data from MySQL into R.\t\n* Involved in creating data visualization charts.\n* Created Scatter plots, line charts.\n* Interacting with SQL Server to retrieve data from database. Performed Data Manipulations such as SELECT, INSERT, UPDATE, DELETE etc.\n* Developed a Decision tree model to find out the significant factors which influence turnover.\n* Developed logistic regression model to predict Employee attrition.\n\nAssociate Software Engineer                                CGI, Bangalore                                         June 2014 �Jan 2015\nClient: Leading Insurance Company in Finland\nTools used:  DB2, Legacy technologies\t\t\t\t\t\nJob Responsibilities:\n* Analyzing and providing estimates for new projects or enhancements.\n* Requirements clarification if necessary through client interaction and meetings with Business analysts.\n* Analyzing and designing the technical specification document for any new project.\n* Code development work for a new project or an enhancement.\n* Unit testing and Peer code review.\n* Providing QA support to the testers.\n* Support after the production deployment.\n* Assisting the team members on need basis.\n* Involved in knowledge transfer to the new joiners within the team.\nProfessional and Academic Achievements \n\n* Best Team CORONA Award for Year 2017 Q2.\n* Got the Best team player award.\n* Twice, got the pat on the back award.\n* Got the top rating during appraisal cycles, every year.\n\nAcademic Profile \n\nBachelor of Technology, Electrical and Electronics Engineering, April 2013\nSree Vidyanikethan Engineering College, JNTU Anantapur, Tirupati, Andhra Pradesh.\tPercentage: 78.06%\n\nTechnical Skills \n\nProgramming Languages\t   : R, Basics in Python, SQL\nDatabase\t\t\t   : MySQL, DB2\nMachine learning algorithms: Supervised Learning (Logistic Regression, Linear Regression, SVM, Decision Trees, Random Forests, and Na�ve Bayes etc.) Un-Supervised Learning (K-Means, Hierarchal, PCA)\nStatistics: Mathematics/statistical modelling, Hypothesis Testing, Chi-Square test, ANOVA.","annotation":[{"label":["Skills"],"points":[{"start":6125,"end":6127,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":6103,"end":6105,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":6095,"end":6100,"text":"Python"}]},{"label":["Location"],"points":[{"start":4890,"end":4898,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":4544,"end":4546,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":4424,"end":4426,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":3037,"end":3064,"text":"Machine Learning Algorithms "}]},{"label":["Location"],"points":[{"start":1938,"end":1946,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":966,"end":978,"text":"R programming"}]},{"label":["Name"],"points":[{"start":0,"end":9,"text":"Ashok Bole"}]}],"extras":null,"metadata":{"first_done_at":1532688951000,"last_updated_at":1532688951000,"sec_taken":171,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "RESUME\n\nAtmanand Singh\n# 16, Nanjappa Layout\nYelachenahalli\nBangalore - 560062\nPassport �K2676244\nMob. No: +91 � 9972133553/8553615100\n\t   \nE-mail: atma2018@gmail.com\n\n\nProfessional Summary:\n\n* Having 9 Years of IT experience in Predictive Modeling, Machine Learning, Data Quality, and Data Warehousing.\n* Hands on experience in client's requirement's gathering & analysis (RGA), Data Analysis, and building statistical models in Logistic, Linear Regression, Decision Tree, Random Forest, and Gradient Boosting Machine.\n* Hands on experience on Revolution R, RStudio, Hive, and Python.\n* Worked in domains like Insurance (Property and Casualty), Banking, Healthcare, and Telecommunication.\n* Excellent analytical, quick learning, problem solving and troubleshooting skills with desire to work in a team oriented environment.\n* An enthusiastic and passionate approach to work and having good communication skills.\n\nExperience Details:\n\n* Worked as Assistant Manager at AIG Data Services (P) Ltd., Bangalore from March 2014 to March 2017.\n* Worked as Senior Software Analyst for IBM India (P) Ltd., Bangalore from Nityo Infotech Services Pvt. Ltd. from October 2012 to March 2014.\n* Worked as Software Analyst for IBM India (P) Ltd., Bangalore from Source One Management Services Pvt. Ltd., Bangalore from Feb 2012 to October 2012.\n* Worked as Software Analyst for SLK Software Services Pvt. Ltd., Bangalore from BEST HR Outsourcing Services from May 2008 to February 2012.\n\nTechnical Skills:\n\n* Statistical Tools\t\t:Revolution R, RStudio, Python\n* DW Tools\t\t\t:IBM Infosphere DataStage, Informatica Power Center\n* DQ Tools\t\t\t:IBM Information Analyzer, IBM QualityStage\n* Database\t\t\t:Oracle, Teradata, DB2, Sybase, Hive\n* Operating System\t\t:Unix, Ubuntu\n\n\nEducational Summary:\n* M.C.A., (Master in Computer Application) 2004.\nProjects Executed (Most recent to oldest):\n\nProject #1:\n\nName\nClaims Bucketing\nDescription\nThis project deals with predicting large loss claims propensity. The prediction is performed after 10 days from the date of claim lodgment.\nOrganization\nAmerican International Group / United Guaranty Corporation, NC\nDuration\nFrom Jan 2016 to March 2017\nEnvironment\n\nModels/Techniques : Decision Tree, Treebag, Random Forest, GBM, Ensemble Classification (Treebag, Random Forest and GBM) \nDatabase: DB/2\nTools: Revolution R\n\nResponsibilities:\n* Understanding client�s requirements.\n* Liaise with functional lead to understand and clarify meaning and impact of key data variables.\n* Data analysis and data preparation for modeling.\n* Model development, testing and getting inferential input to be provided for business decision support using Revolution R.\n* Representing results in MS Excel and PowerPoint presentation.\n\n\n\nProject #2:\n\nName\nUnited Guaranty Housing Price Prediction Model\nDescription\nThis model predicts market value of residential units in Greensboro, NC to know their value before insuring them.\nOrganization\nAmerican International Group / United Guaranty Corporation, NC\nDuration\nFrom December 2014 to November 2015\nEnvironment\n\nModels/Techniques : Decision Tree, Treebag, Random Forest, GBM, Ensemble Classification (Treebag, Random Forest and GBM) \nDatabase: DB/2\nTools: Revolution R\n\nResponsibilities:\n* Understanding client�s requirements.\n* Liaise with functional lead to understand and clarify meaning and impact of key data variables.\n* Data analysis and data preparation for modeling.\n* Model development, testing and getting inferential input to be provided for business decision support using Revolution R.\n* Representing results in MS Excel and PowerPoint presentation.\n\nProject #3:\n\nName\nProperty and Casualty Group Broker Tiering (PCGBT) \nDescription\nThis project identifies performing and nonperforming brokers based on the business provided by them.\nOrganization\nAmerican International Group / United Guaranty Corporation, NC\nDuration\nFrom April 2014 to November 2014\nEnvironment\n\nModels/Techniques: Diagnostic\nDatabase: DB2\nTools: SQL\n\nResponsibilities:\n* Understanding client�s requirements.\n* Liaise with functional lead to understand and clarify meaning and impact of key data variables.\n* Data manipulation and analysis using SQL.\n* Representing results in MS Excel.\n\n\n\nProject #4:\n\nName\nCredit Risk Assessment Model\nDescription\nThis model considers the various aspects of the applicant and produces an assessment of the Probability of Default (PD) of the applicant.\nOrganization\nIBM India (P) Ltd., Bangalore/Australia and New Zealand Bank\nDuration\nFrom October 2012 to March 2014\nEnvironment\n\nModels/Techniques: Decision Tree\nDatabase: Oracle\nTools: R Studio\n\nResponsibilities:\n* Understanding client�s requirements \n* Liaise with functional lead to understand and clarify meaning and impact of key data variables\n* Data analysis and data preparation for modeling.\n* Model development, testing and getting inferential input to be provided for business decision support using R Studio.\n* Representing results in MS Excel and PowerPoint presentation.\n\n\nProject #5:\n\nName\nGE Capital Americas (GECA) Fleet\nDescription\nThis project provided quality data for the creation of a data warehouse for GE Capital�s 1.5 million vehicle fleet scattered in 17 countries. \nOrganization\nIBM India (P) Ltd., Bangalore\nDuration\nFrom Feb 2012 to Oct 2012\nEnvironment\n\nLanguages: Unix shell scripting, TSQL, SQL\nDatabase: Teradata, DB2, Mainframe, Sybase\nTools: IBM Information Analyzer, IBM QualityStage, IBM DataStage\n\nResponsibilities:\n* Column profiling of the data and provide a dashboard.\n* Understand, document, classify data in to data 4 data quality dimensions, and discuss and implement various data quality related issues/solutions with the data owners.\n* Raising defects in HP Application Life Management for the agreed data issues.\n* Performing data cleaning activities.\n* Providing inputs to avoid future data quality issues.\n\n\n\nProject #6:\n\nName\nGrace Health System (GHS) \nDescription\nThis project involved creation of a data warehouse by first creating various data marts for Grace Health System.\nOrganization\nSLK Software Services Pvt. Ltd.\nDuration\nFrom March 2010 to Feb 2012\nEnvironment\n\nLanguages: Unix shell scripting, SQL\nDatabase: Oracle 10g\nTools: Informatica\n\nResponsibilities:\n* Understanding functional requirements of the application.\n* Design walkthroughs with the BA, testers and PMs.\n* ETL development, unit testing, ETL Testing.\n* Performance tuning, query optimization, partitioning.\n* Unix shell scripting.\n* Issue analysis with BA.\n* Defect analysis and reporting in Quality Center.\n\n\nProject #7:\n\nName\nGT Warehouse\nDescription\nThis Project involved the creation of a data warehouse to be used for detailed bill generation for its customers, payment to the service providers, and various other reports. \nOrganization\nSLK Software Services Pvt. Ltd.\nDuration\nFrom May 2008  to Feb 2010\nEnvironment\n\nLanguages: Unix shell scripting, SQL\nDatabase: Oracle 10g\nTools: Informatica\n\nResponsibilities:\n* Understanding functional requirements of the application.\n* Design walkthroughs with the BA, testers and PMs.\n* ETL development and unit testing.\n* Performance tuning, query optimization, partitioning.\n* Issue analysis with BA.\n\n\n\nPersonal Details:\n\nSex\t:        Male\nMarital Status\t:        Married\nNationality\t:        Indian\nPassport\t:        Valid till April 2022\nVisa (B1/B2 for USA)\t:        Valid till October 2024\n\n\nI hereby declare that the information stated above is true to the best of my knowledge.\n\n\n\nDate: _________________\nPlace: Bangalore (Karnataka)\n                           \t                     _________________________\n\t\t\t                                                           ATMANAND SINGH\n\n\n5","annotation":[{"label":["Location"],"points":[{"start":7509,"end":7517,"text":"Bangalore"}]},{"label":["Location"],"points":[{"start":5242,"end":5250,"text":"Bangalore"}]},{"label":["Location"],"points":[{"start":4450,"end":4458,"text":"Bangalore"}]},{"label":["Education"],"points":[{"start":1775,"end":1779,"text":"M.C.A"}]},{"label":["Location"],"points":[{"start":1396,"end":1404,"text":"Bangalore"}]},{"label":["Location"],"points":[{"start":1289,"end":1297,"text":"Bangalore"}]},{"label":["Location"],"points":[{"start":1232,"end":1240,"text":"Bangalore"}]},{"label":["Location"],"points":[{"start":1097,"end":1105,"text":"Bangalore"}]},{"label":["Location"],"points":[{"start":996,"end":1004,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":286,"end":301,"text":"Data Warehousing"}]},{"label":["Skills"],"points":[{"start":267,"end":279,"text":" Data Quality"}]},{"label":["Skills"],"points":[{"start":250,"end":265,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":229,"end":247,"text":"Predictive Modeling"}]},{"label":["Location"],"points":[{"start":60,"end":68,"text":"Bangalore"}]},{"label":["Name"],"points":[{"start":8,"end":21,"text":"Atmanand Singh"}]}],"extras":null,"metadata":{"first_done_at":1532680415000,"last_updated_at":1532680415000,"sec_taken":209,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Udaya Laxmi Ch\n\nEmail : laxmi.udaya@gmail.com\n\n\t\n\n\tPhone: -9740606990\n\t\n\n\n\tSummary\n\n\t· 9.5 years of experience in Software Development.\n· 3.5 years of experience in Machine Learning\n· Primary Skills – Machine Learning, R programming, Lotus Notes.\n· Presently working for Wipro Technologies, Bangalore.\n· Experience in planning, estimation, design, development, and testing object oriented applications.\n· Experience in preparing various technical documents like Functional Specs, HLD, LLD, Flowcharts and Test cases.\n· Sound Knowledge in Object Oriented Design Principles\n· Have Team Handling experience.\n· Domain experience of Manufacturing and Finance.\n· Have Experience in Scrum Agile Model\n· Understand business requirements from clients\n\n\n\n\tTechnical Skills\n\n\tKey skills: \n\tMachine Learning,R Programming, MySQL, PostgreSQL, Microsoft Access, SQL Server, FileMaker, Oracle, RDBMS, dBASE, Clipper, FoxPro, Firebase, Mongodb, Python,  ava, J2EE, Oracle Fusion,Oracle Cloud, Salesforce, Devops Android, Business Analyst, UI Developer, DBAs, Embedded Systems, .NET, Hadoop, SQL Developer, Big Data, Tableau, Networking, Etl, Informatica, Ios, Quality Analyst, Project Manager, Python, Data Science, Python, Machine Learning, SAS, Java, Scala, Hadoop, Hive, Bigdata, Programming, SQL server reporting, Msbi Ssis, Ssrs, Msbi, Sql Reporting, Artificial Intelligence, Pandas, Pyspark, Sklearn, Flask, Django, Map Reduce, Parametric Design, Modeling, Regression, Patterns, Data Mining, Text Mining, Oops, Deep Learning, Web Analytics, Time Series, Regression, Tensorflow, Azure, Linear Regression, Logistic Regression, Decision Tree, Random Forest, Data Structure, Computer Vision, IHS, WAS, Java EE, SQL Server, .NET core, C#, ASP.NET, Rdlc, Linq, Sql, Web Api, Mvc, Javascript, Web Services, Oracle, MS SQL, PHP, Laravel, CodeIgniter, Symfony, Zend, Phalcon, CakePHP, Yii, FuelPHP, React, Vue, Angular, Ember, Backbone, Lotus Notes\n\n\tAlgorithms:\n\tNaïve Bayes, K means clustering,Word Cloud\n\n\tDatabases: \n\tMicrosoft SQL, Mongo DB\n\n\tWeb Technologies: \n\tXML, XSLT, HTML,  JavaScript,  AJAX, JQuery\n\n\tIDE:\n\tR studio,Pycharm\n\n\n\tProfessional Experience\n\n\tCurrent Employer :\n\tWipro Technologies., Bangalore  – (Oct  2010  to till date) – Technical Lead/Data Scientist\n\n\tPrevious Employers :\n\tHSBC Software development , Hyderabad (June  2008  to Sep 2010)  - SE\n\n\n\tQualification\n\n\tDegree\n\tCollege\n\tUniversity/Board\n\tYear\n\tPercentage (%)\n\n\tMCA\n\tNizam College, Basheerbagh,Hyderabad\n\tOsmania University\n\t2008\n\t75\n\n\n\tProject Experience \n\n\tProject 1 : Exploratory Data Analysis:\n\nProject Description:   Performed EDA analysis to analyze the Purchase frequency of vehicles which occurred over past 3 years and try to predict the frequency occurring in the future.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Performed EDA analysis to find the insights of the data. Observed the summary of each and every variable to understand the variables.\n\n· Performed the feature selection using hypothesis testing.\n\n· Identified the outliers using box plot.\n\n· Identified the trend in the purchases using histogram.\n\n\n\n\tProject 2: Word Cloud Analysis:\n\nProject Description:   Performed Word cloud and Sentimental Analysis of the customer feedbacks. Graphically represented the most frequently occurred words through Word cloud. Through sentimental analysis we identified whether a user-generated text expresses positive, negative or neutral opinion.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Created a Corpus using TM package and performed pre-processing of data.\n\n· Removed the punctuations, stemming and stop words which are of no analytical value.\n\n· Built a Document term matrix and identified the most frequently occurring words\n\n· Graphically represented it using  RColorbrewer Package\n\n\n\tProject 3: Sentimental Analysis:\n\nProject Description: Performed Sentimental Analysis of customer feedbacks through Naïve Bayes. Used “e1071” Package for implementing naïve Bayes method.\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· The DTM created using TM package was an input to the Naive Bayes Model.\n\n· As Naive Bayes classifier is typically trained on data with categorical features. We have converted the count of the words into a factor variable that indicates Yes or No whether the word is present or not.\n\n\tProject 4: Clustering Analysis:\n\nProject Description: Classified the customers on the basis of their purchases whether they have purchased low variant or high variant trucks. It in turn helped in building the right customer strategies.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Performed data preparation and Normalization of data using min-max method.\n\n· As K-means algorithm groups a dataset into a user-specified number (k) of clusters. Identified the initial cluster centroids as 3.\n\n· K clusters are creating by associating every observation with the nearest mean.\n\n· Used elbow method to validate the number of clusters such that within-cluster sum of square(wss) is minimized.\n\n\n\n\tProject 5 : Inter Connection Management Tool\nProject Description: Inter-connection Management (IMT) is prototype being developed for Engineering and Sales department to handle customizations of an existing product based on the customer's requirement. Users from engineering department will identify the items, which need to be customized out of the entire product design.\nRole\n\n       : Module Lead\n\nEnvironment\n       : Python, Mongo DB, jQuery\n\nTasks handled:\n\n· Gathering Requirements and providing Project Plan and Effort Estimation details.\n\n· Understanding business requirements and preparing SoU (Statement of Understanding) and Functional/Technical Specification documents.\n\n· Providing Effort & Resource estimations\n\n· Planning for application development and deployment\n\n· Writing and executing Test Cases and Test scenarios\n\n· Creating design elements using Technical Specification.\n\n· Performing Unit testing & Peer Reviews\n\n· Work Allocation and mentoring the team\n\n· Providing Technical guidance to the team. \n\n\tProject 6\n: cvdAEI Application\n\nProject Description\n     : CVDAEI is a web based multilingual application developed for handling the Change Management process in Truck division of Daimler. The change request flows through different phases mainly Initialization, Evaluation, Decision and Conclusion. This application has a configurable workflow where the request flow and the responsible persons can be configured easily at any point of time. \n\nRole\n\n    : Developer/Tester\n\nEnvironment\n     : Lotus Notes, Java, HTML, XML, Java Script, JQuery\n\nTasks handled:\n\n· Gathering Requirements and providing Project Plan and Effort Estimation details.\n\n· Understanding business requirements and preparing SoU (Statement of Understanding) and Functional/Technical Specification documents.\n\n· Providing Effort & Resource estimations\n\n· Planning for application development and deployment\n\n· Writing and executing Test Cases and Test scenarios\n\n· Creating design elements using Technical Specification.\n\n· Performing Unit testing & Peer Reviews\n\n· Work Allocation and mentoring the team\n\n· Providing Technical guidance to the team. \n\n\n\n\tProject Title: Project Management Office \nProject Description: The purpose of this system is to enable the Project Management Office to manage and execute the IT Applications and Operations driven project tasks in  more systematic manner. It will also enable them to efficiently perform a role as a facilitator to coordinate various IT Operations teams and to ensure that project activity enters the department through one common interface. The project tasks will subsequently be dealt with in a common format and in a consistent and appropriate manner, ensuring open and regular communication between all involved parties.\n\nRole\n\n    : Developer/Tester\n\nEnvironment\n     : Lotus Notes, Java, HTML, XML, Java Script, JQuery\n\nTasks Handled :\n\n· Writing and Executing Test cases in client server based environment\n· Individually provided application support","annotation":[{"label":["Skills"],"points":[{"start":7951,"end":7956,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":7938,"end":7948,"text":"Java Script"}]},{"label":["Skills"],"points":[{"start":7933,"end":7935,"text":"XML"}]},{"label":["Skills"],"points":[{"start":7927,"end":7930,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":7921,"end":7924,"text":"Java"}]},{"label":["Skills"],"points":[{"start":7908,"end":7918,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":6645,"end":6650,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":6632,"end":6642,"text":"Java Script"}]},{"label":["Skills"],"points":[{"start":6627,"end":6629,"text":"XML"}]},{"label":["Skills"],"points":[{"start":6621,"end":6624,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":6615,"end":6618,"text":"Java"}]},{"label":["Skills"],"points":[{"start":6602,"end":6612,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":5522,"end":5527,"text":"jQuery"}]},{"label":["Skills"],"points":[{"start":5512,"end":5519,"text":"Mongo DB"}]},{"label":["Skills"],"points":[{"start":5504,"end":5509,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4645,"end":4652,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":4054,"end":4061,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":3941,"end":3951,"text":"Naïve Bayes"}]},{"label":["Skills"],"points":[{"start":3494,"end":3501,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":3132,"end":3141,"text":"Word Cloud"}]},{"label":["Skills"],"points":[{"start":2793,"end":2800,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":2110,"end":2116,"text":"Pycharm"}]},{"label":["Skills"],"points":[{"start":2101,"end":2108,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":2086,"end":2091,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":2080,"end":2083,"text":"AJAX"}]},{"label":["Skills"],"points":[{"start":2067,"end":2076,"text":"JavaScript"}]},{"label":["Skills"],"points":[{"start":2060,"end":2063,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":2054,"end":2057,"text":"XSLT"}]},{"label":["Skills"],"points":[{"start":2049,"end":2051,"text":"XML"}]},{"label":["Skills"],"points":[{"start":2018,"end":2025,"text":"Mongo DB"}]},{"label":["Skills"],"points":[{"start":2003,"end":2015,"text":"Microsoft SQL"}]},{"label":["Skills"],"points":[{"start":1977,"end":1986,"text":"Word Cloud"}]},{"label":["Skills"],"points":[{"start":1958,"end":1975,"text":"K means clustering"}]},{"label":["Skills"],"points":[{"start":1945,"end":1955,"text":"Naïve Bayes"}]},{"label":["Skills"],"points":[{"start":1918,"end":1928,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":1908,"end":1915,"text":"Backbone"}]},{"label":["Skills"],"points":[{"start":1901,"end":1905,"text":"Ember"}]},{"label":["Skills"],"points":[{"start":1892,"end":1898,"text":"Angular"}]},{"label":["Skills"],"points":[{"start":1887,"end":1889,"text":"Vue"}]},{"label":["Skills"],"points":[{"start":1880,"end":1884,"text":"React"}]},{"label":["Skills"],"points":[{"start":1871,"end":1877,"text":"FuelPHP"}]},{"label":["Skills"],"points":[{"start":1866,"end":1868,"text":"Yii"}]},{"label":["Skills"],"points":[{"start":1857,"end":1863,"text":"CakePHP"}]},{"label":["Skills"],"points":[{"start":1848,"end":1854,"text":"Phalcon"}]},{"label":["Skills"],"points":[{"start":1842,"end":1845,"text":"Zend"}]},{"label":["Skills"],"points":[{"start":1833,"end":1839,"text":"Symfony"}]},{"label":["Skills"],"points":[{"start":1820,"end":1830,"text":"CodeIgniter"}]},{"label":["Skills"],"points":[{"start":1811,"end":1817,"text":"Laravel"}]},{"label":["Skills"],"points":[{"start":1806,"end":1808,"text":"PHP"}]},{"label":["Skills"],"points":[{"start":1798,"end":1803,"text":"MS SQL"}]},{"label":["Skills"],"points":[{"start":1790,"end":1795,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":1776,"end":1787,"text":"Web Services"}]},{"label":["Skills"],"points":[{"start":1764,"end":1773,"text":"Javascript"}]},{"label":["Skills"],"points":[{"start":1759,"end":1761,"text":"Mvc"}]},{"label":["Skills"],"points":[{"start":1750,"end":1756,"text":"Web Api"}]},{"label":["Skills"],"points":[{"start":1745,"end":1747,"text":"Sql"}]},{"label":["Skills"],"points":[{"start":1739,"end":1742,"text":"Linq"}]},{"label":["Skills"],"points":[{"start":1733,"end":1736,"text":"Rdlc"}]},{"label":["Skills"],"points":[{"start":1724,"end":1730,"text":"ASP.NET"}]},{"label":["Skills"],"points":[{"start":1720,"end":1721,"text":"C#"}]},{"label":["Skills"],"points":[{"start":1709,"end":1717,"text":".NET core"}]},{"label":["Skills"],"points":[{"start":1697,"end":1706,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":1688,"end":1694,"text":"Java EE"}]},{"label":["Skills"],"points":[{"start":1683,"end":1685,"text":"WAS"}]},{"label":["Skills"],"points":[{"start":1678,"end":1680,"text":"IHS"}]},{"label":["Skills"],"points":[{"start":1661,"end":1675,"text":"Computer Vision"}]},{"label":["Skills"],"points":[{"start":1645,"end":1658,"text":"Data Structure"}]},{"label":["Skills"],"points":[{"start":1630,"end":1642,"text":"Random Forest"}]},{"label":["Skills"],"points":[{"start":1615,"end":1627,"text":"Decision Tree"}]},{"label":["Skills"],"points":[{"start":1594,"end":1612,"text":"Logistic Regression"}]},{"label":["Skills"],"points":[{"start":1575,"end":1591,"text":"Linear Regression"}]},{"label":["Skills"],"points":[{"start":1568,"end":1572,"text":"Azure"}]},{"label":["Skills"],"points":[{"start":1556,"end":1565,"text":"Tensorflow"}]},{"label":["Skills"],"points":[{"start":1544,"end":1553,"text":"Regression"}]},{"label":["Skills"],"points":[{"start":1531,"end":1541,"text":"Time Series"}]},{"label":["Skills"],"points":[{"start":1516,"end":1528,"text":"Web Analytics"}]},{"label":["Skills"],"points":[{"start":1501,"end":1513,"text":"Deep Learning"}]},{"label":["Skills"],"points":[{"start":1495,"end":1498,"text":"Oops"}]},{"label":["Skills"],"points":[{"start":1482,"end":1492,"text":"Text Mining"}]},{"label":["Skills"],"points":[{"start":1469,"end":1479,"text":"Data Mining"}]},{"label":["Skills"],"points":[{"start":1459,"end":1466,"text":"Patterns"}]},{"label":["Skills"],"points":[{"start":1447,"end":1456,"text":"Regression"}]},{"label":["Skills"],"points":[{"start":1437,"end":1444,"text":"Modeling"}]},{"label":["Skills"],"points":[{"start":1418,"end":1434,"text":"Parametric Design"}]},{"label":["Skills"],"points":[{"start":1406,"end":1415,"text":"Map Reduce"}]},{"label":["Skills"],"points":[{"start":1398,"end":1403,"text":"Django"}]},{"label":["Skills"],"points":[{"start":1391,"end":1395,"text":"Flask"}]},{"label":["Skills"],"points":[{"start":1382,"end":1388,"text":"Sklearn"}]},{"label":["Skills"],"points":[{"start":1373,"end":1379,"text":"Pyspark"}]},{"label":["Skills"],"points":[{"start":1365,"end":1370,"text":"Pandas"}]},{"label":["Skills"],"points":[{"start":1340,"end":1362,"text":"Artificial Intelligence"}]},{"label":["Skills"],"points":[{"start":1325,"end":1337,"text":"Sql Reporting"}]},{"label":["Skills"],"points":[{"start":1325,"end":1327,"text":"Sql"}]},{"label":["Skills"],"points":[{"start":1319,"end":1322,"text":"Msbi"}]},{"label":["Skills"],"points":[{"start":1313,"end":1316,"text":"Ssrs"}]},{"label":["Skills"],"points":[{"start":1302,"end":1310,"text":"Msbi Ssis"}]},{"label":["Skills"],"points":[{"start":1302,"end":1305,"text":"Msbi"}]},{"label":["Skills"],"points":[{"start":1280,"end":1299,"text":"SQL server reporting"}]},{"label":["Skills"],"points":[{"start":1267,"end":1277,"text":"Programming"}]},{"label":["Skills"],"points":[{"start":1258,"end":1264,"text":"Bigdata"}]},{"label":["Skills"],"points":[{"start":1252,"end":1255,"text":"Hive"}]},{"label":["Skills"],"points":[{"start":1244,"end":1249,"text":"Hadoop"}]},{"label":["Skills"],"points":[{"start":1237,"end":1241,"text":"Scala"}]},{"label":["Skills"],"points":[{"start":1231,"end":1234,"text":"Java"}]},{"label":["Skills"],"points":[{"start":1226,"end":1228,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1208,"end":1223,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1200,"end":1205,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1186,"end":1197,"text":"Data Science"}]},{"label":["Skills"],"points":[{"start":1178,"end":1183,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1161,"end":1175,"text":"Project Manager"}]},{"label":["Skills"],"points":[{"start":1144,"end":1158,"text":"Quality Analyst"}]},{"label":["Skills"],"points":[{"start":1139,"end":1141,"text":"Ios"}]},{"label":["Skills"],"points":[{"start":1126,"end":1136,"text":"Informatica"}]},{"label":["Skills"],"points":[{"start":1121,"end":1123,"text":"Etl"}]},{"label":["Skills"],"points":[{"start":1109,"end":1118,"text":"Networking"}]},{"label":["Skills"],"points":[{"start":1100,"end":1106,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":1090,"end":1097,"text":"Big Data"}]},{"label":["Skills"],"points":[{"start":1075,"end":1087,"text":"SQL Developer"}]},{"label":["Skills"],"points":[{"start":1067,"end":1072,"text":"Hadoop"}]},{"label":["Skills"],"points":[{"start":1061,"end":1064,"text":".NET"}]},{"label":["Skills"],"points":[{"start":1043,"end":1058,"text":"Embedded Systems"}]},{"label":["Skills"],"points":[{"start":1037,"end":1040,"text":"DBAs"}]},{"label":["Skills"],"points":[{"start":1023,"end":1034,"text":"UI Developer"}]},{"label":["Skills"],"points":[{"start":1005,"end":1020,"text":"Business Analyst"}]},{"label":["Skills"],"points":[{"start":989,"end":1002,"text":"Devops Android"}]},{"label":["Skills"],"points":[{"start":977,"end":986,"text":"Salesforce"}]},{"label":["Skills"],"points":[{"start":963,"end":974,"text":"Oracle Cloud"}]},{"label":["Skills"],"points":[{"start":949,"end":961,"text":"Oracle Fusion"}]},{"label":["Skills"],"points":[{"start":943,"end":946,"text":"J2EE"}]},{"label":["Skills"],"points":[{"start":929,"end":934,"text":"Python"}]},{"label":["Skills"],"points":[{"start":920,"end":926,"text":"Mongodb"}]},{"label":["Skills"],"points":[{"start":910,"end":917,"text":"Firebase"}]},{"label":["Skills"],"points":[{"start":902,"end":907,"text":"FoxPro"}]},{"label":["Skills"],"points":[{"start":893,"end":899,"text":"Clipper"}]},{"label":["Skills"],"points":[{"start":886,"end":890,"text":"dBASE"}]},{"label":["Skills"],"points":[{"start":879,"end":883,"text":"RDBMS"}]},{"label":["Skills"],"points":[{"start":871,"end":876,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":860,"end":868,"text":"FileMaker"}]},{"label":["Skills"],"points":[{"start":848,"end":857,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":830,"end":845,"text":"Microsoft Access"}]},{"label":["Skills"],"points":[{"start":818,"end":827,"text":"PostgreSQL"}]},{"label":["Skills"],"points":[{"start":811,"end":815,"text":"MySQL"}]},{"label":["Skills"],"points":[{"start":798,"end":808,"text":"Programming"}]},{"label":["Skills"],"points":[{"start":796,"end":808,"text":"R Programming"}]},{"label":["Skills"],"points":[{"start":779,"end":794,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":234,"end":244,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":219,"end":231,"text":"R programming"}]},{"label":["Skills"],"points":[{"start":201,"end":216,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":165,"end":180,"text":"Machine Learning"}]},{"label":["Name"],"points":[{"start":0,"end":13,"text":"Udaya Laxmi Ch"}]}],"extras":null,"metadata":{"first_done_at":1579625576000,"last_updated_at":1579626369000,"sec_taken":0,"last_updated_by":"aJOmJy1lvpOYFetVNuqLvFo9Vx42","status":"done","evaluation":"NONE"}}
{"content": "AbdulMajedRaja RS \namrrs.data@gmail.com\n +91-8007938947 \n\nDOB: January 15 1990 \nhttps://github.com/amrrs  \n\nhttps://datascienceplus.com/author/abdulmajed-raja/  \n \n \n\nData Scientist / Analytics Consultant \nSUMMARY  \n\n \n\n Data Scientist / Analytics Consultant with 6+ Years of International experience across different sectors (Consulting, Digital, Telecom) \n\n Training & Mentoring Students and Freshers in Machine Learning Concepts & Tools for them to establish a Career in Data Science \n\n Author and Maintainer of 3 R-packages (itunesr, coindeskr and coinmarketcapr) on CRAN  \n\n One of the Top writers on DataScience + \n \n\nEDUCATION  \n\n2011 BE (Computer Science Engineering) Government College of Technology, Coimbatore 8.08 CGPA \n\n2007 Class XII Reliance Matric. Hr. Sec. School, Komarapalayam 95.58% \n\n2005 Class X Reliance Matric. Hr. Sec. School, Komarapalayam 91.54% \n\nTOOLS \n\nR, Python, SAS, SQL, RShiny, Tensorflow, Keras, HTML, Qliksense, Tableau, Adobe SiteCatalyst, Google Analytics, Social Media APIs \n\nWORK EXPERIENCE (6+ YEARS)  \n\nDeputy Manager (Analytics) – Vodafone Shared Services, Pune (June 2016 to Present) \n\nAccomplishments \n\n Highlighted Key Pain-points of Early Life & In-Life Customers with (VOC) Text Analytics  \n\n Suggested UX changes that reduce Potential Customer Fall-outs at Social Networks Following & App downloads \n\n Implemented Data-Driven Approach for App Store & Mobile App Analytics to improve My Vodafone App Ratings  \n\n Identified factors driving Customers abandon Digital Self-Service in order to improve Digital Service Resolution \n\nMarket United Kingdom \n\nAssistant Manager (Analytics) – Girnarsoft (CarDekho.com), Jaipur (Dec 2015 to June 2016) \n\nAccomplishments \n\n Saved 2FTEs Manual & Time-consuming Reporting work with just one month of Automation Scripting Efforts \n\n Created Social Media Analytics & Campaign Frameworks for new market entry in South East Asian Countries  \n\n Implemented Statistical Models as part of Data Science Consulting for CarDekho, CarBay, Pricedekho & other BDs   \n\nMarket India, Indonesia, Philippines \n\nAnalyst - BUZ Marketing & Consulting, Dubai (Jan 2014 to June 2015) \n\nAccomplishments \n Saved ~50% cost in Dubai Celebration Chain Campaign with completely Analytics-Driven Campaign Strategy \n\n Setup KPIs and Target modeling for Accounts after understanding the Business Objectives from Brand Managers \n\n Helped Account Managers meet their targets (Engagement Rate & PTAT ) with data-driven content strategy \n\nMarket Middle East (GCC) \n\nAnalyst - Streamport Media FZCO, Dubai (Jan 2012 to Dec 2013) \n\nAccomplishments \n Improved Acquisition to Success Lead Conversion Rate by ~25% with a Lead scoring model \n\n Identified high-potential accounts and Created Upsell/Cross-selling options that helped in additional revenue  \n\nMarket Europe, Middle East and Africa \n\nMember Technical - Broadridge Financial Solutions, Hyderabad (May 2011 to December 2011) \n\nResponsibilities \n Collected & Understood Business Requirements from On-Site Partners for ICS Document Processing \n\n Developed & Maintained Mainframe applications with COBOL, JCL and DB \n\nMarket United States \n\nCERTIFICATIONS  \n\n Google Analytics Individual Qualification (GAIQ) (August 2015 – February 2017) \n\n Hubspot Certified Inbound-Marketing Specialist (August 2015) \n\nPUBLICATIONS  \n\n A Data-driven Digital Analytics Framework for Mobile App Analytics – International Journal of Computer Applications (October ‘17) \n\nhttps://github.com/amrrs\nhttps://datascienceplus.com/author/abdulmajed-raja/\nhttps://cran.r-project.org/web/packages/itunesr/index.html\nhttps://cran.r-project.org/package=coindeskr\nhttps://cran.r-project.org/web/packages/coinmarketcapr/index.html\nhttps://datascienceplus.com/author/abdulmajed-raja/\n\n\n \n\nPROJECTS  \n\nVodafone \n\n \n\nApp Customer Segmentation to improve App Penetration – R, Adobe Analytics \n\n Profiling Mobile App Customers into different segments based on usage patterns and other characteristics identified as \n\npart of the (unsupervised) clustering process \n\n \n\nNPS Improvement & Detractor Analysis (Text Analytics) – R \n\n Automated Verbatim Categorizing of VOC collected from Surveys across different journeys and touchpoints and correlating \n\nthe categories trend shift with the change in NPS to understand primary detractor drivers \n\n \n\nApp Store (iTunes & Google Play) Analysis & Dashboard – R, Tableau \n\n Defining internal KPIs and Standardized Issue Categories across App Stores to correlate the average ratings movement with \n\nApp Performance and Availability metrics \n\n \n\nGirnarSoft \n\n(CarDekho.Com) \n\n \n\nEmail Campaign Targeting Model – R \n\n Propensity Modelling for better Targeting of Email Campaign to increase open rate and reduce subscription rate \n\n \n\nCustomer Life Cycle (Value) Management - R \n\n Created CVM segments better representing the Life Cycle Stages that are further used for Campaigns, Micro-moment \n\nMarketing & Upsell/Cross-selling Opportunities  \n\n \n\nProduct Bundling and Recommendation Engine for Car Accessories Portal - R \n\n Collaborative Filtering based Recommendation Engine and Product Bundling to improve Cart Value & Size for Prestashop-\n\nbased Car Accessories Portal \n\n  \n\nBUZ Marketing \n\n& Consulting \n\nExecutive Social Media KPIs Dashboard  – R, Tableau \n\n Dashboard with Social Media KPIs for Account Managers and Clients to keep a track of Growth and Spend \n\n \n\nSocial Media Traffic GA Alert (Dec 2015) - R \n\n  Automated  Email Alert to monitor Social Media Traffic as part of Conversion Rate Optimization (CRO) \n\nHobby Projects \n\n \n\niTunes Text Analysis Web App – R Shiny \n\nResponsive WebApp in RShiny using the package itunesr for iTunes AppStore Review Extraction and Analysis.  \n\nitunesr: To Access iTunes App Store Ratings and Reviews - R   \n\nTo enable 'iOS' App Developers to access iTunes App Store Ratings and Reviews using R.  \n\nQuote Tweeting Twitter Bot - R \n\nTwitter Bot (@Welcomequote) that automatically scrapes and tweets the ‘Quote of the day’ from Forbes with customized \n\nhashtags. \n\n \n\nText URL to Markdown Link Formatter - Python \n\nPython code to identify links/URL from a text file and Format it as required in Markdown to have inline Hyperlink. \n\nMOOCs Audience Profiling & Course Completion Performance - SAS   \n\nExtracted insights about the profile (age, gender, level of education, country) of students who take up online courses \n\nfrom public data released by EDX. \n\nGovernment \n\nCollege of \n\nTechnology \n\n \n\nAssociative Classification Data Mining for Detecting Phishing Websites - Weka \n\n  A simple classifier was built based on different association rules (URL & Domain Identity, Security & Encryption) to classify \n\nPhishing Websites from the training Dataset \n\nHOBBIES  \n\n Watching (MOOCs), Reading (Books/Blogs), Teaching (Kids/Students), Coding (FOSS) \n\n \n\nhttps://amrrs.shinyapps.io/itunesr_webapp/\nhttps://cran.r-project.org/web/packages/itunesr/index.html\nhttps://www.twitter.com/welcomequote\nhttps://github.com/amrrs/Txt2MdLinkFormatter\nhttps://github.com/amrrs/online-courses-analysis-sas","annotation":[{"label":["Skills"],"points":[{"start":6763,"end":6763,"text":"R"}]},{"label":["Skills"],"points":[{"start":6627,"end":6627,"text":"R"}]},{"label":["Skills"],"points":[{"start":6549,"end":6553,"text":"Weka "}]},{"label":["Skills"],"points":[{"start":6124,"end":6124,"text":"R"}]},{"label":["Skills"],"points":[{"start":6093,"end":6098,"text":"Python"}]},{"label":["Skills"],"points":[{"start":6084,"end":6089,"text":"Python"}]},{"label":["Skills"],"points":[{"start":6052,"end":6052,"text":"R"}]},{"label":["Skills"],"points":[{"start":5908,"end":5908,"text":"R"}]},{"label":["Skills"],"points":[{"start":5873,"end":5873,"text":"R"}]},{"label":["Skills"],"points":[{"start":5859,"end":5859,"text":"R"}]},{"label":["Skills"],"points":[{"start":5847,"end":5847,"text":"R"}]},{"label":["Skills"],"points":[{"start":5783,"end":5783,"text":"R"}]},{"label":["Skills"],"points":[{"start":5773,"end":5773,"text":"R"}]},{"label":["Skills"],"points":[{"start":5761,"end":5761,"text":"R"}]},{"label":["Skills"],"points":[{"start":5690,"end":5690,"text":"R"}]},{"label":["Skills"],"points":[{"start":5637,"end":5637,"text":"R"}]},{"label":["Skills"],"points":[{"start":5616,"end":5616,"text":"R"}]},{"label":["Skills"],"points":[{"start":5606,"end":5606,"text":"R"}]},{"label":["Skills"],"points":[{"start":5549,"end":5549,"text":"R"}]},{"label":["Skills"],"points":[{"start":5529,"end":5529,"text":"R"}]},{"label":["Skills"],"points":[{"start":5446,"end":5446,"text":"R"}]},{"label":["Skills"],"points":[{"start":5282,"end":5282,"text":"R"}]},{"label":["Skills"],"points":[{"start":5086,"end":5086,"text":"R"}]},{"label":["Skills"],"points":[{"start":5051,"end":5051,"text":"R"}]},{"label":["Skills"],"points":[{"start":5000,"end":5000,"text":"R"}]},{"label":["Skills"],"points":[{"start":4806,"end":4806,"text":"R"}]},{"label":["Skills"],"points":[{"start":4644,"end":4644,"text":"R"}]},{"label":["Skills"],"points":[{"start":4394,"end":4394,"text":"R"}]},{"label":["Skills"],"points":[{"start":4116,"end":4116,"text":"R"}]},{"label":["Skills"],"points":[{"start":3866,"end":3866,"text":"R"}]},{"label":["Skills"],"points":[{"start":3786,"end":3786,"text":"R"}]},{"label":["Skills"],"points":[{"start":3185,"end":3200,"text":"Google Analytics"}]},{"label":["Skills"],"points":[{"start":3167,"end":3167,"text":"R"}]},{"label":["Skills"],"points":[{"start":3004,"end":3004,"text":"R"}]},{"label":["Skills"],"points":[{"start":2952,"end":2952,"text":"R"}]},{"label":["Skills"],"points":[{"start":2665,"end":2665,"text":"R"}]},{"label":["Skills"],"points":[{"start":2457,"end":2457,"text":"R"}]},{"label":["Skills"],"points":[{"start":1760,"end":1760,"text":"R"}]},{"label":["Skills"],"points":[{"start":1575,"end":1575,"text":"R"}]},{"label":["Skills"],"points":[{"start":1460,"end":1460,"text":"R"}]},{"label":["Skills"],"points":[{"start":1047,"end":1047,"text":"R"}]},{"label":["Skills"],"points":[{"start":1033,"end":1033,"text":"R"}]},{"label":["Skills"],"points":[{"start":1026,"end":1026,"text":"R"}]},{"label":["Skills"],"points":[{"start":986,"end":1001,"text":"Google Analytics"}]},{"label":["Skills"],"points":[{"start":913,"end":913,"text":"R"}]},{"label":["Skills"],"points":[{"start":895,"end":900,"text":"Python"}]},{"label":["Skills"],"points":[{"start":892,"end":892,"text":"R"}]},{"label":["Skills"],"points":[{"start":827,"end":827,"text":"R"}]},{"label":["Skills"],"points":[{"start":757,"end":757,"text":"R"}]},{"label":["Education"],"points":[{"start":650,"end":684,"text":" BE (Computer Science Engineering) "}]},{"label":["Skills"],"points":[{"start":580,"end":580,"text":"R"}]},{"label":["Skills"],"points":[{"start":525,"end":525,"text":"R"}]},{"label":["Skills"],"points":[{"start":216,"end":216,"text":"R"}]},{"label":["Skills"],"points":[{"start":15,"end":15,"text":"R"}]},{"label":["Skills"],"points":[{"start":10,"end":10,"text":"R"}]},{"label":["Name"],"points":[{"start":0,"end":17,"text":"AbdulMajedRaja RS "}]}],"extras":null,"metadata":{"first_done_at":1532670211000,"last_updated_at":1532670211000,"sec_taken":139,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Adithya Konda \nH No: 5-101, Road No: 2, Kakatiya Nagar, Medipally, Hyderabad, Telangana - 500098, India \n\nE-mail: adithyak57@gmail.com, Mobile: +91 - (0) 9032717616 \n \n\nCAREER OBJECTIVE \n \n\n Looking to constantly update & advance my skills in the field of Data Science.  \n\n Seeking a challenging environment that encourages continuous learning, creativity & exposure to \nnew ideas which stimulates personal and professional growth.  \n\n \n\nAREAS OF EXPERTISE \n\n \nSecondary Research, R Programming, Tableau, Risk index, Data analysis, SWOT analysis, PEST \nanalysis, Exploratory Analysis, Porters five force analysis, Magic quadrant analysis, Consumer \ntrends, Competitive Intelligence and Report writing. \n\n \n\nSNAPSHOTS \n  \n\n A professional with 3+ years’ experience in Data Analysis & Strategic Consulting.  \n\n Successfully completed Certified Research Analyst (CRA) certification at IIPMR, USA. \n\n Certification on R Programming by Johns Hopkins University on Coursera.  \n\n Presently working as Analyst at Digital Insights Research Pvt. Ltd (Global Data) & Previously \nworked as Market Research Analyst at Peregrine Innowaytech Pvt ltd  \n\n \nWORK EXPERIENCE  \n\n\n   ORGANIZATION Digital Insights Research Pvt ltd (Global Data) \n\nPERIOD March 2016 - Present  \nDESIGNATION Analyst \n\n  \n Hands on experience in Data forecasting by Linear & multiple regressions, time-series analysis, \n\nand using various analysis tools like R & excel.   \n Designing statistical models for estimating and forecasting on various industry and economic \n\nrelated topics \n Managing the delivery of insightful and original market / product / company analysis in both \n\nquantitative (databases, models) and qualitative (profiles, presentations, reports) forms and \ntaking responsibility for their production to publishable standards.  \n\n Handling all the client queries on regular basis and also maintain quality standards of data.   \n Covering more than 150 countries macro indicators at different frequencies for time series and \n\nalso conducting analysis on various topics using qualitative and quantitative techniques.   \n Utilizing a good knowledge of competitor’s products in order to help shape and position the \n\nproduct.  \n Communicating regularly with team members in both formal presentations and informal on-the-\n\njob training.   \n Making sure that methods of data collection are effective and accurate.   \n Analyse complex data to bring out solutions for various scenarios.\n\n\n\n \n     ORGANIZATION Peregrine Innowaytech Pvt ltd \n\nPERIOD May 2014 – March 2016  \nDESIGNATION Market Research Analyst \n\n \n Conduct extensive primary and secondary market research using different data sources to analyse \n\nindustry drivers/ Market leaders, identify emerging opportunities and key challenges  \n Collect data from key people in the industry to get insights on different industries   \n Conduct market research to analyse the suppliers in the market, market trends and pricing   \n Analysing qualitative & quantitative information to support and review new and existing \n\nmarketing and sales strategies.   \n Preparing market research reports on specific products and Defining target markets and \n\nopportunities within them and also the need for adding new lines to existing products.   \n Investigate the economic conditions surrounding business activity such as industry trends and \n\ncompetition   \n Find the Supply, Demand, Production capacity of Suppliers/Manufacturers of products as \n\nrequested by clients.   \n Create RFI, RFQ, RFP to help clients procure the products at the right price and right quality   \n Develop appropriate Procurement strategy by means of research and analysis to help clients \n\nreduce cost in their Procurement spend   \n Responsible for Organizing, reviewing, analysing, editing and commissioning the literature, data \n\nand logs of various industrial reports that are obtained from various sources.   \n Working closely with internal departments to ensure smooth execution of all activities including \n\npreparation of various reports.   \n Developing relationships with key decision-makers in the organization for report development.   \n Conducting literature surveys and handling Study sample analysis as per Regulatory Guidelines.   \n Active participation in industry forums, client discussions, and conferences as a representative of \n\nthe organization in Hyderabad. Influential role in company initiatives for developing new projects.   \n Identifying PR opportunities for the company which would result in more visibility.   \n Identifying necessary distribution channels and partners to increase the product’s reach.   \n Familiar with databases such as D&B, Factiva, OneSource, Hoovers, Data Monitor, Bloomberg, \n\nICIS, RISI, Polymer update, CMAI, Reuters, EIU, Plastic news, IMS, metal prices, Asian metals, base \nmetals etc.  \n\n \n\n \n\n \nINTERNSHIP EXPERIENCE \n\n \nORGANIZATION Air India \nPERIOD May 2013 – June 2013  \nROLE  Service Marketing \n\n \n \n\nCustomer Adoption of Technology Based Self Services for Air India, Hyderabad \n \n\nThe internship involved market segmentation, evaluation of social media platforms for marketing \npurpose and carrying out promotional activities for Kiosk machine usage. The situational influence \non passenger’s actual choice between self-service and personal service for Air India and the \nimpact of past experiences on self-service technology by the passengers was studied.  \n\n\n\n \nACADEMIC CREDENTIALS \n \n\n \nDegree/ Year of \n\nSchool/Institute \nPercentage  \n\nExamination Passing /CGPA \n \n\n \n \n\nMBA ( Marketing 2014 \nDepartment of Management Studies, \n\n  7.20  \nNational Institute of Technology-Trichy  \n\n& Analytics)       \n \n\nB.Tech, ECE 2012 CVSR College of Engineering, Hyderabad     64.20 \n \n\n     \n\nClass XII 2008 SR Junior College, Hanamkonda, Warangal 93.70 \n \n\n     \n\nClass X 2006 St Mary’s High School, Jangaon, Warangal  91.00 \n \n\n \n \n\n \n\nPROFESSIONAL CERTIFICATION & TRAINING \n\n \n\n Certified Research Analyst (CRA) from IIPMR, USA  ( ID: INIIPMR16154 )  \n \n \n\nACADEMIC ACHIEVEMENTS \n\n\n\n Secured first position in Quiz on Road Safety Movement- \"SAFAR\"2005.   \n Secured first position at Divisional and district level on National Science Day- 28th FEB, 2006  \n Secured first position in Divisional Level Science Exhibition in 2005.   \n Served as School Pupil Leader of St Mary’s High School in 2005-2006.  \n \n\n \nKEY SKILLS AND COMPETENCIES \n\n\n\n Thorough knowledge of entire gamut of Market Research & adept at developing Comprehensive \nResearch Reports   \n\n Ability to work well with numbers and analyse complex data   \n In-depth knowledge of market research tools and databases   \n Ability to work in a structured and organized manner   \n Creative problem-solving skills and Accuracy/attention to detail   \n Good organizational and time-management skills  \n\n \n \nPERSONAL DETAILS \n\n  \nDate of Birth 20th May 1991 \nMarital Status Married \nLanguages English, Telugu and Hindi \n\n \nYours sincerely \n\n \n(Adithya Konda)","annotation":[{"label":["Location"],"points":[{"start":5743,"end":5751,"text":"Hyderabad"}]},{"label":["Education"],"points":[{"start":5564,"end":5566,"text":"MBA"}]},{"label":["Location"],"points":[{"start":5055,"end":5063,"text":"Hyderabad"}]},{"label":["Location"],"points":[{"start":4391,"end":4399,"text":"Hyderabad"}]},{"label":["Skills"],"points":[{"start":919,"end":931,"text":"R Programming"}]},{"label":["Skills"],"points":[{"start":786,"end":805,"text":"Strategic Consulting"}]},{"label":["Skills"],"points":[{"start":770,"end":782,"text":"Data Analysis"}]},{"label":["Skills"],"points":[{"start":483,"end":495,"text":"R Programming"}]},{"label":["Location"],"points":[{"start":67,"end":75,"text":"Hyderabad"}]},{"label":["Name"],"points":[{"start":0,"end":13,"text":"Adithya Konda "}]}],"extras":null,"metadata":{"first_done_at":1532672930000,"last_updated_at":1532672930000,"sec_taken":109,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Anish Mathur \n5-N-5, R C Vyas, \nBhilwara (Raj). \nContact No. - +91 962 463 1206 \nE-mail: ​anish.mathur007@gmail.com \n \nObjective \nDevelop; Innovate; keep up building and sharing my knowledge, skills and abilities for the best  \nbenefit of organization, giving a hand in the development of the IT industry. \n \nSummary of Qualifications \n\n● IT Professional with 7+ Years of experience in Software Development \n● In-depth knowledge of requirement analysis, design, develop and deployment \n● Experience in designing and architect application using tired, lambda and kappa architecture \n● Experience with NLP, machine learning, voice  assistant and data analytics \n● A systematic, organized, quick learner, hardworking and dedicated with an analytical bent of mind determined               \n\nto be a part of a growth-oriented organization \n● Professional always intense to learn research and implement new technologies \n● Professional with leadership skills, troubleshooting, communication, and prioritization with ability to create            \n\nand sustain high work tempo within the team \n● Proficient in web application development with open source technologies \n● Excellent understanding of agile development methodology \n● Experience in embedded systems, IOT, telephony, business intelligence, machine learning, AI, web application             \n\nand SaaS based applications \n● Proven ability to manage multiple projects with excellent organization skills \n● Ability to work independently and cross functions in a timely manner \n● Deep understanding of technology with focus on delivering business solutions \n \n\nTechnical Expertise \n● Extensive programming experience​ with Python, JavaScript, PHP, Lua and DJango \n● Frequent use of​ Python, shell script, JavaScript, PostgreSQL, Linux and SQL \n● Familiar with​ Tensorflow, Amazon Alexa, IBM Watson, Speech to Text, NLP, Apache Spark, Kafka, FreeSWITCH, \n\nSIP, VoIP, Elasticsearch, PostgreSQL, MySQL, HTML. CSS and NoSQL \n● Familiar with tools and technologies​ like Linux, Apache2, uWSGI, Nginx, Uniitest, Selenium, Build Systems, Log \n\nStash, Kibana,  ETL (GeoKettle) , GIT and SVN \n \n\nExperience \nMSBC Solutions, Ahmedabad (Gujarat) \nJuly 2017 – Present \nTech Lead \n \nResponsibilities: \n\n1. Responsible for developing application with open source technologies. \n2. Also evaluating designs, determining appropriate architectures, laying out and styling controls. \n3. Responsible for developing AI and Machine learning solutions like Alexa, chatbot, image reconisation, NLP, \n\ncomputer vision. \n4. Develop new tools, concepts, and technologies on data analytics using all available existing data from \n\ncomputer systems. \n5. Also developing POC’s based on AI and Machine Learning. \n6. Development team Management and technical guidance to teams. \n\nmailto:anish.mathur007@gmail.com\n\n\n \n \n\nProjects​: \nThermo Fisher Scientific (Alexa assistant skills), OmegaWeb,  Instruction Engine for Crown app (Speech to text), \nPersonal Assistant for OTAS app(Based on Alexa), Object recognizer for Crown mobile app(Image recognition), Chatbot \nfor Aecom. \n \nTechnologies​: \nPython, DJango, TensorFlow, Amazon Alexa, Alexa Custom Skills, Google Speech Recognition, NLP, Elasticsearch, Fuzzy \nSearch based on ES, IBM Watson. \n \nTrellissoft Engineering Services Pvt Ltd, Gandhinagar (Gujarat) \nDec 2016 – June 2017 \nProject Lead \nVavni Services Pvt Ltd taken over by TrellisSoft from Dec 2016. \n \nVavni Services Pvt Ltd, Gandhinagar (Gujarat) \nApr 2016 – Nov 2016 \nProject Lead \n \nResponsibilities: \n\n1. Work as part of an interdisciplinary team to achieve project milestones. \n2. Monitor workflow and make timeline adjustments as needed. \n3. Develop status reports, project estimates, and resource plans. \n4. Make vital decisions and drive decision-making across projects. \n5. Involved in System Designs and Architect \n6. Involved in feasibility study and suggesting technology requirements.  \n7. Involved in system development and deployment. \n8. Contributed to code development. \n9. Development team Management and technical guidance to teams. \n10. Handled Communication with clients and stakeholders. \n11. Followed Agile Methodology for software development using JIRA & other tools. \n\n \nProjects​: \nPatient Accounts Services (Collection Industry), Cashman Photo’s, Crowdz.io, Crowdz zSupplyChain \n \nVavni Services Pvt Ltd, Gandhinagar (Gujarat) \nApr 2013 - March 2016 \nSoftware Development Engineer \n \nIt was a startup when I joined. \nResponsibilities​: \n\n1. Understanding requirement and development. \n2. System Designs and Architect. \n3. Helping team members to solve the technical challenges. \n4. Providing ideas for the products. \n5. Application deployment. \n6. Handled communication with client and stakeholders. \n7. Write scalable system in both dimension. \n \n\n\n\nTechnologies​:  \nPython, DJango, PostgreSQL, NoSQL (Redis), Javascript (JQuery and AngularJS), Apache, uWSGI, Varnish, shell script \netc. \n \nProjects​: \nCrowdz.io, Smart Lock(POC), Auto CLI, Seagate SpyGlass / LaCie FUEL \n \nBuzzworks Business Services Private Limited, Noida (U.P) \nJan 2012 – Jan 2013 \nSoftware Developer \n \nThis was a startup company when I joined so handled various roles. \nResponsibilities​: \n\n1. Involved in feasibility study and suggesting technology requirements.  \n2. Involved in design and architecture of the systems. \n3. Involved in system development and deployment. \n4. Understanding requirement and development. \n5. Providing ideas for the products. \n\n \nTechnologies​: \nPython, Lua, Django, FreeSWITCH, NoSQL(Redis), PostgreSQL, NodeJS, libraries like ESL, ZMQ, curl, xmlrpc  etc. \n \nProjects​: \n\nFlexydial – Lite, Flexydial - Full Fledged and Exa Wealth IVR \n \n\n \nReadybytes Software Labs Pvt. Ltd., Bhilwara (Raj.) \nJan 2011 – Jan 2012 \nSoftware Engineer \n \nThis was a startup company when I joined so handled various roles. \nResponsibilities​: \n\n1. Hold whole ownership of the project, involved in the major part of coding and unit testing. Involved in the \nentire software development life-cycle \n\n2. Successful completion of the project way ahead of schedule \n3. Understanding requirement and development. \n4. Helping team members to solve the technical challenges. \n5. Providing ideas for the products. \n \n\nProjects​: \nPayPlans, JomSocial Profile Type (JSPT) and  JoomlaXi User Search (XIUS) \n\n \nTechnologies​: \nPHP, Joomla, Phing (Build system) based on ANT, PHPUnit, JQuery and Selenium \n \nEducation \n\n● MCA ​from​ ​Seedling College, Jaipur​ (Jaipur National University, Jaipur) ​with 68%​. \n● 'A' Level ​(Advanced Diploma) From DOEACC, New Delhi. \n● 'O' Level​ From DOEACC (Dept. of Electronics, Govt. of India) New Delhi. \n\n \n\n\n\nPersonal \nDate of Birth          :  Sep. 27​th ​, 1985 \nFather Name          :  Mr. Arun Mathur \nMarital Status        :  Married \nLanguage Known   :  English, Hindi \nHobby             :  Cricket, Internet Surfing, Music and Reading about technology. \nNationality              :  Indian \n\n \nDeclaration \n\nI hereby declare that information furnished above is true to the best of my knowledge. \n \nDate:                                                                                                                                                         (Anish Mathur) \nPlace: Gandhinagar, Guj.","annotation":[{"label":["Name"],"points":[{"start":7231,"end":7242,"text":"Anish Mathur"}]},{"label":["Education"],"points":[{"start":6450,"end":6452,"text":"MCA"}]},{"label":["Skills"],"points":[{"start":6403,"end":6406,"text":" PHP"}]},{"label":["Skills"],"points":[{"start":5529,"end":5538,"text":"FreeSWITCH"}]},{"label":["Skills"],"points":[{"start":5516,"end":5518,"text":"Lua"}]},{"label":["Skills"],"points":[{"start":5508,"end":5514,"text":"Python,"}]},{"label":["Skills"],"points":[{"start":4825,"end":4831,"text":"Python,"}]},{"label":["Skills"],"points":[{"start":3248,"end":3257,"text":"IBM Watson"}]},{"label":["Skills"],"points":[{"start":3200,"end":3203,"text":" NLP"}]},{"label":["Skills"],"points":[{"start":3138,"end":3150,"text":" Amazon Alexa"}]},{"label":["Skills"],"points":[{"start":3111,"end":3117,"text":"Python,"}]},{"label":["Skills"],"points":[{"start":2519,"end":2522,"text":" NLP"}]},{"label":["Skills"],"points":[{"start":1891,"end":1900,"text":"FreeSWITCH"}]},{"label":["Skills"],"points":[{"start":1884,"end":1888,"text":"Kafka"}]},{"label":["Skills"],"points":[{"start":1870,"end":1881,"text":"Apache Spark"}]},{"label":["Skills"],"points":[{"start":1864,"end":1867,"text":" NLP"}]},{"label":["Skills"],"points":[{"start":1837,"end":1846,"text":"IBM Watson"}]},{"label":["Skills"],"points":[{"start":1822,"end":1834,"text":" Amazon Alexa"}]},{"label":["Skills"],"points":[{"start":1755,"end":1764,"text":"JavaScript"}]},{"label":["Skills"],"points":[{"start":1733,"end":1739,"text":"Python,"}]},{"label":["Skills"],"points":[{"start":1706,"end":1712,"text":"DJango "}]},{"label":["Skills"],"points":[{"start":1698,"end":1700,"text":"Lua"}]},{"label":["Skills"],"points":[{"start":1692,"end":1695,"text":" PHP"}]},{"label":["Skills"],"points":[{"start":1681,"end":1690,"text":"JavaScript"}]},{"label":["Skills"],"points":[{"start":1673,"end":1679,"text":"Python,"}]},{"label":["Skills"],"points":[{"start":599,"end":602,"text":" NLP"}]},{"label":["Name"],"points":[{"start":0,"end":11,"text":"Anish Mathur"}]}],"extras":null,"metadata":{"first_done_at":1532685895000,"last_updated_at":1532685895000,"sec_taken":496,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Aravinda U.S\n\n\n\n\nSummary\n\n\n\n\n\n\nEducation\n\n\nTechnical Skills\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExperience\n\nSourcebits Pvt.Ltd(Dec 30th 2015 - Mar-2017)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAchumen Technologies Pvt.Ltd(Nov 5th 2012 –)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSaaranga Infotech LLP (15th November 2010 – 7th October -2012)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNyku Systems : Feb-2009-July-2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrainings Taken\n\n\n\n\n\n\n\n\n\n\n\nPersonal Details\n\n\tAssociate Technical Lead \n#72,“Mandara”,3rd Cross, 6th Main, 1st Block, Narayana  Nagar ,Bengaluru-560062 \narvind.aithal@gmail.com\n(+91)9901835835\nOverall 7.7 Years of IT Experience in Opensource Frontend Web Application Development, Integration and Deployment  in Linux servers.Working experience under integration of  Business Intelligence tool, CMS website integration, Application Deployment  in Cloud, Dedicated and Shared Servers. \n\nB.E. in computer Science ,VTU(2007)\n\n\nLanguages\nPython,PHP,HTML,CSS,Jquery,Javascript\n\nFramework\nDjango, Codeigniter, Drupal(CMS)\n\nDatabase\nPostgres, MySQL\n\nBI Tool\nJasper soft\n\nDeployment\nAWS(Cloud),Ubuntu and Debian (Dedicated Servers), Shared Servers.\n\n\n\n\nAssociate Technical Lead, Lemeno(Jun-2016- Mar-2017)\n· Backend Development using Django(Python Framework) with Postgres as Backend\n· REST API’s using django for Mobile platforms.\n· Hosted applications in AWS, RDS, Elasticache, S3.\n\n\nAssociate Technical Lead, HeyBnB (Jan-2016-Jun-2016)\n\n· Integration and development of REST API’s for Mobile Platforms \n· Backend with Yii Framework and MySql.\n· AWS server setup for the application hosting\n\n\n\nSenior Software Engineer, Saaramsha - Achumen Technologies, Jan 2014-Dec-15\n· Business Intelligence tool on cloud report creations and data capabilities.\n· Front end development in Codeigniter with MySql, with UI designed in HTML, CSS.\n· Integration of Jasper soft for BI capabilities.\n· Hosting on AWS cloud server and AWS Redshift\n\n\nSoftware Engineer, Dataconnect Online – Achumen Technologies, August-2013-Jan-2014\n· Online Advertising Management System allows users and franchise to earn money by posting ads.\n· Front end development in Codeigniter with MySql, HTML, CSS\n· Involved in Integration of Payment Gateway into the system.\n· Deployment  in Windows Server.  \n\nSoftware Engineer, MyOp – Achumen Technlogies Feb-2013-July-2013\n· Application is mainly based on customer service experience and  feedback system. System  built on Django with Mysql.\n· Involved in development of modules regarding moderation\n· Involved in hosting on AWS cloud server.\n\nSoftware Engineer, VTR Travels – Achumen Technologies\n· A travel website built on Drupal content management System.\n· Involved in integration  and deployment of  website.\n\nSoftware Engineer, Simple Learning – Achumen technologies\n· Website which has been developed for consulting organization which involves client size in the fields of Manufacturing, Retail, IT and ITES.\n· Technologies involved in development are : Drupal 7, Html 5 and CSS 3\n\n\nAssociate Software Engineer \n\n· Worked with integrating and developing Content Management System of version Drupal 6 and Drupal.\n· Sites for non profit organisations like United Way, Unity, American Redcross ,Humane Society , CFC etc.for several local and national chapters of United States and global chapters.\n· Built websites on multisite environment running in Linux with PHP5, MySql in dedicated servers of Debian and Ubuntu.\n· Given time to time Technical Support and maintenance for the issues raised by customers.\n· Integrated CiviCRM 3.4.8 to 4.2.2 version for most of the non profit organizations.\n· Integrated Secure Pages for serveral chapters of the United Way, Unity, Humane Society.\n· Integrated Ubercart module for several chapters of United Way and Unity.\n· Worked with the Drupal CMS system to build sites for clients of all sizes, including\n· eCommerce site, Non profits, Social networking sites like sampada, mysoreassociation , graam\n· Integrated SSL for several sites mainly for CiviCRM and Ubercart.\n· Experience includes Drupal 6/7, integrating theme using Zen, Omega, experience with CCK,Views and more.\n· Worked on migration of sites from server to server, installing new sites.\n· Worked integrating UI for android mobile application development.\n· Experience includes the knowledge of views, intents etc. in android application development.\n                  Sample sites are http://unitedwaytoledo.org/ http://cfcvp.org etc\n\n\nJanjeevan Foundation – Software Engineer\n· This website is an application for the children medical foundation. Features incorporated “mailing option” for the donors who helps the children having rare\n disorder and for the children education foundation.\n· “Member login facility” for the members to get the details and solutions of disorders from\n· doctors.\n· Involved in development through PHP, web page design through Html and CSS.\n Managed development, uploading site in server and maintenance.\n\nVideo memories - Software Engineer\n\n· Video memories is a site for uploading and downloading videos.\n· Involved in functionality testing, also included form validation and CSS issues.\n\nIP@Web - Software Engineer\n· Website is a personal profile of a politician called TM Umesh.\n· Involved in developing this project through Drupal 5, and Mysql using PHPMyadmin.\n· Features involved are Gallery integration, content creation using CCK etc.\n· Involved in site maintenance and support.Worked this project in WAMP environment\n\nTPSET – Php developer\n\n· Internal Application TPSET is a tool developed for employees of TPS organisation which contains the Employee details, Employee work status and leave management.\n· Involved in integrating and developing this through PHP, Mysql.Worked this project in WAMP environment.\n\n\n· VXL instruments - 2008  Internship for 3months\n\n· NIIT Jayanagar - 2010 3 months Diploma in dot net training includes, C# 3.5,ASP.net and MSSQL.\nProject undertaken here was to make a web portal using C#,Asp.net and MsSQL to create  online test application for the students UI included with HTML, Javascript and Jquery. \n· Master skills - 2010  1 month Android Application Development.\n\n\n\nDOB : 24-08-1984","annotation":[{"label":["Skills"],"points":[{"start":6065,"end":6070,"text":"Jquery"}]},{"label":["Skills"],"points":[{"start":6044,"end":6047,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":5698,"end":5700,"text":"PHP"}]},{"label":["Skills"],"points":[{"start":5285,"end":5287,"text":"PHP"}]},{"label":["Skills"],"points":[{"start":5108,"end":5110,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":4866,"end":4868,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":4828,"end":4830,"text":"PHP"}]},{"label":["Skills"],"points":[{"start":3359,"end":3361,"text":"PHP"}]},{"label":["Skills"],"points":[{"start":2975,"end":2977,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":2148,"end":2150,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":2142,"end":2145,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":1808,"end":1810,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":1802,"end":1805,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":1222,"end":1227,"text":"Python"}]},{"label":["Skills"],"points":[{"start":943,"end":948,"text":"Jquery"}]},{"label":["Skills"],"points":[{"start":939,"end":941,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":934,"end":937,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":930,"end":932,"text":"PHP"}]},{"label":["Skills"],"points":[{"start":923,"end":928,"text":"Python"}]},{"label":["Education"],"points":[{"start":875,"end":877,"text":"B.E"}]},{"label":["Location"],"points":[{"start":525,"end":533,"text":"Bengaluru"}]},{"label":["Name"],"points":[{"start":0,"end":11,"text":"Aravinda U.S"}]}],"extras":null,"metadata":{"first_done_at":1532688273000,"last_updated_at":1532688273000,"sec_taken":160,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Ashok Bole\nEmail: ashok.bole7@gmail.com\t\t          Mobile:- +91-9742888783\nCareer objective\t\n\nA challenging position in data analytics and machine learning, providing an effective and efficient solution that will assist organization to get the finest solutions to the business problems which could increase productivity and delight\nCustomers as well as enhance my data science skills.\nSummary\n\n· Software Engineer with 3.7 years of overall Experience, with 2+ years of experience in Analytics Domain.\n· Exposure to statistical concepts like univariate, bivariate, multivariate analysis, Hypothesis, P value, Central Limit theorem, Inferential ,predictive and descriptive statistics. \n· Exposure to data cleansing techniques like outlier treatment, missing value treatment etc.\n· Exposure in Multivariate Analysis Techniques (Linear & Logistic Regression, SVM, Decision trees, Random Forest Principal component Analysis and Associate rule Learning).\n· Proficiency in R programming and R packages.\n· Exposure to data visualization using various visualization charts like scatterplots, barplots, histograms,Shiny.ino ggplots etc.\n· Exposure to importing data from external files, external databases into R environment.\n· A team player with the strong communication and interpersonal skills. Contributed effectively to the achievement of team goals.\n· A quick learner with the ability to work under pressure and meet deadlines.\n· Ability to work independently and cross functions in a timely manner.\n· Good presentation skills with distinguished abilities of team building and taking initiatives; self-motivated, fast learner, coordinate effectively across levels/ multi-location teams.\n· High capability to quickly learn new technology and adapt to a new environment.\n· Proven ability to manage multiple projects with excellent organization skills.\n\nProfessional Experience\nSoftware Engineer                                              CGI Bangalore                                         Jan 2015 – Till date\n1. Insurance policy purchase prediction:\nClient: Leading Insurance Company\nPOC Description:\nThe main goal of this project is to predict the exact car insurance options purchased by individual customers. And using customer’s shopping history; we need to predict what policy a new customer will end up choosing.\nRole Description:\n· Involved in Data Exploration and Visualization.\n· Feature Engineering on the data set and created new additional features using transformations or combinations of features.\n· Involved in creating data visualization charts.\n· Clustering on featured data set to find out the different patterns in the data.\n· Presenting the Analysis and insights to client in weekly calls and enhanced the analysis and Insights generation based on Change Request.\n· Developed logistic regression model for predicting which customers would change from their final quote.\n· Developed a RandomForest model to find out which car insurance options and coverage information a customer will end up choosing.\nTools Used:  R, Machine Learning Algorithms – Logistic regression, Multinomial logistic regression, Random Forest.\n2. Car Insurance Campaign:\nClient: Leading Insurance Company\nProject Description: OP organizes regular campaigns to attract new clients. The bank has potential customers’ data, and bank’s employees call them for advertising available car insurance options. They have provided with general information about clients as well as more specific information about the current insurance sell campaign (communication, last contact day) and previous campaigns. The main goal of this project is to predict for the customers who were contacted during the current campaign, whether they will buy car insurance or not.\nRole Description:\nDeveloped a Decision tree model whether they will buy car insurance or not, and did Statistical significance testing using R. \n3. Employee attrition:\nPOC Description: Employee turnover (attrition) is a major cost to an organization, and predicting turnover is at the forefront of needs of Human Resources (HR) in the organization. Some costs are tangible such as training expenses and the time it takes from when an employee starts to when they become a productive member. So with advances in machine learning and data science, predicted the employee attrition by understanding the key variables that influence turnover. \nRole Description:\n· Importing data from MySQL into R.\t\n· Involved in creating data visualization charts.\n· Created Scatter plots, line charts.\n· Interacting with SQL Server to retrieve data from database. Performed Data Manipulations such as SELECT, INSERT, UPDATE, DELETE etc.\n· Developed a Decision tree model to find out the significant factors which influence turnover.\n· Developed logistic regression model to predict Employee attrition.\n\nAssociate Software Engineer                                CGI, Bangalore                                         June 2014 –Jan 2015\nClient: Leading Insurance Company in Finland\nTools used:  DB2, Legacy technologies\t\t\t\t\t\nJob Responsibilities:\n· Analyzing and providing estimates for new projects or enhancements.\n· Requirements clarification if necessary through client interaction and meetings with Business analysts.\n· Analyzing and designing the technical specification document for any new project.\n· Code development work for a new project or an enhancement.\n· Unit testing and Peer code review.\n· Providing QA support to the testers.\n· Support after the production deployment.\n· Assisting the team members on need basis.\n· Involved in knowledge transfer to the new joiners within the team.\nProfessional and Academic Achievements \n\n· Best Team CORONA Award for Year 2017 Q2.\n· Got the Best team player award.\n· Twice, got the pat on the back award.\n· Got the top rating during appraisal cycles, every year.\n\nAcademic Profile \n\nBachelor of Technology, Electrical and Electronics Engineering, April 2013\nSree Vidyanikethan Engineering College, JNTU Anantapur, Tirupati, Andhra Pradesh.\tPercentage: 78.06%\n\nTechnical Skills \n\nProgramming Languages\t   : R, Basics in Python, SQL\nDatabase\t\t\t   : MySQL, DB2\nMachine learning algorithms: Supervised Learning (Logistic Regression, Linear Regression, SVM, Decision Trees, Random Forests, and Naïve Bayes etc.) Un-Supervised Learning (K-Means, Hierarchal, PCA)\nStatistics: Mathematics/statistical modelling, Hypothesis Testing, Chi-Square test, ANOVA.","annotation":[{"label":["Skills"],"points":[{"start":6245,"end":6245,"text":"R"}]},{"label":["Skills"],"points":[{"start":6212,"end":6212,"text":"R"}]},{"label":["Skills"],"points":[{"start":6193,"end":6193,"text":"R"}]},{"label":["Skills"],"points":[{"start":6125,"end":6127,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":6103,"end":6105,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":6095,"end":6100,"text":"Python"}]},{"label":["Skills"],"points":[{"start":6082,"end":6082,"text":"R"}]},{"label":["Education"],"points":[{"start":5859,"end":5880,"text":"Bachelor of Technology"}]},{"label":["Skills"],"points":[{"start":5678,"end":5678,"text":"R"}]},{"label":["Skills"],"points":[{"start":5142,"end":5142,"text":"R"}]},{"label":["Skills"],"points":[{"start":5052,"end":5052,"text":"R"}]},{"label":["Skills"],"points":[{"start":4636,"end":4636,"text":"R"}]},{"label":["Skills"],"points":[{"start":4544,"end":4546,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":4433,"end":4433,"text":"R"}]},{"label":["Skills"],"points":[{"start":4424,"end":4426,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":4382,"end":4382,"text":"R"}]},{"label":["Skills"],"points":[{"start":4067,"end":4067,"text":"R"}]},{"label":["Skills"],"points":[{"start":4055,"end":4055,"text":"R"}]},{"label":["Skills"],"points":[{"start":3883,"end":3883,"text":"R"}]},{"label":["Skills"],"points":[{"start":3742,"end":3742,"text":"R"}]},{"label":["Skills"],"points":[{"start":3121,"end":3121,"text":"R"}]},{"label":["Skills"],"points":[{"start":3034,"end":3034,"text":"R"}]},{"label":["Skills"],"points":[{"start":2904,"end":2904,"text":"R"}]},{"label":["Skills"],"points":[{"start":2775,"end":2775,"text":"R"}]},{"label":["Skills"],"points":[{"start":2319,"end":2319,"text":"R"}]},{"label":["Skills"],"points":[{"start":1201,"end":1201,"text":"R"}]},{"label":["Skills"],"points":[{"start":984,"end":984,"text":"R"}]},{"label":["Skills"],"points":[{"start":966,"end":966,"text":"R"}]},{"label":["Skills"],"points":[{"start":876,"end":876,"text":"R"}]},{"label":["Skills"],"points":[{"start":843,"end":843,"text":"R"}]},{"label":["Name"],"points":[{"start":0,"end":9,"text":"Ashok Bole"}]}],"extras":null,"metadata":{"first_done_at":1532680049000,"last_updated_at":1532680049000,"sec_taken":117,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "ASHUTOSH MUDGAL    Linkedin : https://www.linkedin.com/in/ashutosh-mudgal-697b4930/ \n\nMobile: 09414746956   \n\nE-Mail: ashutoshmudgal66@gmail.com Github : https://github.com/ashutoshmudgal66 \n \nJOB OBJECTIVE \n\n   Data Science/Data Analytics \nA proactive and fast learning individual seeking an opportunity to work as a dynamic data scientist utilizing \n\nanalytical & methodical skills and relevant expertise to help the company achieve business goals while sticking to \nvision, mission and values. \n\nPROFILE SUMMARY \n \n\n PGDDS (Data Science/Analytics ) from Manipal Global Of Data Science, Manipal University Bangalore specializing in:- \nData Science  SQL/R/PYTHON/HADOOP   Business             \nStatistical Analysis                  Machine Learning/Data Visualization                 Text Analytics/NLP analytics \nSentimental Analytics  NLTK/SCKIT LEARN    TIME SERIES MODELING \nFORECASTING   Marketing Analytics    HR Analytics \n\n \n\n MBA( FINANCE)  from Vardhman Mahaveer University. \n B.Tech. with HONOURS\n Skilled in using software like Tableau, R,PYTHON and SQL Language \n Expertise in preparing & analysing the data using R studio ,Python Anaconda 3(spyder)  as well as advanced tableau so as \n\nto interpret the data and to present the same before the management for future decision making \n Experienced in establishing processes & SOPs, streamlining workflow and creating environment to enhance productivity  \n \nORGANISATIONAL EXPERIENCE Total 3 YEARS EXPERIENCE \n \nSince July’17:                              Tarah Technologies (Artificial Intellegance)  \nDesignation:                              Machine Learning Engineer  \n \nSince Jan’16 to Mar’16:              Intex Technologies \nDesignation:                              Production engineer \n \nSince Oct ’14 to Oct ’15:             Kota Super thermal Power Station ,KOTA(RAJASTHAN) \nDesignation:              Operations (Graduate Apprenticeship Engineer Trainee) \nKey Result Areas:   \n\n Data analysis of online system parameters pertaining to production and execution of prescriptive \nrecommendations to ensure availability of system and improvement of production process.  \n\n Handling the Control Desk System and trouble shooting. \n Data visualization, predictive modeling \n Analysis of real time data obtained through DCS (Distributed Control System) to improve power generation. \n\n \nSince Sept ’12 to Sept ’14:         ILJIN ELECTRONICS ,GREATER NOIDA(NCR) \n\nDesignation:               QUALITY ASSURANCE(Engineer) \n\n \nACADEMIC PROJECTS \n   \nHR ANALYTICS PROBLEM \n\nProblem Statement: predictive modelling technique to predict the Leaver Status. \nSolution: Used tools like R and Tableau to analyses and visualize the dataset and build dashboard and using machine learning \n\nlogistic regression for prediction. \n\n \n\nODI Batting Analysis \n\nProblem Statement: Analyzing and Visualizing ODI dataset to find various underlying trends and insights. \n\nSolution: Used tools like R and Tableau to analyses and visualize the dataset and build dashboard and a story for the same. \n\n \n\nBank Consumer Complaint Analysis \n\nProblem Statement: Analyzing and Visualizing Bank Consumer Complaint dataset to find various underlying trends and \n\ninsights.  \n\nSolution: Used tools like R and Tableau to analyze and visualize the dataset and build dashboard and a story for the same. \n\n \n\nNarendra Modi Tweet Analysis \n\nProblem Statement: Extracting, Analyzing and Visualizing Narendra Modi tweets to find various underlying trends and insights \n\nin the data.  \n\nCertification completion of course Data Analytics by IIIT-  BANGALORE & UpGrad\n\nIntelligence/TABLEAU\n\nfrom Presidency College Of Engineering, Kota.\n\nTableau : https://public.tableau.com/profile/ashutosh7396#!/\n\n\n\nSolution: Used tools like R and Tableau to analyse and visualize the dataset and build dashboard and a story for the same. \n\n \n\nLaptop battery life \n\nSolution: -First checked the data set for missing value, then plotted the data to see the trend of data. Based on that provided the \n\nsolution how much battery will last. \n\n \n\nBreast cancer dataset \n\nregression. Compare the results of all these model and predicted that naivebayes is giving 99.25% accuracy followed by \n\nrandomforest 98.51%. \n\n \n\n \nEDUCATION \n\n POST GRADUATION (DATA SCIENCE) from Manipal Global Academy Of Data Science, Bengalore.  \n MBA(finance) from Vardhman  Mahavir University,Kota,Pursuing. \n B.Tech. (Electronics & communication Engineering) from Presidency College , kota in 2012 with 70.19% \n\n 12th from RBSE Board, Kota in 2008 with 62.12% \n 10th from RBSE Board, Kota in 2006 with 75.13% \n\n \nIBM –BDU CERTIFICATIONS \n\n R 101 \n Data science 101, \n Predictive Modeling Fundamentals I, \n Hadoop Foundations - Level 1 (HADOOP 101), \n MapReduce and YARN, \n\n \n \n\nSUMMER TRAINING \n\nDCM SHRIRAM CONSOLIDATED LIMITED, Kota  \n\nDuration: 45 Days  \n\n \n EXTRA CURRICULAR ACTIVITIES \n Won and Participated in the college Hackthon 2017(data visualization).   \n Participated in the Cultural and Sports activities in College \n Event manager for Annual functions. \n Volunteer in Technical festival in Feb,2012 \n Participated in Technical festival ‘SHAKSHAM’ of Bikaner Govt. College. \n\n \nIT SKILLS \n \nDatabase Management   :  MS-Excel,  R Language, Tableau, PYTHON Language, SQL,HADOOP,MongoDb  \nOperating System             :  Windows (XP, Vista, Win-7/8) \n\n \n \nPERSONAL DETAILS  \n \nDate of Birth  : 8th Feb 1991 \nTemporary Address          :               JP Nagar, Bangalore-452005 (KARNATAKA)     \nPermanent Address          :               House no 980 ,Mahaveer nagar 2 ,kota,Rajasthan                                                                   \nLanguages Known :              English, Hindi  \n\nSolution: -Used different classification model on given data set like KNN, Rpart, Ctree, Randomforest, Naive bayes and Logistic \n\nCertification completion of course Data Analytics by IIIT BANGALORE &  UpGrad","annotation":[{"label":["Skills"],"points":[{"start":5909,"end":5909,"text":"R"}]},{"label":["Skills"],"points":[{"start":5803,"end":5803,"text":"R"}]},{"label":["Skills"],"points":[{"start":5789,"end":5789,"text":"R"}]},{"label":["Skills"],"points":[{"start":5588,"end":5588,"text":"R"}]},{"label":["Skills"],"points":[{"start":5494,"end":5494,"text":"R"}]},{"label":["Location"],"points":[{"start":5473,"end":5482,"text":" Bangalore"}]},{"label":["Skills"],"points":[{"start":5371,"end":5371,"text":"R"}]},{"label":["Skills"],"points":[{"start":5292,"end":5299,"text":"MongoDb "}]},{"label":["Skills"],"points":[{"start":5285,"end":5290,"text":"HADOOP"}]},{"label":["Skills"],"points":[{"start":5281,"end":5283,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":5264,"end":5270,"text":"PYTHON "}]},{"label":["Skills"],"points":[{"start":5255,"end":5261,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":5243,"end":5243,"text":"R"}]},{"label":["Skills"],"points":[{"start":4875,"end":4875,"text":"R"}]},{"label":["Skills"],"points":[{"start":4869,"end":4869,"text":"R"}]},{"label":["Skills"],"points":[{"start":4868,"end":4868,"text":"R"}]},{"label":["Skills"],"points":[{"start":4863,"end":4863,"text":"R"}]},{"label":["Skills"],"points":[{"start":4802,"end":4802,"text":"R"}]},{"label":["Skills"],"points":[{"start":4800,"end":4800,"text":"R"}]},{"label":["Skills"],"points":[{"start":4784,"end":4784,"text":"R"}]},{"label":["Skills"],"points":[{"start":4781,"end":4781,"text":"R"}]},{"label":["Skills"],"points":[{"start":4764,"end":4764,"text":"R"}]},{"label":["Skills"],"points":[{"start":4751,"end":4751,"text":"R"}]},{"label":["Skills"],"points":[{"start":4732,"end":4737,"text":"HADOOP"}]},{"label":["Skills"],"points":[{"start":4633,"end":4633,"text":"R"}]},{"label":["Skills"],"points":[{"start":4616,"end":4616,"text":"R"}]},{"label":["Skills"],"points":[{"start":4564,"end":4564,"text":"R"}]},{"label":["Skills"],"points":[{"start":4514,"end":4514,"text":"R"}]},{"label":["Skills"],"points":[{"start":4249,"end":4249,"text":"R"}]},{"label":["Skills"],"points":[{"start":3762,"end":3768,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":3756,"end":3756,"text":"R"}]},{"label":["Skills"],"points":[{"start":3666,"end":3672,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":3584,"end":3584,"text":"R"}]},{"label":["Skills"],"points":[{"start":3247,"end":3253,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":3241,"end":3241,"text":"R"}]},{"label":["Skills"],"points":[{"start":2953,"end":2959,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":2947,"end":2947,"text":"R"}]},{"label":["Skills"],"points":[{"start":2655,"end":2661,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":2649,"end":2649,"text":"R"}]},{"label":["Skills"],"points":[{"start":2533,"end":2533,"text":"R"}]},{"label":["Skills"],"points":[{"start":2520,"end":2520,"text":"R"}]},{"label":["Skills"],"points":[{"start":2506,"end":2506,"text":"R"}]},{"label":["Skills"],"points":[{"start":2476,"end":2476,"text":"R"}]},{"label":["Skills"],"points":[{"start":2432,"end":2432,"text":"R"}]},{"label":["Skills"],"points":[{"start":2422,"end":2422,"text":"R"}]},{"label":["Skills"],"points":[{"start":2417,"end":2417,"text":"R"}]},{"label":["Skills"],"points":[{"start":2408,"end":2408,"text":"R"}]},{"label":["Skills"],"points":[{"start":1939,"end":1939,"text":"R"}]},{"label":["Skills"],"points":[{"start":1842,"end":1842,"text":"R"}]},{"label":["Skills"],"points":[{"start":1470,"end":1470,"text":"R"}]},{"label":["Skills"],"points":[{"start":1463,"end":1463,"text":"R"}]},{"label":["Skills"],"points":[{"start":1445,"end":1445,"text":"R"}]},{"label":["Skills"],"points":[{"start":1427,"end":1427,"text":"R"}]},{"label":["Skills"],"points":[{"start":1134,"end":1134,"text":"R"}]},{"label":["Skills"],"points":[{"start":1068,"end":1070,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1057,"end":1063,"text":"PYTHON "}]},{"label":["Skills"],"points":[{"start":1055,"end":1055,"text":"R"}]},{"label":["Skills"],"points":[{"start":1046,"end":1052,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":1010,"end":1010,"text":"R"}]},{"label":["Skills"],"points":[{"start":919,"end":919,"text":"R"}]},{"label":["Skills"],"points":[{"start":883,"end":883,"text":"R"}]},{"label":["Skills"],"points":[{"start":866,"end":866,"text":"R"}]},{"label":["Skills"],"points":[{"start":853,"end":853,"text":"R"}]},{"label":["Skills"],"points":[{"start":665,"end":670,"text":"HADOOP"}]},{"label":["Skills"],"points":[{"start":656,"end":656,"text":"R"}]},{"label":["Skills"],"points":[{"start":652,"end":654,"text":"SQL"}]},{"label":["Location"],"points":[{"start":608,"end":617,"text":" Bangalore"}]},{"label":["Education"],"points":[{"start":521,"end":552,"text":"PGDDS (Data Science/Analytics ) "}]},{"label":["Skills"],"points":[{"start":512,"end":512,"text":"R"}]},{"label":["Skills"],"points":[{"start":500,"end":500,"text":"R"}]},{"label":["Name"],"points":[{"start":0,"end":14,"text":"ASHUTOSH MUDGAL"}]}],"extras":null,"metadata":{"first_done_at":1532689407000,"last_updated_at":1532689407000,"sec_taken":112,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Curriculum vitae      \n \n\nCareer Objective: \n \nTo associate with an organization, that gives me an opportunity to prove my capabilities, analytical skills \nas well as to apply my technical knowledge to explore & excel the practical world which in turn results in \nachievement of individual as well as organizational goals. \n\n \n\nBhavik Patel \n \nE mail: \nbhavike3781@yahoo.com \n \nMob: +91 9998605385 \n \nPresent Address \n \n19/112 Pragatinagar Flats, Near \nPragatinagar BRTS Corridor, \nNaranpura, Ahmedabad-380001 \n \nPersonal Information \n \n\nDate of Birth     : 12-02-1991 \nGender             : Male \nNationality        : Indian \nMarital Status   : Single \n \n\nLanguages       : English, Hindi, \nKnown               Gujarati \n \n                            \n\nArea of interest : Data Science,                                                             \nMachine Learning \nand Big Data \nAnalytics \n\n \nHobbies           : Mountaineering n                     \n\nTrekking, Solving \nPuzzles, Music \n\nProfessional Experience  \n\n Working as Machine Learning Analyst at Capitaworld Global Pvt \nLTD, Ahmedabad since Sep’17 \n\n Working as a Data Scientist at Tata Consultancy Services LTD, \nMumbai since Jan’17. \n\n Worked as a Business Analyst at Tata Consultancy Services LTD \n(KPO), Vadodara (July’14- Dec’16) \n\n \nTechnical Expertise \n\n \nOperating Systems: WindowsXP/7/8/10, Linux (Ubuntu 14) \n \nProgramming Languages: R, Base SAS, SQL, Python \n                      \nPackages & Tools: MS Office, Rapid Miner/KNIME, Tableau, Talend \n \nDatabases: Oracle, MySQL, MongoDB (NoSQL) \n \nAreas of Interest \n\n \n Machine Learning, Data Mining and Big Data Analytics,Market- \n\nResearch, Business, Retail/ Manufacturing/ Finance Domains \n \n\n  Education \n\n \n M.sc in Statistics from The M. S. University of Baroda, Gujarat \n\nfrom year 2014. \n \n B.sc in Statistics, from The M. S. University of Baroda, Gujarat \n\nfrom year 2012. \n \n\n Completed MOOC course in Big Data Analytics like Hadoop and its \nEcosystems (HDFS/Pig/Hive/Spark) and Tableau  \n \n\n  Workshops and Seminars: \n\n \n Attended National Big Data Workshops by IEEE Baroda Chapter \n\n1. Big Data, Hadoop and Map-Reduce Technology” \n2. Machine Learning and Spark MlLib \n\n Presented Seminar on “Assigning Credit Rating in Statistical \nAspects”. \n\n Presented Seminar on “Supply Chain Management”. \n\n\n\n     \n \n       \n \n               SUMMARY \n\n A Post graduate in Statistics & Graduate degree in Statistics with 3.5+ \nyears of experience in the field of Data Science/ Machine Learning in \nvarious domain like CPG-FMCG, Aerospace Manufacturing and Finance \nTechnology. \n\n A dynamic professional having strong analytical & communication skills \n\nwith detail-orientation and quality-focus to Business clients. \n\n Capable of working with Statistical Modelling/ Machine learning techniques \n\nand effectively handled large datasets to draw insights through Descriptive \n\n& inferential Analysis. \n\n \nProjects Undertaken At Professional Level at Capitaworld Global Pvt Ltd: \n \n\n \n \n\nTEAM SIZE:  4 \n \nNo. of Projects: 1 \n \nINVOLVEMENT: \n- Data Cleaning & Preparation \n- Analyzing data  \n- Model build & Validation \n \nSoftware/ Tools:  \n -    Excel \n -    R & R-Studio \n -    Python & Jupyter \n\nMachine Learning Analyst \n\nIn-house Research Development \n\n \nProduct Summary: \n\n Product: Algo Trading (HFT- High Frequency Trading) for NSE \n\n Predict stock price for every next 5sec \n\n Generate sentiment scores for business market news and build for \nimpact on stock prices \n\n Predict momentum of stock price based on 25+ technical indicators and \ncandle-stick patterns \n\n \n\nPackages: R: readxl, RODBC, tidy-verse, tm                                        \nPython: numpy, pandas, scikit-learn, NLTK, beautiful-soup \n\n \n \nProjects Undertaken At Professional Level at Tata Consultancy Services Limited: \n \n \n\n \n \n\nTEAM SIZE:  4 \n \nNo. of Clients: 1 \n \nNo. of Projects: 1 \n \nINVOLVEMENT: \n- Analyzing data  \n- Data extraction \n- Sample management \n- Data Cleaning & Preparation \n- Model build & Validation \n \nSoftware/ Tools:  \n -    Excel \n -    R & R-Studio \n -    Python & Jupyter \n -    Talend Big Data Platform \n -    Talend Data Preparation \n -    Teradata & MongoDB \n -    Tableau \n \n \n \n\nData Scientist (Material Services Analytics) \n\nClient: Boeing, USA. \n\n \nProject Summary & Responsibilities: \n\n Problem: Need to create a comprehensive 360 view of customer \n\npurchasing behavior by providing dashboard using Tableau \n\n wide variety of datasets of inconsistent format (size, type, frequency, \nsources) \n\n MyBoeingFleet.com, B2B site and ILS-a Boeing Company have large \namount of data in form of surveys filled by customers and part number & \nother information searched by customers \n\n Solution: Provided Solution approach for self-service data analysis to \n\ngrow parts sales. \n\n Configuration Data wrangling tool (Talend Data Preparation & Big Data \nPlatform) for operationalization (Input, temp storage, Output etc.) \n\n Script development for customized activities like format change & \naccuracy validation in R & Python \n\n MongoDB database creation as a storage after processed inconsistent \ndatasets and generate tableau reports \n\n Solution provided using feature engineering and text analytics/ NLP \ntechniques like Bag-of-words, N-gram, Word2Vec, GloVe etc. \n\n \n\nPackages: R: readxl, RODBC, dplyr, reshape, tidyr, tm                                        \nPython: numpy, pandas, scikit-learn, NLTK, beautifulsoup \n\n\n\n \n \n\nTEAM SIZE:  3 \n \nNo. of Clients: 1 \n \nNo. of Projects: 2 (MSci & GMO) \n \nINVOLVEMENT: \n- Sample Design & Universe \n\nUpdate \n- Analyzing data  \n- Data extraction \n- Sample management \n- Data Cleaning & Preparation \n- Model build & Validation \n \nSoftware/ Tools:  \n -     Advanced Excel \n -     SAS \n -     R & R-Studio \n -     Python & Anaconda \n -     KNIME Analytics \n -     PL/SQL & SQL Developer \n -     Retail Factory (Nielsen Tool) \n \n \n \n\nBusiness Analyst (Statistics COE) \n\nClient: The Nielsen Company Pte Ltd (Singapore). \n\nMarket Country: Philippines, Malaysia, Singapore \n\n \nProject Summary & Responsibilities: \n\n Setup panel and Universe update. \n\n The quality & consistency of volumetric and causal (promotional) format \nof sales data is validated for multipacks, price checks, outliers, shelf-\nspace and baselines in order to calculate market facts like market share, \nsales value and sales volumes and expected incremented sales from \npromotions etc. \n\n Quality Check, Trend Check, suggest correction by doing Simulation and \nImpact Analysis \n\n Review Sample Compliance and Market break down report by calculating \nRSE \n\n Outlier Detection, Missing Value Imputation \n\n Back Trend Modelling & Regression Analysis for developing Market mix \nmodels based on accuracy matrix \n\n Dashboard  \n\n Forecast coverage and derive media ROI at optimum business strategy \n \n\nPackages: R: readxl, readr, RODBC, dplyr, reshape, caret, tm,                                             \nsample, stringr/stringi, shiny, ggplot2 \n\nPython: xlrd/xlwt, numpy, pandas \n \nAchievements: \n\n- Awarded Star Performer of the Month from TCS \n- Awarded Individual Spirit of the team (Gold) from Nielsen for 45% \n\nproductivity gain by automating the BAU tasks using R programming. \n\n- Successfully Completed internal Lean Six Sigma Project by automate the \nmonthly KPI Generation Report.  \n\n \n \nProjects Undertaken In Academia (M.sc) : 1 \n \n \n\n \n \n\nTEAM SIZE:  4 \n \nSOFTWARE:  \n -  R & R-Studio \n -  Rapid Miner \n \nINVOLVEMENT: \n- Data Collection & Network \n\nSetup \n- Data Mining and Analysis  \n- Generating Tables and Graphs \n- Preparing Report \n \n \n\nProject:  Network Traffic Analysis \n\nSite:  Computer Lab, The M S University of Baroda. \n\nStatistical tools used: Data Mining, Frequent Pattern Mining, Association \n\nRules Mining, Clustering, Classification (CART/CHAID/randomforest), \n\nAppropriate Tests based on objectives. \n\nSkills used: Data collection(By Wireshark), Computer programming (R, \n\nRapid miner, Sql developer), Statistical analysis, Statistical interpretation \n\nResponsibilities:  \n\n Protocol/Packets Exploratory Analysis like average count/size/delta-time \nof packets \n\n Analyzing packet/protocol behavior  \n\n Identify most frequent URLs (IP addresses) visited by users using \nfrequent pattern mining analysis \n\n Network anomaly detection by fitting classification model (rpart/naïve \nbayes) \n\n \n \nProjects Undertaken in Academia (M.sc): 2 \n \n \n\n\n\n \n \n\nTEAM SIZE:  4 \n \nSOFTWARE:  \n -  Excel \n -  MS Word \n \nINVOLVEMENT \n- Data Collection \n- Analyzing \n- Generating Tables and Graphs \n- Preparing Report \n \n \n\nProject: Acceptance of E-Banking among Customers in      \nVadodara City.  \n\nSite:  Vadodara City (Major 4 wards) \n\nStatistical tools used: Multi-stage cluster sampling, Graphical \n\nRepresentation (By various kind of graphs), Extrapolation, Correlation and \n\nAssociation Tests  \n\nSkills used: Data collection (By Questionnaire), Statistical analysis, \n\nStatistical interpretation. \n\n \n\n \n \n\n \n\nDECLARATION : \n \n\n \nI hereby declare that all the information provided above is true to the best of my knowledge. \n\n \n\nDate:   /   /         Bhavik Patel \n\nPlace:  Vadodara","annotation":[{"label":["Location"],"points":[{"start":9151,"end":9158,"text":"Vadodara"}]},{"label":["Name"],"points":[{"start":9128,"end":9139,"text":"Bhavik Patel"}]},{"label":["Location"],"points":[{"start":8677,"end":8684,"text":"Vadodara"}]},{"label":["Location"],"points":[{"start":8652,"end":8659,"text":"Vadodara"}]},{"label":["Skills"],"points":[{"start":3223,"end":3239,"text":"Machine Learning "}]},{"label":["Skills"],"points":[{"start":2504,"end":2520,"text":"Machine Learning "}]},{"label":["Skills"],"points":[{"start":2171,"end":2187,"text":"Machine Learning "}]},{"label":["Location"],"points":[{"start":1270,"end":1277,"text":"Vadodara"}]},{"label":["Skills"],"points":[{"start":1028,"end":1044,"text":"Machine Learning "}]},{"label":["Skills"],"points":[{"start":869,"end":888,"text":"Big Data \nAnalytics "}]},{"label":["Skills"],"points":[{"start":847,"end":863,"text":"Machine Learning "}]},{"label":["Name"],"points":[{"start":328,"end":339,"text":"Bhavik Patel"}]}],"extras":null,"metadata":{"first_done_at":1532676361000,"last_updated_at":1532676361000,"sec_taken":126,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "- 2 -\n\n\t- 1 -\n\n\tC S ANANTHA RAGHAVAN             \nEmail - anantharaghavan.cs@gmail.com \nMob - 9003013244\n\n\n     \t                                    \t\t       \n\nCareer Synopsis\n\n\tOverall, 13+ years’ experience in IT Services Industry handling wide range of roles.\nCurrently, handling IT managed services for global accounts, focusing on delivering the best customer service complying with ITIL processes. Possess Industry specific Experience handling IT services to Clients from BFSI, Life Science, Insurance, Telecom, Health Care and Software Development. With greater interpersonal skills, was able to liaison between the internal technology team and customers efficiently. In short, a leader with good customer handling skills with greater understanding of the business (Both on Technology and Operations) that works on ITIL Framework. Has been actively involved in deriving cost effective solution for delivering leveraged services. Seeking a Senior service delivery role with technically challenging Datacenter Environment.\n\n\n\n\nProfessional Profile\n\t\n· Total Years of Experience: 13+ Yrs (6th Oct 2003 till date)\n· Current Company: NTT Data Services (Formerly DELL Services)\n· Current Role:  Service Delivery Manager (Team Size – 70)\n· Primary Responsibility: Manage Service Delivery for ICS (Infrastructure, Cloud and Security Services) Organization. Currently, handling a large BFSI Account with Multiple Deliverables.\n· Secondary Responsibility: Manage all kinds of Training & Development activities, HR Generalist (Partially) and Internal Communications for the IS Team in Chennai.\n\nNTT Data Services (Formerly DELL Services): (July2011 till date)\n\nIT Service Management: \n\n· Responsible for delivering SLA’s as committed to the customer.\n· Would be a part of tactical and strategic governance meetings.\n· Manage account delivery ensuring high level of customer satisfaction.\n· Own Service Management processes, tools and disciplines and ensure they are applied in all aspects of contract delivery. \n· Validate Solutions and cost model from service delivery standpoint.\n· Resource planning and Management. \n· Manage the team on Request, Incident, Problem and Change management as per the contract.\n· Responsible for performance, cost, scope, quality, and appropriate business measurements as per SOW.\n· Escalation point with respect to the customers.\n· Define BCP/BRP/TRP framework based on the agreement.\n· Involved in RFI, RFP and Solution phase. \n· Support Account Executives with Contract proposals and Client Presentation.\n· Actively involved in solution-ing Cloud services deal using rate card model.\n· Performance Management for the team of Operation managers, Leads and Engineers.\n· Involved in POA validation, change reviews and approval along with the customer.\n· Handle all customer escalations and providing POA for improvement opportunities.\n· Managing operation managers designated at Remote desk and onsite including Command Center.\n· Drive SIP initiatives based on Ticket and call analysis.\n· Conduct Perception CSAT to understand the actual verbatim of the customer.\n· Reviewing Low CSAT, Reopen ticket, Downtime & Incident/Request Reduction analysis.\n· Monitoring and Driving Escalation & Action Tracker.\n· Partner management pertaining to Service Delivery and pricing.\n· Improve Operational Efficiency through automation, incident reduction and Productivity analysis.\n· Responsible P&L for the accounts managed.\n· Involved in transformation initiative to optimize the accounts that are not meeting service levels and to improve GM.\n· Represented Delivery and Training function in ISO9001:2015 external audit.\n· Crisis Management \n    \n\nTalent Transformation & Internal Communications:\n\n· Designing, Developing and conducting Technical/Soft Skills Training for Service Desk.\n· Conducting Training Course Evaluation and address the training needs based on the results.\n· Conducting communication skills screening and providing appropriate feedback for service desk and technology domains. \n· Co-ordinate with the external training vendors and organize technical/soft skills training for the IS team as required. \n· Manage online learning for the IS team in Chennai. Also publish course completion report.\n· Publish Training calendar and dashboard to the Sr. Management.\n· Organize the “Training Needs Identified (TNI)” list every quarter based on the requirement and publish the training calendar.\n· Streamline process flows along with the quality team for certain projects.\n· Manage Internal Communication team which is responsible for creating go-live mailers, IS newsletters, Birthday mailers and other initiatives. \n· Handle the role of a HR- Generalist, supporting the Regional HR Head with respect to maintaining and managing the resource list for Chennai.\n\nCareer Highlights – NTT Data:\n\n· Handling large BFSI customer with multiple deliverables.\n· Improved Customer Satisfaction through Skill Gap Analysis.\n· Played a pivotal role in ISO9001:2015 Certification upgrade.\n· Brought additional scope to the existing BFSI account.\n· Transformation projects transitioned from the internal team to improve gross margin.\n· Additional Revenue driven for the accounts handled.\n· 20% Cost reduction to the customer based on the abandoned call analysis.\n· IVR Solution for outages had resulted in call reduction which is directly proportional to the cost.\n· Was instrumental setting up a remote technical desk that reduced the onsite cost by 60% for one of the life science account.\n· Retained a challenging customer and ensured processes have been set for a streamlined sustenance phase.\n· Was a part of the designing global service desk solution.\n· Perception CSAT was welcomed and appreciated by the customer.\n· Was Instrumental in the expansion of relatively a small desk covering APJ countries to EMEA.\n· IS Newsletter is a new initiative developed and conceptualized based on the inputs from the IS Head. This helped the sales team to understand the site’s IT Services Capabilities in detail and position the same to the potential clients for a successful deal.\n· Designed and Developed Communication Training Agenda- OAAS\n· Formulated L2 Resolver, Field Services and Asset Management Process flow along with the Delivery and transition team involved at a workshop held in Malaysia.\n\nSutherland Global Services: (Oct 2003 – Jun 2011) \n\nTraining\n\n· More than 7 years’ experience in Designing, Coordinating and Conducting Technical Training (PC Hardware, WinXP, Win Vista, Win 7, Networking and Internet Security) for various processes like DELL, Microsoft, Symantec, Mcafee, Verizon, and UOL & ATT.\n· Conducting New Hire Orientation/Induction.\n· Evaluating Trainer performance and the effectiveness of training programs, providing recommendations for improvement.\n· Developing Trainee and Trainer Evaluation Procedures.\n· Conducting Course Evaluation (Feedback) to identify the gaps/needs and provide a workable solution.\n· Develop and organize training manuals, multimedia visual aids, Facilitators Guide and other Training tools.\n· Initiate Trainer Development Programs based on the need.\n· Analyzing training needs to develop new training programs or modify and improve existing programs.\n· Train instructors in techniques and skills for training and dealing with the trainees ensuring quality Training Experience.\n\n· Managing integration of established internal training courses with the external training firms and vendors.\n· Organizing updates from the Process Training and maintaining training documentation and records.\n· Compile, analyze and report on various metrics related to training which will be delivered to various members of the executive leadership team.\n\nHighlights:\n\nCareer Development Program\n\n· Designed, Developed and Implemented Career Development Program at Sutherland understanding the Business Need.\n· Devised a new learning strategy by introducing a Blended learning model with online support services (Email and Chat) and Employee Progression tracking.\n· Devised a Training plan based on the employee’s shift schedule to ensure maximum product utilization.\n\nTools Design and Development:\n\n· Managed a team to develop Technical Knowledge base. \n· Assessed tools like PC tune up, Internet Booster, Diagnostic Manager and CRM.\n· Coordinated in providing the requirements / Logic to build in house Learning Management System (LMS) and portal for Technical Training and Career Development Program.\n· Designed a Vocabulary Test for the communication training team.\n· Identified a suitable solution for the communication training team to test the pronunciation levels of the trainees using a tool.\n\n\n\n\n\n\n\n\nExperience Summary:\n\n\t\nOrganization\n\t\nDesignation\n\t\nDuration\n\t\nProgram\n\n\tNTT Data Services(Formerly DELL Services)\n\tDelivery Manager II\n\t1st Nov’16 till Date\n\tICS \n\n\tDELL Services\n\tDelivery Manager II\n\t1st Oct’14 to 31st Oct’16\n\tI&CC (Infrastructure and Cloud Computing)\n\n\t\n\tTechnical Support Manager\n\t20 Aug’12 to 30th Sep’4\n\t\n\n\t\n\tTechnical Training Advisor\n\t11th July’11 to till date\n\t\n\n\t\nSutherland Global Services  Pvt. Ltd.,\n\n\tManager -  Training\n\t26th Dec 2008 to 30th Jun 2011\n\t\nNew Hire Training Team\n\n\t\n\tDeputy Manager - Training\n\t26th Dec 2007 to 25th Dec 2008\n\t\n\n\t\n\tAssistant Manager - Training\n\t26th Dec 2006 to 25th Dec 2007\n\t\n\n\t\n\tSenior Technical Trainer\n\t1st Apr 2005 to 25th Dec 2006\n\t\n\n\t\n\tTechnical Trainer\n\t14th Jun 2004 to 31st Mar 2005\n\t\n\n\t\n\tHelp Desk Engineer\n\t16th Apr 2004 to 13th  Jun 2004\n\t\nHP Ferrari\n\n\t\n\tSupervisor\n\t8th Jan 2004 to 15th Apr 2004\n\t\nIntuit CTG\n\n\t\n\tCustomer Support Executive\n\n\t6th Oct 2003 to 7th Jan 2004\n\t\nIntuit CTG\n\n\n\n\nProfessional Expertise:\n\n· Drive Operational Efficiency for large scale account.\n· CSI baseline and drive towards quantifiable outcome \n· Expertise in handling transformational initiative.\n· Process Implementation inline to the ITIL Guidelines.\n· Assessing existing system and developing effective training solutions.\n· Strong expertise in functional testing and designing tools like PC tune up, Internet Booster, Diagnostic Manager, Widgets and CRM.\n· Troubleshooting various Software and Hardware Issues including Malware Issues, IP TV, VOIP Phones, HSIA and XBOX.\n· Coordinating with the team members, setting tasks and motivating them to meet timelines.\n\nClients Handled:\n\n\t· DELL\n\t· KPMG\n\t\n\n\t· HP\n\t· GE\n\t\n\n\t· Intuit\n\t· Symphony Teleca\n\t\n\n\t· Bell Canada\n\t· Merck\n\t\n\n\t· Symantec\n\t· Citi\n\t\n\n\t· Microsoft\n\t\n\t\n\n\t· McAfee\n\t\n\t\n\n\t· Virgin\n\t\n\t\n\n\n\nOverseas Experience:\n\n\tCompany Name\n\tDuration\n\tLocation\n\tPurpose\n\n\t\n\nDELL Services\n\t31-Oct-15 to 9-Nov-15\n\tIrving, Texas\nUnited States\n\tConducting KT for Change admin-Cyber Secops – Large BFSI Client\n\n\t\n\t02-May-15 to 10-May-15 \n\tIrving, Texas\nUnited States\n\tConducting KT for Cyber Security operations- Large BFSI Client.\n\n\t\n\t29-Jan-12 to 4-Feb-12\n\tKualalumpur, Malaysia\n\tProcess Workshop for EUS \n\n\tSutherland Global Services\n\tJuly 2006 – Oct 2006\n\tClark, Philippines\n\tTransition ISP Process and setting up the training team\n\n\t\n\tSep 2009 – Feb 2010\n\tMakati, Philippines\n\tTo set up a training team for a  pilot launch of a  pay for support process, Support Delivery as part of Early Life Support and transition IPTV Process to Chennai\n\n\t\n\tNov 2010 – Jan 2011\n\tAlexandria, Egypt\n\tTo set up the Tech Training Team and support delivery as part of Early Life Support.\n\n\n\n\n\n\t\n\n\nProjects:\n\n\tProject Name\n\tProject Description\n\tCompany/Account Name\n\tProject Period\n\n\tReduction of AHT\n\tWas involved in the Lean Six Sigma initiative to reduce the AHT of one of PFS account.\nExecuting this reduced the handle from 40 Mins to 26 Mins.\n\tSutherland Global Services \nPFS – Airline Industry\n\tNov’09-Jan’10\n\n\tMTTD Optimization and Margin Improvement\n\tTriage and Dispatch Time from 9 Minutes brought to 4 Minutes using Kaizen. It also allowed us to handle 2100 Tickets without increasing resources which resulted in improved Margin by 20%.\n\tDELL International Services – BFSI- Cyber Security BU\n\tOct’15-Dec’15\n\n\tResource Grade Optimization\n\tSeat cost wasn’t added to the price sheet initially as was planned to work out of client premise. Later with the same price, seat cost has been decided by Management to accommodate. Conducted Skill Analysis and drafted a plan to hire n-1 with a specific skill and the gap training organized. Over a period of 6 months the whole team has been hired at n-1.  This initiative helped to accommodate $24000 annually for DELL without affecting the margins. \n\tDELL International Services – BFSI- Cyber Security BU\n\tMar’16- Aug’16\n\n\n\n\nAchievements and Rewards:\n\nDELL Services:\n\n· Received DELL champion award for the year 2013-14 for exceptional customer advocacy.\n· Received Silver Award for bringing additional revenue during Q1- 2017.\n\nSutherland Global Services:\n\n· Was awarded “Individual Excellence” in the year 2007.\n· Was promoted to an Assistant Manager – Training for transitioning and managing the training team at Philippines.\n· Represented Training & Development for PCMM level 5 Implementation.\n· Was awarded “Bravo Vintage” for successfully completing 5 years in the organization.\n· Implementation of Vocabulary Test and Pronunciation Software.\n· Automation of the Lab Assessment for Technical Training.\n\nTechnical Expertise:\n\n\t\nOperating System\n\t\nWindows 9X/ 2000 Professional/ XP/ Vista/ 7/8\n\n\tApplications\n\tMS OFFICE 2013\n\n\t\nNetworking\n\tLAN Concepts\n\n\tITSM Tools\n\tSUMMIT, Service Now, BMC Remedy, HPSM \n\n\n\t\n\nOther Tools\n\tCRM/Chat Tools: CLARIFY, Sutherland Developed EzCLM, ICARE, Talisma (Email and Chat), Sento Recite Chat tool, Conversive Chat tool, 2X Client.\nDiagnostic/Tune up Tools: PC Tune up Tool, Diagnostic Manager, Internet Booster.\nRemote Management tools: mstsc, Bomgar, Logmein Dameware…\n\n\t\nAssembly Language\n\t\nIntel 8085\n\n\t\nHardware\n\t\nAssembled, Installed and configured Desktop and Laptop PC’s\n\n\t\nProducts Used\n\tHP Desktops and Laptops, DELL Desktops, laptops and XPS, IP TV, HSIA, VOIP Phones\n\n\n\nInternational Certification:\n          \n\tCertification Name\n\tCertification ID\n\tPassed Year\n\n\tMCP- Windows 2000 Professional\n\tMCP ID - 3386179\n\t2005\n\n\tMCTS– Windows Vista\n\n\tMCP ID - 3386179\n\t2008\n\n\tITIL Foundation \n\tEXIN ID - 5900198\n\t2017\n\n\n\n\nCourses Completed:\n\n\tCourse Name\n\tInstitute/Company\n\tDate/Year\n\n\tCompTIA A+\n\tSutherland Global Services\n\t2003\n\n\tCCNA\n\tSansbound\n\t2005\n\n\tCompTIA N+\n\tSutherland Global Services\n\t2007\n\n\tSix Sigma Yellow Belt\n\tSutherland Global Services\n\t2008\n\n\tITIL V3\n\tDell International Services\n\t2011\n\n\tMicrosoft Lync Administration 2010\n\tDell International Services\n\t2012\n\n\tMicrosoft SCCM 2010\n\n\tDell International Services\n\t2012\n\n\tISO9001:2008 Internal Auditor Course\n\n\tDell International Services – DNV Trainer\n\t2013\n\n\tDELL KACE\n\tDell International Services\n\t2014\n\n\tISO9001:2015\n\tDell International Services\n\t2016\n\n\n\nEducational Qualification:\n\n\t\nQualification\n\t\nInstitution\n\n\t\nYear of Passing\n\n\t\nPercentage\n\n\n\t\nPGDBA (HR)\n\n\tSymbiosis Center for Distance Learning\n\t2008\n\tB Grade\n\n\t\nB.E (E.C.E) \n\t\nHindustan College of Engineering. University Of Madras \n\t\n2003\n\n\t\n73%\n\n\n\t\nH.S.C \n\n\t\nGill Adarsh Mat. Hr. Sec. School\n\t1999\n\n\t\n94%\n\n\n\t\nS.S.L.C       \n\n\tThe Hindu Senior Secondary School, CBSE. \n\t1997\n\t71%\n\n\n\nDeclaration:\n\nI hereby declare that the above information given by me are true and complete to the best of my knowledge.\n\n\nChennai\t\t\t\t\t\t\t           (C. S. Anantha Raghavan)","annotation":[{"label":["Location"],"points":[{"start":15267,"end":15273,"text":"Chennai"}]},{"label":["Skills"],"points":[{"start":13361,"end":13397,"text":"SUMMIT, Service Now, BMC Remedy, HPSM"}]},{"label":["Primary skill"],"points":[{"start":13322,"end":13331,"text":"Networking"}]},{"label":["Location"],"points":[{"start":11191,"end":11197,"text":"Chennai"}]},{"label":["Primary skill"],"points":[{"start":6506,"end":6515,"text":"Networking"}]},{"label":["Location"],"points":[{"start":4779,"end":4785,"text":"Chennai"}]},{"label":["Location"],"points":[{"start":4182,"end":4188,"text":"Chennai"}]},{"label":["Location"],"points":[{"start":1581,"end":1587,"text":"Chennai"}]},{"label":["Name"],"points":[{"start":16,"end":35,"text":"C S ANANTHA RAGHAVAN"}]}],"extras":null,"metadata":{"first_done_at":1532657538000,"last_updated_at":1532657538000,"sec_taken":0,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Udaya Laxmi Ch\n\nEmail : laxmi.udaya@gmail.com\n\n\t\n\n\tPhone: -9740606990\n\t\n\n\n\tSummary\n\n\t· 9.5 years of experience in Software Development.\n· 3.5 years of experience in Machine Learning\n· Primary Skills – Machine Learning, R programming, Lotus Notes.\n· Presently working for Wipro Technologies, Bangalore.\n· Experience in planning, estimation, design, development, and testing object oriented applications.\n· Experience in preparing various technical documents like Functional Specs, HLD, LLD, Flowcharts and Test cases.\n· Sound Knowledge in Object Oriented Design Principles\n· Have Team Handling experience.\n· Domain experience of Manufacturing and Finance.\n· Have Experience in Scrum Agile Model\n· Understand business requirements from clients\n\n\n\n\tTechnical Skills\n\n\tKey skills: \n\tMachine Learning,R Programming, MySQL, PostgreSQL, Microsoft Access, SQL Server, FileMaker, Oracle, RDBMS, dBASE, Clipper, FoxPro, Firebase, Mongodb, Python,  ava, J2EE, Oracle Fusion,Oracle Cloud, Salesforce, Devops Android, Business Analyst, UI Developer, DBAs, Embedded Systems, .NET, Hadoop, SQL Developer, Big Data, Tableau, Networking, Etl, Informatica, Ios, Quality Analyst, Project Manager, Python, Data Science, Python, Machine Learning, SAS, Java, Scala, Hadoop, Hive, Bigdata, Programming, SQL server reporting, Msbi Ssis, Ssrs, Msbi, Sql Reporting, Artificial Intelligence, Pandas, Pyspark, Sklearn, Flask, Django, Map Reduce, Parametric Design, Modeling, Regression, Patterns, Data Mining, Text Mining, Oops, Deep Learning, Web Analytics, Time Series, Regression, Tensorflow, Azure, Linear Regression, Logistic Regression, Decision Tree, Random Forest, Data Structure, Computer Vision, IHS, WAS, Java EE, SQL Server, .NET core, C#, ASP.NET, Rdlc, Linq, Sql, Web Api, Mvc, Javascript, Web Services, Oracle, MS SQL, PHP, Laravel, CodeIgniter, Symfony, Zend, Phalcon, CakePHP, Yii, FuelPHP, React, Vue, Angular, Ember, Backbone, Lotus Notes\n\n\tAlgorithms:\n\tNaïve Bayes, K means clustering,Word Cloud\n\n\tDatabases: \n\tMicrosoft SQL, Mongo DB\n\n\tWeb Technologies: \n\tXML, XSLT, HTML,  JavaScript,  AJAX, JQuery\n\n\tIDE:\n\tR studio,Pycharm\n\n\n\tProfessional Experience\n\n\tCurrent Employer :\n\tWipro Technologies., Bangalore  – (Oct  2010  to till date) – Technical Lead/Data Scientist\n\n\tPrevious Employers :\n\tHSBC Software development , Hyderabad (June  2008  to Sep 2010)  - SE\n\n\n\tQualification\n\n\tDegree\n\tCollege\n\tUniversity/Board\n\tYear\n\tPercentage (%)\n\n\tMCA\n\tNizam College, Basheerbagh,Hyderabad\n\tOsmania University\n\t2008\n\t75\n\n\n\tProject Experience \n\n\tProject 1 : Exploratory Data Analysis:\n\nProject Description:   Performed EDA analysis to analyze the Purchase frequency of vehicles which occurred over past 3 years and try to predict the frequency occurring in the future.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Performed EDA analysis to find the insights of the data. Observed the summary of each and every variable to understand the variables.\n\n· Performed the feature selection using hypothesis testing.\n\n· Identified the outliers using box plot.\n\n· Identified the trend in the purchases using histogram.\n\n\n\n\tProject 2: Word Cloud Analysis:\n\nProject Description:   Performed Word cloud and Sentimental Analysis of the customer feedbacks. Graphically represented the most frequently occurred words through Word cloud. Through sentimental analysis we identified whether a user-generated text expresses positive, negative or neutral opinion.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Created a Corpus using TM package and performed pre-processing of data.\n\n· Removed the punctuations, stemming and stop words which are of no analytical value.\n\n· Built a Document term matrix and identified the most frequently occurring words\n\n· Graphically represented it using  RColorbrewer Package\n\n\n\tProject 3: Sentimental Analysis:\n\nProject Description: Performed Sentimental Analysis of customer feedbacks through Naïve Bayes. Used “e1071” Package for implementing naïve Bayes method.\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· The DTM created using TM package was an input to the Naive Bayes Model.\n\n· As Naive Bayes classifier is typically trained on data with categorical features. We have converted the count of the words into a factor variable that indicates Yes or No whether the word is present or not.\n\n\tProject 4: Clustering Analysis:\n\nProject Description: Classified the customers on the basis of their purchases whether they have purchased low variant or high variant trucks. It in turn helped in building the right customer strategies.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Performed data preparation and Normalization of data using min-max method.\n\n· As K-means algorithm groups a dataset into a user-specified number (k) of clusters. Identified the initial cluster centroids as 3.\n\n· K clusters are creating by associating every observation with the nearest mean.\n\n· Used elbow method to validate the number of clusters such that within-cluster sum of square(wss) is minimized.\n\n\n\n\tProject 5 : Inter Connection Management Tool\nProject Description: Inter-connection Management (IMT) is prototype being developed for Engineering and Sales department to handle customizations of an existing product based on the customer's requirement. Users from engineering department will identify the items, which need to be customized out of the entire product design.\nRole\n\n       : Module Lead\n\nEnvironment\n       : Python, Mongo DB, jQuery\n\nTasks handled:\n\n· Gathering Requirements and providing Project Plan and Effort Estimation details.\n\n· Understanding business requirements and preparing SoU (Statement of Understanding) and Functional/Technical Specification documents.\n\n· Providing Effort & Resource estimations\n\n· Planning for application development and deployment\n\n· Writing and executing Test Cases and Test scenarios\n\n· Creating design elements using Technical Specification.\n\n· Performing Unit testing & Peer Reviews\n\n· Work Allocation and mentoring the team\n\n· Providing Technical guidance to the team. \n\n\tProject 6\n: cvdAEI Application\n\nProject Description\n     : CVDAEI is a web based multilingual application developed for handling the Change Management process in Truck division of Daimler. The change request flows through different phases mainly Initialization, Evaluation, Decision and Conclusion. This application has a configurable workflow where the request flow and the responsible persons can be configured easily at any point of time. \n\nRole\n\n    : Developer/Tester\n\nEnvironment\n     : Lotus Notes, Java, HTML, XML, Java Script, JQuery\n\nTasks handled:\n\n· Gathering Requirements and providing Project Plan and Effort Estimation details.\n\n· Understanding business requirements and preparing SoU (Statement of Understanding) and Functional/Technical Specification documents.\n\n· Providing Effort & Resource estimations\n\n· Planning for application development and deployment\n\n· Writing and executing Test Cases and Test scenarios\n\n· Creating design elements using Technical Specification.\n\n· Performing Unit testing & Peer Reviews\n\n· Work Allocation and mentoring the team\n\n· Providing Technical guidance to the team. \n\n\n\n\tProject Title: Project Management Office \nProject Description: The purpose of this system is to enable the Project Management Office to manage and execute the IT Applications and Operations driven project tasks in  more systematic manner. It will also enable them to efficiently perform a role as a facilitator to coordinate various IT Operations teams and to ensure that project activity enters the department through one common interface. The project tasks will subsequently be dealt with in a common format and in a consistent and appropriate manner, ensuring open and regular communication between all involved parties.\n\nRole\n\n    : Developer/Tester\n\nEnvironment\n     : Lotus Notes, Java, HTML, XML, Java Script, JQuery\n\nTasks Handled :\n\n· Writing and Executing Test cases in client server based environment\n· Individually provided application support","annotation":[{"label":["Skills"],"points":[{"start":7951,"end":7956,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":7938,"end":7948,"text":"Java Script"}]},{"label":["Skills"],"points":[{"start":7933,"end":7935,"text":"XML"}]},{"label":["Skills"],"points":[{"start":7927,"end":7930,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":7921,"end":7924,"text":"Java"}]},{"label":["Skills"],"points":[{"start":7908,"end":7918,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":6645,"end":6650,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":6632,"end":6642,"text":"Java Script"}]},{"label":["Skills"],"points":[{"start":6627,"end":6629,"text":"XML"}]},{"label":["Skills"],"points":[{"start":6621,"end":6624,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":6615,"end":6618,"text":"Java"}]},{"label":["Skills"],"points":[{"start":6602,"end":6612,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":5522,"end":5527,"text":"jQuery"}]},{"label":["Skills"],"points":[{"start":5512,"end":5519,"text":"Mongo DB"}]},{"label":["Skills"],"points":[{"start":5504,"end":5509,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4645,"end":4652,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":4054,"end":4061,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":3941,"end":3951,"text":"Naïve Bayes"}]},{"label":["Skills"],"points":[{"start":3494,"end":3501,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":3132,"end":3141,"text":"Word Cloud"}]},{"label":["Skills"],"points":[{"start":2793,"end":2800,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":2110,"end":2116,"text":"Pycharm"}]},{"label":["Skills"],"points":[{"start":2101,"end":2108,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":2086,"end":2091,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":2080,"end":2083,"text":"AJAX"}]},{"label":["Skills"],"points":[{"start":2067,"end":2076,"text":"JavaScript"}]},{"label":["Skills"],"points":[{"start":2060,"end":2063,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":2054,"end":2057,"text":"XSLT"}]},{"label":["Skills"],"points":[{"start":2049,"end":2051,"text":"XML"}]},{"label":["Skills"],"points":[{"start":2018,"end":2025,"text":"Mongo DB"}]},{"label":["Skills"],"points":[{"start":2003,"end":2015,"text":"Microsoft SQL"}]},{"label":["Skills"],"points":[{"start":1977,"end":1986,"text":"Word Cloud"}]},{"label":["Skills"],"points":[{"start":1958,"end":1975,"text":"K means clustering"}]},{"label":["Skills"],"points":[{"start":1945,"end":1955,"text":"Naïve Bayes"}]},{"label":["Skills"],"points":[{"start":1918,"end":1928,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":1908,"end":1915,"text":"Backbone"}]},{"label":["Skills"],"points":[{"start":1901,"end":1905,"text":"Ember"}]},{"label":["Skills"],"points":[{"start":1892,"end":1898,"text":"Angular"}]},{"label":["Skills"],"points":[{"start":1887,"end":1889,"text":"Vue"}]},{"label":["Skills"],"points":[{"start":1880,"end":1884,"text":"React"}]},{"label":["Skills"],"points":[{"start":1871,"end":1877,"text":"FuelPHP"}]},{"label":["Skills"],"points":[{"start":1866,"end":1868,"text":"Yii"}]},{"label":["Skills"],"points":[{"start":1857,"end":1863,"text":"CakePHP"}]},{"label":["Skills"],"points":[{"start":1848,"end":1854,"text":"Phalcon"}]},{"label":["Skills"],"points":[{"start":1842,"end":1845,"text":"Zend"}]},{"label":["Skills"],"points":[{"start":1833,"end":1839,"text":"Symfony"}]},{"label":["Skills"],"points":[{"start":1820,"end":1830,"text":"CodeIgniter"}]},{"label":["Skills"],"points":[{"start":1811,"end":1817,"text":"Laravel"}]},{"label":["Skills"],"points":[{"start":1806,"end":1808,"text":"PHP"}]},{"label":["Skills"],"points":[{"start":1798,"end":1803,"text":"MS SQL"}]},{"label":["Skills"],"points":[{"start":1790,"end":1795,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":1776,"end":1787,"text":"Web Services"}]},{"label":["Skills"],"points":[{"start":1764,"end":1773,"text":"Javascript"}]},{"label":["Skills"],"points":[{"start":1759,"end":1761,"text":"Mvc"}]},{"label":["Skills"],"points":[{"start":1750,"end":1756,"text":"Web Api"}]},{"label":["Skills"],"points":[{"start":1745,"end":1747,"text":"Sql"}]},{"label":["Skills"],"points":[{"start":1739,"end":1742,"text":"Linq"}]},{"label":["Skills"],"points":[{"start":1733,"end":1736,"text":"Rdlc"}]},{"label":["Skills"],"points":[{"start":1724,"end":1730,"text":"ASP.NET"}]},{"label":["Skills"],"points":[{"start":1720,"end":1721,"text":"C#"}]},{"label":["Skills"],"points":[{"start":1709,"end":1717,"text":".NET core"}]},{"label":["Skills"],"points":[{"start":1697,"end":1706,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":1688,"end":1694,"text":"Java EE"}]},{"label":["Skills"],"points":[{"start":1683,"end":1685,"text":"WAS"}]},{"label":["Skills"],"points":[{"start":1678,"end":1680,"text":"IHS"}]},{"label":["Skills"],"points":[{"start":1661,"end":1675,"text":"Computer Vision"}]},{"label":["Skills"],"points":[{"start":1645,"end":1658,"text":"Data Structure"}]},{"label":["Skills"],"points":[{"start":1630,"end":1642,"text":"Random Forest"}]},{"label":["Skills"],"points":[{"start":1615,"end":1627,"text":"Decision Tree"}]},{"label":["Skills"],"points":[{"start":1594,"end":1612,"text":"Logistic Regression"}]},{"label":["Skills"],"points":[{"start":1575,"end":1591,"text":"Linear Regression"}]},{"label":["Skills"],"points":[{"start":1568,"end":1572,"text":"Azure"}]},{"label":["Skills"],"points":[{"start":1556,"end":1565,"text":"Tensorflow"}]},{"label":["Skills"],"points":[{"start":1544,"end":1553,"text":"Regression"}]},{"label":["Skills"],"points":[{"start":1531,"end":1541,"text":"Time Series"}]},{"label":["Skills"],"points":[{"start":1516,"end":1528,"text":"Web Analytics"}]},{"label":["Skills"],"points":[{"start":1501,"end":1513,"text":"Deep Learning"}]},{"label":["Skills"],"points":[{"start":1495,"end":1498,"text":"Oops"}]},{"label":["Skills"],"points":[{"start":1482,"end":1492,"text":"Text Mining"}]},{"label":["Skills"],"points":[{"start":1469,"end":1479,"text":"Data Mining"}]},{"label":["Skills"],"points":[{"start":1459,"end":1466,"text":"Patterns"}]},{"label":["Skills"],"points":[{"start":1447,"end":1456,"text":"Regression"}]},{"label":["Skills"],"points":[{"start":1437,"end":1444,"text":"Modeling"}]},{"label":["Skills"],"points":[{"start":1418,"end":1434,"text":"Parametric Design"}]},{"label":["Skills"],"points":[{"start":1406,"end":1415,"text":"Map Reduce"}]},{"label":["Skills"],"points":[{"start":1398,"end":1403,"text":"Django"}]},{"label":["Skills"],"points":[{"start":1391,"end":1395,"text":"Flask"}]},{"label":["Skills"],"points":[{"start":1382,"end":1388,"text":"Sklearn"}]},{"label":["Skills"],"points":[{"start":1373,"end":1379,"text":"Pyspark"}]},{"label":["Skills"],"points":[{"start":1365,"end":1370,"text":"Pandas"}]},{"label":["Skills"],"points":[{"start":1340,"end":1362,"text":"Artificial Intelligence"}]},{"label":["Skills"],"points":[{"start":1325,"end":1337,"text":"Sql Reporting"}]},{"label":["Skills"],"points":[{"start":1325,"end":1327,"text":"Sql"}]},{"label":["Skills"],"points":[{"start":1319,"end":1322,"text":"Msbi"}]},{"label":["Skills"],"points":[{"start":1313,"end":1316,"text":"Ssrs"}]},{"label":["Skills"],"points":[{"start":1302,"end":1310,"text":"Msbi Ssis"}]},{"label":["Skills"],"points":[{"start":1302,"end":1305,"text":"Msbi"}]},{"label":["Skills"],"points":[{"start":1280,"end":1299,"text":"SQL server reporting"}]},{"label":["Skills"],"points":[{"start":1267,"end":1277,"text":"Programming"}]},{"label":["Skills"],"points":[{"start":1258,"end":1264,"text":"Bigdata"}]},{"label":["Skills"],"points":[{"start":1252,"end":1255,"text":"Hive"}]},{"label":["Skills"],"points":[{"start":1244,"end":1249,"text":"Hadoop"}]},{"label":["Skills"],"points":[{"start":1237,"end":1241,"text":"Scala"}]},{"label":["Skills"],"points":[{"start":1231,"end":1234,"text":"Java"}]},{"label":["Skills"],"points":[{"start":1226,"end":1228,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1208,"end":1223,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1200,"end":1205,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1186,"end":1197,"text":"Data Science"}]},{"label":["Skills"],"points":[{"start":1178,"end":1183,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1161,"end":1175,"text":"Project Manager"}]},{"label":["Skills"],"points":[{"start":1144,"end":1158,"text":"Quality Analyst"}]},{"label":["Skills"],"points":[{"start":1139,"end":1141,"text":"Ios"}]},{"label":["Skills"],"points":[{"start":1126,"end":1136,"text":"Informatica"}]},{"label":["Skills"],"points":[{"start":1121,"end":1123,"text":"Etl"}]},{"label":["Skills"],"points":[{"start":1109,"end":1118,"text":"Networking"}]},{"label":["Skills"],"points":[{"start":1100,"end":1106,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":1090,"end":1097,"text":"Big Data"}]},{"label":["Skills"],"points":[{"start":1075,"end":1087,"text":"SQL Developer"}]},{"label":["Skills"],"points":[{"start":1067,"end":1072,"text":"Hadoop"}]},{"label":["Skills"],"points":[{"start":1061,"end":1064,"text":".NET"}]},{"label":["Skills"],"points":[{"start":1043,"end":1058,"text":"Embedded Systems"}]},{"label":["Skills"],"points":[{"start":1037,"end":1040,"text":"DBAs"}]},{"label":["Skills"],"points":[{"start":1023,"end":1034,"text":"UI Developer"}]},{"label":["Skills"],"points":[{"start":1005,"end":1020,"text":"Business Analyst"}]},{"label":["Skills"],"points":[{"start":989,"end":1002,"text":"Devops Android"}]},{"label":["Skills"],"points":[{"start":977,"end":986,"text":"Salesforce"}]},{"label":["Skills"],"points":[{"start":963,"end":974,"text":"Oracle Cloud"}]},{"label":["Skills"],"points":[{"start":949,"end":961,"text":"Oracle Fusion"}]},{"label":["Skills"],"points":[{"start":943,"end":946,"text":"J2EE"}]},{"label":["Skills"],"points":[{"start":929,"end":934,"text":"Python"}]},{"label":["Skills"],"points":[{"start":920,"end":926,"text":"Mongodb"}]},{"label":["Skills"],"points":[{"start":910,"end":917,"text":"Firebase"}]},{"label":["Skills"],"points":[{"start":902,"end":907,"text":"FoxPro"}]},{"label":["Skills"],"points":[{"start":893,"end":899,"text":"Clipper"}]},{"label":["Skills"],"points":[{"start":886,"end":890,"text":"dBASE"}]},{"label":["Skills"],"points":[{"start":879,"end":883,"text":"RDBMS"}]},{"label":["Skills"],"points":[{"start":871,"end":876,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":860,"end":868,"text":"FileMaker"}]},{"label":["Skills"],"points":[{"start":848,"end":857,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":830,"end":845,"text":"Microsoft Access"}]},{"label":["Skills"],"points":[{"start":818,"end":827,"text":"PostgreSQL"}]},{"label":["Skills"],"points":[{"start":811,"end":815,"text":"MySQL"}]},{"label":["Skills"],"points":[{"start":798,"end":808,"text":"Programming"}]},{"label":["Skills"],"points":[{"start":796,"end":808,"text":"R Programming"}]},{"label":["Skills"],"points":[{"start":779,"end":794,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":234,"end":244,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":219,"end":231,"text":"R programming"}]},{"label":["Skills"],"points":[{"start":201,"end":216,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":165,"end":180,"text":"Machine Learning"}]},{"label":["Name"],"points":[{"start":0,"end":13,"text":"Udaya Laxmi Ch"}]}],"extras":null,"metadata":{"first_done_at":1579625576000,"last_updated_at":1579626369000,"sec_taken":0,"last_updated_by":"aJOmJy1lvpOYFetVNuqLvFo9Vx42","status":"done","evaluation":"NONE"}}
{"content": "Bangalore, KA-560011\nE-mail : sekahr2011@gmail.com\nContact no.  +91-8147340366\n                  +91-9618434317\n\n\n\nCHANDRA SEKHAR M\n M\n\n\n\n\n\nCareer Objective:\n\nTo build a long-term career in Data Science platforms with opportunities for career growth.\n\nSummary:\n\n· Total 3+ Years of Experience in Data Analytics using R. \n· Hands on Programming experience using Core Java and My SQL.\n· Experience in Installation, Configuration and Administration of R script and its packages.\n· Worked on Data Integrity tools like Pentaho (Kettle 5.2.0).\n· Experience in traditional RDBMS, MySQL and SQL server.\n\nCareer Focus:\n\n            My current R knowledge includes:\n· Linear (simple & Multiple) and Logistic Regression.\n· Predictive modelling.\n· Support vector Machines, Decision Trees and Random forests.\n· Naïve Bayes.\n· K-Means Clustering and K-Nearest Neighbors.\n· Text mining, Forecasting and Time series analysis.\n· Statistics (Hypothesis testing, confidence interval finding, ANOVA).\n· R (dplyr, lm, glm, decision tree, n-fold cross validation, random forests, ggplot, shiny).\n· Extensively worked on Twitter Sentiment Analysis using R packages & Tableau to map the followers & friends as per the geographic locations.\n· Working on Twitter Sentiment Analysis using Shiny & R.\n· Extensively worked on Titanic, Twitter & Iris data to explore the various Regression & Predictive models using R Packages & used tableau for visualization.\n· Extensively worked on data exploration, data cleaning methods using R.\n· Performed data mining, data cleaning & explored data visualization techniques on a variety of data stored in spreadsheets and text files using R and plotting the same using ggplot2 function.\n· Sufficient exposure to designing and developing Tableau reports and dashboards for data visualization using R & Tableau.\n· Sufficient knowledge about the Natural Language Processing using R.\n\nCompetencies:\n\n· Focused, Quick Learner and Self-Starter, possesses skills to work under pressure and utilize the learned concepts quickly in a productive manner.\n· Possess Good interpersonal, analytical capabilities and a proven track record of in time Deliverables.\n\nTechnical Skills: \n\n· Programming\t\t: R, Core Java\n· Database\t\t: MySQL\n· Operating system\t: Linux, Windows XP/7/8.\n· Ms Office\t\t: Excel\nProfessional Experience:\n\nZyme Solutions Pvt Ltd, Bangalore - Jun 2014 to Present \n\nRole\t\t\t: Senior Analyst in Channel Data Management.\t\n\n\n\nResponsibility:\n\n· Managing the Data base of the particular client throughout its existence in Company.\n· Setup Data loading tools like Qlikview and other BO tools.\n· Managing and deploying database of the particular customer.\n· Writing scripts for manipulating the particular data as per the customer requirements.\n· Fixing issues and writing code for enhancement.\n· Unit testing and integration testing of owned use cases.\n· Writing different kind of analysis, design, testing and Business validations.\n\nProject:\n\nName:  Iris visual dysfunction data prediction using R.\n\nDetails : design and development of algorithms to predict eye sight of patient.by using clustering methodologies.\n\nObjectives: To evaluate visual dysfunction and its correlation with structural changes in the retina in patients with Parkinson's disease (PD).\n\nMethods: Patients with PD (n=37) and controls (n=37) were included in an observational cross-sectional study, and underwent visual acuity (VA), colour vision (using the Farnsworth and Lanthony desaturated D15 colour tests) and contrast sensitivity vision (CSV; using the Pelli-Robson chart and CSV 1000E test) evaluation to measure visual dysfunction. Structural measurements of the retinal nerve fibre layer (RNFL), and macular and ganglion cell layer (GCL) thicknesses, were obtained using spectral domain optical coherence tomography (SD-OCT). Comparison of obtained data, and correlation analysis between functional and structural results were performed.\nResults: VA (in all different contrast levels) and all CSV spatial frequencies were significantly worse in patients with PD than in controls. Colour vision was significantly affected based on the Lanthony colour test. Significant GCL loss was observed in the minimum GCL+inner plexiform layer. A clear tendency towards a reduction in several macular sectors (central, outer inferior, outer temporal and superior (inner and outer)) and in the temporal quadrant of the RNFL thickness was observed, although the difference was not significant. CSV was the functional parameter most strongly correlated with structural measurements in PD. Colour vision was associated with most GCL measurements. Macular thickness was strongly correlated with macular volume and functional parameters (r>0.70, p<0.05).\nConclusions: Patients with PD had visual dysfunction that correlated with structural changes evaluated by SD-OCT. GCL measurements may be reliable indicators of visual impairment in patients with PD.\nRoles and responsibilities:\nModeling: Design and implement statistical / predictive models and cutting edge algorithms utilizing diverse sources of data to predict demand, risk and price elasticity. Experience with creating ETL processes to source and link data.\n\nAnalytics: Utilize analytical applications like SAS to identify trends and relationships between different pieces of data, draw appropriate conclusions and translate analytical findings into risk management and marketing strategies that drive value.\n\nDrive Enhancements: Develop tools and reports that help users access and analyze data resulting in higher revenues and margins and a better customer experience.\nCommunications and Project Management: Capable of turning dry analysis into an exciting story that influences the direction of the business and communicating with diverse teams to take a project from start to finish. Collaborate with product teams to develop and support our internal data platform and to support ongoing analyses.\n\n\nEducation:\n\n\n· M.Sc. (statistics & Computer Applications) from Dravidian University, Kuppam in 2014.\n· BSc (statistics & Computer Applications) from Dravidian University, Kuppam in 2012.\n\n\n\n\nExtra-Curricular Activities: to\n\n· Actively participated in various fests conducted by different Colleges.\n· Participated in Cricket tournament which is held at Tirupati.\n\nAchievements:\n\n1. Awarded as the best student of the Mathematical Science Department for the Academic Year 2013-14 in Dravidian University.\n\n2. Awarded as the best new joinee for the year 2014-15 in Zyme solutions Pvt Ltd.\n\n3. Certified on R Programming from Igeeks institute.\n\n     \nPersonal Details:  \n\nDate of Birth\t  : 20-11-1991\nGender\t  : Male\nMarital Status\t  : Single\nLanguages Known\t  : English, Telugu and Kannada.\nCurrent Address\t\t  : No 35, 3rd Cross, Lalbagh Siddapura Road,\n                                \t                Jayanagar 1st Block, Bangalore-560011\nDeclaration:\n\nI declare that the above mentioned information is correct to the best of my knowledge.         \n   \n                                                                                                                        \n                                                      \t\t\t\t\tCHANDRA SEKHAR","annotation":[{"label":["Location"],"points":[{"start":6855,"end":6863,"text":"Bangalore"}]},{"label":["Education"],"points":[{"start":5949,"end":5952,"text":"M.Sc"}]},{"label":["Location"],"points":[{"start":2345,"end":2353,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":2205,"end":2208,"text":"Java"}]},{"label":["Skills"],"points":[{"start":449,"end":457,"text":"R script "}]},{"label":["Skills"],"points":[{"start":375,"end":380,"text":"My SQL"}]},{"label":["Skills"],"points":[{"start":366,"end":369,"text":"Java"}]},{"label":["Skills"],"points":[{"start":296,"end":309,"text":"Data Analytics"}]},{"label":["Name"],"points":[{"start":115,"end":130,"text":"CHANDRA SEKHAR M"}]},{"label":["Location"],"points":[{"start":0,"end":8,"text":"Bangalore"}]}],"extras":null,"metadata":{"first_done_at":1532674642000,"last_updated_at":1532674642000,"sec_taken":234,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Chiranjib Konwar\n\nchiranjib.konwar@gmail.com\n\nhttps://github.com/chiranjibKonwar/\n\n\n\n\t\t\t\t\t     \n  \t\t\t\t\t\t\t\t\tMobile: 9620201002\n// PROFILE\n\nA performance driven Python programmer and Django web developer, having experience of 3+ years in scientific computing and in multiple domains. Proficient in all phases of software development, QA testing, IT and end-to-end delivery.\n\n// OBJECTIVE\n\nLooking for a fresher python and Django developer position where I can utilise my technical skills for the growth of business and the organisation.\n\n// WORK EXPERIENCE\n\nLuitpad software\tDjango web developer\nMay 2016-August 2017\tHTML, Bootstrap, CSS, Javascript, Django, REST API\n\nLuitpad software\tPython Programmer \n\nMay 2014- April 2016\tPython, Machine Learning\n\nMarquistech\tSoftware Analyst \n\nMay 2013 - April 2014\tMobile software testing\n\nSamsung India Electronics\tTest Engineer\n\nMarch 2010 - March 2013\tTesting and QA of mobile\n\nVodafone India\tNetwork Engineer\n\nJuly 2008 - June 2009\tTransmission\n\n\n// PROJECTS\n// Luitpad (Since May 2016– August 2017)\n\tClient\n\tLuitpad software\n\n\tProject Description\n\tDevelopment of a Django website containing databases at the backend for bioinformatics research.\n\n\n\n\n\n\n\n\n\n// Luitpad (Since Mar 2015 – April 2016)\n\tClient\n\tLuitpad software\n\n\tProject Description\n\tClassification problem in gene annotations (Bioinformatics). training a standard data-sets with a number of features carefully selected, on different available machine learning model for accuracy comparison.\n\n\tTeam Size\n\t6\n\n\tMy Position\n\tPython programmer involving use of Machine learning python\nLibraries scikit-learn, tensorFlow, theano, numpy, pandas.\n\n\tMy Responsibilities\n\tDeveloping python codes for the project.\n\n\tTechnologies Used\n\tpython, Machine Learning classification-regression models\nKNN, DecisionTreeClassifier, Random Forest, Naive Bayes.\n\n\n\n\n// Luitpad (May 2014 - Feb 2015)\n\tClient\n\tLuitpad software\n\n\tProject Description\n\tA Unicode based Assamese writing software for predicting text\n\n\tTeam Size\n\t4\n\n\tMy Position\n\tpython programmer\n\n\tMy Responsibilities\n\t1. Write clean, maintainable code following best practices (unit testing, source control, continuous integration, automation, design patterns, etc.) \n2. Debug code and troubleshoot problems.\n3. Collaborate with other developers, testers, and system engineers to ensure quality product enhancements. \n4. Take full responsibility for the quality of code and test cases that are developed\n\n\tTechnologies Used\n\tPython, Linux, github.\n\n\n\n\n// Marquis technologies Pvt Ltd (May 2013-April 2014)(NOKIA client, Bangalore)\n\tClient\n\tNokia\n\n\tProject Description\n\tHandset manual testing pre-launch.\n\n\tTeam Size\n\t8\n\n\tMy Position\n\tSoftware Analyst and Network related tester\n\n\tMy Responsibilities\n\t1. finding defects in functionalities of mobile devices pre-launch.\n2. Report bugs and follow up with developer for fix.\n3. writing reports\n\n\tTechnologies Used\n\tQC, bugzila\n\n\n\n//Samsung Software Engineering Lab (March 2010-March 2013)(payroll of Samsung, Noida)\n\tClient\n\tSamsung Mobile division\n\n\tProject Description\n\tSamsung quality assurace of mobile devices\n\n\tTeam Size\n\t60 (mobile evaluation team of India)\n\n\tMy Position\n\tTest Engineer.\n\n\tMy Responsibilities\n\t1. carrying out manual testing as per test cases.\n2. finding bugs in the development version of OS android.\n3. automation test using samsung propreiority tools.\n\n\tTechnologies Used\n\tAutomation testing tools provided by samsung developers.\n\n\n\n\n//Vodafone India Ltd. (July 2008-June 2009) (payroll of vodafone India)\n\tClient\n\tVodafone Network\n\n\tProject Description\n\tNetwork maintenance and project management\n\n\tTeam Size\n\t15\n\n\tMy Position\n\tNetwork Engineer.\n\n\tMy Responsibilities\n\t1. troubeshooting network at the BSS level\n2. managing technician team for resolving power issues at sites.\n3. project roll out of new sites and site acceptace test.\n\n\tTechnologies Used\n\tMicrosoft excel, CCNA\n\n\n\n// SKILLS                                                                                            \nMachine Learning, Linux, Networking, R, Python programming\n\n Mobile OS testing experience of 5 years\n\nProbability theory and statistics\n\nDjango, HTML, CSS, Javascript, REST API\n\n\n// EDUCATION\n\n\n· B.E.  in Electronics & Telecommunication from Assam Engineering College\n( Gauhati University from July 2003 - June 2008 )\n\n\n\n// INTERESTS\n\n· Machine Learning, Python, Django, HTML, Bootstrap, CSS, Javascipt, REST API\n· Bioinformatics\n· Mobile handset Quality Asssurance, Testing and bugs reporting\n\n// CERTIFICATIONS\n\n· Red hat certified Engineer (CERTIFICATE NUMBER: 160-032-587)\n\n// REFERENCES\n\nhttps://www.linkedin.com/in/kishorikonwar/","annotation":[{"label":["Skills"],"points":[{"start":4358,"end":4363,"text":"Python"}]},{"label":["Education"],"points":[{"start":4199,"end":4202,"text":"B.E."}]},{"label":["Skills"],"points":[{"start":4043,"end":4048,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2470,"end":2475,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1526,"end":1531,"text":"Python"}]},{"label":["Skills"],"points":[{"start":804,"end":826,"text":"Mobile software testing"}]},{"label":["Skills"],"points":[{"start":684,"end":700,"text":"Python Programmer"}]},{"label":["Skills"],"points":[{"start":573,"end":592,"text":"Django web developer"}]},{"label":["Skills"],"points":[{"start":181,"end":200,"text":"Django web developer"}]},{"label":["Skills"],"points":[{"start":159,"end":164,"text":"Python"}]},{"label":["Name"],"points":[{"start":0,"end":15,"text":"Chiranjib Konwar"}]}],"extras":null,"metadata":{"first_done_at":1532687563000,"last_updated_at":1532687563000,"sec_taken":164,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "18th January 2017 \n \n\nCicil Thomas \nKochi • +91 9496 041 442 • cicilthomas@gmail.com \n\n \n\nProfessional Experience - 5.3 Years (as of January 2017)      \n\nCognizant, Kochi                        April 2016 – Present \n\nAssociate - Projects   \n\n▪ Gained tremendous experience in Amazon Alexa Skill development. An Alexa skill framework was \n\ndeveloped on top of Amazon Alexa SDK with state/context handling for easier and faster Skill \n\ndevelopment, using which a dynamic content skill was developed. Direct inputs/suggestions from \n\nAmazon Alexa architects were integrated.   \n\n▪ Did numerous POCs on Alexa, API.AI, Lex , AWS Lambda-springboot integration. \n\n▪ Designed and implemented batch-job-service which populates data and performs all calculations in \n\nCognizant Work Activate application.  \n\nTata Consultancy Services, Kochi                 April 2014 – March 2016 \n\nSystems Engineer   \n\n Automated Custom Sports Rating Tool, a legacy application, saving 60% of manual effort involved.  \n\n Developed a Liferay data conversion portlet for the CDAR (Consumer Data Analysis and Reporting) \n\napplication, thereby reducing the number web service calls to one for a set of data. And a token based \n\nAuto-Login into the Liferay Portal from CDAR. \n\n Implemented 3 reports in PD Advantage Web helping the business to retire a legacy application.  \n\nArbitron Inc., Kochi                                 Sept 2012 – March 2014 \n\nGraduate Specialist        \n\n Integrated ‘Multi Selection’ component into TAPSCAN, a flag-ship product of Arbitron.  \n\n Designed and implemented Arbitron Recruiter System, which handles the entire HR process. \n\n Rebranded two applications into Nielsen UI standards when Arbitron was acquired. \n\nEducation \n\nIndus College of Engineering, Coimbatore                           Sept 2008 – June 2012 \n\nComputer Science and Engineering, Affiliated to Anna University, Chennai                                      CGPA-8.8 \n\n Project work: Android app using DNA Cryptography for secure text transmission between clients. \n\nAchievements \n\n Emerging Star Award for outstanding performance in TCS-Nielsen, SDO Team.                  August 2014 \n\n Best Academic Performer for achieving the highest CGPA in Computer Science department.  June 2012 \n\nPersonal Projects \n\n TurritopsisD - A minimalistic user friendly billing system using Swing, Spring-core and Derby. \n\n GlassSponge - A highly customizable online web2print solution where users can design products. \n\n Be Fit Alexa Skill – A simple Alexa skill that fetches user’s calorie consumption from Google Fit API. \n\nTechnical Skills \n\n Java, Amazon Alexa, Lex, Spring-boot, Spring-batch, Google Cloud Messaging, AWS SES, AWS EC2, AWS \n\nLambda, Heroku, Web Services-REST,  MySQL, Maven, HTML, CSS, JavaScript, Bootstrap.  \n\n Tools: CVS, SVN, Git, Eclipse IDE, STS, HP Quality Center. \n\nmailto:cicilthomas@gmail.com","annotation":[{"label":["Skills"],"points":[{"start":2711,"end":2715,"text":" AWS "}]},{"label":["Skills"],"points":[{"start":2702,"end":2709,"text":" AWS EC2"}]},{"label":["Skills"],"points":[{"start":2702,"end":2706,"text":" AWS "}]},{"label":["Skills"],"points":[{"start":2694,"end":2700,"text":"AWS SES"}]},{"label":["Skills"],"points":[{"start":2693,"end":2697,"text":" AWS "}]},{"label":["Skills"],"points":[{"start":2670,"end":2691,"text":"Google Cloud Messaging"}]},{"label":["Skills"],"points":[{"start":2638,"end":2640,"text":"Lex"}]},{"label":["Skills"],"points":[{"start":2631,"end":2635,"text":"Alexa"}]},{"label":["Skills"],"points":[{"start":2522,"end":2526,"text":"Alexa"}]},{"label":["Skills"],"points":[{"start":2499,"end":2503,"text":"Alexa"}]},{"label":["Location"],"points":[{"start":1364,"end":1369,"text":"Kochi "}]},{"label":["Location"],"points":[{"start":825,"end":830,"text":"Kochi "}]},{"label":["Skills"],"points":[{"start":620,"end":652,"text":"AWS Lambda-springboot integration"}]},{"label":["Skills"],"points":[{"start":619,"end":623,"text":" AWS "}]},{"label":["Skills"],"points":[{"start":614,"end":616,"text":"Lex"}]},{"label":["Skills"],"points":[{"start":606,"end":611,"text":"API.AI"}]},{"label":["Skills"],"points":[{"start":599,"end":603,"text":"Alexa"}]},{"label":["Skills"],"points":[{"start":538,"end":542,"text":"Alexa"}]},{"label":["Skills"],"points":[{"start":366,"end":370,"text":"Alexa"}]},{"label":["Skills"],"points":[{"start":311,"end":315,"text":"Alexa"}]},{"label":["Skills"],"points":[{"start":283,"end":287,"text":"Alexa"}]},{"label":["Location"],"points":[{"start":165,"end":170,"text":"Kochi "}]},{"label":["Location"],"points":[{"start":36,"end":41,"text":"Kochi "}]},{"label":["Name"],"points":[{"start":22,"end":33,"text":"Cicil Thomas"}]}],"extras":null,"metadata":{"first_done_at":1532687061000,"last_updated_at":1532687061000,"sec_taken":133,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Deepankar Mahapatro - Software Engineer II (Adobe Systems)\n+91 8884013976\t          deepankarmahapatro@gmail.com             linkedin.com/in/deepankarmahapatro\nProfile\nSummary\t“Data is people, not just numbers”- I believe in telling stories using data which would make sense and order to people. 4.4+ years of brainstorming has helped me develop skills in Data Science and Machine Learning to build systems that deal with massive amount of Data. \nData Science \tHandling Data platforms, analysis & modelling of Flashplayer & Reader distribution center which has generated over $1B in revenue via distribution of 3rd party software. Led initiative to build statistical models using historical data for Product Advertisement to predict Customer’s behavior. Implemented sentiment analysis from stream data for several Adobe Twitter handles. Created an end-to-end Data platform which performs Data munging, Insertion into DB, Daily/ Weekly/Monthly reporting, Dashboards for Engineering/Product divisions, Automated ad-hoc analysis for health checks.\nImpact\tPlayed a pivotal role in changing a pure engineering team into a data-driven team within a short span. My rigorous analysis on the Data has amplified the revenue generation (30% to be exact) and has brought in more business to the product.\nCollaboration\tExtensive experience working in large, diverse teams of Engineers (Dev/QA) and     Product Managers. Collaborated with partners in critical business meetings to use the knowledge of data in making quick decisions.\n\nWork Experience\nSep 14 - Present\tSoftware Engineer II at Adobe Systems, Bangalore\nJul 13 - Sep 14\tSoftware Engineer at Tuebora, Bangalore\nJan 13 - Jul 13\tAssociate Software Engineer at Accenture, Bangalore\n\nTechnical Skills\nProgramming\tPython (Including Pandas, Numpy, Matplotlib, Scikit-learn, NLTK), Machine Learning (Classification, Regression, Clustering etc.), Natural Language Processing, Structured data (SQL, JSON, XML), Unix/Linux, Bash Shell Scripting, Object Oriented Programming\nSoftware/Tools\tJupyter (iPython) Notebook, Elastic Search – Logstash - Kibana (ELK Stack), Oracle Database, MS Excel, Jenkins, Cygwin, Charles, Azure Machine Learning, Spyder (IDE)\n\nEducation\n2012\tB.Tech, Electronics & Communication Engineering, \n\tNational Institute of Science & Technology, Odisha (8.9/10)\n2008\t10+2, SKCG Junior College, Paralakhemundi, Odisha (87%)\n2006\t10th, Devagiri High School, Andrasingi, Odisha (92%)\n\nCertifications (Currently undergoing Microsoft Professional Program Certificate in Data Science on EdX). \nCompleted courses:\nMicrosoft: DAT203.2x: Principles of Machine Learning\nMicrosoft: DAT203.1x: Data Science Essentials\nMicrosoft: DAT208x Introduction to Python for Data Science\nMicrosoft: DAT101x: Data Science Orientation\nMicrosoft: DAT201x: Querying with Transact-SQL\nMicrosoft: DAT206x Analyzing and Visualizing Data with Excel\n\nOngoing courses:\nMicrosoft: DAT210x: Programming with Python for Data Science\nMicrosoft: DS101x: Statistical Thinking for Data Science and Analytics\nMachine Learning (Stanford University) by Andrew Ng (Coursera)\n\n\nProjects\nData Platforms & Statistical Modelling (Adobe Systems):\n· Implemented sentiment analysis from stream data for various Twitter handles & Adobe Hashtags using NLTK, scikit-learn, pandas modules in Python. \n· Extended the implementation for Flashplayer/Reader forum posts to figure out the support related items for easier operations using state-of-the-art machine learning models.\n· Developed a system to choose & display one of the 4 in-product advertisements using various classifiers. Implemented the projects using scikit-learn, p0061ndas & matplotlib. \n· Designed & Developed Data Engineering & Analysis infrastructure for Flashplayer & Reader Distribution platform built using ELK Stack (Elasticsearch – Logstash - Kibana) for instant Traffic analysis & visualizations. \n· Created multiple automated processes using Python which clean, integrate and evaluate Terabytes of unstructured data into a form suitable for analysis and then analyze it, build visualizations.\n· Adhoc analysis & deep-dives to identify the root cause of deviations in data & metric. Implemented the metrics to help the management to use \"numbers\" as a strategic asset. \n· Interacting with product and engineering managers to identify gaps, questions, and issues for data analysis and opportunities. Helping the Dev/QA team in automating regular tasks.\n\nMachine Learning & Analysis Platform (Tuebora):\n· Applied various classification algorithms for accurate judgements about employees having more access than needed or if access is unused, and thereby helping Enterprises detect & prevent fraud.\n· Developed Python scripts to collect & clean data from various applications which would later be utilized for Predictive Analysis to mature the IAM process. \n\n\nAchievements\n· Spot Award (2016)- For contribution in creating Statistical models to predict customer’s behavior.\n· Special Contribution Award (2015) - For developing sentiment analysis platform from social media steams.\n· Promotion to Software Engineer-II within 4 months of service in Adobe.\n· University (BPUT) topper in 1st year scoring 9.79/10. \n· Honored with Amul- Vidya Bhushan award in 10+2 (District topper & State rank holder).\n· Honored with Amul- Vidya Shree award in 10th (District topper & State rank holder).","annotation":[{"label":["Skills"],"points":[{"start":4685,"end":4690,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3920,"end":3925,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3295,"end":3300,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2931,"end":2936,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2699,"end":2704,"text":"Python"}]},{"label":["Education"],"points":[{"start":2209,"end":2214,"text":"B.Tech"}]},{"label":["Skills"],"points":[{"start":2156,"end":2177,"text":"Azure Machine Learning"}]},{"label":["Skills"],"points":[{"start":2037,"end":2042,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1984,"end":2010,"text":"Object Oriented Programming"}]},{"label":["Skills"],"points":[{"start":1757,"end":1762,"text":"Python"}]},{"label":["Location"],"points":[{"start":1717,"end":1725,"text":"Bangalore"}]},{"label":["Location"],"points":[{"start":1649,"end":1657,"text":"Bangalore"}]},{"label":["Location"],"points":[{"start":1593,"end":1601,"text":"Bangalore"}]},{"label":["Name"],"points":[{"start":0,"end":18,"text":"Deepankar Mahapatro"}]}],"extras":null,"metadata":{"first_done_at":1532667045000,"last_updated_at":1532667045000,"sec_taken":206,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "DHANAPAL MANICKAM \n\nData Scientist - Deep Learning & Machine Learning \n\nN0:52, Xavier Layout, Bangalore-560047, Email-dhanapalsing@gmail.com, P: (+91) 9900978685 \n\nAn innovative Data Science expert with over six years of corporate experience (6 yrs.), and a Bachelor's \n\ndegree in Biochemistry. Successful background in delivering end to end solutions that address \n\ncustomer pain points, across domains like Machine Learning, Deep Learning and statistical modelling. \n\nExpert in Python Libraries and Big data Spark for implementing machine learning algorithms in \n\nproduction environment. Strong Experience using TensorFlow open source framework. Passionate \n\nabout building data driven models to solve real world business applications across various sectors. \n\nExcellent understanding of business operations and analytics tools for effective analysis of data.  \n\nEXPERIENCE:  \n\nEthna Attributes Soft Technologies Pvt Ltd, Sep’ 2011 to Oct’ 2017. \n\nPROGRAMING SKILLS:  \n\nDeep Learning   : CNN, RNN, Activation functions, LSTM \n\nNLP     : Text Summarization, Word Embedding, Seq2Seq  \n\nMachine Learning   : Decision Tree, Random Forest, SVM, PCA, Naïve Bayes, NLP \n\n                                                             Linear Regression, Logistic Regression, K Means Clustering, KNN \n\n                                                             Time Series Forecasting  \n\nLanguages & Libraries  : TensorFlow, NumPy, Pandas, Scikit-learn, Matplotlib, SciPy, NLTK \n\nBig Data Technologies   : Hive, Pig, HDFS, HBase, Sqoop, Kafka, Spark  \n\nData visualization    : Mat plotlip, Seaborn, Tableau  \n\nETL     : Informatica  \n\nDatabases     : Oracle   \n\nOperating Systems    : Windows, Linux \n\nProject: 1             Sep 2016 to Oct 2017 \n\nData Scientist, Comerica Bank.                                \n\nDescription: The project was to build an algorithm that accurately classifies credit card holders among \n\nmultiple classes based on the historical data available on multiple variables. The objective of the \n\nproject was to improve bank's efficiency by reducing default rate while offering new products. \n\n Responsible for predictive analysis of credit scoring to predict whether or not credit extended \n\nto a new or an existing applicant will likely result in profit or losses. \n\nmailto:Email-dhanapalsing@gmail.com\n\n\n Analyzed cash withdrawal transactions at an ATM level to find non performing machines and \n\nlocations \n\n Developed a Logistic Regression model to predict whether a customer will pay income tax \n\nthrough the bank's facilities. \n\n Used k-fold cross validation to avoid over fitting. \n\nProject: 2                     Sep 2015 to August 2016  \n\nData Scientist, Jet.com Hoboken, NJ.            \n\nDescription: The focus of project was on sales prediction by using sales data into supervised \n\nclassification algorithm to predict customer churn and implement successful strategy.  \n\nResponsibilities:   \n\n Developed and implemented a model to predict customer buying behavior based on past \n\nhistory using gradient boosting with accuracy of 76%.  \n\n Worked with sales management team to refine predictive methods & sales planning analytical \n\nprocess. Prepared Dashboards using calculations, parameters in Tableau.  \n\n Used machine learning techniques for predictions & forecasting based on the Sales training        \n\ndata. Executed overall data aggregation and process improvement reporting within the sales \n\ndepartment.  \n\n Regression analysis to understand customer discount patterns with R square of 68% \n\nProjects: 3                         July 2014 to Sep 2015  \n\nDescription: Worked as team lead solving long term analytics and optimization problems for largest \n\nInsurance in the U.S. Also responsible for managing client relationships, client workshops and \n\nmentoring of juniors. \n\n \n\n Data cleaning and profiling of source data systems in preparation for data analytics work. \n\n Assisted in building policy rate setting models \n\n High level Risk Management modeling of personal auto data highlighting opportunities for \n\n20% lower claims \n\nProjects: 4                     June 2013 to June 2014 \n\nSr. Data Analyst, Safety National St. Louis, MO  \n\nDescription: Safety National Insurance provides a wide range of Insurance Policies. This project is \n\nintended to replace existing legacy applications in Mainframes for storing and processing the data of \n\nBilling, Payments, and Disbursements Application Databases entirely to Hadoop ecosystem we need \n\nto conduct regular backups and perform performance tuning and ensure technical and functional \n\ndesigns meet business requirements. \n\n Analyzed 5,000+ contacts in a spreadsheet, successfully drawing conclusions about consumer \n\ndata \n\n Proposed solutions to improve system efficiencies and reduce total expenses \n\n Created partitioned and bucketed tables in Hive, loading data and writing hive queries which \n\ninvolve multiple join scenarios  \n\n\n\nProject: 5                          Sep 2012 to June 2013 \n\nData Analyst, Gillette healthcare, USA                \n\nDescription: This project involved the development of Tableau Dashboards to project Activity KPI's \n\nfor analysis of Patients and the diversity calculation. Created dashboard for different for innovative \n\nmedical and surgical intervention, proven therapies and showed their performance on region wise. \n\n Developed SQL Queries to fetch complex data from different tables in remote databases using \njoins,  \n\n Worked with other team members to complete special projects and achieve project deadlines. \n Used advanced Excel functions to generate spreadsheets and pivot tables. \n Analysed the partitioned and bucketed data and compute various metrics for reporting. \n\n \n\nProject: 6                      Oct2011 to August 2012       \n\nData Analyst, Sun Pharmaceutical Mumbai.              \n\nDescription: Sun Pharmaceutical Industries Limited is an Indian multinational pharmaceutical \n\ncompany headquartered in Mumbai, Maharashtra that manufactures and sells pharmaceutical \n\nformulations and active pharmaceutical. \n\n Building forecast model and build predictive models with the relevant information  \n\n Implementing and developing data visualization models for the business presentations \n\n Conducted reports for implementation of marketing strategies, leading to 34% growth in \n\ncustomer acquisition. \n\n Developed Stored Procedures for parameterized, drill-down, and drill-through reports in \n\nTableau.","annotation":[{"label":["Skills"],"points":[{"start":1473,"end":1493,"text":"Big Data Technologies"}]},{"label":["Skills"],"points":[{"start":1160,"end":1163,"text":"NLP "}]},{"label":["Skills"],"points":[{"start":1086,"end":1101,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1029,"end":1032,"text":"NLP "}]},{"label":["Skills"],"points":[{"start":972,"end":984,"text":"Deep Learning"}]},{"label":["Skills"],"points":[{"start":427,"end":439,"text":"Deep Learning"}]},{"label":["Skills"],"points":[{"start":409,"end":424,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":53,"end":68,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":37,"end":49,"text":"Deep Learning"}]},{"label":["Name"],"points":[{"start":0,"end":17,"text":"DHANAPAL MANICKAM "}]}],"extras":null,"metadata":{"first_done_at":1532689581000,"last_updated_at":1532689581000,"sec_taken":172,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Udaya Laxmi Ch\n\nEmail : laxmi.udaya@gmail.com\n\n\t\n\n\tPhone: -9740606990\n\t\n\n\n\tSummary\n\n\t· 9.5 years of experience in Software Development.\n· 3.5 years of experience in Machine Learning\n· Primary Skills – Machine Learning, R programming, Lotus Notes.\n· Presently working for Wipro Technologies, Bangalore.\n· Experience in planning, estimation, design, development, and testing object oriented applications.\n· Experience in preparing various technical documents like Functional Specs, HLD, LLD, Flowcharts and Test cases.\n· Sound Knowledge in Object Oriented Design Principles\n· Have Team Handling experience.\n· Domain experience of Manufacturing and Finance.\n· Have Experience in Scrum Agile Model\n· Understand business requirements from clients\n\n\n\n\tTechnical Skills\n\n\tKey skills: \n\tMachine Learning,R Programming, MySQL, PostgreSQL, Microsoft Access, SQL Server, FileMaker, Oracle, RDBMS, dBASE, Clipper, FoxPro, Firebase, Mongodb, Python,  ava, J2EE, Oracle Fusion,Oracle Cloud, Salesforce, Devops Android, Business Analyst, UI Developer, DBAs, Embedded Systems, .NET, Hadoop, SQL Developer, Big Data, Tableau, Networking, Etl, Informatica, Ios, Quality Analyst, Project Manager, Python, Data Science, Python, Machine Learning, SAS, Java, Scala, Hadoop, Hive, Bigdata, Programming, SQL server reporting, Msbi Ssis, Ssrs, Msbi, Sql Reporting, Artificial Intelligence, Pandas, Pyspark, Sklearn, Flask, Django, Map Reduce, Parametric Design, Modeling, Regression, Patterns, Data Mining, Text Mining, Oops, Deep Learning, Web Analytics, Time Series, Regression, Tensorflow, Azure, Linear Regression, Logistic Regression, Decision Tree, Random Forest, Data Structure, Computer Vision, IHS, WAS, Java EE, SQL Server, .NET core, C#, ASP.NET, Rdlc, Linq, Sql, Web Api, Mvc, Javascript, Web Services, Oracle, MS SQL, PHP, Laravel, CodeIgniter, Symfony, Zend, Phalcon, CakePHP, Yii, FuelPHP, React, Vue, Angular, Ember, Backbone, Lotus Notes\n\n\tAlgorithms:\n\tNaïve Bayes, K means clustering,Word Cloud\n\n\tDatabases: \n\tMicrosoft SQL, Mongo DB\n\n\tWeb Technologies: \n\tXML, XSLT, HTML,  JavaScript,  AJAX, JQuery\n\n\tIDE:\n\tR studio,Pycharm\n\n\n\tProfessional Experience\n\n\tCurrent Employer :\n\tWipro Technologies., Bangalore  – (Oct  2010  to till date) – Technical Lead/Data Scientist\n\n\tPrevious Employers :\n\tHSBC Software development , Hyderabad (June  2008  to Sep 2010)  - SE\n\n\n\tQualification\n\n\tDegree\n\tCollege\n\tUniversity/Board\n\tYear\n\tPercentage (%)\n\n\tMCA\n\tNizam College, Basheerbagh,Hyderabad\n\tOsmania University\n\t2008\n\t75\n\n\n\tProject Experience \n\n\tProject 1 : Exploratory Data Analysis:\n\nProject Description:   Performed EDA analysis to analyze the Purchase frequency of vehicles which occurred over past 3 years and try to predict the frequency occurring in the future.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Performed EDA analysis to find the insights of the data. Observed the summary of each and every variable to understand the variables.\n\n· Performed the feature selection using hypothesis testing.\n\n· Identified the outliers using box plot.\n\n· Identified the trend in the purchases using histogram.\n\n\n\n\tProject 2: Word Cloud Analysis:\n\nProject Description:   Performed Word cloud and Sentimental Analysis of the customer feedbacks. Graphically represented the most frequently occurred words through Word cloud. Through sentimental analysis we identified whether a user-generated text expresses positive, negative or neutral opinion.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Created a Corpus using TM package and performed pre-processing of data.\n\n· Removed the punctuations, stemming and stop words which are of no analytical value.\n\n· Built a Document term matrix and identified the most frequently occurring words\n\n· Graphically represented it using  RColorbrewer Package\n\n\n\tProject 3: Sentimental Analysis:\n\nProject Description: Performed Sentimental Analysis of customer feedbacks through Naïve Bayes. Used “e1071” Package for implementing naïve Bayes method.\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· The DTM created using TM package was an input to the Naive Bayes Model.\n\n· As Naive Bayes classifier is typically trained on data with categorical features. We have converted the count of the words into a factor variable that indicates Yes or No whether the word is present or not.\n\n\tProject 4: Clustering Analysis:\n\nProject Description: Classified the customers on the basis of their purchases whether they have purchased low variant or high variant trucks. It in turn helped in building the right customer strategies.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Performed data preparation and Normalization of data using min-max method.\n\n· As K-means algorithm groups a dataset into a user-specified number (k) of clusters. Identified the initial cluster centroids as 3.\n\n· K clusters are creating by associating every observation with the nearest mean.\n\n· Used elbow method to validate the number of clusters such that within-cluster sum of square(wss) is minimized.\n\n\n\n\tProject 5 : Inter Connection Management Tool\nProject Description: Inter-connection Management (IMT) is prototype being developed for Engineering and Sales department to handle customizations of an existing product based on the customer's requirement. Users from engineering department will identify the items, which need to be customized out of the entire product design.\nRole\n\n       : Module Lead\n\nEnvironment\n       : Python, Mongo DB, jQuery\n\nTasks handled:\n\n· Gathering Requirements and providing Project Plan and Effort Estimation details.\n\n· Understanding business requirements and preparing SoU (Statement of Understanding) and Functional/Technical Specification documents.\n\n· Providing Effort & Resource estimations\n\n· Planning for application development and deployment\n\n· Writing and executing Test Cases and Test scenarios\n\n· Creating design elements using Technical Specification.\n\n· Performing Unit testing & Peer Reviews\n\n· Work Allocation and mentoring the team\n\n· Providing Technical guidance to the team. \n\n\tProject 6\n: cvdAEI Application\n\nProject Description\n     : CVDAEI is a web based multilingual application developed for handling the Change Management process in Truck division of Daimler. The change request flows through different phases mainly Initialization, Evaluation, Decision and Conclusion. This application has a configurable workflow where the request flow and the responsible persons can be configured easily at any point of time. \n\nRole\n\n    : Developer/Tester\n\nEnvironment\n     : Lotus Notes, Java, HTML, XML, Java Script, JQuery\n\nTasks handled:\n\n· Gathering Requirements and providing Project Plan and Effort Estimation details.\n\n· Understanding business requirements and preparing SoU (Statement of Understanding) and Functional/Technical Specification documents.\n\n· Providing Effort & Resource estimations\n\n· Planning for application development and deployment\n\n· Writing and executing Test Cases and Test scenarios\n\n· Creating design elements using Technical Specification.\n\n· Performing Unit testing & Peer Reviews\n\n· Work Allocation and mentoring the team\n\n· Providing Technical guidance to the team. \n\n\n\n\tProject Title: Project Management Office \nProject Description: The purpose of this system is to enable the Project Management Office to manage and execute the IT Applications and Operations driven project tasks in  more systematic manner. It will also enable them to efficiently perform a role as a facilitator to coordinate various IT Operations teams and to ensure that project activity enters the department through one common interface. The project tasks will subsequently be dealt with in a common format and in a consistent and appropriate manner, ensuring open and regular communication between all involved parties.\n\nRole\n\n    : Developer/Tester\n\nEnvironment\n     : Lotus Notes, Java, HTML, XML, Java Script, JQuery\n\nTasks Handled :\n\n· Writing and Executing Test cases in client server based environment\n· Individually provided application support","annotation":[{"label":["Skills"],"points":[{"start":7951,"end":7956,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":7938,"end":7948,"text":"Java Script"}]},{"label":["Skills"],"points":[{"start":7933,"end":7935,"text":"XML"}]},{"label":["Skills"],"points":[{"start":7927,"end":7930,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":7921,"end":7924,"text":"Java"}]},{"label":["Skills"],"points":[{"start":7908,"end":7918,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":6645,"end":6650,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":6632,"end":6642,"text":"Java Script"}]},{"label":["Skills"],"points":[{"start":6627,"end":6629,"text":"XML"}]},{"label":["Skills"],"points":[{"start":6621,"end":6624,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":6615,"end":6618,"text":"Java"}]},{"label":["Skills"],"points":[{"start":6602,"end":6612,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":5522,"end":5527,"text":"jQuery"}]},{"label":["Skills"],"points":[{"start":5512,"end":5519,"text":"Mongo DB"}]},{"label":["Skills"],"points":[{"start":5504,"end":5509,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4645,"end":4652,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":4054,"end":4061,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":3941,"end":3951,"text":"Naïve Bayes"}]},{"label":["Skills"],"points":[{"start":3494,"end":3501,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":3132,"end":3141,"text":"Word Cloud"}]},{"label":["Skills"],"points":[{"start":2793,"end":2800,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":2110,"end":2116,"text":"Pycharm"}]},{"label":["Skills"],"points":[{"start":2101,"end":2108,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":2086,"end":2091,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":2080,"end":2083,"text":"AJAX"}]},{"label":["Skills"],"points":[{"start":2067,"end":2076,"text":"JavaScript"}]},{"label":["Skills"],"points":[{"start":2060,"end":2063,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":2054,"end":2057,"text":"XSLT"}]},{"label":["Skills"],"points":[{"start":2049,"end":2051,"text":"XML"}]},{"label":["Skills"],"points":[{"start":2018,"end":2025,"text":"Mongo DB"}]},{"label":["Skills"],"points":[{"start":2003,"end":2015,"text":"Microsoft SQL"}]},{"label":["Skills"],"points":[{"start":1977,"end":1986,"text":"Word Cloud"}]},{"label":["Skills"],"points":[{"start":1958,"end":1975,"text":"K means clustering"}]},{"label":["Skills"],"points":[{"start":1945,"end":1955,"text":"Naïve Bayes"}]},{"label":["Skills"],"points":[{"start":1918,"end":1928,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":1908,"end":1915,"text":"Backbone"}]},{"label":["Skills"],"points":[{"start":1901,"end":1905,"text":"Ember"}]},{"label":["Skills"],"points":[{"start":1892,"end":1898,"text":"Angular"}]},{"label":["Skills"],"points":[{"start":1887,"end":1889,"text":"Vue"}]},{"label":["Skills"],"points":[{"start":1880,"end":1884,"text":"React"}]},{"label":["Skills"],"points":[{"start":1871,"end":1877,"text":"FuelPHP"}]},{"label":["Skills"],"points":[{"start":1866,"end":1868,"text":"Yii"}]},{"label":["Skills"],"points":[{"start":1857,"end":1863,"text":"CakePHP"}]},{"label":["Skills"],"points":[{"start":1848,"end":1854,"text":"Phalcon"}]},{"label":["Skills"],"points":[{"start":1842,"end":1845,"text":"Zend"}]},{"label":["Skills"],"points":[{"start":1833,"end":1839,"text":"Symfony"}]},{"label":["Skills"],"points":[{"start":1820,"end":1830,"text":"CodeIgniter"}]},{"label":["Skills"],"points":[{"start":1811,"end":1817,"text":"Laravel"}]},{"label":["Skills"],"points":[{"start":1806,"end":1808,"text":"PHP"}]},{"label":["Skills"],"points":[{"start":1798,"end":1803,"text":"MS SQL"}]},{"label":["Skills"],"points":[{"start":1790,"end":1795,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":1776,"end":1787,"text":"Web Services"}]},{"label":["Skills"],"points":[{"start":1764,"end":1773,"text":"Javascript"}]},{"label":["Skills"],"points":[{"start":1759,"end":1761,"text":"Mvc"}]},{"label":["Skills"],"points":[{"start":1750,"end":1756,"text":"Web Api"}]},{"label":["Skills"],"points":[{"start":1745,"end":1747,"text":"Sql"}]},{"label":["Skills"],"points":[{"start":1739,"end":1742,"text":"Linq"}]},{"label":["Skills"],"points":[{"start":1733,"end":1736,"text":"Rdlc"}]},{"label":["Skills"],"points":[{"start":1724,"end":1730,"text":"ASP.NET"}]},{"label":["Skills"],"points":[{"start":1720,"end":1721,"text":"C#"}]},{"label":["Skills"],"points":[{"start":1709,"end":1717,"text":".NET core"}]},{"label":["Skills"],"points":[{"start":1697,"end":1706,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":1688,"end":1694,"text":"Java EE"}]},{"label":["Skills"],"points":[{"start":1683,"end":1685,"text":"WAS"}]},{"label":["Skills"],"points":[{"start":1678,"end":1680,"text":"IHS"}]},{"label":["Skills"],"points":[{"start":1661,"end":1675,"text":"Computer Vision"}]},{"label":["Skills"],"points":[{"start":1645,"end":1658,"text":"Data Structure"}]},{"label":["Skills"],"points":[{"start":1630,"end":1642,"text":"Random Forest"}]},{"label":["Skills"],"points":[{"start":1615,"end":1627,"text":"Decision Tree"}]},{"label":["Skills"],"points":[{"start":1594,"end":1612,"text":"Logistic Regression"}]},{"label":["Skills"],"points":[{"start":1575,"end":1591,"text":"Linear Regression"}]},{"label":["Skills"],"points":[{"start":1568,"end":1572,"text":"Azure"}]},{"label":["Skills"],"points":[{"start":1556,"end":1565,"text":"Tensorflow"}]},{"label":["Skills"],"points":[{"start":1544,"end":1553,"text":"Regression"}]},{"label":["Skills"],"points":[{"start":1531,"end":1541,"text":"Time Series"}]},{"label":["Skills"],"points":[{"start":1516,"end":1528,"text":"Web Analytics"}]},{"label":["Skills"],"points":[{"start":1501,"end":1513,"text":"Deep Learning"}]},{"label":["Skills"],"points":[{"start":1495,"end":1498,"text":"Oops"}]},{"label":["Skills"],"points":[{"start":1482,"end":1492,"text":"Text Mining"}]},{"label":["Skills"],"points":[{"start":1469,"end":1479,"text":"Data Mining"}]},{"label":["Skills"],"points":[{"start":1459,"end":1466,"text":"Patterns"}]},{"label":["Skills"],"points":[{"start":1447,"end":1456,"text":"Regression"}]},{"label":["Skills"],"points":[{"start":1437,"end":1444,"text":"Modeling"}]},{"label":["Skills"],"points":[{"start":1418,"end":1434,"text":"Parametric Design"}]},{"label":["Skills"],"points":[{"start":1406,"end":1415,"text":"Map Reduce"}]},{"label":["Skills"],"points":[{"start":1398,"end":1403,"text":"Django"}]},{"label":["Skills"],"points":[{"start":1391,"end":1395,"text":"Flask"}]},{"label":["Skills"],"points":[{"start":1382,"end":1388,"text":"Sklearn"}]},{"label":["Skills"],"points":[{"start":1373,"end":1379,"text":"Pyspark"}]},{"label":["Skills"],"points":[{"start":1365,"end":1370,"text":"Pandas"}]},{"label":["Skills"],"points":[{"start":1340,"end":1362,"text":"Artificial Intelligence"}]},{"label":["Skills"],"points":[{"start":1325,"end":1337,"text":"Sql Reporting"}]},{"label":["Skills"],"points":[{"start":1325,"end":1327,"text":"Sql"}]},{"label":["Skills"],"points":[{"start":1319,"end":1322,"text":"Msbi"}]},{"label":["Skills"],"points":[{"start":1313,"end":1316,"text":"Ssrs"}]},{"label":["Skills"],"points":[{"start":1302,"end":1310,"text":"Msbi Ssis"}]},{"label":["Skills"],"points":[{"start":1302,"end":1305,"text":"Msbi"}]},{"label":["Skills"],"points":[{"start":1280,"end":1299,"text":"SQL server reporting"}]},{"label":["Skills"],"points":[{"start":1267,"end":1277,"text":"Programming"}]},{"label":["Skills"],"points":[{"start":1258,"end":1264,"text":"Bigdata"}]},{"label":["Skills"],"points":[{"start":1252,"end":1255,"text":"Hive"}]},{"label":["Skills"],"points":[{"start":1244,"end":1249,"text":"Hadoop"}]},{"label":["Skills"],"points":[{"start":1237,"end":1241,"text":"Scala"}]},{"label":["Skills"],"points":[{"start":1231,"end":1234,"text":"Java"}]},{"label":["Skills"],"points":[{"start":1226,"end":1228,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1208,"end":1223,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1200,"end":1205,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1186,"end":1197,"text":"Data Science"}]},{"label":["Skills"],"points":[{"start":1178,"end":1183,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1161,"end":1175,"text":"Project Manager"}]},{"label":["Skills"],"points":[{"start":1144,"end":1158,"text":"Quality Analyst"}]},{"label":["Skills"],"points":[{"start":1139,"end":1141,"text":"Ios"}]},{"label":["Skills"],"points":[{"start":1126,"end":1136,"text":"Informatica"}]},{"label":["Skills"],"points":[{"start":1121,"end":1123,"text":"Etl"}]},{"label":["Skills"],"points":[{"start":1109,"end":1118,"text":"Networking"}]},{"label":["Skills"],"points":[{"start":1100,"end":1106,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":1090,"end":1097,"text":"Big Data"}]},{"label":["Skills"],"points":[{"start":1075,"end":1087,"text":"SQL Developer"}]},{"label":["Skills"],"points":[{"start":1067,"end":1072,"text":"Hadoop"}]},{"label":["Skills"],"points":[{"start":1061,"end":1064,"text":".NET"}]},{"label":["Skills"],"points":[{"start":1043,"end":1058,"text":"Embedded Systems"}]},{"label":["Skills"],"points":[{"start":1037,"end":1040,"text":"DBAs"}]},{"label":["Skills"],"points":[{"start":1023,"end":1034,"text":"UI Developer"}]},{"label":["Skills"],"points":[{"start":1005,"end":1020,"text":"Business Analyst"}]},{"label":["Skills"],"points":[{"start":989,"end":1002,"text":"Devops Android"}]},{"label":["Skills"],"points":[{"start":977,"end":986,"text":"Salesforce"}]},{"label":["Skills"],"points":[{"start":963,"end":974,"text":"Oracle Cloud"}]},{"label":["Skills"],"points":[{"start":949,"end":961,"text":"Oracle Fusion"}]},{"label":["Skills"],"points":[{"start":943,"end":946,"text":"J2EE"}]},{"label":["Skills"],"points":[{"start":929,"end":934,"text":"Python"}]},{"label":["Skills"],"points":[{"start":920,"end":926,"text":"Mongodb"}]},{"label":["Skills"],"points":[{"start":910,"end":917,"text":"Firebase"}]},{"label":["Skills"],"points":[{"start":902,"end":907,"text":"FoxPro"}]},{"label":["Skills"],"points":[{"start":893,"end":899,"text":"Clipper"}]},{"label":["Skills"],"points":[{"start":886,"end":890,"text":"dBASE"}]},{"label":["Skills"],"points":[{"start":879,"end":883,"text":"RDBMS"}]},{"label":["Skills"],"points":[{"start":871,"end":876,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":860,"end":868,"text":"FileMaker"}]},{"label":["Skills"],"points":[{"start":848,"end":857,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":830,"end":845,"text":"Microsoft Access"}]},{"label":["Skills"],"points":[{"start":818,"end":827,"text":"PostgreSQL"}]},{"label":["Skills"],"points":[{"start":811,"end":815,"text":"MySQL"}]},{"label":["Skills"],"points":[{"start":798,"end":808,"text":"Programming"}]},{"label":["Skills"],"points":[{"start":796,"end":808,"text":"R Programming"}]},{"label":["Skills"],"points":[{"start":779,"end":794,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":234,"end":244,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":219,"end":231,"text":"R programming"}]},{"label":["Skills"],"points":[{"start":201,"end":216,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":165,"end":180,"text":"Machine Learning"}]},{"label":["Name"],"points":[{"start":0,"end":13,"text":"Udaya Laxmi Ch"}]}],"extras":null,"metadata":{"first_done_at":1579625576000,"last_updated_at":1579626369000,"sec_taken":0,"last_updated_by":"aJOmJy1lvpOYFetVNuqLvFo9Vx42","status":"done","evaluation":"NONE"}}
{"content": "Dhanesh Kumar Solanki\n\n\n\n\n\n    E 325 III-B, Khetri Nagar\nsolankidhanesh@gmail.com\n\n\n\n\n    Jhunjhunu, Rajasthan\n\n                                                   \n\n\n\n\n    00919880419933\nCareer Objective: - \n\nTo work with a Company/Organization in which I can utilize my computational Research and analytical skill to develop different types of Tools and Software which are safe and useful for people.\n\nKey Skills: -\n· Excellent Understanding of Machine Learning, NLP, Data Mining & Image Processing Techniques.\n\n· Team Player & also the ability to take Individual Assignments.\n\n· Team Management & Multi-Tasking Abilities.\n\n· Ability to extract & gather data & information from various resources.\n\n· Very Good in Using Open Libraries for ML, NLP, Image Processing.\nAcademics: -\n· Part-Time PhD Student In ISI Bangalore (under Dr. Saroj K. Meher- System Science & Information Unit {SSIU}).\n\n· Completed MS in Software Systems from B.I.T.S Pilani (WILPD) 2012-14.\n· BE “CSE” from IET ALWAR under University of Rajasthan 2005-09 with 62.18 %.\n\n· High Secondary School from C.A. No-1 under C.B.S.E BOARD-04 with 52.8 %.\n· Secondary School from C. A. No-1 under C.B.S.E. BORAD-02 with 50.8 %.\nExperience: -\n\nPart Time PhD: - Working on Deep Learning with NLP to develop some application for graph based search engine with help of Ne04j graph Database, using Conventional Neural Network with deep net, for defining the search index in each and every node for search under shortest path.\nColortokens India LLP Pvt\n\n\n\n\n10th Aug-2017 \n\nLead Data Scientist\n\nProject: -\n\nRisk: - Introduction of risk on network, bizapp, resources connection to create a new CVSS score.\n\nPolicy and Recommendation Engine: - Using ML to create a policy for different bizapp and recommendation for their different resources to help client to improve their risk score on IOT and different cloud platform with secured user access using power BI as visualization tool. Working on Virus traces for time – now till end of identify the virus and its implement on their connected sources, also Dos attack at different level with ransom and wannacry too. Working with NO-SQL, Mongo DB, Kafka and schema design with pattern identification.\nKPIT Technologies\n\n\n\n\n\n7th Sept 2016 -\n 9th Aug 2017\n\n\nSr. Tech Leader\nProjects: -\n\n\nPSA: - SME (Subject Matter Expert): - Statistical Modelling for Machine Learning algorithm for Image and ADAS Data under Data Mining Process, to give cost factor in implementing deep neural network with tensorflow chart for ADAS process.  \n\nV&V: - Solution Architect – Need to design some high architecture for verification and validation to check the requirements and test cases as per the use cases for the project.\n\nADAS: - Project Lead - Implementation for Machine Learning algorithm for Automotive Driver Assistant System, as Solution Architecture Level.\n\nIBM India Pvt Ltd.\n\nCognitive Data Scientist\n\n\n\n    8th Mar 2016 -  30-July 2016\nProjects: - \n1. TWC: - Working on predication of Power consumptions with machine learning algorithm for Texas USA with the help of neural network, using python as language. (Internal)\n2. Yield Management: - Worked to increase revenue of the airlines with the help of Random forest with different parameters, used python as language. (Internal)\nSigma Aldrich Chemical Pvt Ltd (Sigma-Aldrich Chemicals Pvt Ltd. is a subsidiary of Merck)\nData Scientist\n\n\n\n\n\n\n10th Aug 2015- 26th Feb 2016\nProjects: -\n1. Text Mining and Customer Prediction: - working on the Architecture design with building some algorithm with algorithm with SVM with layering of collective Intelligence.\n2. Big data analysis support: - Support routine big data analysis requests from internal team/customer, including NGS, Big Query etc.\n\n3. Bioinformatics support: - Support bioinformatics requests for R&D, Production, Operation, Marketing, Sales and other.\n\nWorking with Python on Spark Engine with Google Cloud Computing as Hadoop with GHFS and maintaining the pipelines of Algorithm.\n\nLiterature Mining & Handling Pipeline\n\nMobizz.in {Freelancer}\n\n\n\n\n\n\n\n3rd Mar 2015-31st July\nHead of Data Science, R&D, Data Scientist\n\nProject: - \n\n· Working on B2C for creating a new page ranking algorithm on near 30 parameters and their dependences for predicting the behaviours, with logs, chat sentimental, history and many more. \n· Tried to implement argument reality for this project. \n· Handling nodejs, with mongo dB, servers & API for connecting algorithm to B2C.\n\n· Helping on Schema and Architecture for this project.   \n\n· Working on very high level of ML, NLP, Hadoop, and Python with Many IDE’s.\n\nIntelligence Node Pvt. Ltd\n\n\n\n\n20th Oct 2014-31st Dec2014\nData Scientist\n\nProjects: - \n· Categorization of different e-commerce item as per the matching of items in all online portals, to find the mutual price calculations.  Making a new algorithm on Image Processing with Machine Learning under Pattern Recognition on Matlab, opencv which will process on the cloud. Algorithm using under this project is corners detections, PCA + SIFT and nearest neighbours with threshold values matching. Using high end machine learning algorithm to solve this big data of images from different portals, to find the matches of all the images and then find the probabilities of prices in the ecommerce.  \n· Handling Categorization of different item by R Language with Machine Learning for NLP String Matching too.\n\nCouncil of Scientific & Industrial Research (CSIR-CSIO)                     3rd April 14-15Oct 2014\nM.Tech thesis Trainee (M. Tech Training)\nProject: - Active labelling of facial Emotion with Swarm Intelligence.\n\nWorking on Recurrent Neural Network “Cellular Automata” with high level of Bayesian Probabilities with Action Units (“Eyes, Brow, Nose, mouth”) with their mutual information.\n\nProject:-\nSao Carlo University Barzil\n\n\n\n                                  11th Oct 13-16 Oct 14\n\nSenior R & D Scientist\n (Freelancer)\nProject:- TORO Tomography (Bio-Physic), developing one stimulator for tomography with Machine Learning (this contains high level of un-supervised data with supervised classification and un-supervised classification and SVM, PSVM and many more) and advance AI technologies like Image Processing, Data Processing and pattern Recognition.\nMatlab, C++ and other open tools.\nThe Millennium Project (Non Profitable)                                                June 12-15th Feb 2013\nProject: - 3D game with collective intelligence (big data), new Algorithm and Artificial Neural Network with Machine Learning with Android Mobile Technology to solve Pattern and Noise Problem.\n\nTech Lead (Tele Intern)\n\nThe Millennium Project is an org which build future Projects with the AI technology on BOINC SUPER COMPUTER with hadoop and cloud computing and for its teams across the world. They design new product of information Technology with AI, Collective Intelligence, Pythons, Python master and Java.\n\nIn this I had Done Research on new algorithm for 3D games (NLP, ML, Collective Intelligence with hadoop, NodeJs, MongoDB). \nResponsibilities:\n\n· Done Research on new Algorithm Design on BONIC SUPER COMPUTER for 3D games and data processing according to NLP,ML, AI  & collective Intelligence.\n\n· Developed a Prototype of Algorithm on 3D games on Super Server Cloud Computing (LINUX Based) with cloud computing WILDLIFE.INFO \n\n· Developed Pattern Recognition System with R System for Data Processing.\n\n· Developed open Library in System R for Unsupervised to Supervised Data.\n· Handle Multiple Research Teams From BONIC SUPER COMPUTER\n        BONIC SUPER COMPUTER CERTIFICATE\n\n· Become User of Day Near 10-12 times on Solving Machine Learning Problems with hadoop.\n· Certificate from Prime Grid.\n\n· Certificate from ABC @ Home.\n\n· Certificate from HAL @ Home.\n\n· Certificate from Enigma @ Home.\n\n· Certificate from OProject @ Home.\nLanguage Used: - Core Java & java, Python & Matlab.\n\nGerson Lehrman Group                                                                                                 June-10—June 12\nProjects:- \n\n· INVUS S.A.S (ITALY):- In this project I provide them a new research based algo which is from disturbed data mining according NLP, Ml with lexical analysis, Artificial neural network with deep coding of complex relation with input and output of data with hadoop and cloud computing. Used Machine Translation for text to Speech in Artificial Neural Network.\n· Energy/Commodity Trading & Risk (from Austin):- In this Project I done research on NLP, ML, AI according to the grammar, and translation between complex data and ANN data mining. \n· Intelligent System (E-ID Cards (IS)):- In this project, I does research on electronic data processing with ANN, Bayesian Model, Moore’s Law, Markov Chain properties with Inductive logic programming (ILP), Cluster analysis, Decision tree learning (DTL). Classification to detect the Pattern of Digital Images. \nResponsibilities:\n\n· Help the client with code and formation of Library with hadoop and cloud computing.\n\n· Done research with client on different platform of AI with Collective intelligence to provide them latest technology.\n\n· Educate them about ANN and HNN and other properties like Bayesian Model, Moore law.\n\nLanguage Used: - Core Java & java, Python\nNSTC NOIDA: -                                                                                                                 Jan 2009- Jun 2010\nProject: - Silver Nano Science                                                                        Online Research member\n\nNSTC NOIDA is org which provide training and work experience according to project for AI in Nano science (Computer and Electronics). I had learned Data processing with algorithm with NLP, ML with Python, Python Master with Java, Submitted thesis on this project.\n\nResponsibilities:\n\n· Done Research on New algorithm with data processing.\n\n· Done core coding with research in Python, Python master and Java.\n\nLanguage Used: - Core Java & java, Python\n\nBooks:-\nReview: -\n· Hadoop Beginner's Guide By Garry TurKington from Packt Publication.\n\n· Hadoop MapReduce Cookbook By Srinath Perera & Thilina Gunarathe from Packt Publication.\n\n· Hadoop Real-World Solutions Cookbook By Jonathan R. Owens, Jon Lentz & Brian Femiano from Packt Publication.\n· Memories with Maya – The science of Augmented Reality and AI in a Transhuman society from Clyde DeSouza.\n\n· Getting Started with Greenplum for Big Data Analytics-by Sunila Gollapudi from Packt Publication\nPersonal Book Chapters:-\n\n· Dhanesh Kumar Solanki, Dr. Ajit Kumar--A Statistical approach for Neural-Network-Security (NNS) Algorithm to handle data disturbance and virus detections of Cloud Computing. (Accepted)\n\n·  Dhanesh Kumar Solanki, Dr. Ajit Kumar-- Analytical Approach for Fusion Based Brain Tumor Detection.(accepted)\n\n· Book Chapter Accepted- \"Detection of Different Facial Features under Swarm Optimization,\" for the upcoming book, \"Handbook of Research on Identity Management and Authentication for Homeland Security.\"\n· Accepted Under IGI Global – “Patterned Search: - An Analytical Graph Based Clustering Algorithm for Complex Data,” for upcoming book \"Advancing Cloud Database Systems and Capacity Planning with Dynamic Applications.\"\n\n· Abstract Submitted – “Dynamic root based graph-patterned search path with Neo4J,” for upcoming book “Handbook of Research on Ubiquitous Machine Learning and its Applications”.\nResearch & Development “international competitions”:-\n\n\nProject Name: 1st Biometric Recognition with Portable Devices Competition\nOrganization: Faculdade de Engenharia da Universidade do Porto,                           Instituto de engenharia biomedical & INESC Porto. \n\nLanguage and Tech:  C+, Python & Open GL, Matlab, Machine Learning, MRI Brain Signals, EYE-EEG Signals, Image Processing & Virtual Brain images.\n\nTeam Size: 1\n\nRole: All\n\nDuration: 18 Months\n\nDescription: The highlight of this competition will be the application of biometric recognition, conditioned by the acquisition environment under which data is collected, to portable devices \n\nSuch as tablets and Smartphone’s.\n\nSuch a paradigm shift will involve the development of robust recognition algorithms capable of overcoming the new challenges posed by the introduction of less controlled acquisition conditions. Participants will not be limited to work on a specific trait but, instead, be allowed to work on one (or multiple) biometric modalities.\n\nProject Name: Brain Computer Interaction\nOrganization: G.Tec Medical Engineering\n\nLanguage and Tech:  C+, Python, Brain Images and Signals, Matlab, Openworm, Open signal & Open GL, EEGLAB, MRI Brain Signals, Image Processing with Pattern Recognition.\n\nTeam Size: 1\n\nRole: All\n\nDuration: 6 Months\n\nDescription: Bio aides nanobots will going to help us to learn and develop a Super\n\nIntelligence System with Collective Intelligence, A machine which have the ability to\n\nRecognised with the of 99.99% accurate answers each and every time. This Human computer Interaction is fully depend on the Nano cells in human brain and other parts, this machine can be used in all stream of development(medical, security, etc).\n\nThe understanding of human brain waves and other neurons structure in machine with\n\nWireless connection is going to built a super human Interaction system, which can’t be\n\nWrong (accurate up to 99.99%) because it read the brain waves with EEG, HEG with Nano\n\nCells from Inside of human brain.\nPaper Published:-\n· Editor In-Chair of “Evolution of Socially Intelligent Robot in Lovotics”.\n\n· Editor In-Chair of  ““Human Emotions, Happiness and Love towards Robot in Lovotics”.\n\n· Editor In-Chair of  “Machine Learning for Natural language Processing with Statics in Lovotics”.\n\n· Editor and Member of Editorial Board of LOVOTICS & OMICS Publishing Group\n· Dhanesh Kumar Solanki, Dr. Naresh Kumar Solanki, Dr. Adam-Fusion of Multi-slice MR-Scan Images with Genetic Algorithm with Curvelet-transform DOI no: 10.4172/2090-9888.1000109\n· Solanki, Dhanesh and Fakhreldin, Mohammed Adam Ibrahim and  Jasni, Mohamad Zain and Mazlina, Abdul Majid and Mohamad Fadli, Zolkipli (2014) Study of Security Layers Under Attack on Different Layers of Cloud Computing. Wulfenia Journal . ISSN 1561-882X (In Press).\n\n· Dhanesh Solanki, Dr. Adam, “Paper Submitted on Detection of Attacks and Prevention in Cloud Computing with Neural Networks”. Accepted\n\n•         Dhanesh Solanki, Dr. Adam, “Review Paper on Predictive Algorithm on Clustering on Big Data on Map-Reduce”. Accepted.\n\nCertification :-\n· Certificates in A.I (Artificial Intelligence) from Dr. Peter Norvig & Dr. Sebastian Thrun        Under Udacity (Online Course) with 100% score.\n·  Certificate in M.L (Machine Learning) from Stanford (Engineering) University, Stanford (coursera Online Course) with 80% score.\n· Certificate in NLP (Natural Language Certificate) from Stanford (Engineering) University, Stanford (courser Online Course) with 86% score.\n· Certificate in R-Data from Computing Data Analysis (Coursera Online Course).\n· Certificate in Big Data from (Coursera Online Course)\n· Certificate in Computational NeuroScience from (Coursera Online Course).\n· Certificate in Mobile Robotics from (Coursera Online Course).\n· Certificate of Java training From Ducat Noida.\n\nBlog and Groups:-\n· Keep Innovating www. http://dhaneshsolanki.blogspot.in/ \n\nExtra Curricular Activities and Achievements:-\n\n· Technology Advisor Member In LockSchuppen-FutureLab2056. \n· Developer under “Aster TeraData” from Processing and making new apps for R Tool to process Data.\n\n· Seniors Technical Member Under “Vibrant Data Lab” for Decision Tree for Human Virtual Data with MAP R.\n· Member and Reviewer of International Association of Computer Science and Information Technology (I.A.C.S.I.T.), Singapore. \n· Member of International Association for Automation and Robotics “ I.A.A.R.C.”\n· Member of INTERNATIONAL ASSOCAITION OF ENGG “IAENG”.\n· Member of International Research Association for Talent Development and Excellence (IRATDE).\nProgramming Language and Technology Knowledge Known and worked:-\n· Programming Language: C, Java, R and Python \n· Data processing Machine Learning, R with OLAP,OLTP\n· IDE: Matlab 2008,2012, Visual Studio-2008/2010/2012, AVR Dude \n· Database: MS SQL Server-2005/2008, Oracle 10i, My SQL, Access \n· Operating System: Debian, Ubuntu, Linux & Windows\n· Virtualization Tool: XEN Hypervisor(http://www.xenproject.org/)\n· Business Intelligence Tool: Pentaho (www.pentaho.com) and aligned tool for Pentaho\n· Project Management Tool: Vertec (www.vertec.com)\n· Other: OCL (Object Control Language)\n· Open Source: OpenGL, Open CV, Java ML, Open Muscle Model, JCUDA, EYE-EEG, MRI-EEG,EEGLAB, BSP SIGNAL TOOL BOX,Open Signal 2.0, Open worm, Open EclipseBrainstorm, Brain Explorer 2 & Open R Analysis Tools Etc… \nInterest Area:-\n· Brain Computer Interface\n\n· Computational Neuro Science\n\n· Digital Image Processing with Neuro Image & Signals\n· Natural Language Processing\n\n· Machine learning\n\nHobbies:-\nReading Books, Cycling & Listening Soft Songs.\n\nPersonal Details:-\nDate of Birth\n\n\n:  06/11/1986\n\n            \nLanguage Known\n\n:   English, Hindi.\n\nContact No.          \n\n:  +919880419933\nPan Card\n\n\n:  BHJPS0799F\n\n               Skype Id\n\n\n:  solankidhanesh\n\nDeclaration:- \n\nI hereby, declare that all the information given above is accurate to the best of my knowledge.\n\n\n\n\n\n\n\n\n\n\n\nDhanesh Kumar Solanki","annotation":[{"label":["Name"],"points":[{"start":17373,"end":17393,"text":"Dhanesh Kumar Solanki"}]},{"label":["Skills"],"points":[{"start":16886,"end":16902,"text":"Image Processing "}]},{"label":["Skills"],"points":[{"start":16173,"end":16179,"text":" Matlab"}]},{"label":["Skills"],"points":[{"start":16132,"end":16147,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":16106,"end":16111,"text":"Python"}]},{"label":["Skills"],"points":[{"start":14807,"end":14809,"text":"NLP"}]},{"label":["Skills"],"points":[{"start":14682,"end":14697,"text":"Machine Learning"}]},{"label":["Name"],"points":[{"start":13788,"end":13808,"text":"Dhanesh Kumar Solanki"}]},{"label":["Skills"],"points":[{"start":13633,"end":13648,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":12628,"end":12644,"text":"Image Processing "}]},{"label":["Skills"],"points":[{"start":12559,"end":12565,"text":" Matlab"}]},{"label":["Skills"],"points":[{"start":12526,"end":12531,"text":"Python"}]},{"label":["Skills"],"points":[{"start":12522,"end":12523,"text":"C+"}]},{"label":["Skills"],"points":[{"start":11772,"end":11788,"text":"Image Processing "}]},{"label":["Skills"],"points":[{"start":11718,"end":11733,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":11709,"end":11715,"text":" Matlab"}]},{"label":["Skills"],"points":[{"start":11692,"end":11697,"text":"Python"}]},{"label":["Skills"],"points":[{"start":11688,"end":11689,"text":"C+"}]},{"label":["Skills"],"points":[{"start":11356,"end":11371,"text":"Machine Learning"}]},{"label":["Name"],"points":[{"start":10684,"end":10704,"text":"Dhanesh Kumar Solanki"}]},{"label":["Name"],"points":[{"start":10495,"end":10515,"text":"Dhanesh Kumar Solanki"}]},{"label":["Skills"],"points":[{"start":9961,"end":9966,"text":"Python"}]},{"label":["Skills"],"points":[{"start":9901,"end":9906,"text":"Python"}]},{"label":["Skills"],"points":[{"start":9893,"end":9898,"text":"Python"}]},{"label":["Skills"],"points":[{"start":9722,"end":9727,"text":"Python"}]},{"label":["Skills"],"points":[{"start":9714,"end":9719,"text":"Python"}]},{"label":["Skills"],"points":[{"start":9701,"end":9703,"text":"NLP"}]},{"label":["Skills"],"points":[{"start":9240,"end":9245,"text":"Python"}]},{"label":["Skills"],"points":[{"start":8482,"end":8484,"text":"NLP"}]},{"label":["Skills"],"points":[{"start":8166,"end":8168,"text":"NLP"}]},{"label":["Skills"],"points":[{"start":7883,"end":7889,"text":" Matlab"}]},{"label":["Skills"],"points":[{"start":7875,"end":7880,"text":"Python"}]},{"label":["Skills"],"points":[{"start":7634,"end":7649,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":7163,"end":7165,"text":"NLP"}]},{"label":["Skills"],"points":[{"start":6969,"end":6971,"text":"NLP"}]},{"label":["Skills"],"points":[{"start":6885,"end":6890,"text":"Python"}]},{"label":["Skills"],"points":[{"start":6876,"end":6881,"text":"Python"}]},{"label":["Skills"],"points":[{"start":6506,"end":6521,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":6262,"end":6263,"text":"C+"}]},{"label":["Skills"],"points":[{"start":6004,"end":6019,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":5368,"end":5370,"text":"NLP"}]},{"label":["Skills"],"points":[{"start":5347,"end":5362,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":4912,"end":4918,"text":" Matlab"}]},{"label":["Skills"],"points":[{"start":4867,"end":4882,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":4845,"end":4861,"text":"Image Processing "}]},{"label":["Skills"],"points":[{"start":4569,"end":4574,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4552,"end":4554,"text":"NLP"}]},{"label":["Skills"],"points":[{"start":3867,"end":3872,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2747,"end":2762,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":2407,"end":2417,"text":"Data Mining"}]},{"label":["Skills"],"points":[{"start":2350,"end":2365,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1251,"end":1253,"text":"NLP"}]},{"label":["Location"],"points":[{"start":1009,"end":1017,"text":"Rajasthan"}]},{"label":["Skills"],"points":[{"start":743,"end":745,"text":"NLP"}]},{"label":["Skills"],"points":[{"start":483,"end":499,"text":"Image Processing "}]},{"label":["Skills"],"points":[{"start":469,"end":479,"text":"Data Mining"}]},{"label":["Skills"],"points":[{"start":464,"end":466,"text":"NLP"}]},{"label":["Skills"],"points":[{"start":446,"end":461,"text":"Machine Learning"}]},{"label":["Location"],"points":[{"start":101,"end":109,"text":"Rajasthan"}]},{"label":["Name"],"points":[{"start":0,"end":20,"text":"Dhanesh Kumar Solanki"}]}],"extras":null,"metadata":{"first_done_at":1532687397000,"last_updated_at":1532687397000,"sec_taken":335,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Dipayan Das\nC/o  - No. 20, Bhavana Nilaya, Mariyappa Block, Dinnur Main Road, R T Nagar, Bangalore - 560032\n\nM: +91-8055622338\nE: 4udipayan@gmail.com / dipayandas@hotmail.com \n\n\n\n\n\tSummary\n\tI have total 5.7 Years of experience in software development covering the complete software development life cycle for different cases by designing, developing, integrating and testing applications with technical skills of Java/J2EE, frameworks like Spring, Struts2, Node js, ORMs like Hibernate, database like mysql, DB2, in-memory database like redis. I also have experience of Amazon Web Service and IBM Bluemix. My experience includes the creation of high and low level design documents. I also have some sound knowledge in scripting languages like Javascript. I was involved in 2 Enterprise Projects as a Full Stack Developer. I have experience in dev-ops work like building deployment toolchain or like writing Infrastructure as a code. I have experience in using tools like Vagrant, Docker, Maven, Jenkins. I am a quick learner in adapting technology with ease.\n\n\n\tExperience\n\tSoftware Developer, GTS Labs, IBM India Private Ltd.\nBangalore, Karnataka — March, 2016 - Present\nAs a software developer my primary responsibility is to scale the application. Apart from that my responsibility is to take requirements from the architect and propose a solution for the enhancement requirements. Also implement the solution and resolve the issues raised by clients. \n\nAccomplishments\n· Experience in IBM bluemix, Spring Boot.\n· Experience in cutting edge technology like Angular 4 and MongoDB\n· Building dev-ops tool chain\n \nSoftware Engineer, KreativSARG Technology Solutions LLP\nPune, Maharashtra — September, 2012 - February, 2016\nAs a software engineer my responsibility is to gather the requirements and figure out a some possible solutions, among which later most feasible solution will be taken. After finalizing the solution it will be implemented by our team.\n\nAccomplishments\n· Technical expertise in development and deployment of web based social media system for large scale enterprises. \n· Experience includes MVC architecture, data driven dynamic site development, data wire only, data modeling, query optimization.\n· Asynchronous site development, real time application development, api development.\n\n\n\n\nSoftware Engineer Associate, KreativSARG Technology Solutions LLP\nPune, Maharashtra — April, 2012 - September, 2012\nAs a software engineer associate my responsibility is to my job was to implement the solution according to the problem. I had to write the basic controller actions using ORMs or others, whatever its dictated accordingly. \n\nAccomplishments\n· Got appreciation from the clients for making work done in time\n· Got concepts about the workflow of the code\n· Got learned to work in a pressurized situation where result matters.\n\n\n\n\tSkills\n\t· Programming Languages, Frameworks and Web servers : Java, J2EE, Spring MVC, Spring Data, Spring Security, Struts2, Hibernate, JSP, Spring Data Rest, Angular JS(1.X & 4.X), JQuery, HTML, CSS, Vagrant, Docker, JavaScript, Jenkins Build Tool, Redis, Apache Tomcat, Jetty.\n· Cloud computing : Amazon Web Service, Bluemix\n· IDE : Eclipse, STS\n· Operating System : Mac, Linux(Ubuntu), Windows\n· Databases : MySQL 5.5/5.6, DB2, Mongo DB, SQL Server 2008\n· Devops Tool : Vagrant, Docker\n· Package Manager : Maven, NPM, Bower\n· Tools Used : SVN, GIT, RTC, MySQL workbench\n\n\t\nProjects Handled\n\t\n\tProject Name\n\tIBM Services And Platform With Watson (ISPW)\n\n\tClient Name\n\tIBM Corp (Own Product) \n\n\tDuration\n\tSeptember 2017 - Present\n\n\tLanguage\n\tJava, Javascript\n\n\tCloud Server\n\tIBM Bluemix\n\n\tFrameworks\n\tSpring, J2EE, Angular JS (4.X)\n\n\tDatabase\n\tMongo DB\n\n\tRole\n\tApplication (Spring and Angular 4) Developer\n\n\tDescription\n\tThe ISPW is an end to end, integrated platform for IT, infused with intelligence that enables a higher quality of service, better visibility into the IT environment and improved cost and performance optimization. The ISPW provides a unified architecture that ensures pervasive security, continuous governance and compliance, and an agile Devops process that enables our clients to benefit and grow.\n\n\tResponsibilities\n\t· Reinvent the existing UI introducing bleeding edge technology like Angular 4 \n· To improve the performance of the portal by tuning the backend application logic as well as frontend application logic\n· Lead the development with advance technologies and chalk down the development path\n\n\n\n\n\tProject Name\n\tHardware Software Currency Management System\n\n\tClient Name\n\tIBM Corp (Own Product) \n\n\tDuration\n\tMarch 2016 - Present\n\n\tLanguage\n\tJava, Javascript\n\n\tCloud Server\n\tIBM Bluemix\n\n\tFrameworks\n\tStruts2, Spring, JQuery, Angular JS (1.X)\n\n\tDatabase\n\tDB2\n\n\tRole\n\tFull Stack Developer\n\n\tDescription\n\tHSCMS is an enterprise solution, that is built for IBM’s client, to provide them a common interface to check and monitor the health of their devices.\n\n\tResponsibilities\n\t· Comprehend the requirements and propose a solution. \n· Collaborate with the remote team.\n· Implement those solutions and apply the fixtures for different issues.\n\n\n\n\n\n\tProject Name\n\tHelloDox\n\n\tClient Name\n\tKreativSARG (Own Product) \n\n\tDuration\n\tApril 2013 - February 2016\n\n\tLanguage\n\tJava, Javascript\n\n\tFrameworks\n\tSpring MVC, Spring Data, Spring Security, Hibernate, Spring data rest, Spring security, Node Js, Socket io\n\n\tDatabase\n\tMySQL 5.6, Redis (In memory DB and For Caching)\n\n\tCloud Server\n\tAmazon web service \n\n\tRole\n\tFull Stack Developer\n\n\tDescription\n\tHelloDox is a professional social networking site for Doctors only to provide a platform to communicate with each other. Here they can make connections, groups, posts, jobs etc.\n\n\tResponsibilities\n\t· Comprehend the requirements and create web services using REST api and scope of other enhancements. \n· Designing real time notification using Node js and socket io using Pub-Sub architecture of Redis. \n· Developer - Developing api and test them so that can be consumed by client apps properly. Patching the defects on test fails by the test team and send it again to them.\n\n\n\n\n\n\tProject Name\n\tMLM\n\n\tClient Name\n\tAmuro (Germany) \n\n\tDuration\n\tAug 2012 - April 2013\n\n\tLanguage\n\tJava, Javascript\n\n\tFrameworks\n\tJ2EE, JQuery\n\n\tDatabase\n\tSQL Server 2008\n\n\tRole\n\tDeveloper\n\n\tDescription\n\tMLM is a Amuro Back Office project for Amuro Beauty Product, which helps them to calculate points, bonus for manage users, their respective rank and generating invoices in against Bonus.\n\n\tResponsibilities\n\t· Depending upon requirements first different possible solutions were produced by each of the team members. \n· After best solution among them is chosen for the situation, it’s implemented.\n· Developer - Developing the feature according to the proposed solution, test them, patch them and send it to the test team.\n\n\n\n\n\n\n\tProject Name\n\tIBP\n\n\tClient Name\n\tEvis Media (Germany)\n\n\tDuration\n\tApril 2012 - Aug 2012\n\n\tLanguage\n\tJava\n\n\tFrameworks\n\tStruts 2, Free marker\n\n\tDatabase\n\tMySQL 5.5\n\n\tRole\n\tDeveloper\n\n\tDescription\n\tIBP is a web based solution for internal notice board and blog posting to provide a platform where admin people can put some notice, can give everyone's tentative task, internal people f an organization can express their queries.\n\n\tResponsibilities\n\t· Read the requirements carefully and document the possible classes, properties, methods. \n· Optimize the methods if possible.\n· Code cleaning if possible anywhere. \n· Developer - Implement the methods, actions and map them through the xml.\n\n\n\n\n\tEducation\n\tWest Bengal University Of Technology\nAsansol Engineering College\nMCA — 2011\nUniversity Of Calcutta\nCity College\nBSC — 2008                                                                                                                                                                                                                                                   \nWest Bengal Council Of Higher Secondary Education\nBongaon Kabi Keshablal Vidyapith\nHSC— 2004 \nWest Bengal Board Of Secondary Education\nBongaon Kabi Keshablal Vidyapith\nSSC— 2002 \n\n\tPersonal Details\n\t· Date Of Birth : December 18, 1986\n· Gender : Male\n· Experience : 5.7 Years\n· Strength : Professionally committed, responsible, team player, highly collaborative, adjusting and quick learner\n· Languages Spoken : English, Hindi, Bengali\n· Nationality : Indian\n· Marital Status : Married\n· Local Address : No. 20, Bhabhana Nilaya, Mariyappa Block, Dinnur Main Road, RT Nagar, Bangalore - 560032\n· Permanent Address : Ramnagar Road Kurir Math, Bongaon, North 24 Parganas West Bengal, 743235\n\n\n\n\n\n\n\n\nI hereby declare that, the information furnished above is true to the best of my knowledge and belief.\n\n\n\tDate :\n\t\n\n\tPlace : Bangalore\n\tDipayan Das","annotation":[{"label":["Name"],"points":[{"start":8728,"end":8738,"text":"Dipayan Das"}]},{"label":["Location"],"points":[{"start":8470,"end":8479,"text":"Bangalore "}]},{"label":["Education"],"points":[{"start":7595,"end":7597,"text":"MCA"}]},{"label":["Skills"],"points":[{"start":5314,"end":5322,"text":"Hibernate"}]},{"label":["Skills"],"points":[{"start":4737,"end":4739,"text":"DB2"}]},{"label":["Skills"],"points":[{"start":4657,"end":4667,"text":"IBM Bluemix"}]},{"label":["Skills"],"points":[{"start":3625,"end":3635,"text":"IBM Bluemix"}]},{"label":["Skills"],"points":[{"start":3275,"end":3277,"text":"DB2"}]},{"label":["Skills"],"points":[{"start":3148,"end":3165,"text":"Amazon Web Service"}]},{"label":["Skills"],"points":[{"start":2974,"end":2982,"text":"Hibernate"}]},{"label":["Skills"],"points":[{"start":593,"end":603,"text":"IBM Bluemix"}]},{"label":["Skills"],"points":[{"start":570,"end":587,"text":"Amazon Web Service"}]},{"label":["Skills"],"points":[{"start":508,"end":510,"text":"DB2"}]},{"label":["Skills"],"points":[{"start":501,"end":505,"text":"mysql"}]},{"label":["Skills"],"points":[{"start":476,"end":484,"text":"Hibernate"}]},{"label":["Skills"],"points":[{"start":413,"end":421,"text":"Java/J2EE"}]},{"label":["Location"],"points":[{"start":89,"end":98,"text":"Bangalore "}]},{"label":["Name"],"points":[{"start":0,"end":10,"text":"Dipayan Das"}]}],"extras":null,"metadata":{"first_done_at":1532694103000,"last_updated_at":1532694103000,"sec_taken":0,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Udaya Laxmi Ch\n\nEmail : laxmi.udaya@gmail.com\n\n\t\n\n\tPhone: -9740606990\n\t\n\n\n\tSummary\n\n\t· 9.5 years of experience in Software Development.\n· 3.5 years of experience in Machine Learning\n· Primary Skills – Machine Learning, R programming, Lotus Notes.\n· Presently working for Wipro Technologies, Bangalore.\n· Experience in planning, estimation, design, development, and testing object oriented applications.\n· Experience in preparing various technical documents like Functional Specs, HLD, LLD, Flowcharts and Test cases.\n· Sound Knowledge in Object Oriented Design Principles\n· Have Team Handling experience.\n· Domain experience of Manufacturing and Finance.\n· Have Experience in Scrum Agile Model\n· Understand business requirements from clients\n\n\n\n\tTechnical Skills\n\n\tKey skills: \n\tMachine Learning,R Programming, MySQL, PostgreSQL, Microsoft Access, SQL Server, FileMaker, Oracle, RDBMS, dBASE, Clipper, FoxPro, Firebase, Mongodb, Python,  ava, J2EE, Oracle Fusion,Oracle Cloud, Salesforce, Devops Android, Business Analyst, UI Developer, DBAs, Embedded Systems, .NET, Hadoop, SQL Developer, Big Data, Tableau, Networking, Etl, Informatica, Ios, Quality Analyst, Project Manager, Python, Data Science, Python, Machine Learning, SAS, Java, Scala, Hadoop, Hive, Bigdata, Programming, SQL server reporting, Msbi Ssis, Ssrs, Msbi, Sql Reporting, Artificial Intelligence, Pandas, Pyspark, Sklearn, Flask, Django, Map Reduce, Parametric Design, Modeling, Regression, Patterns, Data Mining, Text Mining, Oops, Deep Learning, Web Analytics, Time Series, Regression, Tensorflow, Azure, Linear Regression, Logistic Regression, Decision Tree, Random Forest, Data Structure, Computer Vision, IHS, WAS, Java EE, SQL Server, .NET core, C#, ASP.NET, Rdlc, Linq, Sql, Web Api, Mvc, Javascript, Web Services, Oracle, MS SQL, PHP, Laravel, CodeIgniter, Symfony, Zend, Phalcon, CakePHP, Yii, FuelPHP, React, Vue, Angular, Ember, Backbone, Lotus Notes\n\n\tAlgorithms:\n\tNaïve Bayes, K means clustering,Word Cloud\n\n\tDatabases: \n\tMicrosoft SQL, Mongo DB\n\n\tWeb Technologies: \n\tXML, XSLT, HTML,  JavaScript,  AJAX, JQuery\n\n\tIDE:\n\tR studio,Pycharm\n\n\n\tProfessional Experience\n\n\tCurrent Employer :\n\tWipro Technologies., Bangalore  – (Oct  2010  to till date) – Technical Lead/Data Scientist\n\n\tPrevious Employers :\n\tHSBC Software development , Hyderabad (June  2008  to Sep 2010)  - SE\n\n\n\tQualification\n\n\tDegree\n\tCollege\n\tUniversity/Board\n\tYear\n\tPercentage (%)\n\n\tMCA\n\tNizam College, Basheerbagh,Hyderabad\n\tOsmania University\n\t2008\n\t75\n\n\n\tProject Experience \n\n\tProject 1 : Exploratory Data Analysis:\n\nProject Description:   Performed EDA analysis to analyze the Purchase frequency of vehicles which occurred over past 3 years and try to predict the frequency occurring in the future.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Performed EDA analysis to find the insights of the data. Observed the summary of each and every variable to understand the variables.\n\n· Performed the feature selection using hypothesis testing.\n\n· Identified the outliers using box plot.\n\n· Identified the trend in the purchases using histogram.\n\n\n\n\tProject 2: Word Cloud Analysis:\n\nProject Description:   Performed Word cloud and Sentimental Analysis of the customer feedbacks. Graphically represented the most frequently occurred words through Word cloud. Through sentimental analysis we identified whether a user-generated text expresses positive, negative or neutral opinion.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Created a Corpus using TM package and performed pre-processing of data.\n\n· Removed the punctuations, stemming and stop words which are of no analytical value.\n\n· Built a Document term matrix and identified the most frequently occurring words\n\n· Graphically represented it using  RColorbrewer Package\n\n\n\tProject 3: Sentimental Analysis:\n\nProject Description: Performed Sentimental Analysis of customer feedbacks through Naïve Bayes. Used “e1071” Package for implementing naïve Bayes method.\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· The DTM created using TM package was an input to the Naive Bayes Model.\n\n· As Naive Bayes classifier is typically trained on data with categorical features. We have converted the count of the words into a factor variable that indicates Yes or No whether the word is present or not.\n\n\tProject 4: Clustering Analysis:\n\nProject Description: Classified the customers on the basis of their purchases whether they have purchased low variant or high variant trucks. It in turn helped in building the right customer strategies.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Performed data preparation and Normalization of data using min-max method.\n\n· As K-means algorithm groups a dataset into a user-specified number (k) of clusters. Identified the initial cluster centroids as 3.\n\n· K clusters are creating by associating every observation with the nearest mean.\n\n· Used elbow method to validate the number of clusters such that within-cluster sum of square(wss) is minimized.\n\n\n\n\tProject 5 : Inter Connection Management Tool\nProject Description: Inter-connection Management (IMT) is prototype being developed for Engineering and Sales department to handle customizations of an existing product based on the customer's requirement. Users from engineering department will identify the items, which need to be customized out of the entire product design.\nRole\n\n       : Module Lead\n\nEnvironment\n       : Python, Mongo DB, jQuery\n\nTasks handled:\n\n· Gathering Requirements and providing Project Plan and Effort Estimation details.\n\n· Understanding business requirements and preparing SoU (Statement of Understanding) and Functional/Technical Specification documents.\n\n· Providing Effort & Resource estimations\n\n· Planning for application development and deployment\n\n· Writing and executing Test Cases and Test scenarios\n\n· Creating design elements using Technical Specification.\n\n· Performing Unit testing & Peer Reviews\n\n· Work Allocation and mentoring the team\n\n· Providing Technical guidance to the team. \n\n\tProject 6\n: cvdAEI Application\n\nProject Description\n     : CVDAEI is a web based multilingual application developed for handling the Change Management process in Truck division of Daimler. The change request flows through different phases mainly Initialization, Evaluation, Decision and Conclusion. This application has a configurable workflow where the request flow and the responsible persons can be configured easily at any point of time. \n\nRole\n\n    : Developer/Tester\n\nEnvironment\n     : Lotus Notes, Java, HTML, XML, Java Script, JQuery\n\nTasks handled:\n\n· Gathering Requirements and providing Project Plan and Effort Estimation details.\n\n· Understanding business requirements and preparing SoU (Statement of Understanding) and Functional/Technical Specification documents.\n\n· Providing Effort & Resource estimations\n\n· Planning for application development and deployment\n\n· Writing and executing Test Cases and Test scenarios\n\n· Creating design elements using Technical Specification.\n\n· Performing Unit testing & Peer Reviews\n\n· Work Allocation and mentoring the team\n\n· Providing Technical guidance to the team. \n\n\n\n\tProject Title: Project Management Office \nProject Description: The purpose of this system is to enable the Project Management Office to manage and execute the IT Applications and Operations driven project tasks in  more systematic manner. It will also enable them to efficiently perform a role as a facilitator to coordinate various IT Operations teams and to ensure that project activity enters the department through one common interface. The project tasks will subsequently be dealt with in a common format and in a consistent and appropriate manner, ensuring open and regular communication between all involved parties.\n\nRole\n\n    : Developer/Tester\n\nEnvironment\n     : Lotus Notes, Java, HTML, XML, Java Script, JQuery\n\nTasks Handled :\n\n· Writing and Executing Test cases in client server based environment\n· Individually provided application support","annotation":[{"label":["Skills"],"points":[{"start":7951,"end":7956,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":7938,"end":7948,"text":"Java Script"}]},{"label":["Skills"],"points":[{"start":7933,"end":7935,"text":"XML"}]},{"label":["Skills"],"points":[{"start":7927,"end":7930,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":7921,"end":7924,"text":"Java"}]},{"label":["Skills"],"points":[{"start":7908,"end":7918,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":6645,"end":6650,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":6632,"end":6642,"text":"Java Script"}]},{"label":["Skills"],"points":[{"start":6627,"end":6629,"text":"XML"}]},{"label":["Skills"],"points":[{"start":6621,"end":6624,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":6615,"end":6618,"text":"Java"}]},{"label":["Skills"],"points":[{"start":6602,"end":6612,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":5522,"end":5527,"text":"jQuery"}]},{"label":["Skills"],"points":[{"start":5512,"end":5519,"text":"Mongo DB"}]},{"label":["Skills"],"points":[{"start":5504,"end":5509,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4645,"end":4652,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":4054,"end":4061,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":3941,"end":3951,"text":"Naïve Bayes"}]},{"label":["Skills"],"points":[{"start":3494,"end":3501,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":3132,"end":3141,"text":"Word Cloud"}]},{"label":["Skills"],"points":[{"start":2793,"end":2800,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":2110,"end":2116,"text":"Pycharm"}]},{"label":["Skills"],"points":[{"start":2101,"end":2108,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":2086,"end":2091,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":2080,"end":2083,"text":"AJAX"}]},{"label":["Skills"],"points":[{"start":2067,"end":2076,"text":"JavaScript"}]},{"label":["Skills"],"points":[{"start":2060,"end":2063,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":2054,"end":2057,"text":"XSLT"}]},{"label":["Skills"],"points":[{"start":2049,"end":2051,"text":"XML"}]},{"label":["Skills"],"points":[{"start":2018,"end":2025,"text":"Mongo DB"}]},{"label":["Skills"],"points":[{"start":2003,"end":2015,"text":"Microsoft SQL"}]},{"label":["Skills"],"points":[{"start":1977,"end":1986,"text":"Word Cloud"}]},{"label":["Skills"],"points":[{"start":1958,"end":1975,"text":"K means clustering"}]},{"label":["Skills"],"points":[{"start":1945,"end":1955,"text":"Naïve Bayes"}]},{"label":["Skills"],"points":[{"start":1918,"end":1928,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":1908,"end":1915,"text":"Backbone"}]},{"label":["Skills"],"points":[{"start":1901,"end":1905,"text":"Ember"}]},{"label":["Skills"],"points":[{"start":1892,"end":1898,"text":"Angular"}]},{"label":["Skills"],"points":[{"start":1887,"end":1889,"text":"Vue"}]},{"label":["Skills"],"points":[{"start":1880,"end":1884,"text":"React"}]},{"label":["Skills"],"points":[{"start":1871,"end":1877,"text":"FuelPHP"}]},{"label":["Skills"],"points":[{"start":1866,"end":1868,"text":"Yii"}]},{"label":["Skills"],"points":[{"start":1857,"end":1863,"text":"CakePHP"}]},{"label":["Skills"],"points":[{"start":1848,"end":1854,"text":"Phalcon"}]},{"label":["Skills"],"points":[{"start":1842,"end":1845,"text":"Zend"}]},{"label":["Skills"],"points":[{"start":1833,"end":1839,"text":"Symfony"}]},{"label":["Skills"],"points":[{"start":1820,"end":1830,"text":"CodeIgniter"}]},{"label":["Skills"],"points":[{"start":1811,"end":1817,"text":"Laravel"}]},{"label":["Skills"],"points":[{"start":1806,"end":1808,"text":"PHP"}]},{"label":["Skills"],"points":[{"start":1798,"end":1803,"text":"MS SQL"}]},{"label":["Skills"],"points":[{"start":1790,"end":1795,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":1776,"end":1787,"text":"Web Services"}]},{"label":["Skills"],"points":[{"start":1764,"end":1773,"text":"Javascript"}]},{"label":["Skills"],"points":[{"start":1759,"end":1761,"text":"Mvc"}]},{"label":["Skills"],"points":[{"start":1750,"end":1756,"text":"Web Api"}]},{"label":["Skills"],"points":[{"start":1745,"end":1747,"text":"Sql"}]},{"label":["Skills"],"points":[{"start":1739,"end":1742,"text":"Linq"}]},{"label":["Skills"],"points":[{"start":1733,"end":1736,"text":"Rdlc"}]},{"label":["Skills"],"points":[{"start":1724,"end":1730,"text":"ASP.NET"}]},{"label":["Skills"],"points":[{"start":1720,"end":1721,"text":"C#"}]},{"label":["Skills"],"points":[{"start":1709,"end":1717,"text":".NET core"}]},{"label":["Skills"],"points":[{"start":1697,"end":1706,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":1688,"end":1694,"text":"Java EE"}]},{"label":["Skills"],"points":[{"start":1683,"end":1685,"text":"WAS"}]},{"label":["Skills"],"points":[{"start":1678,"end":1680,"text":"IHS"}]},{"label":["Skills"],"points":[{"start":1661,"end":1675,"text":"Computer Vision"}]},{"label":["Skills"],"points":[{"start":1645,"end":1658,"text":"Data Structure"}]},{"label":["Skills"],"points":[{"start":1630,"end":1642,"text":"Random Forest"}]},{"label":["Skills"],"points":[{"start":1615,"end":1627,"text":"Decision Tree"}]},{"label":["Skills"],"points":[{"start":1594,"end":1612,"text":"Logistic Regression"}]},{"label":["Skills"],"points":[{"start":1575,"end":1591,"text":"Linear Regression"}]},{"label":["Skills"],"points":[{"start":1568,"end":1572,"text":"Azure"}]},{"label":["Skills"],"points":[{"start":1556,"end":1565,"text":"Tensorflow"}]},{"label":["Skills"],"points":[{"start":1544,"end":1553,"text":"Regression"}]},{"label":["Skills"],"points":[{"start":1531,"end":1541,"text":"Time Series"}]},{"label":["Skills"],"points":[{"start":1516,"end":1528,"text":"Web Analytics"}]},{"label":["Skills"],"points":[{"start":1501,"end":1513,"text":"Deep Learning"}]},{"label":["Skills"],"points":[{"start":1495,"end":1498,"text":"Oops"}]},{"label":["Skills"],"points":[{"start":1482,"end":1492,"text":"Text Mining"}]},{"label":["Skills"],"points":[{"start":1469,"end":1479,"text":"Data Mining"}]},{"label":["Skills"],"points":[{"start":1459,"end":1466,"text":"Patterns"}]},{"label":["Skills"],"points":[{"start":1447,"end":1456,"text":"Regression"}]},{"label":["Skills"],"points":[{"start":1437,"end":1444,"text":"Modeling"}]},{"label":["Skills"],"points":[{"start":1418,"end":1434,"text":"Parametric Design"}]},{"label":["Skills"],"points":[{"start":1406,"end":1415,"text":"Map Reduce"}]},{"label":["Skills"],"points":[{"start":1398,"end":1403,"text":"Django"}]},{"label":["Skills"],"points":[{"start":1391,"end":1395,"text":"Flask"}]},{"label":["Skills"],"points":[{"start":1382,"end":1388,"text":"Sklearn"}]},{"label":["Skills"],"points":[{"start":1373,"end":1379,"text":"Pyspark"}]},{"label":["Skills"],"points":[{"start":1365,"end":1370,"text":"Pandas"}]},{"label":["Skills"],"points":[{"start":1340,"end":1362,"text":"Artificial Intelligence"}]},{"label":["Skills"],"points":[{"start":1325,"end":1337,"text":"Sql Reporting"}]},{"label":["Skills"],"points":[{"start":1325,"end":1327,"text":"Sql"}]},{"label":["Skills"],"points":[{"start":1319,"end":1322,"text":"Msbi"}]},{"label":["Skills"],"points":[{"start":1313,"end":1316,"text":"Ssrs"}]},{"label":["Skills"],"points":[{"start":1302,"end":1310,"text":"Msbi Ssis"}]},{"label":["Skills"],"points":[{"start":1302,"end":1305,"text":"Msbi"}]},{"label":["Skills"],"points":[{"start":1280,"end":1299,"text":"SQL server reporting"}]},{"label":["Skills"],"points":[{"start":1267,"end":1277,"text":"Programming"}]},{"label":["Skills"],"points":[{"start":1258,"end":1264,"text":"Bigdata"}]},{"label":["Skills"],"points":[{"start":1252,"end":1255,"text":"Hive"}]},{"label":["Skills"],"points":[{"start":1244,"end":1249,"text":"Hadoop"}]},{"label":["Skills"],"points":[{"start":1237,"end":1241,"text":"Scala"}]},{"label":["Skills"],"points":[{"start":1231,"end":1234,"text":"Java"}]},{"label":["Skills"],"points":[{"start":1226,"end":1228,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1208,"end":1223,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1200,"end":1205,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1186,"end":1197,"text":"Data Science"}]},{"label":["Skills"],"points":[{"start":1178,"end":1183,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1161,"end":1175,"text":"Project Manager"}]},{"label":["Skills"],"points":[{"start":1144,"end":1158,"text":"Quality Analyst"}]},{"label":["Skills"],"points":[{"start":1139,"end":1141,"text":"Ios"}]},{"label":["Skills"],"points":[{"start":1126,"end":1136,"text":"Informatica"}]},{"label":["Skills"],"points":[{"start":1121,"end":1123,"text":"Etl"}]},{"label":["Skills"],"points":[{"start":1109,"end":1118,"text":"Networking"}]},{"label":["Skills"],"points":[{"start":1100,"end":1106,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":1090,"end":1097,"text":"Big Data"}]},{"label":["Skills"],"points":[{"start":1075,"end":1087,"text":"SQL Developer"}]},{"label":["Skills"],"points":[{"start":1067,"end":1072,"text":"Hadoop"}]},{"label":["Skills"],"points":[{"start":1061,"end":1064,"text":".NET"}]},{"label":["Skills"],"points":[{"start":1043,"end":1058,"text":"Embedded Systems"}]},{"label":["Skills"],"points":[{"start":1037,"end":1040,"text":"DBAs"}]},{"label":["Skills"],"points":[{"start":1023,"end":1034,"text":"UI Developer"}]},{"label":["Skills"],"points":[{"start":1005,"end":1020,"text":"Business Analyst"}]},{"label":["Skills"],"points":[{"start":989,"end":1002,"text":"Devops Android"}]},{"label":["Skills"],"points":[{"start":977,"end":986,"text":"Salesforce"}]},{"label":["Skills"],"points":[{"start":963,"end":974,"text":"Oracle Cloud"}]},{"label":["Skills"],"points":[{"start":949,"end":961,"text":"Oracle Fusion"}]},{"label":["Skills"],"points":[{"start":943,"end":946,"text":"J2EE"}]},{"label":["Skills"],"points":[{"start":929,"end":934,"text":"Python"}]},{"label":["Skills"],"points":[{"start":920,"end":926,"text":"Mongodb"}]},{"label":["Skills"],"points":[{"start":910,"end":917,"text":"Firebase"}]},{"label":["Skills"],"points":[{"start":902,"end":907,"text":"FoxPro"}]},{"label":["Skills"],"points":[{"start":893,"end":899,"text":"Clipper"}]},{"label":["Skills"],"points":[{"start":886,"end":890,"text":"dBASE"}]},{"label":["Skills"],"points":[{"start":879,"end":883,"text":"RDBMS"}]},{"label":["Skills"],"points":[{"start":871,"end":876,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":860,"end":868,"text":"FileMaker"}]},{"label":["Skills"],"points":[{"start":848,"end":857,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":830,"end":845,"text":"Microsoft Access"}]},{"label":["Skills"],"points":[{"start":818,"end":827,"text":"PostgreSQL"}]},{"label":["Skills"],"points":[{"start":811,"end":815,"text":"MySQL"}]},{"label":["Skills"],"points":[{"start":798,"end":808,"text":"Programming"}]},{"label":["Skills"],"points":[{"start":796,"end":808,"text":"R Programming"}]},{"label":["Skills"],"points":[{"start":779,"end":794,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":234,"end":244,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":219,"end":231,"text":"R programming"}]},{"label":["Skills"],"points":[{"start":201,"end":216,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":165,"end":180,"text":"Machine Learning"}]},{"label":["Name"],"points":[{"start":0,"end":13,"text":"Udaya Laxmi Ch"}]}],"extras":null,"metadata":{"first_done_at":1579625576000,"last_updated_at":1579626369000,"sec_taken":0,"last_updated_by":"aJOmJy1lvpOYFetVNuqLvFo9Vx42","status":"done","evaluation":"NONE"}}
{"content": "Dodda\nVenkata Satish\n\n\n\n\n                      Mobile: +91-9742999134 \n\nJr Data Analyst\n\n\n\n\n\n                    Email: dvenkatasatish@gmail.com         \n\nEXPERIENCE SUMMARY: -\n· Around 10.3 years of rich experience in IT, both SDLC & STLC.\n\n· Have very good experience in Expertise in building statistical models in Fraud Management Analysis.\n· Strong expertise in analytical and quantitative techniques including predictive modelling, Response modelling, multivariate analysis, Decision Trees, Targeting and Segmentation Analytics.\n\n· Proficient at leading teams for running successful process operations \n\n· Managing the project stakeholders with Preparation and Maintenance of Project Plans and schedule.\n\n· Established and maintained relationships with third parties/vendors\n\n· Adept in end-to-end development of products from requirement analysis, system study, designing, coding, testing, de-bugging, documentation, implementation and maintenance.  \n\n\n· Extensive knowledge on Planning and People, Stakeholders Managements Process Improvement, Implementation.\n\n· Significant exposure in Application Development, Maintenance & Support, Business Intelligence & Product Engineering across Multiple Technologies\n\n· Adroit in analysing, design, developing, testing and implementing varied software applications\n\nBusiness Analytics EXPERIENCE: -\n· Maintained a deep understanding of business and the marketplace dynamics to bring about continuous improvements\n\n· Building and optimizing classifiers using machine learning techniques\n\n· Understand the problem in-depth, map it using a structured approach and identify the appropriate analytical model to solve the problem\n\n· Selecting features, building and optimizing classifiers using machine learning techniques\n\n· Processing, cleansing, and verifying the integrity of data used for analysis\n\n· Doing ad-hoc analysis and presenting results in a clear manner\n\n· Provide expertise on statistical / mathematical concepts for identified problems and provide appropriate models to solve them.\n\n· Test various machine learning and analytical tools, build prototypes which can be easily scaled up for production deployments\n\nCERTIFICATIONS: -\n· DATA ANALYTICS Internal course from TCS\n\n\n\n\n2016\n· INS 21 certification\n\n\n\n\n\n\n\n2015\n· LOT-801 - IBM Lotus Notes Domino 8 Application Development Update\n2011\nSkill Sets – Software PROFICIENCY: -\n· Analytical Methods       \n:   Regression, ANOVA, Hypothesis Testing, Experimental Design,\n\n                                             \n    Time Series Analysis, Confidence intervals\n\n· Data Analytics Tool         \n:   R Scripting language, XL Miner tool for data mining                    \n\n·  Data Mining Techniques :  Market Basket Analysis, Cluster Analysis, Principal component          analysis, Classification using SVM, Decision Tree\n·  Tools/Scripting Language  :   R-Studio, Hadoop, Hive, Pig, Scoop, Lotus Notes C, Java, JavaScript, Lotus Script, R-programming\n· Change Management    \n:   Service-Now\n\nROLES & RESPONSIBILITIES: -\n· Used R to understand data patterns and proposed machine learning based solutions for Fraud Management Analysis and Supply-Management Risk Analysis.\n\n· Managing offshore customer visits and managing client relationships for India Incubating and evangelizing data science service.\n· Analysing business problems and identifying key solution interventions leveraging advanced analytics methods.\n· Experienced in Statistical Learning: - Predictive & Prescriptive Analytics, Web Analytics, Data/Text Mining, NLP, Decision Trees, Adaptive Decision Algorithms, Random Forest, Neural Networks, Deep Learning Algorithms\n\n· Experienced in Machine Learning, supervised and unsupervised: - Forecasting, Classification\n\n· Parametric and Non-parametric models, Regression, Time Series, Dynamic/Causal Model\n\n· Awareness in big data analytics and advanced data mining techniques to analyse data, identifying trends, patterns, and outliers in data.\n· Experienced with statistical programming languages, analytical packages/libraries (R, Python)\nPROJECTS: -\nTata Consultancy Services: (Mar 2011 to Till Date) \nClient Name         :  Reputed Retailer\n\nProject Title         :  Prediction Modelling for Sales\n\nProject Location :  TCS Bangalore\nPeriod                   :  Sep 2017 – Till Date\n\nPosition                :  Jr. Data Analyst\n\nProject                  :  The goal is to build a prediction model to predict the Sales of a prominent Retailer based on the given set of variables with good accuracy.\nResponsibilities  : \n\n· Performed the Exploratory Data Analysis\n· Employed Imputation techniques for missing data\n\n· Handled the outlier data using the KNN technique\n· Performed Feature Engineering\n· Examined the plots and executed transformations to improve the efficiency of the model\n· Done Model building using Multi linear regression techniques and increased the accuracy of the model by constantly improving it using clustering techniques\n· Performing Prediction analysis using the model and built confidence intervals for model coefficients.\nEnvironments    : Data Model using R, Machine Learning, Regression Techniques, Prediction Analysis, Clustering\n____________________________________________________________________________\nClient Name         :  Allianz Global Corporate & Speciality\nProject Title         :  Fraud Detection in Insurance Claims\nProject Location :  AGCS Paris\nPeriod                   :  July 2015 – Aug 2017\nPosition                :  Jr. Data Analyst\n\nProject                  :  \n· Used analytics to help identify fraud and allow an insurer to optimize the resources they have available in combating fraud \n· Predictive analytics is applied in developing a more consistent claim referral process, such that the benefit of the expertise of the best adjusters and investigators is applied to all claims. \n\nResponsibilities  : \n\n· Used R to understand data patterns and proposed machine learning based solutions\n\n· Analysing business problems and identifying key solution interventions leveraging advanced analytics methods.\n\n· Tracking of the new requirements from the project and forecast/estimate the project future requirements.\n\nAdapted to a dynamic, rapidly changing business and technical needs.\nEnvironments    : Analytics Model using R, Regression, Neural Networks, Association Rules, Text Mining, PCA\n\n____________________________________________________________________________\n\nClient Name         :  Allianz Global Corporate & Speciality\nProject Title         :  Business Enhancements and AGCS – Application Maintenance Onsite SPoC\nProject Location :  AGCS London\nPeriod                   :  Mar  2011 to June 2015\nPosition                :  Onsite Lead and FO Lead/Srum Master\nProject                  :  Allianz Global Corporate Specialty Insurers are one of the world's leading specialty Insurance Company. Their Corporate IT department has different types of IT systems like policy administration, underwriting, accounts, etc.. IT department will be enhancing many Legacy systems and consolidating systems to obtain optimal efficiency and to reduce the complexity and risk\nResponsibilities  : \n\n· Playing the role of a Team Lead, Issue tracking & Status Reporting\n\n· Leading a team of 8, coordinating and supporting them on their activities, and also involved in Enhancement/ Change Requests.\n\n· Client liaison & Project co-ordination\n· Taken complete ownership of implementation to ensure there are no issues. Also provided post implementation support to the users through the team.\n\n· Attended the Business/System Requirements Review Meeting, and provide feedback from the testing teams perspective.\n\nFacilitating Scrum ceremonies like Sprint Planning, Sprint Review and Sprint Retrospective and Daily Scrum Meetings\nEnvironments    : Lotus Notes Domino, Formula Language, Lotus Script, Javascript, Ajax, HTML\n____________________________________________________________________________\nIBM INDIA Pvt Ltd:  (Sep 2007 to Feb 2011) \n\nClient Name         :  IBM Denmark\nProject Title         :  Single point of Entry (SPoE), Carlsberg\nProject Location :  IBM Kolkata\nPeriod                   :  Sep 2007 – Feb 2011\nPosition                :  Team Member, Module Lead\n\nProject                  :  SPoE provides a standard web front where users can order, cancel, update and/or transfer telecommunication services to another user. These functionalities are proposed for UMTS/3G/GPRS, ADSL, Audio Conferencing, Blackberry, Mobile and IP Telephony.\n\n· Database covers establishing user friendly web front end to place orders for telecommunication services.\n\n· Requests going through necessary management approvals for requests for services.\n\nAllow automated delivery of orders to suppliers when possible.\nResponsibilities  : \n\n· Playing the role of a Software Developer.\n\n· Involved in Change Requests/Enhancement.\n\nCo-coordinating with the teams involved and clients in the project to sort out the technical Issues.\nEnvironments    : Notes Domino, Lotus Script, Web, Java Script, DB2\n\n____________________________________________________________________________\nEducation:-\n\n\tQUALIFICATION\n\tYEAR\n\tUNIVERISTY/BOARD\n\tPERCENTAGE\n\n\tB. TECH\n\t2003-2007\n\tM.V.G.R College of Engieering/J.N.T.U.\n\t70.81\n\n\tINTERMEDIATE\n\t2001-2003\n\tBoard of Intermediate, Andhra Pradesh\n\t94\n\n\tS.S.C.\n\t200-2001\n\tS.S.C.\n\t84.5\n\n\nPersonal Details:-\n\nNAME \n\n\n\n: DODDA VENKATA SATISH\n\nEMAIL \n\n\n\n: dvenkatasatish@gmail.com\nDOB\n\n\n\n:  18th  AUG 1986\n\nGENDER \n\n\n:  MALE\n\nCONTACT\n \n\n: +91 9742999134\nPERMANENT ADDRESS\n:  Door No 12-88, Balaji Nagar, Arilova,\n\n                                    \n\n   Visakhapatnam,\n\n                                     \n\n   Andhra Pradesh-530040\n\nDECLARATION:\n\nI hereby declare that all the above furnished details are true to the best of my knowledge.\n\nDate: 30/01/2018                                                                           Dodda Venkata Satish\nPlace: Bangalore\n5","annotation":[{"label":["Location"],"points":[{"start":9931,"end":9939,"text":"Bangalore"}]},{"label":["Education"],"points":[{"start":9190,"end":9196,"text":"B. TECH"}]},{"label":["Skills"],"points":[{"start":9029,"end":9032,"text":"Java"}]},{"label":["Skills"],"points":[{"start":7855,"end":7858,"text":"Java"}]},{"label":["Location"],"points":[{"start":4245,"end":4253,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":3871,"end":3881,"text":"data mining"}]},{"label":["Skills"],"points":[{"start":2946,"end":2958,"text":"R-programming"}]},{"label":["Skills"],"points":[{"start":2920,"end":2929,"text":"JavaScript"}]},{"label":["Skills"],"points":[{"start":2920,"end":2923,"text":"Java"}]},{"label":["Skills"],"points":[{"start":2914,"end":2917,"text":"Java"}]},{"label":["Skills"],"points":[{"start":2647,"end":2657,"text":"data mining"}]},{"label":["Name"],"points":[{"start":0,"end":19,"text":"Dodda\nVenkata Satish"}]}],"extras":null,"metadata":{"first_done_at":1532670891000,"last_updated_at":1532670891000,"sec_taken":193,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "GAURAV SONI\ngaurav.soni1302@gmail.com\n+91.8860226996\n\tProfile Summary\n\n· Overall more than 6 years of industry experience in Analysis, Design, Development, Implementation and Testing of application which includes 4 Years 2 months of working with Java technologies and frameworks and almost 2 Years 1 month of working on Machine Learning.\n· Experience of working in different phases of Software Development Life Cycle inlcuding Designing, Development and Deployment.\n\n· Experience in Scrum, Agile and Waterfall software development models.\n\n· Worked in Client facing team with continuous client interaction.\n· Business Report creation based on different specifications.\n· Well versed with different OS platforms like Unix, Linux, AIX.\n· Created and optimized multiple SQL queries and PL/SQL procedures to save time and CPU utlisation.\n· Created and modified shell scripts and perl scripts(with cron jobs) to monitor per minute, daily, weekly, monthly and yearly trasaction and publish Transaction Reports accordingly.\n· Statistical Analytics: Worked in application which is responsible for publishing different graphs based on popularity and current trend to analyse the performance of different voice and data offers for different categories of subscribers. \n\n· Data Handling: The models were created from 14 daily CAR files and 7 monthly CAR files with customer data generated after EOD process. As part of cleaning, a part of customer data has to be trimmed out based on account validity and other eligibility criteria. \n· Regression: The commonest approach used in application for creating models and predicting performance of most popular offers in different categories was linear regression since delivered data used to be tidy which further improved performance.\n· Got opportunity to work from Client site in Cape Town to have better understanding of Business process.\n\n\n\tTechnical Skill Set\n\n\t\n\n\tJava Programming Tools\n\t\n\n\tProgramming Languages\n\tJava 1.7, Python\n\n\tDevelopment/Build Tools\n\tRAD 7.5, Eclipse, SVN, Harvest, Maven, Anaconda, IPython\n\n\tScripting Languages\n\tSQL, JavaScript, HostBridge (HBJS), HBX\n\n\tDatabase\n\tOracle, IBM DB2, Oracle HTB\n\n\tServers\n\tWebLogic, Apache Tomcat\n\n\tWeb Technologies\n\tServlet, JSP, JSF, Web Services\n\n\tFramework\n\tIntegralAdminFramework (like Struts2.0), JPA using Hibernate\n\n\tXML Technologies\n\tHostBridge Scripting, XML Parsing, Xpath\n\n\tAnalytics Tools\n\t\n\n\tProgramming Language\n\tPython, Advanced Excel\n\n\tPython Libraries\n\tNumPy, Pandas, scikit-learn, Matplotlib, ggplot2, Flask\n\n\tDatabase\n\tOracle, Cassandra\n\n\tData Cleansing \n\tETL\n\n\t\n\t\n\n\tWork Experience\n\n\tHaving Six Years and three months of experience in Software Development with working knowledge in Healthcare and Telecom domains.\n\n\n\tEmployment History\n\n\t\n\n\tOrganization \n\tCSC India Pvt. Ltd., Noida\n\n\tExperience\n\t3 Years 6 months\n\n\tDesignation\n\tProfessional: Product Developer\n\n\tDuration\n\tAug2011- Feb2015\n\n\t\n\t\n\n\tOrganization \n\tAccenture India\n\n\tExperience\n\t2 Years 9 month\n\n\tDesignation\n\tSoftware Engineer, Senior Analyst\n\n\tDuration\n\tFrom Feb2015 till date\n\n\t\n\t\n\n\tProfessional Experience\n\n\n1. Project Name: Clinical Suite\n\tClient \n\tDenmark Hospitals\n\n\tDuration\n\t3 Years 6 months\n\n\tDomain\n\tHealthcare\n\n\tRole\n\tProduct Developer\n\n\tProject Details\n\tCSC Clinical Suite™ is an electronic patient record that potentially covers the whole hospital across professions, departments, specialties and organization. The solution supports tasks from the referral and the admission to the discharge of the patient. It collects and structures all the patient information that exists in the form of clinical activities and the associated documentation in one place.\n\n\tProgramming Language\n\tJava, JPA, Callbacks, Webservices, JMX, SQL\n\n\tDevelopment Tool\n\tIntelliJ Idea\n\n\tFramework/API/IDE\n\tJSF, JPA Hibernate\n\n\tDatabase\n\tOracle HTB\n\n\tResponsibilities\n\t· Create end to end module for new patient encounter.\n\n· Involved in defect fixing.\n\n· Create new front end in xhtml which is more interactive.\n\n· Optimize DB calls to minimize response time.\n\n· Optimize inter module communication to provide more transparency to encounters.\n\n\n2. Project Name: Chordiant Decisioning Management\n\tClient \n\tVodacom South Africa\n\n\tDuration\n\tFrom Mar 2015 to Nov 2015\n\n\tDomain\n\tTelecom\n\n\tRole\n\tSoftware Developer, Senior Analyst\n\n\tProject Details\n\tThe Chodiant Decision Management tool (a Pega Product) is a part of Vodacom SA rollout to assist various channels in providing their customers with new and unique offers for product they may be interested in. The offers are based on customer’s historical data which is analyzed in the background and used to determine which offers the customer may be interested in.\n\n\tProgramming Language\n\tJava, Webservices, Weblogic, SQL, PL/SQL\n\n\tDevelopment Tool\n\tEclipse, Maven\n\n\tFramework/API/IDE\n\tJSF, Chordiant, Spring boot\n\n\tDatabase\n\tOracle\n\n\tOperating System\n\tRHEL, AIX\n\n\tResponsibilities\n\t· Leading team of 4 developers and support analysts.\n\n· Creating new logics and instructions in Chordiant.\n\n· Creating new adapter to improve DB access time per transaction.\n\n· Involved in defect fixing.\n\n· Worked on introducing new etl processes.\n\n· Developing a Java based tool to automate repetitive tasks to save manual efforts of support team.\n\n· Automated daily graphs in that tool that can be accessed password-less.\n\n· Created PL/SQL procedures to ensure health of DB tables.\n\n· Created Shell scripts to generate and distribute system performance reports at regular intervals.\n\n· Supporting the production application deployment and logic deployment.\n\n· Capacity Planning, Transaction Reporting and Performance Testing.\n\n\tAchievement\n\t· Got a chance to work in Client side in Cape Town, South Africa.\n\n· Received multiple recommendations and appreciations from client and other coordinating teams.\n\n· Communicating with client several times a day is part of a day to day activities.\n\n\n3. Project Name: Chordiant Asset Enablement\n\tClient\n\tVodacom SA\n\n\tDuration\n\tDec 2015 to Present\n\n\tDomain\n\tTelecom\n\n\tRole\n\tSoftware Developer, Senior Analyst\n\n\tProject Details\n\tChordiant Asset Enablement enables Vodacom to predict the performance of high propensity offers and manipulate the offer presentation weightage to maximize offer acceptance ratio for different subscriber groups.\n\n\tProgramming Language\n\tPython, Shell script, SQL\n\n\tLibraries\n\tNumPy, SciPy, Pandas, Matplotlib\n\n\tFramework/API/IDE\n\tAnaconda\n\n\tDatabase\n\tOracle\n\n\tOperating System\n\tRHEL\n\n\tResponsibilities\n\t· Verify the data and check for different and maintain consistency. Remove unnecessary attributes and expired data. \n\n· Understand the business logic and study the relation between different attributes of customer data to increase the efficiency of model. \n· Create new models with different attributes and check for accuracy and correlation.\n· Keep up existing models and maintain regular report publishing.\n\n· Provide Business reports as per the business specifications provided. \n\n\t\n\t\n\n\tAcademic Details\n\n\t\n\n\tQualification\n\tInstitute\n\tBoard/Univ.\n\tYear\n\n\tB.E.(IT)\n\tTruba Inst of Engg. & IT, Bhopal\n\tRGPV, Bhopal\n\t2007-11\n\n\t\n\n\tPersonal Details\n\n\t\n\n\tPresent Address\n\tNo 534, 5th B Cross, 4th Stage, BEML Layout\nNear Best Club, Rajarajeshwari Nagar \n\nBangalore 560098  \n\n\n\tLanguages Known\n\tHindi & English \n\n\tMarital Status\n\tUnmarried\n\n\tNationality\n\tIndian\n\n\n\n\t\n\t\n\n\tDeclaration\n\n\t\n\n\tI hereby certify that the information furnished above is correct and complete to the best of my knowledge.\n\n\t\n\n\nGaurav Soni","annotation":[{"label":["Location"],"points":[{"start":7217,"end":7225,"text":"Bangalore"}]},{"label":["Education"],"points":[{"start":7024,"end":7031,"text":"B.E.(IT)"}]},{"label":["Skills"],"points":[{"start":6322,"end":6324,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":6300,"end":6305,"text":"Python"}]},{"label":["Skills"],"points":[{"start":5333,"end":5335,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":5330,"end":5335,"text":"PL/SQL"}]},{"label":["Skills"],"points":[{"start":4738,"end":4740,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":4735,"end":4740,"text":"PL/SQL"}]},{"label":["Skills"],"points":[{"start":4730,"end":4732,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":3714,"end":3716,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":2448,"end":2453,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2423,"end":2428,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2077,"end":2079,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":2047,"end":2052,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1963,"end":1968,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1953,"end":1960,"text":"Java 1.7"}]},{"label":["Skills"],"points":[{"start":786,"end":788,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":783,"end":788,"text":"PL/SQL"}]},{"label":["Skills"],"points":[{"start":767,"end":769,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":483,"end":487,"text":"Scrum"}]},{"label":["Name"],"points":[{"start":0,"end":10,"text":"GAURAV SONI"}]}],"extras":null,"metadata":{"first_done_at":1532671585000,"last_updated_at":1532671585000,"sec_taken":97,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "GAURAV SONI\ngaurav.soni1302@gmail.com\n+91.8860226996\n\tProfile Summary\n\n· Overall more than 6 years of industry experience in Analysis, Design, Development, Implementation and Testing of application which includes 4 Years 2 months of working with Java technologies and frameworks and almost 2 Years 1 month of working on Machine Learning.\n· Experience of working in different phases of Software Development Life Cycle inlcuding Designing, Development and Deployment.\n\n· Experience in Scrum, Agile and Waterfall software development models.\n\n· Worked in Client facing team with continuous client interaction.\n· Business Report creation based on different specifications.\n· Well versed with different OS platforms like Unix, Linux, AIX.\n· Created and optimized multiple SQL queries and PL/SQL procedures to save time and CPU utlisation.\n· Created and modified shell scripts and perl scripts(with cron jobs) to monitor per minute, daily, weekly, monthly and yearly trasaction and publish Transaction Reports accordingly.\n· Statistical Analytics: Worked in application which is responsible for publishing different graphs based on popularity and current trend to analyse the performance of different voice and data offers for different categories of subscribers. \n\n· Data Handling: The models were created from 14 daily CAR files and 7 monthly CAR files with customer data generated after EOD process. As part of cleaning, a part of customer data has to be trimmed out based on account validity and other eligibility criteria. \n· Regression: The commonest approach used in application for creating models and predicting performance of most popular offers in different categories was linear regression since delivered data used to be tidy which further improved performance.\n· Got opportunity to work from Client site in Cape Town to have better understanding of Business process.\n\n\n\tTechnical Skill Set\n\n\t\n\n\tJava Programming Tools\n\t\n\n\tProgramming Languages\n\tJava 1.7, Python\n\n\tDevelopment/Build Tools\n\tRAD 7.5, Eclipse, SVN, Harvest, Maven, Anaconda, IPython\n\n\tScripting Languages\n\tSQL, JavaScript, HostBridge (HBJS), HBX\n\n\tDatabase\n\tOracle, IBM DB2, Oracle HTB\n\n\tServers\n\tWebLogic, Apache Tomcat\n\n\tWeb Technologies\n\tServlet, JSP, JSF, Web Services\n\n\tFramework\n\tIntegralAdminFramework (like Struts2.0), JPA using Hibernate\n\n\tXML Technologies\n\tHostBridge Scripting, XML Parsing, Xpath\n\n\tAnalytics Tools\n\t\n\n\tProgramming Language\n\tPython, Advanced Excel\n\n\tPython Libraries\n\tNumPy, Pandas, scikit-learn, Matplotlib, ggplot2, Flask\n\n\tDatabase\n\tOracle, Cassandra\n\n\tData Cleansing \n\tETL\n\n\t\n\t\n\n\tWork Experience\n\n\tHaving Six Years and three months of experience in Software Development with working knowledge in Healthcare and Telecom domains.\n\n\n\tEmployment History\n\n\t\n\n\tOrganization \n\tCSC India Pvt. Ltd., Noida\n\n\tExperience\n\t3 Years 6 months\n\n\tDesignation\n\tProfessional: Product Developer\n\n\tDuration\n\tAug2011- Feb2015\n\n\t\n\t\n\n\tOrganization \n\tAccenture India\n\n\tExperience\n\t2 Years 9 month\n\n\tDesignation\n\tSoftware Engineer, Senior Analyst\n\n\tDuration\n\tFrom Feb2015 till date\n\n\t\n\t\n\n\tProfessional Experience\n\n\n1. Project Name: Clinical Suite\n\tClient \n\tDenmark Hospitals\n\n\tDuration\n\t3 Years 6 months\n\n\tDomain\n\tHealthcare\n\n\tRole\n\tProduct Developer\n\n\tProject Details\n\tCSC Clinical Suite™ is an electronic patient record that potentially covers the whole hospital across professions, departments, specialties and organization. The solution supports tasks from the referral and the admission to the discharge of the patient. It collects and structures all the patient information that exists in the form of clinical activities and the associated documentation in one place.\n\n\tProgramming Language\n\tJava, JPA, Callbacks, Webservices, JMX, SQL\n\n\tDevelopment Tool\n\tIntelliJ Idea\n\n\tFramework/API/IDE\n\tJSF, JPA Hibernate\n\n\tDatabase\n\tOracle HTB\n\n\tResponsibilities\n\t· Create end to end module for new patient encounter.\n\n· Involved in defect fixing.\n\n· Create new front end in xhtml which is more interactive.\n\n· Optimize DB calls to minimize response time.\n\n· Optimize inter module communication to provide more transparency to encounters.\n\n\n2. Project Name: Chordiant Decisioning Management\n\tClient \n\tVodacom South Africa\n\n\tDuration\n\tFrom Mar 2015 to Nov 2015\n\n\tDomain\n\tTelecom\n\n\tRole\n\tSoftware Developer, Senior Analyst\n\n\tProject Details\n\tThe Chodiant Decision Management tool (a Pega Product) is a part of Vodacom SA rollout to assist various channels in providing their customers with new and unique offers for product they may be interested in. The offers are based on customer’s historical data which is analyzed in the background and used to determine which offers the customer may be interested in.\n\n\tProgramming Language\n\tJava, Webservices, Weblogic, SQL, PL/SQL\n\n\tDevelopment Tool\n\tEclipse, Maven\n\n\tFramework/API/IDE\n\tJSF, Chordiant, Spring boot\n\n\tDatabase\n\tOracle\n\n\tOperating System\n\tRHEL, AIX\n\n\tResponsibilities\n\t· Leading team of 4 developers and support analysts.\n\n· Creating new logics and instructions in Chordiant.\n\n· Creating new adapter to improve DB access time per transaction.\n\n· Involved in defect fixing.\n\n· Worked on introducing new etl processes.\n\n· Developing a Java based tool to automate repetitive tasks to save manual efforts of support team.\n\n· Automated daily graphs in that tool that can be accessed password-less.\n\n· Created PL/SQL procedures to ensure health of DB tables.\n\n· Created Shell scripts to generate and distribute system performance reports at regular intervals.\n\n· Supporting the production application deployment and logic deployment.\n\n· Capacity Planning, Transaction Reporting and Performance Testing.\n\n\tAchievement\n\t· Got a chance to work in Client side in Cape Town, South Africa.\n\n· Received multiple recommendations and appreciations from client and other coordinating teams.\n\n· Communicating with client several times a day is part of a day to day activities.\n\n\n3. Project Name: Chordiant Asset Enablement\n\tClient\n\tVodacom SA\n\n\tDuration\n\tDec 2015 to Present\n\n\tDomain\n\tTelecom\n\n\tRole\n\tSoftware Developer, Senior Analyst\n\n\tProject Details\n\tChordiant Asset Enablement enables Vodacom to predict the performance of high propensity offers and manipulate the offer presentation weightage to maximize offer acceptance ratio for different subscriber groups.\n\n\tProgramming Language\n\tPython, Shell script, SQL\n\n\tLibraries\n\tNumPy, SciPy, Pandas, Matplotlib\n\n\tFramework/API/IDE\n\tAnaconda\n\n\tDatabase\n\tOracle\n\n\tOperating System\n\tRHEL\n\n\tResponsibilities\n\t· Verify the data and check for different and maintain consistency. Remove unnecessary attributes and expired data. \n\n· Understand the business logic and study the relation between different attributes of customer data to increase the efficiency of model. \n· Create new models with different attributes and check for accuracy and correlation.\n· Keep up existing models and maintain regular report publishing.\n\n· Provide Business reports as per the business specifications provided. \n\n\t\n\t\n\n\tAcademic Details\n\n\t\n\n\tQualification\n\tInstitute\n\tBoard/Univ.\n\tYear\n\n\tB.E.(IT)\n\tTruba Inst of Engg. & IT, Bhopal\n\tRGPV, Bhopal\n\t2007-11\n\n\t\n\n\tPersonal Details\n\n\t\n\n\tPresent Address\n\tNo 534, 5th B Cross, 4th Stage, BEML Layout\nNear Best Club, Rajarajeshwari Nagar \n\nBangalore 560098  \n\n\n\tLanguages Known\n\tHindi & English \n\n\tMarital Status\n\tUnmarried\n\n\tNationality\n\tIndian\n\n\n\n\t\n\t\n\n\tDeclaration\n\n\t\n\n\tI hereby certify that the information furnished above is correct and complete to the best of my knowledge.\n\n\t\n\n\nGaurav Soni","annotation":[{"label":["Location"],"points":[{"start":7217,"end":7225,"text":"Bangalore"}]},{"label":["Education"],"points":[{"start":7024,"end":7031,"text":"B.E.(IT)"}]},{"label":["Skills"],"points":[{"start":6322,"end":6324,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":6300,"end":6305,"text":"Python"}]},{"label":["Skills"],"points":[{"start":5333,"end":5335,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":4738,"end":4740,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":4730,"end":4732,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":3714,"end":3716,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":2448,"end":2453,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2423,"end":2428,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2113,"end":2115,"text":"HBX"}]},{"label":["Skills"],"points":[{"start":2094,"end":2110,"text":"HostBridge (HBJS)"}]},{"label":["Skills"],"points":[{"start":2082,"end":2091,"text":"JavaScript"}]},{"label":["Skills"],"points":[{"start":2077,"end":2079,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":2047,"end":2052,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1963,"end":1968,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1953,"end":1960,"text":"Java 1.7"}]},{"label":["Skills"],"points":[{"start":786,"end":788,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":767,"end":769,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":320,"end":335,"text":"Machine Learning"}]},{"label":["Name"],"points":[{"start":0,"end":10,"text":"GAURAV SONI"}]}],"extras":null,"metadata":{"first_done_at":1532684678000,"last_updated_at":1532684678000,"sec_taken":159,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "GIRDHAR SINGH BORA\nE-Mail: girdhar_coer@yahoo.co.in\nPhone:09582054499\nLinkedIn ID: https://www.linkedin.com/in/girdhar-singh-bora-24688319/\n\t\n\nResult-driven professional, targeting assignments in Software Development/Data Science,preferably \nin IT Services/Consulting Industry\n\n\n\tCore Competencies\n\nMachine Learning Engineering\nPython Programming\nScikit Learn\nPandas,  Numpy and Matplotlib\nRequirement Gatheing\n\n\n\n\n\n\n\n\t\n\tProfile Summary\n\n\n· A B.Tech. (Information Technology) professional,having over 7 years of experience in software development and 4 years in Machine Learning; zeal to make a winning carrier in Data Science/Machine Learning\n· Currently working on Genpact Neural Intelligent Platform project\n· Experienced in machine learning, Neural Network, NLP, algorithms and iOS application development\n·  Completed 12 weeks Machine Learning Certificate from Coursera created by Stanford University\n· Completed 8 weeks Machine Learning Certificate from NPTEL created by IIT Kharagpur\n· Gained knowledge of programming languages like Python, Swift and Objective C\n· Knowledge of Scikit Learn framework\n· Team handling expreince.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOrganisational Experience\nGenpact India Pvt.Ltd., NOIDA as a Lead Consultant                                                                                                           Jul’13-Present       \nKey Result Areas:\n· Involved in the development of Machine Learning Models in the area of Text Processing. \n· Working on Machine Learning, Neural Network, NLP algorithms. Domain: Python/Scikit- Learn/nltk/Tensorflow/Keras \n· Data transformation and training & testing models for optimization of results. \n· Development of web crawlers for large online publishers. Domain: Python\n· Development of webservices . Domain: Python\n· Backend Infrastructure development and Dev environment setup on AWS. Domain: Python Platform: Linux\nHighlights:\n· Developed:\n· A text base classifier using machine-learning Naive Bayes algorithms\n· Churn Model using deep learning Artificial Neural Network.\n· Chat-bot module using socket.io framework\n· REST API using python bottle framework\n· Took measures to ensure that applications were in line with the requirement specified by clients\n· Suggested enhancements to improve application performance and additional business \nComputer Science Corporation India(CSC), NOIDA as a Consultant Mar’12-Jul’13 \nHighlights:\n· Developed:\n· Full stack software development for iOS application development\n· Enterprise applications for iPhone and iPad\n· Deployed  iOS application into Apple App store and interacted with clients\n· Led initiatives to build competencies of team\n\nTeleDNA Communication, Bangalore as Software EngineerOct’10-Mar’12                                     \n Highlights:\n· Developed iOS applications for iPhone and iPad\n· Deployed iOS application into Apple App store and interacted with clients\n· Delivered projects on time under the right supervision and thus increased productivity\nProject details\n\nProject:Genpact Neural Intelligent Platform\nPeriod: Jan'16 – Present\nDescription:Genpact Neural Intelligence Platform is for chat augments customer service agents, helping them to provide the best response to customer inquiries during a customer service chat. This automated chat solution responds like a human agent, mining large-scale datasets to bring all environmental, historical and contextually relevant data to bear. This solution reduces the time required to manually mine such data.\nRole:\n· Involved in the development and integration of Classifier using Naive Bayes algorithms. Domain:Python/Scikit-Learn\n· Data transformation and training & testing models for optimization of results. Domain: Python\n· Development of web crawlers for large online publishers. Domain: Python \n· Development of webservices . Domain: Python\n· Backend Infrastructure development and Dev environment setup on AWS. Domain: Python, Platform: Linux\n· Formulation of Chat bot using Node Js in Socket I/O Framework\n\nProject: Churn Model\nPeriod: Mar'15 - Dec `15\nDescription: Churn Machine learning methods, specifically classification, are widely used due to their high performance and ability to handle complex relationships in data. On the other hand, survival analyses can provide value by answering a different set of questions. Quantities,such as survival and hazard functions, can be used to forecast which customers will churn in a particular time period.\nRole:\n· Involved in the development and integration of Churn Model using Artificial Nural Network(ANN). Domain:Python/Scikit-Learn/Keras/Tensorflow.\n· Data transformation and training & testing models for optimization of results. Domain: Python\n· Development of webservices . Domain: Python\n· Backend Infrastructure development and Dev environment setup on AWS. Domain: Python, Platform: Linux\n\nProject: Review System(Sentiment Analyser)\nPeriod: Mar'14 – Sep’14\nDescription: Review System(Sentiment Analyser) is a machine learning model. It is use to computationally identifying and categorizing opinions expressed in a piece of text, especially in order to determine whether the writer's attitude towards a particular topic, product, etc. is positive, negative, or neutral\nRole:\n· Involved in the development of Sentiment Analyser Model using Naive Baise Algorithm. Domain:Python/Scikit-Learn.\n· Tuning the algorithm parameters to improve accuracy of the Classifier.\n· Data transformation and training & testing models for optimization of results. Domain: Python\n· Development of webservices . Domain: Python\n· Backend Infrastructure development and Dev environment setup on AWS. Domain: Python, Platform: Linux\n\nProject: Principal Component Analysis (PCA) System\nPeriod: Aug'13 – Dec’13\nDescription: The main idea of principal component analysis (PCA) is to reduce the dimensionality of a data set consisting of many variables correlated with each other, either heavily or lightly, while retaining the variation present in the dataset. In the PCA sytem we provide the dataset and the number of principal component as a input then the system will generate the principal component for the given input dataset. Finaly we are visualising the output data in the 2D or 3D grapth crosponding to the target variable.\nRole:\n· Involved in the development of Principal Component Analysis Algorithm using Pandas and Numpy. Domain:Python.\n· Integrating the UI with the PCA system.\n· Visualising  the Principal component into the 2D or 3D grapth using Matplotlib. Domain Python.\n· Development of webservices . Domain: Python\n· Backend Infrastructure development and Dev environment setup on AWS. Domain: Python, Platform: Linux\n\n\n\n\n\nAcademic details\n· B.Tech. (Information Technology) from College of Engineering Roorkee in 2009; secured 75%\n· Diploma in Information Technology from BTE Roorkee in 2006; secured 76%\nIT Skills\n\n· Programming:\t Python, Swift, Objective C\n· Algorithm: \t\tLinear & Logistic Regression, KNN, Naive Bayes, SVM, K-means Clustering, Decision Tree, Neural                   \n                                         Networks, Random Forest, Ada boost, XGBoost\n· Frameworks:                Scikit Learn, Pandas, Matplotlib, Numpy, Socket IO\n· Tools:                              Jupyter Notebook, GIT, SVN and Pycharme\n\nCertifications\n\n· 12 weeks Machine Learning Course created by Stanford University and taught by Andrew NG\n· 8 weeks Machine Learning Certification Course created by IIT Kharagpur and NPTEL\n\nPersonal Details\n\nDate of Birth: \t\t7thJuly1985\nLanguages Known: \tEnglish&Hindi\nAddress:     F-37, Sector 51, NOIDA-201301, Uttar Pradesh","annotation":[{"label":["Location"],"points":[{"start":7588,"end":7600,"text":"Uttar Pradesh"}]},{"label":["Skills"],"points":[{"start":7391,"end":7406,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":7302,"end":7317,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":5318,"end":5336,"text":"Python/Scikit-Learn"}]},{"label":["Skills"],"points":[{"start":4555,"end":4573,"text":"Python/Scikit-Learn"}]},{"label":["Skills"],"points":[{"start":3592,"end":3610,"text":"Python/Scikit-Learn"}]},{"label":["Skills"],"points":[{"start":1475,"end":1490,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1405,"end":1420,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":926,"end":941,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":832,"end":847,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":627,"end":642,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":562,"end":577,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":299,"end":314,"text":"Machine Learning"}]},{"label":["Name"],"points":[{"start":0,"end":17,"text":"GIRDHAR SINGH BORA"}]}],"extras":null,"metadata":{"first_done_at":1532674406000,"last_updated_at":1532674406000,"sec_taken":159,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Gitanjali Chhotray\nCurrent Company: Tata Consultancy Services\nPhone: +91-9535497675\ngeeta.chhotaray@gmail.com\n\t\n\nCAREER OBJECTIVE:\nTo be a part of a result oriented organization where acquired knowledge and skills gained during my professional experience will be utilized towards continuous growth and development of the organization. \n\nBRIEF PROFILE: \nData Science and Analytics professional with over 10+ years of experience in the area of Advance analytics, Machine learning, Deep Learning, Predix, Text Mining and Big Data, Operation Research.\n\nWork Experience: 10+ Years in Analytics and  Data Science. \nCurrent Employer: TCS - Analytics & Insights, Bangalore. \nHighest Degree: M.Sc. Statistics, MCA.  \n\nSUMMARY OF EXPERIENCE:\n· Experience in analytics capability development, team mentoring and client  interaction. \n· Excellent analytical, problem-solving, decision-making and strong technical skills.\n· Exceptional ability to learn new industries and business processes quickly.\n· Analytics practices in Predictive, Descriptive, Investigative, Text Mining, and Data Mining.\n· Hands on experience in linear Regression, Logistic Regression, Cluster analysis, Factor Analysis, Conjoint, Sentiment Analysis and Monte Carlo simulation.  \n· Hands on experience in Machine Learning, Deep Learning, Predix. \n· Hadoop Ecosystem – Pig, Hive, Rhadoop, Mahout, Map Reduce.\n· Machine Learning Algorithms- KNN, Naive Bayes, Decision trees, SVM, GBM,ANN, Random Forest.\n· Exposure to multiple Statistical tools like Python, R, SAS, SPSS. \n· Exposure to some programming Languages - SQL, JAVA, C++. \n\nPROFESSIONAL EXPERIENCE:\nI) Company\t\t: Tata Consultancy Services - Analytics & Insights, Bangalore.\nRole   \t\t\t: Lead Data Scientist.\nDuration\t\t: Jul 2012 to Till Date.\nJob Responsibility\t:\n* Mentoring team, Client Interaction and leading Predix COE.\n* Understand partner's business requirements and deliver data driven solutions.\n* Responsible for managing client requirements and on-site team interaction. \n* Helping partners to understand the analytical pattern in the data marts. \n* Drive new actionable insights from the client data marts.\n* Identifying new opportunity areas for customer acquisition of the client. \n* Identified process boundaries and developed opportunities to automate processes and functions. \n* Create Offerings and proposals addressing different problems identified in client business.\n* Advanced Analytics, Machine Learning, Deep Learning using Python and R\n\n II) Company \t: Accenture Consulting Pvt. Ltd, Bangalore.\nRole \t\t: Lead Analyst\nDuration \t: Apr 2010 to Oct 2011\nJob Responsibility      :\n*Responsible for managing client requirements and on-site team interaction.\n* Convert the business problem into Data Driven Solution.\n*Understanding Business problems and provide solution approach\n*Key individual contributor for different business problems.\n* Help the business to get benefited by implementing the solutions.\n*Automate the analytic solutions.\n*Mentoring and guiding junior team members.\n* Gathered business Requirements from users to design process automation.\n* Advance Analytics, Simulation, Optimization.\n\nIII) Company\t: HCL Technology Ltd, Bangalore.\nRole\t\t: Business Analyst.\nDuration\t: Sept 2006 to Sept 2009\nJob Responsibility      :\n* Act as an interface with the client for analytics requirement.\n* Identify appropriate Analytical Solutions using data to address business context.\n*Drive new actionable insights from the client data marts.  \n* Develop segmentation schemes to improve customer acquisition, retention and loyalty.\n* Identifying new opportunity areas for customer acquisition of the client.\n*Analyzed department technology usage and determined the best course for future purchases.\n*Worked independently and organize workload with minimal direct supervision.\n* Helping the marketers to take strategic decisions for marketing, advertisement and product positioning   and launching. \n* Advanced Analytics, Segmentation, Predictive models, Monte Carlo Simulation.  \n\nIV) Company\t\t: IBM, Bangalore.\t\nDuration\t\t: Nov 2005 to Aug 2006.\nJob Responsibility\t:Data Analytics.\n*Analysis of problem domain and Understanding the Data Mart. \n* Gathered technical requirements and participated in design sessions.\n* Bridge the gap between Analytics and technology for analytics product development.\n* Responsible in identifying, assess, and document business requirements, recommending business                                                                                                                              \n    priorities and advising business on options, risks, and costs.\t\n* Accountable for Solution, Conceptual Understanding, Modeling.\n\nTECHNICAL EXPERTISE:\n*Operating System\t            : Windows Family, UNIX.\n*Utility                                       : MS Office\n*Programming Language       : SAS, R, Python, C++, JAVA.\n*RDBMS                                     : Oracle, SQL Server.\n*Optimization Tool                  : CPLEX, GAMS.\n*Simulation Tool                      : ANYLOGIC.\n*Big Data Technology             : HADOOP, HIVE, Pig, Map Reduce (Programming Paradigm)\n\nEDUCATIONAL QUALIFICATION:\n*Master in Computer Application (MCA), Sambalpur University, Orissa, 76%\n*M.Sc. Statistics with specialization in Operations Research, Sample Survey \n  Utkal University, Orissa, 62%\n\nSTRENGTH/ABILITY: \n* Co-operative, career oriented, hardworking, sincere. \n* Good sense of humor.  \n\nHOBBIES/INTERESTS:   \n* Listening to music, travelling, soft skill enhancement, gardening.\n\nPERSONAL DETAILS:\n*Nationality\t\t\t: Indian\n*Gender\t\t\t: Female\n*Language Known\t             : English, Hindi and Oriya\n\nCOMMUNICATION:  \n E-mail: geeta.chhotaray@gmail.com.           \n Mobile: +91 - 9535497675(Primary).\nCorrespondence: Kundanahalli Gate, Bangalore.\n\n\n\n***THANK YOU***","annotation":[{"label":["Location"],"points":[{"start":5800,"end":5808,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":5549,"end":5549,"text":"R"}]},{"label":["Skills"],"points":[{"start":5467,"end":5467,"text":"R"}]},{"label":["Skills"],"points":[{"start":5356,"end":5356,"text":"R"}]},{"label":["Skills"],"points":[{"start":5296,"end":5296,"text":"R"}]},{"label":["Education"],"points":[{"start":5245,"end":5248,"text":"M.Sc"}]},{"label":["Education"],"points":[{"start":5204,"end":5206,"text":"MCA"}]},{"label":["Skills"],"points":[{"start":5113,"end":5113,"text":"R"}]},{"label":["Skills"],"points":[{"start":4890,"end":4894,"text":"RDBMS"}]},{"label":["Skills"],"points":[{"start":4890,"end":4890,"text":"R"}]},{"label":["Skills"],"points":[{"start":4883,"end":4886,"text":"JAVA"}]},{"label":["Skills"],"points":[{"start":4878,"end":4880,"text":"C++"}]},{"label":["Skills"],"points":[{"start":4870,"end":4875,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4867,"end":4867,"text":"R"}]},{"label":["Skills"],"points":[{"start":4712,"end":4712,"text":"R"}]},{"label":["Skills"],"points":[{"start":4345,"end":4345,"text":"R"}]},{"label":["Skills"],"points":[{"start":4093,"end":4093,"text":"R"}]},{"label":["Location"],"points":[{"start":4043,"end":4051,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":3255,"end":3255,"text":"R"}]},{"label":["Skills"],"points":[{"start":3191,"end":3191,"text":"R"}]},{"label":["Location"],"points":[{"start":3180,"end":3188,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":3043,"end":3043,"text":"R"}]},{"label":["Skills"],"points":[{"start":2620,"end":2620,"text":"R"}]},{"label":["Skills"],"points":[{"start":2597,"end":2597,"text":"R"}]},{"label":["Skills"],"points":[{"start":2538,"end":2538,"text":"R"}]},{"label":["Location"],"points":[{"start":2527,"end":2535,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":2477,"end":2477,"text":"R"}]},{"label":["Skills"],"points":[{"start":2466,"end":2471,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2446,"end":2458,"text":"Deep Learning"}]},{"label":["Skills"],"points":[{"start":2428,"end":2443,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1925,"end":1925,"text":"R"}]},{"label":["Skills"],"points":[{"start":1765,"end":1765,"text":"R"}]},{"label":["Skills"],"points":[{"start":1693,"end":1693,"text":"R"}]},{"label":["Location"],"points":[{"start":1682,"end":1690,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":1610,"end":1610,"text":"R"}]},{"label":["Skills"],"points":[{"start":1594,"end":1594,"text":"R"}]},{"label":["Skills"],"points":[{"start":1586,"end":1588,"text":"C++"}]},{"label":["Skills"],"points":[{"start":1580,"end":1583,"text":"JAVA"}]},{"label":["Skills"],"points":[{"start":1517,"end":1517,"text":"R"}]},{"label":["Skills"],"points":[{"start":1509,"end":1514,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1448,"end":1448,"text":"R"}]},{"label":["Skills"],"points":[{"start":1371,"end":1386,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1361,"end":1361,"text":"R"}]},{"label":["Skills"],"points":[{"start":1340,"end":1340,"text":"R"}]},{"label":["Skills"],"points":[{"start":1284,"end":1296,"text":"Deep Learning"}]},{"label":["Skills"],"points":[{"start":1266,"end":1281,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1135,"end":1135,"text":"R"}]},{"label":["Skills"],"points":[{"start":1114,"end":1114,"text":"R"}]},{"label":["Skills"],"points":[{"start":724,"end":724,"text":"R"}]},{"label":["Skills"],"points":[{"start":714,"end":714,"text":"R"}]},{"label":["Education"],"points":[{"start":701,"end":703,"text":"MCA"}]},{"label":["Education"],"points":[{"start":683,"end":686,"text":"M.Sc"}]},{"label":["Location"],"points":[{"start":655,"end":663,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":538,"end":538,"text":"R"}]},{"label":["Skills"],"points":[{"start":479,"end":491,"text":"Deep Learning"}]},{"label":["Skills"],"points":[{"start":344,"end":344,"text":"R"}]},{"label":["Skills"],"points":[{"start":338,"end":338,"text":"R"}]},{"label":["Skills"],"points":[{"start":118,"end":118,"text":"R"}]},{"label":["Skills"],"points":[{"start":115,"end":115,"text":"R"}]},{"label":["Name"],"points":[{"start":0,"end":17,"text":"Gitanjali Chhotray"}]}],"extras":null,"metadata":{"first_done_at":1532694291000,"last_updated_at":1532694291000,"sec_taken":81,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "GOKULRAM BALAKRISHNAN \nAddress:     13/1, Email ID: perkygokul@gmail.com \n\nNew Krishnappa Building,    \n\n5th B Cross, Phone:    +91 81976 96246 \n\nMadivala, Bangalore \n\n560068. \n\n \n\nSUMMARY \n\nA  highly  motivated Horizontal Data Scientist  with  5+  years  of  excellent experience  in  specializing  predictive \n\nmodelling, feature engineering, text analytics, deep learning , data mining, statistics, data visualization  and  software  \n\ndevelopment. \n\n \n\nEDUCATION \n\n  MSc in Software Engineering (5 Years Integrated) at Kongu Engineering College, Tamilnadu, India with GPA of   7.7/10 \n\nduring 2007-2012 \n\n \n\nTECHNICAL SKILLS \n\n Machine Learning: Classification, Regression, Clustering, Feature engineering \n\n Statistical Methods: Regression models, hypothesis testing and confidence intervals, principal component analysis \nand dimensionality reduction \n\n Models Used : Linear Regression, Logistic Regression, Random Forest, Extreme Gradient Boosting, Naïve Bayes,      \n\nK means, Agglomerative Hierarchical clustering \n\n Languages: Python, R, Java, SQL. \n\n Packages and Tools: Tableau , R Studio, Minitab, MS Excel, Eclipse SDK, PyCharm, MySQL, Spring Framework \n\n Platforms: IBM Bluemix \n\n Selected Coursework:  Six Sigma (Green Belt) , Advanced statistics with R, Data mining using python \n\n Area of Interest: Creating real time impact through Predictive Modelling, Artificial Intelligence, Text Analytics \n\n \n\nWORK EXPERIENCE \n\n Predictive Analyst, Honeywell Technology Solutions Lab Pvt. Ltd., Bangalore         March/2016 - Till now  \n\no Comment Volume Prediction using Decision Trees (Inspired by an article presented at ICMS - \n\nResearch in progress): My research is oriented towards the comment volume prediction (CVP) that a \n\ndocument is expected to receive in next expected hours. This application consist of prototypes for crawler, \n\nInformation extractor, information processor and knowledge discovery module. \n\no Social Media Analytics: Gathered data from various social media like Facebook, Twitter and forums to get \n\ndata on a specific group of people to create a recommendation engine to suggest product based on customer’s \n\nbehavior. \n\no HR attrition analysis: Created prediction models using random forest to predict employee’s flight risk and \n\norganizational turn over. Performed feature engineering and model evaluation using R, Minitab and \n\nvisualization via Tableau \n\no Retention program analysis: Created prediction model using Random Forest and recommendation system \n\nusing Hybrid Collaborative Filtering  to help the HR team to target employees who has high flight risk and \n\ngiving suggestion for retention program \n\nmailto:perkygokul@gmail.com\n\n\n \n\no Top performer analysis : Created a binary logistic method to find which employee will perform better in \n\nfuture \n\no Resume screening (Research in progress) : Implementing  a  resume  screening model to rank a resume for \n\nparticular job description by using various text analytics methodologies  \n\no Insider Platform: Created one touch platform to gather data from external data source for the prediction \n\nmodels. This platform gathers data from : \n\n Google map API: Used Google Map API’s to calculate the commuting distance and time of employees \n\nwhich was a critical factor for the employee attrition model using R. \n\n Google Cloud Machine Learning: Used Google Cloud Machine Learning API’s to perform NLP \n\nprocesses, Translations and Image processing \n\n LinkedIn API :  Communicated with LinkedIn API’s to gather the data of a person on LinkedIn related to \n\njob search information for the attrition model using Python  \n\n \n\n Associate Consultant, WIPRO TECHNOLOGIES India Pvt. Ltd., Bangalore                 May/2012 - March 2016 \n\no Recommendation Engine:  Created a Recommendation Engine using K-Means clustering in pharma \n\ndomain to target a particular set of key opinion leaders based on their profile and social media activity \n\no Data Discovery Platform: Created a platform to find the attributes of a product from a user review to \n\nperform sentiment analysis for the particular attribute as well as for the product from the user review data \n\nand to give insight about the products through dashboards \n\no Customer churn Analysis: Created a classification model to predict the likelihood of a customer to \n\ndiscontinue the service and created recommendation engine to recommend additional service to retain the \n\ncustomer. \n\no Price Predictive Model for E-Commerce: Built a model to predict the prices of products based on a retail \n\ndata. \n\no Doculytics: Created a platform to ease the customer on boarding process by validating KYC documents by \n\nOCR and Information Extraction. Also, implemented information extraction algorithm to extract customized \n\nrequired fields from the financial statements to analysis the credit worthiness of an organization. \n\no Secure Trading: Responsible for implementing back office application for Secure trading which is an online \n\ngambling accounting system. I used spring framework, Oracle data base to develop the application. \n\n \n\nLEADERSHIP \n\n Won the Bravo Gold Medal for successfully implementing attrition model in Honeywell AERO which helped to make \n\nprecautions which avoided bulk turnover  \n\n Best developer (The Alchemist) award from Wipro Technologies","annotation":[{"label":["Skills"],"points":[{"start":5192,"end":5192,"text":"R"}]},{"label":["Skills"],"points":[{"start":5096,"end":5096,"text":"R"}]},{"label":["Skills"],"points":[{"start":4895,"end":4895,"text":"R"}]},{"label":["Skills"],"points":[{"start":4670,"end":4670,"text":"R"}]},{"label":["Skills"],"points":[{"start":3779,"end":3779,"text":"R"}]},{"label":["Skills"],"points":[{"start":3745,"end":3745,"text":"R"}]},{"label":["Location"],"points":[{"start":3693,"end":3701,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":3660,"end":3660,"text":"R"}]},{"label":["Skills"],"points":[{"start":3619,"end":3625,"text":" Python"}]},{"label":["Skills"],"points":[{"start":3373,"end":3388,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":3337,"end":3352,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":3317,"end":3317,"text":"R"}]},{"label":["Skills"],"points":[{"start":2833,"end":2833,"text":"R"}]},{"label":["Skills"],"points":[{"start":2815,"end":2815,"text":"R"}]},{"label":["Skills"],"points":[{"start":2563,"end":2563,"text":"R"}]},{"label":["Skills"],"points":[{"start":2470,"end":2470,"text":"R"}]},{"label":["Skills"],"points":[{"start":2411,"end":2411,"text":"R"}]},{"label":["Skills"],"points":[{"start":2364,"end":2364,"text":"R"}]},{"label":["Skills"],"points":[{"start":2173,"end":2173,"text":"R"}]},{"label":["Skills"],"points":[{"start":1650,"end":1650,"text":"R"}]},{"label":["Location"],"points":[{"start":1512,"end":1520,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":1435,"end":1435,"text":"R"}]},{"label":["Skills"],"points":[{"start":1428,"end":1428,"text":"R"}]},{"label":["Skills"],"points":[{"start":1275,"end":1275,"text":"R"}]},{"label":["Skills"],"points":[{"start":1150,"end":1152,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1097,"end":1097,"text":"R"}]},{"label":["Skills"],"points":[{"start":1058,"end":1060,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1052,"end":1055,"text":"Java"}]},{"label":["Skills"],"points":[{"start":1049,"end":1049,"text":"R"}]},{"label":["Skills"],"points":[{"start":1040,"end":1046,"text":" Python"}]},{"label":["Skills"],"points":[{"start":917,"end":917,"text":"R"}]},{"label":["Skills"],"points":[{"start":905,"end":905,"text":"R"}]},{"label":["Skills"],"points":[{"start":884,"end":884,"text":"R"}]},{"label":["Skills"],"points":[{"start":736,"end":736,"text":"R"}]},{"label":["Skills"],"points":[{"start":667,"end":667,"text":"R"}]},{"label":["Skills"],"points":[{"start":633,"end":648,"text":"Machine Learning"}]},{"label":["Education"],"points":[{"start":471,"end":474,"text":"MSc "}]},{"label":["Skills"],"points":[{"start":186,"end":186,"text":"R"}]},{"label":["Location"],"points":[{"start":156,"end":164,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":14,"end":14,"text":"R"}]},{"label":["Skills"],"points":[{"start":5,"end":5,"text":"R"}]},{"label":["Name"],"points":[{"start":0,"end":20,"text":"GOKULRAM BALAKRISHNAN"}]}],"extras":null,"metadata":{"first_done_at":1532670474000,"last_updated_at":1532670474000,"sec_taken":79,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "HEMALATHA SUBRAMANI \n\n6 B Anandham nagar 1st street,\nRamapuram,                                                           Mobile : 9791916468\nChennai -89                                                            Mail Id : svhm.sindhu@gmail.com     \n\nprofessional summary\n\n· 6.6 Years of experience in IT industry with emphasis in development of Data warehousing solutions using ETL tools (Data Stage & TREX) and 1 year of experience in developing Applications using .NET. \n· Skilled at operating in a wide range of platforms such as Python, node.js, Tableau, .NET, SQL Server, HTML and IBM Watson Bluemix Platform.\n· 1+ years of experience in developing cognitive chatbot using IBM Watson Conversation service, node.js, json and html.\n· Have developed many automations for the team’s internal process using python.\n· Worked with all phase of Software Development Life Cycle involving ETL/OLAP and database.\n· Worked in Data Stage Director, Manager and Administrator. \n· Extensively used ETL to load data from Oracle and Flat files to Data Warehouse\n· Have developed templates with the reusable codes in Datastage & TREX\n\n education & certification\n· Completed B.Tech Information Technology in Dr.Mahalingam College of Engineering and Technology, Coimbatore with an aggregate of  75.23% \n· Certified on Big Data – Beginner level course from Big Data Foundations, IBM analytical Services\n\n    Technical Skills                                                                                                                         \n\n\tSkill Group/ Skill\n\tLevel\n\tYears of Experience\n\tLast used\n\n\tETL Tools\n\n\tDatastage 7.5.2\n\tExpert\n\t4.5\n\t2015\n\n\tDatastage 8.1\n\tExpert\n\t2.5\n\t2017\n\n\tTREX\n\tExpert\n\t3\n\t2015\n\n\tReporting Tool\n\n\tTableau 9.x\n\tIntermediate\n\t0.5\n\t2017\n\n\tProgramming Languages\n\n\tC/C++\n\tIntermediate\n\t2\n\t2010\n\n\tC#/VB\n\tIntermediate\n\t1\n\t2010\n\n\tPython\n\tIntermediate\n\t1\n\t2017\n\n\tWeb Application Technology\n\n\tHTML\n\tExpert\n\t2\n\t2017\n\n\tDreamWeaver\n\tExpert\n\t1\n\t2010\n\n\tData Format\n\n\tJSON\n\tBasic\n\t0.5\n\t2017\n\n\tDatabase\n\n\tSQL Server\n\tExpert\n\t1\n\t2010\n\n\tOracle SQL Developer\n\tExpert\n\t3\n\t2017\n\n\n\n    \nCareer Scan\n\n· Worked as Software Developer (C#.NET, VB.NET) in I fact Technologies from May 2009 to April 2010.\n· Worked as Technical Analyst in Truven Health Analytics (Former Healthcare BU of Thomson Reuters) from May 2010 till February 2013.\n· Worked as Technical Analyst in Truven Health Analytics, an IBM company from June 2014 to August 2016.\n· Working as Datawarehouse Analyst in Truven Health Analytics, an IBM company from August 2016 to till date.\n\nProject – Chatbot (POC)\nRole:\t       \tDeveloper\nEnvironment:  Node.js & IBM Watson Conversation Service\n\nThe Chatbot is designed with HTML & Node.js as the front-end and Watson’s Conversation service as the back-end. The bot can interact with people in a human friendly way and answers all the related queries. Also, the bot is trained to recognizes the input in both text & audio formats and respond back. \n\n\nProject: 1\n\n· Customer\t\t     : Employer Clients – Template Development \n       Process.\n· Organization                 : Truven Health Analytics, Chennai.\n· Industry\t\t     : Health Care\n· Project Type\t\t     : Development.\n· Environment\t               : DataStage 8.1, TREX & Advantage Suite.\n\nProject Description:\n\nThis project helps in developing the template with the reusability code to do ETL of eligibility/claims data using Datastage & TREX.\n\nPrimary Responsibilities included: \n\n· Have developed the templates with the reusability codes based on supplier requirements associated with the project.\n· Have written different logics in the Transformation stage(both in Datstage & TREX).\n· Have created a test transformer for a customer with the associated supplier’s template to test the performance.\n· Have performed unit testing of data after the successful execution of the job.\n· Have transferred the existing template jobs in Datastage to TREX.\n\nProject: 2\n\n· Customer\t\t     : US State Govt.\n· Organization                 : Truven Health Analytics, an IBM Company.\n· Industry\t\t     : Health Care\n· Project Type\t\t     : Development.\n· Environment\t               : UNIX, DataStage 8.1.\n\nProject Description:\n\nTo Design and build a decision support and Data warehouse for the state govt Department of Human Services (DHS). This project helps in full range of DHS supporting and decision making needs that improve business results. Our solution combines an Enterprise Relational Data warehouse with the Medstat Advantage suite Decision support System\n\nPrimary Responsibilities included: \n\n· Developed Data stage jobs based on the business requirements.\n· Developed Unix scripts to run the DS jobs.\n· Performed Data validation using Oracle SQL.\n· Performed validation for different business scenarios by mocking up data and testing the functionality of the process.\n\nProject: 3 \n\n· Customer\t\t                   : Employer Clients – Payer Operations.\n· Organization\t\t\t         : Thomson Reuters, Chennai.\n· Industry\t\t                   : Health Care\n· Project Type\t\t                   : Development.\n· Environment\t\t\t         : UNIX, Data Stage 7.5.2,TREX, Advantage                    \n\t\t\t\t   Suite.\nProject Description:\n\nThis project includes extracting various eligibility and claims data from files being supplied from various data suppliers specific to the customers and transformation of the data and load data to the Target DWH.\n \nPrimary Responsibilities included: \n\n· Created jobs as per the requirements associated with the project.\n· Created sequence jobs.\n· Have developed Server Routines.\n· Have written different logics in the Transformation stage.\n· Have performed unit testing of data after the successful execution of the job.\n\n\nProject: 4\n\n· Customer\t\t     : Employer Clients – Migration Process\n· Organization                 : Truven Health Analytics, Chennai.\n· Industry\t\t     : Health Care\n· Project Type\t\t     : Development.\n· Environment\t               : DataStage 7.5.2, TREX & Advantage Suite.\n\n\nProject Description:\n\nThis project helps in transferring the existing ETL jobs with eligibility & claims data from Datastage environment to TREX environment.\n\nPrimary Responsibilities included: \n· Have Migrated the Datastage jobs to TREX environment as per the requirements associated with the project.\n· Have Performed analysis on the existing Datastage job.\n· Have developed the ETL transformation coding in TREX to mimic the logics of Datastage jobs.\n· Have performed unit testing of the data after the successful execution of the job.\n\n\n\nSignificant Accomplishments\n\n· Won Above and Beyond silver award from Truven Health Analytics for outstanding \n· test coverage of Early Retirement Reimbursement Project (initiated by U.S government)\n· Appreciated by Clients for diligent contribution to the projects\n· Won Above and Beyond bronze award from Truven Health for developing and testing job for Client Lucent Technology.\n· Won Above and Beyond bronze award from Truven Health for developing and testing job for client Aetna.\n· Won Employee of the Month award for the outstanding performance and for demonstrating exceptional dedication to the Thomson Reuters core values.\n· Received Best performer award from I fact Technologies for developing the billing application.\n· Won Excellence award for developing an Access database for Truven Health analytics to maintain the metrics.\n\n\nSoft Skills:\n· Certified in Health Insurance Portability and Accountability Act Known as HIPPA\n· Acquired Watson Conversation Badge and Big data foundation badge from IBM Watson training program.\n· Completed online courses of Corporate Writing E-learning, Communication Business Etiquette-mail and Instant Messaging Effectively\n· Attended in house courses for Code of Business Conduct and Ethics, Thomson Reuters - Diversity in Practice, Cultural awareness training, Advanced Communication skill, Advanced Excel 2007.\n\n\n\tPersonal description\n\n\n            Date of Birth\t \t: 14 oct 1987\n           Father’s Name\t: P Subramani\n           Language Known\t: English, Tamil\n           Hobbies                   : Gardening\n           Marital Status          : Married\n                                                                                                                                         \n    Declaration                                                                                                                            \n               I do hereby declare that all the above information furnished is true to the best of my Knowledge and belief.                                                                                                                     \n\nPlace: Chennai                     \t\t   \t                                                                               Date:                                                                        [Signature]","annotation":[{"label":["Location"],"points":[{"start":8651,"end":8657,"text":"Chennai"}]},{"label":["Location"],"points":[{"start":5828,"end":5834,"text":"Chennai"}]},{"label":["Location"],"points":[{"start":4953,"end":4959,"text":"Chennai"}]},{"label":["Location"],"points":[{"start":3100,"end":3106,"text":"Chennai"}]},{"label":["Skills"],"points":[{"start":2678,"end":2681,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":2038,"end":2057,"text":"Oracle SQL Developer"}]},{"label":["Skills"],"points":[{"start":2008,"end":2017,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":1972,"end":1975,"text":"JSON"}]},{"label":["Skills"],"points":[{"start":1927,"end":1937,"text":"DreamWeaver"}]},{"label":["Skills"],"points":[{"start":1903,"end":1906,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":1842,"end":1847,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1811,"end":1815,"text":"C#/VB"}]},{"label":["Skills"],"points":[{"start":1780,"end":1784,"text":"C/C++"}]},{"label":["Education"],"points":[{"start":1161,"end":1166,"text":"B.Tech"}]},{"label":["Skills"],"points":[{"start":578,"end":581,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":566,"end":575,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":534,"end":539,"text":"Python"}]},{"label":["Location"],"points":[{"start":142,"end":148,"text":"Chennai"}]},{"label":["Name"],"points":[{"start":0,"end":19,"text":"HEMALATHA SUBRAMANI "}]}],"extras":null,"metadata":{"first_done_at":1532693534000,"last_updated_at":1532693534000,"sec_taken":0,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Himanshu Panwar   GitHub Profile \nContact: 09971535829 ~ E-Mail: himanshu.panwar08@gmail.com \n\nCareer Objective \n\nSeeking to use strong quantitative skills in the field of Data Science, Analytics and Deep Learning, Image Processing \n\n \n\nProfile Summary \n\n 1+ years of experience in Machine Learning, Statistical Modeling, Image Processing, Deep Learning. \n\n 6+ years of experience in implementing Product Lifecycle Management (PLM) in various industries such as Chemical, \nSemiconductor. Have wealth of expertise entails Charting, Reporting, Dashboards, Requirement Gathering, Business \nRequirements Mapping, Application Design, Technical Documentation, Development and Troubleshooting. \n\n \n\nOrganizational Experience \n\nAug’16 to Present with Cognizant, Bangalore as Sr. Associate \n\nApr’13 to Aug’16 with InsightPLM Consulting Pvt. Ltd., Gurgaon as Sr. PLM Consultant \n\nDec’12 to Jan’13 with Oracle India Pvt. Ltd., Bangalore as Staff Analyst \n\nApr’10 to Dec’12 with Mahindra Satyam Computer Services Limited, Hyderabad as Software Developer \n\n \n\nHighlights: \n\n Top 15% in Dogs vs. Cats Redux on Kaggle. Top 15% in Digit Recognizer on Kaggle. \n\n Pursuing Deep Learning course from fast.ai \n\n \n\nAcademic Details \n\n B.Tech. (Electronics & Communication Engineering) from SRM University, Ghaziabad in 2009 \n\nSkills \n\nPython, R, Machine Learning, Statistical Modeling, Linear, Logistic Regression, Decision Trees, Ensemble Models, Clustering, \nNeural Networks, Deep Learning, CNN, Keras, Tensorflow, Basics of NLP SQL, Java, Oracle Agile PLM \n\n \n\nCase Studies in Predictive Modeling \n\n Project Title: Big Mart Sales Prediction (Online competition on Analytics Vidya. Ranked 93) \n\nDescription: Notebook \n\n Objective is to build a predictive model to find out the sales of each product at a particular store \n\n Analyzed the pattern in the missing product weights, Product identifiers, store size based on total sales of the \nstore \n\n Used Random Forest and GBM for modeling with grid search and cross validation \n\n \n\n Project Title: Analysis of Top 500 Indian Cities (Kaggle dataset) \n\nDescription: Notebook \n\n Objective is to explore the data related to Top 500 Indian cities based on 2011 Census \n\n Analyzed state wise literacy rate, sex ratio, male female population, number of cities per state  \n\n Applied  \n\n \n\n Project Title: Black Friday Sales (Online competition on Analytics Vidya. Ranked under 100) \n\nDescription: \n\n Objective is to understand the customer purchase behavior against various categories \n\n Analyzed the buying pattern of customers to group together high revenue customers \n\n Created new features based on the existing features to boost the accuracy of the models \n\n Applied Random Forest and GBM for modeling and prediction \n\n \n\n Project Title: Loan Prediction problem (Online competition. Ranked 170) \n\nDescription: \n\n Objective is to predict the loan eligibility of a customer based on customer details \n\n Analyzed the data to find that customers with credit history are more likely to get loan \n\n Used Logistic Regression and Random Forest for modeling and prediction \n\nhttps://github.com/sonicboom8/MachineLearning\nmailto:himanshu.panwar08@gmail.com\nhttps://github.com/sonicboom8/MachineLearning/tree/master/AnalyticsVidya/BigMartSales\nhttps://github.com/sonicboom8/MachineLearning/tree/master/Kaggle/Top500IndianCities\n\n\n \n \n\n \n\n \n\n Project Title : Predicting who would buy caravan insurance policy \n\nDescription:  \n\n Objective is to build a classification model to target potential customer for the campaign. \n\n It is an example of imbalanced class classification with majority class being 95% and minority as 5% \n\n Applied various sampling techniques like oversampling, undersampling, SMOTE to balance out the majority and \nminority classes \n\n Modeled logistic regression and SVM with class weights \n\n \n\nAgile PLM Experience \n\nCognizant \nTitle:   Agile PLM Implementation (Sept-16 to Till Now) \nRole:   Implementation Lead \nDescription: Client is using Agile PLM for managing and automating its semiconductor business at various \n\nstages of the processes. It involved developing and designing the PX using Java. Development of \nDashboards using web technologies \n\n \nInsightPLM Consulting Pvt. Ltd., Gurgaon \nProject Title: Agile PLM Implementation (Aug-15 to Aug-16) \nRole:  Implementation Lead + PLM Consultant + Solution Designer \nDescription: SRF Limited has selected Agile PLM as a tool to streamline and re-engineer there Chemicals Technology \n\nGroup business processes. The objective is to strengthen the interface among different business groups to \nimprove the quality of work and reduce the time to market. Various stages of chemical production process, \nraw material procurement are controlled through PLM. \n\n \nProject Title: Agile Upgrade (Apr-15 to July-15) \nRole:  Solution Designer + Implementation Lead \nDescription: The project involves upgrading Agile 9.2.2.7 to Agile 9.3.3 along with integration of ECAD and MCAD \n\nconnectors.  \n \nProject Title: TESSPLM (March-14 to Aug-16) \nRole:  Technical Lead for implementation \nDescription: The project involved work process for Drawing Management and Document Control in NPCIL, covering all \n\nstages in drawing and document preparation/review/approval, storage and distribution. The system acts as \na single data repository which can be accessible to all NPCIL users based on Technical Authorization. \n\n \nProject Title: UEnS (Apr-13 to Feb-14) \nRole:  Team Member \nDescription: The project involved creating reports and charts. It also involved creating custom Dashboard, creating \n\nSubclasses, configuring attributes, creating Workflow, Criteria, Privileges, Roles, User Group.  \n \nMahindra Satyam Computer Services Limited, Hyderabad \nProject Title: Pre Market Regulatory Phase 1 and 2(March-11 to Dec-12) \nRole:  Offshore Lead \nDescription: The project involved creating Templates in PPM module through code by reading the data from excel \n\nsheets. Creating subclasses, configuring attributes. Creating workflow, criteria, privileges, roles, user Group. \nConfiguring Notifications and Dashboards \n\n \nProject Title: Transfer Program (Aug-10 to Feb-11) \nRole:  Team Member \nDescription: Project involved writing Process Extension for creating child project for Program according to the parts \n\ncontained in the Relationship Tab of the Program. The attribute value in the parts decides the type of child \nproject to be created from the pre-defined template.  \n\n \n\nPersonal Details \n\n \n\nLocation: Bangalore       Date:  21-March-17","annotation":[{"label":["Location"],"points":[{"start":6509,"end":6518,"text":"Bangalore "}]},{"label":["Skills"],"points":[{"start":6325,"end":6325,"text":"R"}]},{"label":["Skills"],"points":[{"start":6168,"end":6168,"text":"R"}]},{"label":["Skills"],"points":[{"start":5822,"end":5822,"text":"R"}]},{"label":["Skills"],"points":[{"start":5776,"end":5776,"text":"R"}]},{"label":["Skills"],"points":[{"start":5673,"end":5673,"text":"R"}]},{"label":["Skills"],"points":[{"start":5458,"end":5458,"text":"R"}]},{"label":["Skills"],"points":[{"start":5048,"end":5048,"text":"R"}]},{"label":["Skills"],"points":[{"start":4824,"end":4824,"text":"R"}]},{"label":["Skills"],"points":[{"start":4400,"end":4400,"text":"R"}]},{"label":["Skills"],"points":[{"start":4321,"end":4321,"text":"R"}]},{"label":["Skills"],"points":[{"start":4159,"end":4162,"text":"Java"}]},{"label":["Skills"],"points":[{"start":3948,"end":3948,"text":"R"}]},{"label":["Skills"],"points":[{"start":3070,"end":3070,"text":"R"}]},{"label":["Skills"],"points":[{"start":3055,"end":3055,"text":"R"}]},{"label":["Skills"],"points":[{"start":2828,"end":2828,"text":"R"}]},{"label":["Skills"],"points":[{"start":2711,"end":2711,"text":"R"}]},{"label":["Skills"],"points":[{"start":2399,"end":2399,"text":"R"}]},{"label":["Skills"],"points":[{"start":1942,"end":1942,"text":"R"}]},{"label":["Skills"],"points":[{"start":1669,"end":1669,"text":"R"}]},{"label":["Skills"],"points":[{"start":1520,"end":1523,"text":"Java"}]},{"label":["Skills"],"points":[{"start":1387,"end":1387,"text":"R"}]},{"label":["Skills"],"points":[{"start":1330,"end":1345,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1327,"end":1327,"text":"R"}]},{"label":["Skills"],"points":[{"start":1319,"end":1324,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1275,"end":1275,"text":"R"}]},{"label":["Education"],"points":[{"start":1219,"end":1225,"text":"B.Tech."}]},{"label":["Skills"],"points":[{"start":1124,"end":1124,"text":"R"}]},{"label":["Skills"],"points":[{"start":1090,"end":1090,"text":"R"}]},{"label":["Location"],"points":[{"start":918,"end":927,"text":"Bangalore "}]},{"label":["Location"],"points":[{"start":756,"end":765,"text":"Bangalore "}]},{"label":["Skills"],"points":[{"start":589,"end":589,"text":"R"}]},{"label":["Skills"],"points":[{"start":556,"end":556,"text":"R"}]},{"label":["Skills"],"points":[{"start":533,"end":533,"text":"R"}]},{"label":["Skills"],"points":[{"start":283,"end":298,"text":"Machine Learning"}]},{"label":["Name"],"points":[{"start":0,"end":14,"text":"Himanshu Panwar"}]}],"extras":null,"metadata":{"first_done_at":1532681099000,"last_updated_at":1532681099000,"sec_taken":153,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Jaideep Singh Negi \nNew Delhi - 110023    Phone: +91 8126-9116-12    jaideepnegi7@gmail.com \n\nhttps://www.linkedin.com/in/jaideep-s-negi-16a08b46/ \n \n\n \n\nData Scientist \n \n\nPython| R | SQL | Oracle | Machine learning| Deep learning| Predictive modelling | Tableau | Business \nIntelligence | SPSS | ERP | SAP Basis | Advanced Excel | Presentation skills \n\n \n \n\nTechnical Skills \n \nProgramming Language: Python, R & SPSS \nProblems:                                       Supervised, Unsupervised, Clustering, Dimensionality reduction,           \n                                                          Structured prediction, Anomaly detection, neural networks \nProject Management:   ITIL certification \nData Analysis:    Tableau \nDatabase:    MySQL \n \n \n\n \nProfessional Experiences \n\n \nEricsson India Global Services LTD, Noida, India (1.5 years) \nJuly 2016 - Present \nEngineer, Data Scientist \n \nEricsson is a multinational networking and telecommunications company HQ in Stockholm, Sweden. \nThe company offers services, software and infrastructure in information and communications \ntechnology for telecommunications operators, traditional telecommunications and Internet Protocol \n(IP) networking equipment, mobile and fixed broadband, operations and business support services, \ncable television, IPTV, video systems, and an extensive services operation. \n \nResponsibilities: \n \n\n• Solve problems like recommendation, ads, search and fraud detection.  \n• Vodafone Netherland project – In this project we are working on to create a fraud detection \n\nsystem that can block the suspected anomalies or attacks on the data center. \n• Project Transport management: Understanding the factors impacting or explaining the yearly \n\ncosts of transports. In this we have created a model to find out the factors that are impacting \nthe cost of transport. We have used lasso regression in this project. \n\n• Project on Bill Payment: Understanding the billing and payment strategy of customers using \nhistorical data to improve the cash collection. \n\nmailto:jaideepnegi7@gmail.com\nhttps://www.linkedin.com/in/jaideep-s-negi-16a08b46/\n\n\n• Expert in fitting ARIMA models to time series data using R \n• Data Quality Improvement: Using similarity indexes to improve the city/country names in the \n\nentered data \n• Sentiment Analysis with R  \n• Analyze large datasets of incidents, trouble tickets, and work orders to provide strategic \n\ndirection to the company  \n• We did automation for “Orange’s” ordering team using Python Libraries like Numpy & Pandas. \n• Trained 42 Individuals on Python for automation in excel, Text analysis, PDF’s,etc. \n• Cleaning the unstructured data. \n• Apply deep learning algorithm to improve understanding of user behavior and content. \n• Using Decision Tree algorithm to predict whether to give loan to a person or not \n• Worked on a credit risk model using Logistic regression and decision tree algorithms \n• Web scrapping using beautiful soup and urllib libraries in Python \n• Develop predictive models to assess the probability of successful launch and expected delays \n• ROI modelling, A/B testing  \n• Sourcing: Using time-series and related concepts to predict monthly financial outflow  \n• data collection to data processing, exploration, visualization and modeling. \n• Apply the power of data science to solve real life business problems aligned to key cross-\n\nfunctional organisational objectives through predictive, prescriptive, and cognitive analytics.  \n• Good knowledge of pre-pruning and post pruning in Decision Tree.   \n• Usage of Python, R and different type of Machine Learning algorithms. \n• Good in Supervised and unsupervised learning with scikit learn \n• Hands on on KNN algorithm \n• Good knowledge of Linear and multilinear regression \n• Good knowledge of PCA in R & Python \n• Good knowledge on Lasso and ridge regression \n• Good knowledge of Bagging and Boosting. \n• Good in preprocessing and pipelines in R and python. \n• Experience in Centring and scaling the data \n• Usage of Web development and Tableau to produce front end dashboards. \n\nGood knowledge of SQL \n \n\n \nInfodart Technology India LTD, Gurgaon, India (4 \nyears 6 months) \nJanuary 2012 - June 2016 \n \nEngineer, Data Analyst, 2 years \n\n \nPROJECT VIDEOCON INDUSTRIES LTD \n\n• Acquire data from primary or secondary data sources and maintain databases/data systems.  \n• Ability to use all insights to gather and build a comprehensive summary report.  \n• Ability to collect, organize, analyze, and disseminate significant amounts of information with \n\nattention to detail and accuracy. \n• Collect data from different sources using Internet Application.  \n• Cleaning unstructured data to structured data.  \n•  A/B Testing to predict  if the changes made in any website had increased the number of hits or is \n\nit just by chance, using null hypothesis.  \n\n\n\n• To solve problems related to data Interpreting data, analyzing results using analytics techniques \nand providing ongoing reports Identify, analyze, and interpret trends or patterns in complex data \nsets.  \n\n• Perform data driven analysis to recommend strategies to improve customer engagement, \nmarketing campaigns, and merchandising initiatives. \n\n• Logistic Performance Analysis. \n• Clustering using “R” & Python. \n• Classification Techniques using “R” & Python \n• Forecasting on Delivery Performance. \n• Forecasting on order load for different vendors based on promotion and marketing activities. \n• Intermediate knowledge of SQL and its queries.  \n\n \nEngineer, SAP Basis consultant, 2 Year 6 months \n \n\n• Daily system monitoring which includes:- Checking all Servers and application servers status, Work \nprocess overview, background jobs overview , spool logs, Performance monitoring, Checking \nspace statistics and Backup logs. \n\n \n \n \n\nCertifications and Trainings \n \n\n• DSBA course under Prof.Venkat and Prof. Maitrayee Mukherji. \n• Data camp certified in Introduction to R \n• Data camp certified in Intermediate R \n• Data camp certified in Importing Data in R \n• Data camp certified in Cleaning Data in R \n• Data camp certified in Data Manipulation in R with dplyr \n• Data camp certified in Data visualization in R with ggvis \n• “Data Science using Python” course under Prof.Venkat and Prof. Maitrayee Mukherji. \n• Data camp certified in Introduction to Python for Data Science \n• Data camp certified in Intermediate Python for Data Science \n• Data camp certified in Pandas foundations \n• Data camp certified in Merging Dataframes with Pandas \n• Data camp certified in Statistical Thinking in Python \n• Data camp certified in Supervised Learning with Scikit-Learn \n• Data camp certified in Python Data Science ToolBox \n\n \n \n \n\nEducation \n \nPGDM \nIT and Analytics \nIndian Institute of Management,  Kashipur \n \nBachelor of Technology \nIT \nSri Sukhmani Institute of Engineering and technology, Mohali (PTU) \n \n\n\n\n \n \n  \n \n\nLanguages and Interests \n \n\n• Fluent in English and Hindi. \n• Keeping updated with current affairs. \n• Running, Riding, Reading & Singing. \n\n \n \n \nDeclaration: \n \nI hereby declare that the above furnished details are true to my knowledge. \n \n                                                                                                                                                    \nPlace:  New Delhi         \nDate: 08th December 2017     Jaideep S Negi   \n\n \n \n\n****************************************","annotation":[{"label":["Skills"],"points":[{"start":7006,"end":7006,"text":"R"}]},{"label":["Skills"],"points":[{"start":6998,"end":6998,"text":"R"}]},{"label":["Skills"],"points":[{"start":6989,"end":6989,"text":"R"}]},{"label":["Education"],"points":[{"start":6706,"end":6710,"text":"PGDM "}]},{"label":["Skills"],"points":[{"start":6656,"end":6661,"text":"Python"}]},{"label":["Skills"],"points":[{"start":6559,"end":6564,"text":"Python"}]},{"label":["Skills"],"points":[{"start":6383,"end":6388,"text":"Python"}]},{"label":["Skills"],"points":[{"start":6320,"end":6325,"text":"Python"}]},{"label":["Skills"],"points":[{"start":6215,"end":6220,"text":"Python"}]},{"label":["Skills"],"points":[{"start":6179,"end":6179,"text":"R"}]},{"label":["Skills"],"points":[{"start":6118,"end":6118,"text":"R"}]},{"label":["Skills"],"points":[{"start":6069,"end":6069,"text":"R"}]},{"label":["Skills"],"points":[{"start":6024,"end":6024,"text":"R"}]},{"label":["Skills"],"points":[{"start":5978,"end":5978,"text":"R"}]},{"label":["Skills"],"points":[{"start":5937,"end":5937,"text":"R"}]},{"label":["Skills"],"points":[{"start":5314,"end":5319,"text":"Python"}]},{"label":["Skills"],"points":[{"start":5309,"end":5309,"text":"R"}]},{"label":["Skills"],"points":[{"start":5265,"end":5270,"text":"Python"}]},{"label":["Skills"],"points":[{"start":5260,"end":5260,"text":"R"}]},{"label":["Skills"],"points":[{"start":4264,"end":4264,"text":"R"}]},{"label":["Skills"],"points":[{"start":4242,"end":4242,"text":"R"}]},{"label":["Skills"],"points":[{"start":3946,"end":3946,"text":"R"}]},{"label":["Skills"],"points":[{"start":3806,"end":3811,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3802,"end":3802,"text":"R"}]},{"label":["Skills"],"points":[{"start":3571,"end":3571,"text":"R"}]},{"label":["Skills"],"points":[{"start":3563,"end":3568,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3091,"end":3091,"text":"R"}]},{"label":["Skills"],"points":[{"start":2985,"end":2990,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2570,"end":2575,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2503,"end":2508,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2322,"end":2322,"text":"R"}]},{"label":["Skills"],"points":[{"start":2183,"end":2183,"text":"R"}]},{"label":["Skills"],"points":[{"start":2145,"end":2145,"text":"R"}]},{"label":["Skills"],"points":[{"start":1362,"end":1362,"text":"R"}]},{"label":["Location"],"points":[{"start":823,"end":827,"text":"Noida"}]},{"label":["Skills"],"points":[{"start":416,"end":419,"text":"SPSS"}]},{"label":["Skills"],"points":[{"start":412,"end":412,"text":"R"}]},{"label":["Skills"],"points":[{"start":404,"end":409,"text":"Python"}]},{"label":["Skills"],"points":[{"start":301,"end":301,"text":"R"}]},{"label":["Skills"],"points":[{"start":293,"end":296,"text":"SPSS"}]},{"label":["Skills"],"points":[{"start":183,"end":183,"text":"R"}]},{"label":["Skills"],"points":[{"start":175,"end":180,"text":"Python"}]},{"label":["Name"],"points":[{"start":0,"end":17,"text":"Jaideep Singh Negi"}]}],"extras":null,"metadata":{"first_done_at":1532676090000,"last_updated_at":1532676090000,"sec_taken":112,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "JIGAR PARIKH, PMP  \nSenior Group Manager  \nDomain Preference: RPA, Finance \n \nAspiring for Senior level assignment in Software/Application Development in IT Sector. To take the \nchallenging role of leading end-to end implementation and delivery of IT solutions to create positive \nimpact on business goals of an organization by uplifting productivity, deriving FTE benefits, increasing \nefficiency and reducing cost on errors.  \n \n\nEXPERIENCE & KEY COMPETENCIES \n \n\n Offering 12+ years of Experience in Product Engineering, Project management and Application Development out \n\nof which 3+ Years of exposure into RPA Implementations. \n\n Currently working as a Senior Group Manager in WNS.  \n\n Working as a RPA Expert and Solution Architect in WNS to automate the business operations of it’s various \n\nclients across various verticals. Working as a Subject Matter Expert for all RPA opportunities. \n\n Managing RPA program for WNS. Leading Multiple Client Implementations and Process Assessments. \n\n Led 25+ RPA Implementations for verticals like Finance, ecommerce, Telecom & Cable, Travel, Hotel Domain etc. \n\nusing various RPA platforms.  \n\n Have experience on RPA tools like Blue Prism, Automation Anywhere, Roboworx (In-house Product) etc.  \n\n Defining and controlling the Scope of the Project. Involved in Project Scoping, Proposal & RFP creations, \n\nCosting, Sizing, Estimations, Project Planning, recruiting, reporting, resource management etc. \n\n Business strategist; plan and manage multimillion-dollar projects aligning business goals with technology \n\nsolutions to drive process improvements, competitive advantage and bottom-line gains. \n\n Strong Conceptualization and analytical skills along with significant functional experience in IT industry. \n\n Exposure in designing world-class applications and implementing processes that will enable organization to \n\nconsistently meet and enhance customer satisfaction. Able to manage stakeholder expectations and willing to take \n\nfull responsibility for the delivering of project objectives. \n\n Deft in defining and reviewing conceptual model, Logical data model and physical data model as well as in assisting \n\nProgram manager in defining Program Roadmap. \n\n Managing a team of over 30 administrative & technical staff.  \n\n Cross-functional communicator easily interfaces with high-profile staff and clients. Versatile, innovative, and \n\nloyal management professional able to see the “big picture” while staying on top of all the details.  \n\n Able to function in multi-dimensional role involving business consulting with Client, architecting business \n\nsolutions and get them implemented. \n\n Ability to manage multiple projects simultaneously and under pressure. Demonstrated ability to work with and \n\nsupport cross-functional project teams. A multi-skilled professional with a superb track record of managing complex \nfunctional projects in various environments. Good conflict management and prioritization skills. \n\n Expert in agile and waterfall project management methodologies. Able to manage large project teams and \n\nknown for high-quality deliverables that meet timeline and budgetary targets. \n\n Can understand and document project requirements and dependencies. Excellent documentation & report \n\nwriting skills.  \n\nExpert in planning, organizing, and \n\nmanaging resources to successfully complete \n\nproject goals and objectives, while honoring \n\npredetermined constraints. \n\n\n\nAREAS OF EXPERTISE \n \nProject Management IT Project Lifecycle Value-Added Leadership \n\nCustom Software Development Requirements Scoping & Analysis Client Relations & Presentations  \nDatabase Design (RDBMS) Costing, Budgeting & Scheduling Team Building & Mentoring \n\nSystems Engineering Testing/QA/Rollout/Support Cross-Functional Supervision \nSystem Migrations/Integrations Risk & Issue Management Business & IT Planning \n\nEnterprise wide Implementations Risk Management Strategic Planning \n \n\n \n\n PROFESSIONAL EXPERIENCE  \n \n\nPlan, execute, and finalize projects within triple constraints of delivering on time, within budget and scope objectives, \n\nincluding acquiring resources and coordinating efforts of team members in order to deliver projects according to plan. Led \n\ninternal personnel teams (30+ people) to deliver releases on time/budget using structured project management techniques. \nEffectively communicate project status to project stakeholders. Coach, mentor, and motivate team members, influencing them \n\nto take positive action and accountability for assigned work.  \n\n \nRoles & Responsibilities \n\n \n Carried out elicit and analyses for the requirements from the domain experts and clients. Facilitated the requirement \n\ngathering and analysis. Mapping requirements and providing them best solutions involving evaluation and definition of \nscope of project and finalization of project requirements. \n\n Performed extensive technical reviews for prospective projects, gathering details utilized for pricing project services, \n\nand providing supportive documentation for RFP replies to sponsors. \n\n Defining and controlling the Scope of the Project. Involved in Project Scoping, Proposal & RFP creations, \nSizing, Estimations, Costing Project Planning, recruiting, reporting, resource management etc. \n\n Handled the preparation of Project Plan & ensure the probability of the Project. Producing stage plans, highlight \nreports, risk logs, requests for change etc. \n\nOversaw the: \no Proposals, Costing, Sizing and Estimations \n\no Issue and risk Management \n\no Change Management Control and all other managerial Activities \n Analyzing, understanding and documenting the business processes in detail where required. \n\n Designing Robotic process solutions in accordance with standard design principals and conventions. \n Review and monitor entire Implementation and make sure Team members design Processes and Objects using core \n\nworkflow principals that are efficient, well structured, Scalable, reusable, maintainable and easy to understand. \n Mentoring Team Members through Blue Prism training - Providing advice and Guidance on best practices and \n\nDevelopment techniques. \n\n Identifying and communicating the technical infrastructure requirements. \n Demonstrated outstanding Leadership and superb Project Management skills, consistently scoring 90% or \n\ngreater on Customer Satisfaction surveys distributed to study delivery managers during project initiation, monitoring, \nand closeout phases.  \n\n Pioneered innovative team building and cross-functional project management techniques to expedite \n\nworkflow, simplify processes, and reduce operating costs.  \n Monitoring project risks and scope creep to identify potential problems and proactively identifying solutions to \n\naddress them in advance.  \n Providing strategic direction during the implementation stages. Supervised the day to day activities. \n\n Managing client expectations by ensuring the delivery of the highest quality service. Executes Client Pilot projects. \n\n \n\n\n\nWNS                                                                                              Nov 2016 – Present  \n \nSenior Group Manager                                                                                       Nov 2016 - Present \n\nRPA Implementations  \n \nAutomated processes within trade confirmations space (cash products) using Blue Prism platform:  \n\n \nRPA Platform       Blue Prism & Automation Anywhere \n\nDomain                 Travel, Insurance, Finance \nTeam Size            30+ \n\nRole                     Senior Project Manager & Solution Architect  \n\n \nProjects \n\n \n Refund Request Validation & Execution (BP) – This process includes fetching flight details, Passenger Details, \n\nPayment Details etc. by going to the various Client applications and validate the refund request as per the defined \n\nrules. If refund request is valid, payment needs to be released else request needed to be closed with relevant \ncomments. \n\n Planning Process (BP) - This Process includes creating flight Load plan 18 hours to departure for optimum space \nutilization based on available capacity and shipment booked, ensuring OBPL, restrictions, compatibility are met. \n\nProcess also includes providing special handling instructions as required. \n\n Hotel Details to be fetched from various web sites (AA) – This Process includes fetching of data from various Travel \nWeb Sites and finally suggest Best possible option as per the rule book.  \n\n \neClerx Services LTD                                                   January 2006 – October 2016 \n \n\nSenior Project Manager                                                                         April 2015 – October 2016 \n \n\nRPA Implementations (Blue Prism) \n \n\nAutomated processes within trade confirmations space (cash products) using Blue Prism platform:  \n \n\nRPA Platform       Blue Prism \n\nDomain                 Finance \nTeam Size            20+ \n\nRole                     Senior Project Manager & Solution Architect  \n \n\nProjects \n\n \n Manual Non-Swapping Initiative – unilateral confirmation of low risk OTC cash flows  \n\n Bilateral confirmation of OTC & FX trades – confirming economic & entity parameters over email for releasing or \nreceiving payments  \n\n Netting & settlement of Intercompany cash flows (OTC) – processing cash flows executed between two entities of the \nsame parent  \n\n Creating shape for settlement – manual netting of FX, options & money market trades \n\n \n \n\n \n\n\n\nLed RPA Product Development and Implementations \n \nWas Managing RPA Product Development Roadmap along with automation implementations using this In-\n\nhouse developed RPA Product. \n\n \nRPA Platform        Roboworx (In-House Developed RPA Platform) \n\nTechnology           .Net 4.5 & SQL Server 2012 \nDomain                  Finance, ecommerce, Telecom & Cable \n\nTeam Size             15+ in Product Development 10+ in Implementations \n\nRole                      Senior Project Manager and Solution Architect \n\n \nImplantation Projects \n\n Signal Strength Extraction – Process includes extraction of signal strength and device data from client system as per \nthe defined rules mark the requests for auto scrub. Able to achieve reduction in AHT for the tickets which are not \n\neligible for Auto Scrub by fetching the data points from various screens and helping agent in taking the decision \n\nquickly. \n\n Claim validation and claim initiation Process – Process includes validating the Claims by fetches data from various \nsources and sends automated chasers to counterparties for outstanding claims. Post Customer agreement, Payment \nneeds to be released on Payment system.  \n\n Capturing of outage data and Cancelling the Truck rolls – Bot to read the outage data from the client’s application \nand also read the unstructured data from e-mails, check the status of the device outages and cancel the truck rolls \nwhich resulted in direct cost savings for the client.  \n\n Content Review Automation – Process includes review of Client web site. Need to review the content of agreed \nsections \\ links as per the defined guideline\\rules. Review needs to be performed for 168 different Language pages. \nFinally, consolidated report needs to be generated for all URLs. Erroneous URLs \\ Section needs to be highlighted \nwith exact error description.  \n\nProject Manager                                                                                        April 2012 - March 2015 \nAssociate Project Manager                                                                       April 2009 - March 2012 \n \n\nLed Product Development and Custom Application Development Teams \n \n\nTechnology           .Net 2.0 & 4.0 & SQL Server 2008, Excel – Access, Tableau \nTeam Size             20+ \nProducts Development Projects \n\n RoboWorx (RPA Platform) \n ERMS (Request and Email Management Workflow) \n\n Accurec (Matching, Reconciliation and Resolution Platform) \n\nCustom Application Development Projects \n Data Capture Applications, Workflow Tools, Dashboards, Reconciliations Tools, Risk & Control Dashboards etc.  \n\n Custom Application Developments for Back Office Processing etc. \n Tableau Dashboards \n\n \nSenior Developer \\ Developer                                                                Jan 2006 – March 2009 \nDeveloped multiple custom applications for Various Financial Bank Clients using .Net and SQL Platforms. \n\n \nTimes Infoway                                                             June 2004 – December 2005 \nJunior Software Developer                                                               June 2004 – December 2005 \nDeveloped multiple custom applications for various clients using .Net and SQL Platforms. \n\n\n\n \nEDUCATION & PROFESSIONAL TRAINING \n\n       Master of Computer Application (MCA) - Veer Narmad South Gujarat University, Surat – 2006 – 67.43% \n\nBachelor of Computer Application (BCA) - Veer Narmad South Gujarat University, Surat – 2003 – 75.53% \n12th (HSC) - Gujarat Higher Secondary Education Board – 2000 – 79.50% \n\n10th (SSC) - Gujarat Secondary Education Board – 1998 – 79.29% \n\n \n■■■■■■■ \n\nHIGHLIGHTS OF PROFESSIONAL DEVELOPMENT \nProject Management Professional (PMP) Certified - Certificate Course – 2012 \n\nBlue Prism Certified - 2016 \n\n \n■■■■■■■ \n\nCOMPUTER SKILLS  \nLanguages:  Asp .Net C#, SQL Server, Excel VBA, MS Access, Visual Basic.Net, Visual Basic 6.0, C++ \n\nRPA Tools: Blue Prism, Automation Anywhere, Roboworx (In-house RPA Platform) \n\nMI Tools: Tableau \nProject Management Tools: MS Project, TFS, PMS (In house developed Tool) \n\nGeneral: MS Office (Word, Excel, PowerPoint) MS Outlook, Windows NetMeeting; Microsoft Go To Meeting; WebEx; \n\n \n■■■■■■■ \n\nACHIVEMENTS \nSPM of the Semester 2015-16 Q1 \n\nPM of the Year 2013-14 \nPM of the Semester 2013-14 Q2-Q4 \n\nAnalyst of the Year 2007-08 \n\n \n■■■■■■■ \n\nPERSONAL FORTE \nDate of Birth : 07/07/1982 \n\nAddress : 503, Leena Heritage Apt, 52-C Khurshadji Rana Street,  \n\n  Grant Road (East), Mumbai – 400007, MAHARASTRA \n\nLanguages known : English, Gujarati and Hindi \n\nPassport Number : M5390647 \n\nVisa Details : USA B1 Visa – Expiry Date 01-Jun-2025 \n\n \n\n \nMobile: 09833792070 Email: jigarparikh12@yahoo.com \n\n \n\n \n\nmailto:jigarparikh12@yahoo.com","annotation":[{"label":["UNKNOWN"],"points":[{"start":14060,"end":14113,"text":"\nVisa Details : USA B1 Visa – Expiry Date 01-Jun-2025 "}]},{"label":["Location"],"points":[{"start":13954,"end":13959,"text":"Mumbai"}]},{"label":["Education"],"points":[{"start":12747,"end":12783,"text":"Master of Computer Application (MCA) "}]},{"label":["Skills"],"points":[{"start":12087,"end":12109,"text":"Application Development"}]},{"label":["Skills"],"points":[{"start":11930,"end":11952,"text":"Application Development"}]},{"label":["Skills"],"points":[{"start":11611,"end":11633,"text":"Application Development"}]},{"label":["Skills"],"points":[{"start":8709,"end":8727,"text":"RPA Implementations"}]},{"label":["Skills"],"points":[{"start":7276,"end":7294,"text":"RPA Implementations"}]},{"label":["Skills"],"points":[{"start":1010,"end":1028,"text":"RPA Implementations"}]},{"label":["Skills"],"points":[{"start":613,"end":631,"text":"RPA Implementations"}]},{"label":["Skills"],"points":[{"start":548,"end":570,"text":"Application Development"}]},{"label":["Skills"],"points":[{"start":525,"end":542,"text":"Project management"}]},{"label":["Skills"],"points":[{"start":504,"end":522,"text":"Product Engineering"}]},{"label":["Skills"],"points":[{"start":127,"end":149,"text":"Application Development"}]},{"label":["Name"],"points":[{"start":0,"end":11,"text":"JIGAR PARIKH"}]}],"extras":null,"metadata":{"first_done_at":1532691505000,"last_updated_at":1532691505000,"sec_taken":97,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Ottigunta Jyothi Naidu\n\n     \n\n\n\n\n\n\n\n\n  Mobile : +91 8123459658\n\n      \n\n\n\n\n\n\n\n\n E-mail : jyothi.nadu@gmail.com\n CAREER OBJECTIVE\n\n         To pursue a challenging, innovative and responsible career in the field of software and communication with the help of skills and knowledge acquired by me and implementing then to achieve great pinnacles.\n\n PROFESSIONAL SUMMARY \n\n· Having 5.1 years IT experience in standalone applications and web based applications.\n\n· Expertise on Python, Django, MySQL, SQLite, HTML, CSS, JavaScript. \n\n· 2 months onsite experience in Zkteco for their operation support in China.\n\n· Strong exposure to complete project development life cycle developing expertise including designing/modeling, programming/coding.\n\n· Ability to work independently with minimum supervision in a team environment.\n\n· Ability to grasp concepts quickly and to use them for the development of newer system.\n\n· Ability to follow industry standards and procedures.\n· Ability to quickly master in new applications and a team player.\n· Strong communication and interpersonal skills. Possess Good patience and diplomatic skills in dealing team members. \n· Ability to interact with customers with ease and professionalism.\n TECHNICAL PROFICIENCY\n\n\t   Operating System\n\t: Windows Xp/Vista/7/8, Ubuntu 12.04+, RedHat\n\n\t   Web Technologies    \n\t: HTML, CSS, JavaScript, JQuery, AJAX, AngularJS \n\n\t Programming Language\n\t: Python 2.7.2 \n\n\t   Framework\n\t: Django 1.3/1.4/1.5.2/1.6.2\n\n\t   Database\n\t: MySQL, SQLite, PostgreSQL\n\n\t   Tools & Utilities\n\t: Sub Versioning system (SVN), Komodo Edit(Python Editor), Sublime Editor, \n\n Pycharm, Notepad++.\n\n\n CAREER GRAPH\n\n\tEmployer\n\tPeriod\n\tDesignation\n\n\tEpitome Tec Soft Pvt Ltd\n\nwww.epitomets.com\n\tAug 2011 – October 2012\n\tJr.Programmer\n\n\tEpitome Tec Soft Pvt Ltd\n\nwww.epitomets.com\n\tMay 2013 – Dec 2014\n\tProgrammer\n\n\tZkteco India Security Solutions Pvt Ltd\n\nwww.zkteco.com\n\n\tMay 2015 – March 2016\n\tPython Engineer\n\n\tUST-Global\n\tMarch 2016 – Till Date\n\tSr.Software Engineer\n\n\n EDUCATION DETAILS\n\n\tQualification\n\tInstitution\n\tMarks (%)\n\tPass Out\n\n\tBE (ISE)\n\tAuden Technology & Management Academy\n\tB Grade\n\t2012\n\n\tIntermediate\n\tSri Vivekananda Jr.College, Chittoor\n\t72 %\n\t2007\n\n\tS.S.C\n\tSri Vani Vidhyalaya , Penumuru\n\t66 %\n\t2005\n\n\nPROJECT DETAILS\n\nProject #1\n\n\nTitle\n\n: EAS (e-Alert System)\n\n\nTechnologies\n: Python, Rasberry Pi2, PHP, Javascript\n\n\nClient \n\n: Philips\n\n\nDescription\n: This is a Product which deals with the MRI Machines and Sending \n\n\n\n\n\nThe Alerts and reading the Sensors\n\n\nRole/\n\n\nContribution \n: \n\n· Design patterns and deploying and integrate the New Features to the Application.\n· Generating new reports and implementing the new Features.\n· Prepare DRS Documentation and maintaining the track.\n\n· Was responsible for Manual Testing and documentation for the product.\n\n· Was involving in QMS Documentation Process and get approvals from management to release the product.\n\n· Have prepared the Document Based on manual testing to PRS and QMS Documentation in the development Environment.\n\n· Was involving into attending CCB Meetings to verify and implement and confirm the New and advanced features in the product.\n\n· Analyzing the requirements and designing the data structure.\n Project #2\n\n\nTitle\n\n: ADMS (Zkteco) – Client –Server Based Software\n\n\nTechnologies\n: Python 2.7, Django 1.2, MySQL, JavaScript, JQuery, Ajax, HTML5, CSS3,Ngnix 1.8.0, Redis.\n\n\nClient\n\n: Zkteco (China)\n\n\nDescription\n: ADMS is a product based software which deals with Time Attendance Management System    with high Secured and also implement this software for Connecting to the Biometric Devices to collect the attendance from the device to the software through the server with MySQL and SQL Databases\n\n\nRole/\n\n\n\n\nContribution\n: \n\n· Was responsible for the Local software customizations and implementing the new \n\n\n\n\nFeatures based on the requirements.\n\n· Software Analysis and clear the bugs if the customers are facing any issues and \n\n\n\n\nGiving the alternative solutions for the issues.\n\n· Involved new features and enhancements.\n\n· Involved in clearing the issues and R & D for the competitor software’s and creating\n\n\n\n\nThe documents and giving suggestions to the technical team.\n\n· Implementation on CS Software and customizing the local customers and implementing \n\n\n\n\nThe new features based on the requirements and localization.\n\n· Have worked with China Team in Shenzhen for the understanding the software and \n\n\n\n\nConcerns with the software.\n\n· Generating reports based on Vendors, Products and Projects based on the customer requirements. \n\n· Design and Modification of various web components, stored procedures, views and \n\n             Implementation of a structured deployment process.\n\n· Analyzing the requirements and designing the database structure.\n\nProject #3\n\n\nTitle\n\n: ZKTime Web 2.0 (Web Based)\n\n\nTechnologies\n: Python 2.7, Django 1.2, MySQL, JavaScript, JQuery, Ajax, HTML5, CSS3, Ngnix 1.8.0, Redis.\n\n\nClient\n\n: Zkteco (China)\n\n\nDescription\n: ZKTime Web is a web based Time Attendance Software which includes the Advance Level options from the ADMS and web Based Implementation, which will have the User Login and Employee Self login based on the User Credentials \n\n\nRole/\n\n\n\n\nContribution\n: \n\n· Was responsible for the Local software customizations and implementing the new \n\n\n\n\nFeatures based on the requirements.\n\n· Software Analysis and clear the bugs if the customers are facing any issues and \n\n\n\n\nGiving the alternative solutions for the issues.\n\n· Have researched on Payroll Implementation to the Software and R & D for the same and creating the requirements list and gathering the software’s as per the market strategies\n· Involved in clearing the issues and R & D for the competitor software’s and creating\n\n\n\n\nThe documents and giving suggestions to the technical team.\n\n· Need to check the Marketing Strategy and collect the Advance level software’s from the marketing team evaluating the strategy to make sure the best in the software’s.\n\n· Implementing the Unique products and implementing the new rules and regulations to the Time Attendance for the customer as per the requirements and giving the solutions as possible.\n\n· Have worked with China Team in Shenzhen for the understanding the software and \n\n\n\n\nConcerns with the software.\n\n· Generating reports based on Vendors, Products and Projects based on the customer requirements. \n\n· Design and Modification of various web components, stored procedures, views and \n\n             Implementation of a structured deployment process.\n\n· Analyzing the requirements and designing the database structure.\n\n Project #4\n\n\nTitle\n\n: PMS (Performance Management System) – pms.mahindracomviva.com\n\n\nTechnologies\n: Python 2.7, Django 1.8.2, MySQL, JavaScript, JQuery, Ajax, HTML5, CSS3, Twitter  Ngnix \n\n\nClient\n\n: Mahindra Comviva (Bangalore)\n\n\nDescription\n: AMC – Annual Maintenance Contract. It’s a product of Mahindra Comviva, their main \n\n\n  \n\nactivity is to track all the customers, vendors (Third Party Hardware/Third Party \n\n\n\n             Software), product and projects with price and discount.\n\n\nRole/\n\n\nContribution\n: \n\n· Involved new features and enhancements.\n\n· Analyzing the requirements and designing the database structure.\n\n· Design and Modification of various web components, stored procedures, views and \n\n            Implementation of a structured deployment process.\n\n· Generating reports based on Vendors, Products and Projects.\n Project #5\n\n\nTitle\n\n: Right Arm – www.rightarm.com devrightarm.mahiti.org\n\n\nTechnologies\n: Python 2.7,Django 1.5.2, SQLite, JavaScript, JQuery, HTML5, CSS3, Apache, Linux.\n\n\nClient\n\n: Devendra Bahadur (Head-India Operation)\n\n\nDescription\n: RA is collaborative platform for people to 'give' and make a change to the world we \n\n\nlive in. This project is a platform and addressing challenges faced by Individuals, \n\n\n\nCharities, Non-Profit Organization, Social Enterprises, etc.\n\n\nRole/\n\n\nContribution \n: \n\n· Design and Modification of various web components, stored procedures, views and \n\n         Implementation of a structured deployment process.\n\n Project #6\n\n\nTitle\n\n: GAF (Green Alliance Foundation) – gal.mahiti.org\n\n\nTechnologies\n: Python 2.7, Django 1.5.2, SQLite, JavaScript, JQuery, Ajax, HTML, CSS, Apache 2.2, Linux\n\n\nClient\n\n: Green Alliance Foundation\n\n\nDescription\n: GAL is an organization that has located in Kenya, their main activity is to brought \n\n\n\n\nfarmers in self-help groups and facilities saving amongst farmers group, provides \n\n\n\n\ntraining and micro-finance and a range of loan products.\n\n\nRole/\n\n\nContribution \n:\n\n· Design and Modification of various web components, stored procedures, views and \n\n            Implementation of a structured deployment process.\n\n· Generating reports based on farmers and groups.\n\n· Provided REST API services to capture the farmer, group details.\n\n Project #7\n\n\nTitle\n\n: FML (Faida MaLi) – fml.mahiti.org\n\n\nTechnologies\n: Python 2.7, Django 1.5.2, SQLite, JavaScript, JQuery, Apache 2.2, And Linux Client \n\n: \n\n\nDescription\n: FML works with 30 NGO across six districts and required to enable various types of \n\n\n\n\ninteraction and transaction with partner’s organization in relation with group involved to track \n\n\n\nand evaluate the training programs and banking correspondence functionality. \n\n\nRole/\n\n\nContribution \n: \n\n· Design and Modification of various web components, stored procedures, views and \n\n            Implementation of a structured deployment process.\n\n· Generating reports based on farmers and groups.\n\n· Provided REST API services to capture the farmer, group details.\n\n Project #8\n\n\nTitle\n\n: KPDL (Karagwe Peasants Development Ltd) – kpdl.mahiti.org\n\n\nTechnologies\n: Python 2.7, Django 1.5.2, SQLite, JavaScript, JQuery, Ajax, HTML, CSS, Apache 2.2, Linux\n\n\nClient\n\n:  Karagwe Peasants Development Ltd\n\n\nDescription\n: KPDL based in Tanzania works with over 12,000 coffee growers that are SACCO \n\n\n\n\nmembers and provides them with micro finance and assistance in market linkage. \n\n\n\n\nSo, here our work is to store farmer’s details with their occupational, socio-economic \n\n\n\n\nprofile and to generate report based on farmers group (SACCO).\n\n\nRole/\n\n\nContribution \n: \n\n· Design and Modification of various web components, stored procedures, views and \n\n             Implementation of a structured deployment process.\n\n· Generating reports based on farmers and groups.\n\n· Provided REST API services to capture the farmer, group details.\n\n PERSONAL DETAILS\n\n\tFather Name\n\t:  O Venkatrama Naidu\n\n\tGender\n\t:  Male\n\n\tDate of Birth\n\t:  06 April 1990\n\n\tMarital Status\n\t:  Single\n\n\tLanguages Known\n\t:  English, Telugu, Kannada\n\n\tPresent Address\n\t:  No2, 3rdMain, 5th Cross, Next to BEML Depot, R R Nagar, Channasandra, Bangalore-560098\n\n\tPermanent Address\n\t:  2-59, G.G.Palli, Penumuru (MDL), Chittoor (Dist.), \n\nAndhra Pradesh -517126\n\n\tEmail\n\t:  jyothi.nadu@gmail.com\n\n\tMobile Number\n\t:  +91 8123459658\n\n\n DECLARATION\n\n\nI hereby confirm that the information given above is true to the best of my knowledge.\n\nPlace: Bangalore\n\n\n\n\n\n\nYours Truly,\n\nDate:\n\n\n\n\n\n\n\n\n\n\n     \n       (Ottigunta Jyothi Naidu)","annotation":[{"label":["Name"],"points":[{"start":11112,"end":11133,"text":"Ottigunta Jyothi Naidu"}]},{"label":["Location"],"points":[{"start":11051,"end":11060,"text":" Bangalore"}]},{"label":["Location"],"points":[{"start":10753,"end":10762,"text":" Bangalore"}]},{"label":["Skills"],"points":[{"start":9779,"end":9781,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":9773,"end":9776,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":9759,"end":9764,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":9746,"end":9756,"text":" JavaScript"}]},{"label":["Skills"],"points":[{"start":9713,"end":9718,"text":"Python"}]},{"label":["Skills"],"points":[{"start":8995,"end":9000,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":8982,"end":8992,"text":" JavaScript"}]},{"label":["Skills"],"points":[{"start":8949,"end":8954,"text":"Python"}]},{"label":["Skills"],"points":[{"start":8271,"end":8273,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":8265,"end":8268,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":8251,"end":8256,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":8238,"end":8248,"text":" JavaScript"}]},{"label":["Skills"],"points":[{"start":8205,"end":8210,"text":"Python"}]},{"label":["Skills"],"points":[{"start":7618,"end":7620,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":7611,"end":7614,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":7603,"end":7608,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":7590,"end":7600,"text":" JavaScript"}]},{"label":["Skills"],"points":[{"start":7558,"end":7563,"text":"Python"}]},{"label":["Skills"],"points":[{"start":6794,"end":6796,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":6787,"end":6790,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":6773,"end":6778,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":6760,"end":6770,"text":" JavaScript"}]},{"label":["Skills"],"points":[{"start":6728,"end":6733,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4932,"end":4934,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":4925,"end":4928,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":4911,"end":4916,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":4898,"end":4908,"text":" JavaScript"}]},{"label":["Skills"],"points":[{"start":4868,"end":4873,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3383,"end":3385,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":3376,"end":3379,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":3362,"end":3367,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":3349,"end":3359,"text":" JavaScript"}]},{"label":["Skills"],"points":[{"start":3319,"end":3324,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2344,"end":2349,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1937,"end":1942,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1586,"end":1591,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1417,"end":1422,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1379,"end":1388,"text":"AngularJS "}]},{"label":["Skills"],"points":[{"start":1373,"end":1376,"text":"AJAX"}]},{"label":["Skills"],"points":[{"start":1365,"end":1370,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":1352,"end":1362,"text":" JavaScript"}]},{"label":["Skills"],"points":[{"start":1348,"end":1350,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":1342,"end":1345,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":515,"end":525,"text":" JavaScript"}]},{"label":["Skills"],"points":[{"start":511,"end":513,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":505,"end":508,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":474,"end":479,"text":"Python"}]},{"label":["Name"],"points":[{"start":0,"end":21,"text":"Ottigunta Jyothi Naidu"}]}],"extras":null,"metadata":{"first_done_at":1532675296000,"last_updated_at":1532675296000,"sec_taken":121,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Kalpana Chaudhary\n\nData Science/R Modeling/Data Analytics \n kalpanachdhr07@gmail.com | +91-8285 982 675 | Gurugram, India\n\n\n\n\tProfessional\nProfile\n\t· Over 4 plus years of IT / Non-IT experience spanning across niche areas in Data Science, Analytics, R Modeling and Data Management space.\n· Certified Data Scientist.\n· Business acumen with Advanced Analytics literacy interested to contribute and grow in the data analytics dependent business\n· Possess comprehensive knowledge of Statistics, Machine Learning, Data Mining and Visualization\n· Work closely with the top leadership team to achieve business goals\n· Involve in Client Engagements, to understand client requirements and business problems\n· Collaborate with product engineers on Big Data and Real-time Analytics based products\n· Having hands on experience in production support and provides technical troubleshooting in resolving production issues.\nData Science Expertise: \nModules undertaken: \n· Big Data analytics, Operations Research, Data warehouse and Modeling, Statistics, Machine Learning and Decision Making Technology, Hands-on with Business Analytics\nMachine Learning: \n· Linear Regression, Logistic Regression, Decision Tree, Support Vector Machines, Cluster Analysis\nData Architecture: \n· Responsible for developing data architecture for handling unstructured data at the enterprise Scale. Developed data extraction frameworks for unstructured data including methods such as Web scraping, developed data cleansing framework and data storage methods.\nAnalytics Data warehouse\n· Designed and developed from scratch an analytics data warehouse for holding Subscription and customers’ information.\n· Was responsible for formulating indexing strategy, designed and developed analytics relevant tables and was responsible for creating a strategy for extracting, transforming and storing data relevant to analytics projects.\n\n\n\tProfessional Experience\n\tGenpact, Gurugram, India\nSenior Data Analyst, Sept 2016 – present\n· Collaborate with product engineering team on big data and real-time analytics based product development\n· Contribute in building data science components for developing different use-cases \n· Provide a strong analytical base and work as a solution engineer, to develop solution architecture using company’s product offerings, to address client business problems\n· Responsible for creating/designing and implementing the complete database solution for Healthcare Insurance Inventory along with data from multiple regions.\n· Understand business problems and conceptualize tailored analytics solutions\n· Developed and Deployed Machine learning models with association rule mining, Random forests \n· Wrote R scripts for pricing strategies, elasticity, clustering, statistical tests, file integration automation\n· Recommended product price based on the metrics such as current and past prices, competitor price, unit sold, revenue, margin, conversion rate\n· Designed propensity model to calculate probability of buying several products for Healthcare Insurance clients for online user \n\n\t\n\tGenpact, Gurugram, India\nData Analyst, Aug 2014 – Sept 2016\n· Design professional external facing client presentations that bring out insights and present complex data in a consumable format for various audiences like the senior leadership, management and internal teams\n· Conceptualize and build KPI dashboards to surface powerful data backed insights for business leaders to take strategic decisions\n· Collaborate and coordinate with various teams to gather data, explore and provide valuable business insights from the data\n· Build infrastructure and maintenance strategy of the data to implement analytical approach\n· Increase clientele and client satisfaction, and add value to the business and contribute continuously on processes improvement\n· Scope, plan and manage resources to meet deadlines, and create different internal reports for management to monitor utilization, efficiency and quality of the team on a regular basis, prepare goals sheet of the team, and process documentations\n· Provide training to fresh recruits on the system design, business functionality, tools, projects and processes, and mentor and coach sub-ordinates\n· Automated reports (weekly performance report, incremental report and Strategy dashboards)\n· Actively involved in the project activities (from the Initial days) like requirement gathering, Data Analysis, scoping and source data Analysis across multiple data bases.\n· Active Participation in biweekly client calls\nAjneya Technologies, Noida, India\nTechnical Support, Aug 2013 – Jul 2014\n· Provide technical support to customers over the call for Products based on RFID \n· Designed chat server in C language on Ubuntu\n· Worked on various segments of RFID based products\n\n\t\n\t\n\n\tEducation\n\t· Certified on Data Science (Jigsaw Academy), 2017\n· B.Tech – Electronics and Communication, Ambedkar Institute Of Technology, Guru Gobind Singh Inderprasth University, Delhi 2013 \n\n\t\n\n\t\n\n\tSkills\n\t· Data Mining Tools: R Programming\n· Statistical Tools: R Programming\n· Front-end Visualization tools: GGPLOT2 package in R \n· Database and Data warehouse: Microsoft SQL Server, SQL\n· Expert in Advance Excel\n· MS Access, MS PowerPoint, VBA\n\n\t\n\t\n\n\tProjects\n\tSALES LEAD PREDICTION\nBuilt a recommendation system to recommend related healthcare insurance product components to the users.\nTools Used: R\nMachine Learning Models: Linear Regression\n\nEVENT SUCCESS PREDICTION\nBuilt predictive models to predict the probability of the success of events – based on the attendance, leads, and sales conversion rate. Recognize patterns and identify relationships between different variables to plan the activities effectively.\nTools Used: R\nMachine Learning Models: Decision Trees, Linear Regression (to predict attendance)\n\nCUSTOMER SEGMENTATION\nSegmentation of customers based on customer behavior and profiles using clustering methods to target customers effectively.\nTools Used: R\nMachine Learning Models: K-Means Clustering\n\n\nTEXT MINING & TEXT CLASSIFICATION\nSentiment analysis on the feedback surveys to identify the customer needs and preferences, and the text analytics on the Web and Social media data to identify the key topics for the marketing activities. Based on text classification, find which key words or topics pull more audience.\nTools Used: R\nText Analytics: Positive/Negative Sentiment Analysis\nMachine Learning Models: Naïve Bayes\nKPI DASHBOARDS/REPORTS\nConceptualize and build KPI dashboards to surface powerful data backed insights for marketing leaders to take strategic decisions.\nTools Used: MS-Excel, SQL.\n\n\t\n\t\n\n\tProcess Automations\n\tQUALITY CHECKER\nBuilt an application, which compares the dashboard values with the original source and identify the discrepancies.\nTools Used: MS-Excel – VBA\nPRODUCTIVITY TRACKER\n\n\t\n\tBuilt an application, which provides & compares the Production and Accuracy Reports based on various criteria and identify the discrepancies.\nTools Used: MS-Access – VBA, SQL\n\n\n\tProfessional Achievements\n\t· Achieved 2 Silver and 3 Bronze Awards in Genpact (On Individual Performance)\n· Achieved 1 Gold Awards in Genpact (On Team Performance)\n· Lean Certified\n\n\t\n\t\n\n\tPersonal Details\n\tDate of Birth: July, 1990\nMarital Status: Single\nLanguage: English, Hindi","annotation":[{"label":["Skills"],"points":[{"start":6984,"end":6998,"text":"MS-Access – VBA"}]},{"label":["Skills"],"points":[{"start":5153,"end":5172,"text":"Microsoft SQL Server"}]},{"label":["Skills"],"points":[{"start":5053,"end":5065,"text":"R Programming"}]},{"label":["Skills"],"points":[{"start":5018,"end":5030,"text":"R Programming"}]},{"label":["Education"],"points":[{"start":4853,"end":4858,"text":"B.Tech"}]},{"label":["Location"],"points":[{"start":3078,"end":3085,"text":"Gurugram"}]},{"label":["Location"],"points":[{"start":1926,"end":1933,"text":"Gurugram"}]},{"label":["Location"],"points":[{"start":106,"end":113,"text":"Gurugram"}]},{"label":["Name"],"points":[{"start":0,"end":16,"text":"Kalpana Chaudhary"}]}],"extras":null,"metadata":{"first_done_at":1532693765000,"last_updated_at":1532693765000,"sec_taken":113,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Kalpana Chaudhary\n\nData Science/R Modeling/Data Analytics \n kalpanachdhr07@gmail.com | +91-8285 982 675 | Gurugram, India\n\n\n\n\tProfessional\nProfile\n\t· Over 4 plus years of IT / Non-IT experience spanning across niche areas in Data Science, Analytics, R Modeling and Data Management space.\n· Certified Data Scientist.\n· Business acumen with Advanced Analytics literacy interested to contribute and grow in the data analytics dependent business\n· Possess comprehensive knowledge of Statistics, Machine Learning, Data Mining and Visualization\n· Work closely with the top leadership team to achieve business goals\n· Involve in Client Engagements, to understand client requirements and business problems\n· Collaborate with product engineers on Big Data and Real-time Analytics based products\n· Having hands on experience in production support and provides technical troubleshooting in resolving production issues.\nData Science Expertise: \nModules undertaken: \n· Big Data analytics, Operations Research, Data warehouse and Modeling, Statistics, Machine Learning and Decision Making Technology, Hands-on with Business Analytics\nMachine Learning: \n· Linear Regression, Logistic Regression, Decision Tree, Support Vector Machines, Cluster Analysis\nData Architecture: \n· Responsible for developing data architecture for handling unstructured data at the enterprise Scale. Developed data extraction frameworks for unstructured data including methods such as Web scraping, developed data cleansing framework and data storage methods.\nAnalytics Data warehouse\n· Designed and developed from scratch an analytics data warehouse for holding Subscription and customers’ information.\n· Was responsible for formulating indexing strategy, designed and developed analytics relevant tables and was responsible for creating a strategy for extracting, transforming and storing data relevant to analytics projects.\n\n\n\tProfessional Experience\n\tGenpact, Gurugram, India\nSenior Data Analyst, Sept 2016 – present\n· Collaborate with product engineering team on big data and real-time analytics based product development\n· Contribute in building data science components for developing different use-cases \n· Provide a strong analytical base and work as a solution engineer, to develop solution architecture using company’s product offerings, to address client business problems\n· Responsible for creating/designing and implementing the complete database solution for Healthcare Insurance Inventory along with data from multiple regions.\n· Understand business problems and conceptualize tailored analytics solutions\n· Developed and Deployed Machine learning models with association rule mining, Random forests \n· Wrote R scripts for pricing strategies, elasticity, clustering, statistical tests, file integration automation\n· Recommended product price based on the metrics such as current and past prices, competitor price, unit sold, revenue, margin, conversion rate\n· Designed propensity model to calculate probability of buying several products for Healthcare Insurance clients for online user \n\n\t\n\tGenpact, Gurugram, India\nData Analyst, Aug 2014 – Sept 2016\n· Design professional external facing client presentations that bring out insights and present complex data in a consumable format for various audiences like the senior leadership, management and internal teams\n· Conceptualize and build KPI dashboards to surface powerful data backed insights for business leaders to take strategic decisions\n· Collaborate and coordinate with various teams to gather data, explore and provide valuable business insights from the data\n· Build infrastructure and maintenance strategy of the data to implement analytical approach\n· Increase clientele and client satisfaction, and add value to the business and contribute continuously on processes improvement\n· Scope, plan and manage resources to meet deadlines, and create different internal reports for management to monitor utilization, efficiency and quality of the team on a regular basis, prepare goals sheet of the team, and process documentations\n· Provide training to fresh recruits on the system design, business functionality, tools, projects and processes, and mentor and coach sub-ordinates\n· Automated reports (weekly performance report, incremental report and Strategy dashboards)\n· Actively involved in the project activities (from the Initial days) like requirement gathering, Data Analysis, scoping and source data Analysis across multiple data bases.\n· Active Participation in biweekly client calls\nAjneya Technologies, Noida, India\nTechnical Support, Aug 2013 – Jul 2014\n· Provide technical support to customers over the call for Products based on RFID \n· Designed chat server in C language on Ubuntu\n· Worked on various segments of RFID based products\n\n\t\n\t\n\n\tEducation\n\t· Certified on Data Science (Jigsaw Academy), 2017\n· B.Tech – Electronics and Communication, Ambedkar Institute Of Technology, Guru Gobind Singh Inderprasth University, Delhi 2013 \n\n\t\n\n\t\n\n\tSkills\n\t· Data Mining Tools: R Programming\n· Statistical Tools: R Programming\n· Front-end Visualization tools: GGPLOT2 package in R \n· Database and Data warehouse: Microsoft SQL Server, SQL\n· Expert in Advance Excel\n· MS Access, MS PowerPoint, VBA\n\n\t\n\t\n\n\tProjects\n\tSALES LEAD PREDICTION\nBuilt a recommendation system to recommend related healthcare insurance product components to the users.\nTools Used: R\nMachine Learning Models: Linear Regression\n\nEVENT SUCCESS PREDICTION\nBuilt predictive models to predict the probability of the success of events – based on the attendance, leads, and sales conversion rate. Recognize patterns and identify relationships between different variables to plan the activities effectively.\nTools Used: R\nMachine Learning Models: Decision Trees, Linear Regression (to predict attendance)\n\nCUSTOMER SEGMENTATION\nSegmentation of customers based on customer behavior and profiles using clustering methods to target customers effectively.\nTools Used: R\nMachine Learning Models: K-Means Clustering\n\n\nTEXT MINING & TEXT CLASSIFICATION\nSentiment analysis on the feedback surveys to identify the customer needs and preferences, and the text analytics on the Web and Social media data to identify the key topics for the marketing activities. Based on text classification, find which key words or topics pull more audience.\nTools Used: R\nText Analytics: Positive/Negative Sentiment Analysis\nMachine Learning Models: Naïve Bayes\nKPI DASHBOARDS/REPORTS\nConceptualize and build KPI dashboards to surface powerful data backed insights for marketing leaders to take strategic decisions.\nTools Used: MS-Excel, SQL.\n\n\t\n\t\n\n\tProcess Automations\n\tQUALITY CHECKER\nBuilt an application, which compares the dashboard values with the original source and identify the discrepancies.\nTools Used: MS-Excel – VBA\nPRODUCTIVITY TRACKER\n\n\t\n\tBuilt an application, which provides & compares the Production and Accuracy Reports based on various criteria and identify the discrepancies.\nTools Used: MS-Access – VBA, SQL\n\n\n\tProfessional Achievements\n\t· Achieved 2 Silver and 3 Bronze Awards in Genpact (On Individual Performance)\n· Achieved 1 Gold Awards in Genpact (On Team Performance)\n· Lean Certified\n\n\t\n\t\n\n\tPersonal Details\n\tDate of Birth: July, 1990\nMarital Status: Single\nLanguage: English, Hindi","annotation":[{"label":["Skills"],"points":[{"start":6401,"end":6416,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":5969,"end":5984,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":5725,"end":5740,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":5395,"end":5410,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":5052,"end":5065,"text":" R Programming"}]},{"label":["Skills"],"points":[{"start":5017,"end":5030,"text":" R Programming"}]},{"label":["Skills"],"points":[{"start":4999,"end":5009,"text":"Data Mining"}]},{"label":["Location"],"points":[{"start":3078,"end":3085,"text":"Gurugram"}]},{"label":["Location"],"points":[{"start":1926,"end":1933,"text":"Gurugram"}]},{"label":["Skills"],"points":[{"start":1120,"end":1135,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1038,"end":1053,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1026,"end":1035,"text":"Statistics"}]},{"label":["Skills"],"points":[{"start":956,"end":963,"text":"Big Data"}]},{"label":["Skills"],"points":[{"start":751,"end":770,"text":"Real-time Analytics "}]},{"label":["Skills"],"points":[{"start":738,"end":745,"text":"Big Data"}]},{"label":["Skills"],"points":[{"start":509,"end":519,"text":"Data Mining"}]},{"label":["Skills"],"points":[{"start":491,"end":506,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":479,"end":488,"text":"Statistics"}]},{"label":["Location"],"points":[{"start":106,"end":113,"text":"Gurugram"}]},{"label":["Name"],"points":[{"start":0,"end":16,"text":"Kalpana Chaudhary"}]}],"extras":null,"metadata":{"first_done_at":1532692585000,"last_updated_at":1532692585000,"sec_taken":124,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Kamlesh Jha\nSr. Technical Associate (4.5 years)\n\nSEARS IT and Management Services\n\nEmail: kjha8713@gmail.com                                                                                Mobile: -7744003606\n· Total Exp: 4.5 Yrs.\n\n· R Programming: 3.6 Yrs.\n\n· Machine Learning: 3.6 Yrs. \n\n· NP : 90 Days\n\nCurrently in Pune ready to relocate\n\nInterests:        Deep Learning, Machine Learning, Statistical Analysis\nEducation:     Symbiosis International University, Pune     (2014 – 2016)\n\n· Executive MBA – IT                                 GPA:  2.75/4\n                         University of Pune                                              (2006 – 2010)\n\n· B.E                                                              62%\n\nCertification:   Neural Networks and Deep Learning (COURSERA)    92.2%\n\n                          https://www.coursera.org/account/accomplishments/verify/KSUEGZCTPVT5\nExperience:    \n\n                          SEARS IT AND MANAGEMENT SERVICES       (APR ’16 – TILL DATE)\n              MAP (Member Analytics Platform)- Customer Analytics\n· Value of NPS (Impact Of MSO NPS on Future Sears Holding Sales) It is hypothesized that members who contacted the MSO and rate Sears with higher NPS values (0 is the lowest, 10 the highest) return to purchase often and expenditure will be increased dollars than those members who rate Sears with lower NPS values. We are preparing a predictive model to predict if they will come in future and when depending on their past experiences.(Python, Numpy, TensorFlow) \n· Analysis Of efficiency of Virtual Agents on Repair BU TFN”S and applying Unsupervised Learning techniques to find hidden patterns in conjunction with CDI(Customer Data Integration) (TensorFlow,Python)\n· Individual Member View Dashboard in SHINY APP (Spend History, Redemption Trends, Timing Patterns, Purchase Patterns, communication, Profile)(R, Statistics)\n\n· Hypothesis generation and analysis on impact of the Average number of contacts by state of service and Response time(Statistics, R, Teradata)\n\n· Developed Statistical Algorithm for CCN Feedback – 180 Day Campaign Performance(Excel,R,Statistics)\n\n· Developed Regression equation for MSAT Goals for Fiscal Year 2017-18(Deployed)\n\n· Developed Process Control Charts for Reason for call analysis Reports(Excel)\n\n· Prepared Trending Charts with different Metrics for Different BU’s i.e Online, Delivery, Parts, Repair and Retail(Excel)\n\n· Hypothesis testing to prove multiple responses are increasing while single responses are decreasing for Phone, Web and Chat Channel comparing FY15 and FY16(R,Statistics)\n\n           STERIA INDIA LTD. PUNE                                               (AUG’13 – APR’16)\n\nTESCO\n· Developed a Sales forecasting predictive model using Time series for usage of Regional managers to analyze the sales of a particular region for next quarter so as to plan inventory accordingly(R, Machine Learning, Time Series Forecasting)\n\n· Developed Dashboards for Store managers for Store staff Sales, performance and incentive data(Tableau, Excel)\n              BRITISH TELECOM- CSCS (Call Statistics Centralized System) (JAN’15 – APR’16)\n· Churn prediction- Taking into account the different NNI of Consumer mobility. We prepared Churn prediction model using Clustering, Decision tree and Support vector machines to predict churn for a certain NNI under BT customers. Later same Predictive model was implemented for all the different NNI’s (Network Node Interchange)\n\n(R, Machine Learning, Hive, Hadoop, Statistics)\n\n· CMOB (Consumer Mobility) data mart contains all the call data record related to consumer mobiles. So we analyzed the data to prepare a propensity model for up-selling of a new mobile related scheme(R, Machine Learning, Unsupervised Learning)\n                     SELF MADE PROJECTS \n1. Machine Learning https://github.com/kamleshjha/Machine-Learning-Problems\n· Spam Classifier on Emails \n· Prediction using KNN on Skulls Dataset\n\n· Logistic regression (2 Projects)\n2. Deep Learning using Tensor Flow https://github.com/kamleshjha/Tensor-Flow-Assignments\n· Classification of MNIST Dataset\n· Multinomial Logistic regression using GD and SGD\n· Time Series Stock Analysis\nTECHNICAL SKILLS:\n\n· Software :- Python, Numpy , Pandas, R,R Markdown, SQL, Tensor Flow, Jupyter, Ipython\n· Math:-  Statistics, Probability, Linear Algebra, Calculus\n\n· Cloud - Anaconda\n\n· Hadoop – Pig, Hive\n\n· Database – Oracle, Teradata, SQL Server, MYSQL,MS Access\n\n· BI Tools – Tableau\n\n· Environments – Unix, Windows\n\nI hereby declare that above information are correct and true as per best of my knowledge.\n\n Date                                                                                                                                           \n\n Place -  Pune                                                                                                    Kamlesh  Mani Jha","annotation":[{"label":["Location"],"points":[{"start":4770,"end":4773,"text":"Pune"}]},{"label":["Skills"],"points":[{"start":3818,"end":3833,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":3733,"end":3748,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":3485,"end":3500,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":2904,"end":2919,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1371,"end":1372,"text":"NP"}]},{"label":["Skills"],"points":[{"start":1214,"end":1215,"text":"NP"}]},{"label":["Skills"],"points":[{"start":1098,"end":1099,"text":"NP"}]},{"label":["Skills"],"points":[{"start":1079,"end":1080,"text":"NP"}]},{"label":["Location"],"points":[{"start":594,"end":597,"text":"Pune"}]},{"label":["Location"],"points":[{"start":465,"end":468,"text":"Pune"}]},{"label":["Skills"],"points":[{"start":375,"end":390,"text":"Machine Learning"}]},{"label":["Location"],"points":[{"start":318,"end":321,"text":"Pune"}]},{"label":["Skills"],"points":[{"start":291,"end":292,"text":"NP"}]},{"label":["Skills"],"points":[{"start":260,"end":275,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":233,"end":245,"text":"R Programming"}]},{"label":["Name"],"points":[{"start":0,"end":10,"text":"Kamlesh Jha"}]}],"extras":null,"metadata":{"first_done_at":1532675645000,"last_updated_at":1532675645000,"sec_taken":44,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Karthik Karumanchi\n  Email: karthikdatascience@gmail.com\nPhone: +91-9581321939\nData Analyst/Data scientist\n\nA Data Analyst/Data scientist at EDVNSYS SOLUTIONS with total 3.1 years of rich experience in Information Technology industry, including 3 years in immersive Predictive and Unsupervised Analytics roles involving big dataled decision making.\n• 3.1 years of experience as Data Scientist and Data Analyst.\n• Experience in Working in Hadoop environment, using Hive language to deal with BigData\n\n. Experience in working SparkSql\n\n• Exposure to Machine Learning Algorithms, Predictive Modeling concepts\n• Expertise on Python,R languages, Hive, SQL.\n• Good Knowledge on Data cleaning using R and Python\n• Ability to use Regression concepts in Predictive Modelling and clustering techniques for    text analytics.\n\n. Experience in NLP Web Scraping\n\n• Knowledge on Python for Machine learning, Deep Learning and usage of packages for text mining.\n\n. Experience in OOZIE, HIVE, PIG, SQOOP, HBASE and SPARK,SCALA\n\nWORK EXPERIENCE\n\nData Analyst/Data Scientist\n\nEdvnsys Solutions - Hyderabad, Telangana –Sept 2014 to Present\n\nProject Description:\n\n  The bank wants to improve their services. For instance, the bank managers have only vague idea, who is a good client (whom to offer some additional services) and who is a bad client (whom to watch carefully to minimize the bank loses). Fortunately, the bank stores data about their clients, the accounts (transactions within several months), the loans already granted, the credit cards issued The bank managers hope to improve their understanding of customers and seek specific actions to improve services. A mere application of a discovery tool will not be convincing for them.\n\n  In keeping with the original task description, our project goal is to mine and analyze this bank data in order to extrapolate from it the type of customer who makes a good candidate for a credit card.\n\nResponsibilities:\n\n1. Studying and Understanding of every Variables.\n\n2. Cleaning Data, Imputing Missing Values and Deducting outliers.\n\n3. Visualizing the Variables and understanding their relationships.\n\n4. Preparing Models, Checking Accuracy and Evaluating Accuracy.\n\n5. Generating Reports and presenting it to Client\n6. Developing a confusion matrix and exporting the final data set.\n\n7. Implementing  Linear and Logistic regression algorithms to predict the value of shares, as part of machine learning.\n\n8. Selecting features, building and optimizing Classifiers using Machine learning technique\nData Analyst/Data Scientist\n\nEdvnsys Solutions – Hyderabad\n\nProject Description:\n\n The purpose of the project is to store terabytes of log information generated by the ecommerce website and extract meaning information out of it. The solution is based on the open source BigData s/w Hadoop .The data will be stored in Hadoop file system and processed using Map/Reduce jobs. Which intern includes getting the raw data from the websites, Process the data  to obtain product and pricing information, Extract various reports out of the product pricing information. \n\nResponsibilities:\n\n1.Worked in Hadoop Environment to analyze Big Data. Used Hive language in Hadoop  Environment and SparkSql.\n\n2. Worked on Data pre-processing stage which involved cleaning of data using R/Python.\n\n3. Used data imputation techniques for missing data.\n\n4. Involved in cleaning up various discrepancies in data to make it analysis ready.\n\n5. Visualizing the Variables and understanding their relationships.\n\n6. Preparing Models, Checking Accuracy and Evaluating Accuracy.\n\n7. Generating Reports and presenting it to Client\n\n8. Developing a confusion matrix and exporting the final data set.\n\nEDUCATION:\n\n1)MCA,  JNT University, Hyderabad, CVSR College  with 77.5%\n\n2)Intermediate (MPC), Intermediate Board of Education, KJC college with 78.0%\n\n3)BSC(computers) at PAS college with 70%\n\n4)SSC, Board of Secondary Education  with 77%\n\nTechnical Expertise:\n\nData Analysis: NLP (Natural Language Processing), Time series Analysis, Predictive Analysis, Regression Models, Cluster Analysis, Clustering Algorithm, Classification Models, Association Rule Mining.\n\nMachine Learning: Naïve Bayes, Decision Tree, Random Forest, Neural\n\nNetworks. NLP (Natural Language Processing), SVM, \n\nBig Data Analytics:  Hive,Pig,FLUME, KAFKA, HIVE, PIG, SQOOP \n\nNOSQL Databases: HBASE.\n\nSpark and Scala: Spark Core, Spark SQL, GraphX, MLLib, Spark Streaming.\n\nDatabase knowledge: SQL Server.\n\nIDE’s: Eclipse\n\n  Languages: Python(Good understanding and scikit of numpy, scipy, pandas -learn libraries),Java\n\nVirtualization: Microsoft clustering and Virtualization and VMware Virtualization","annotation":[{"label":["Skills"],"points":[{"start":4510,"end":4515,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4308,"end":4311,"text":"Hive"}]},{"label":["Skills"],"points":[{"start":4212,"end":4212,"text":"R"}]},{"label":["Skills"],"points":[{"start":4152,"end":4152,"text":"R"}]},{"label":["Skills"],"points":[{"start":4058,"end":4058,"text":"R"}]},{"label":["Skills"],"points":[{"start":3752,"end":3752,"text":"R"}]},{"label":["Location"],"points":[{"start":3738,"end":3746,"text":"Hyderabad"}]},{"label":["Education"],"points":[{"start":3716,"end":3718,"text":"MCA"}]},{"label":["Skills"],"points":[{"start":3597,"end":3597,"text":"R"}]},{"label":["Skills"],"points":[{"start":3301,"end":3306,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3299,"end":3299,"text":"R"}]},{"label":["Skills"],"points":[{"start":3187,"end":3192,"text":"Hadoop"}]},{"label":["Skills"],"points":[{"start":3170,"end":3173,"text":"Hive"}]},{"label":["Skills"],"points":[{"start":3125,"end":3130,"text":"Hadoop"}]},{"label":["Skills"],"points":[{"start":3094,"end":3094,"text":"R"}]},{"label":["Skills"],"points":[{"start":2892,"end":2892,"text":"R"}]},{"label":["Skills"],"points":[{"start":2849,"end":2854,"text":"Hadoop"}]},{"label":["Skills"],"points":[{"start":2814,"end":2819,"text":"Hadoop"}]},{"label":["Skills"],"points":[{"start":2802,"end":2808,"text":"BigData"}]},{"label":["Location"],"points":[{"start":2581,"end":2589,"text":"Hyderabad"}]},{"label":["Skills"],"points":[{"start":2215,"end":2215,"text":"R"}]},{"label":["Skills"],"points":[{"start":1930,"end":1930,"text":"R"}]},{"label":["Location"],"points":[{"start":1078,"end":1086,"text":"Hyderabad"}]},{"label":["Skills"],"points":[{"start":1021,"end":1021,"text":"R"}]},{"label":["Skills"],"points":[{"start":1014,"end":1014,"text":"R"}]},{"label":["Skills"],"points":[{"start":1002,"end":1002,"text":"R"}]},{"label":["Skills"],"points":[{"start":865,"end":870,"text":"Python"}]},{"label":["Skills"],"points":[{"start":722,"end":722,"text":"R"}]},{"label":["Skills"],"points":[{"start":698,"end":703,"text":"Python"}]},{"label":["Skills"],"points":[{"start":692,"end":692,"text":"R"}]},{"label":["Skills"],"points":[{"start":641,"end":644,"text":"Hive"}]},{"label":["Skills"],"points":[{"start":628,"end":628,"text":"R"}]},{"label":["Skills"],"points":[{"start":621,"end":626,"text":"Python"}]},{"label":["Skills"],"points":[{"start":491,"end":497,"text":"BigData"}]},{"label":["Skills"],"points":[{"start":464,"end":467,"text":"Hive"}]},{"label":["Skills"],"points":[{"start":438,"end":443,"text":"Hadoop"}]},{"label":["Name"],"points":[{"start":0,"end":17,"text":"Karthik Karumanchi"}]}],"extras":null,"metadata":{"first_done_at":1532667421000,"last_updated_at":1532667421000,"sec_taken":85,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "KAVITA PANDEY\nBangalore, Karnataka C: 9008053875 | kavi.daiict@gmail.com\n\nProfile Summary\n7 years of experience in Data Engineering, Analytics and Data Science. Worked across various industries: Online Retail, Finance and Publishing, including an Indian start-up Can switch roles between a Data-engineer and a Data-Scientist with ease\nCan work across multiple technologies and programming languages with ease\nSkills\nLanguage and API: Python, SQL, R, Pandas, NLTK, Numpy, Scikit\nPlatform: Hadoop, AWS, Google\nCloud\nDatabase: PostgresSQL 9.0,\nTeradata, MongoDB, DynamoDB,\nRedshift\nAlgorithm: Collaborative Filtering, NLP, Linear Regression, Artificial Intelligence\nNaive Bayes, Decision Trees, Ensemble Algorithms,\nBoosting, Logistic Regression, K-Nearest Neighbours\nExperience\nMachine Learning Lead\nDec 2016 to Nov 2017\nAffine Analytics － Bangalore, Karnataka\nCreated item recommendations for customers using collaborative filtering writing multiple map-reduce scripts\nImplemented language-modelling on customer transaction data to predict subsequent product transactions for customers\nSenior Data Scientist Apr 2013 to Dec 2016 Time Inc. (World's biggest publishing house) － Bangalore, Karnataka\nWorked through multiple Python APIs, including Social Media APIs, like Facebook graph API, Twitter API, Pinterest API etc.\nWorked on Text Mining to do sentiment analysis for Facebook comments, Twitter and websites feedbacks\nWorked on Topic Modelling to identify best topics around a given subject as provided by the sales team\nWorked on look-alike modelling, applying logistic regression on the data. Worked on Article recommendation system, based on collaborative filtering. Worked on Market Basket Analysis, to propose solutions for cross-selling of magazines\nAnalyst\nSep 2011 to Jan 2013\nTesco (World's third largest retailer) Sep 2011 to Jan 2013－ Bangalore, Karnataka\nLead the Web-Analytics for non-Food unit\nWorked on customer segmentation, to maintain loyalty dataware house Worked through CRM for segmentation and targeting\nAnalysed the Market-Share, Campaigns, Promotions and Seasonality\nWorked on multiple adhoc-analysis to study the impact of campaigns and events launched on Tesco's Non-Food Website\nAnalysed the Web-Traffic for Tesco's Non Food business as well as for Competitors in Non-Food business including Click stream, Demographic and Mosaic-Group analysis\nOptimized all standard SQL queries written across the team\nLead the interns in the team, and helped them develop technically and analytically\nSoftware Developer\nJul 2010 to Aug 2011\nVerse Innovation Pvt. Ltd (DailyHunt) － Bangalore, Karnataka\nAnalysed massive and highly complex data sets, performing ad-hoc analysis and data manipulation\nCreated reports using Shell Scripts, SQL and Excel Sheets to extract data for analysis to be used by Sales Team and Operations\nOptimised complex queries, maintained dashboards and created datawarehouse\nEducation and Training\n\tB.Tech (ICT)\n\t2010\n\n\nDhirubhai Ambani Institute Of Information And COmmunication Technology － Gandhinagar, Gujarat, India\nCertifications\nIntroduction To Recommendation Systems(Coursera, University of Minnesotta)\nDataSift Pylon\nActivities and Honors\nGot multiple \"Value-Awards\" in Tesco\nExtra-Miller at Time Inc. for 2013-14\nConducted R workshops","annotation":[{"label":["Skills"],"points":[{"start":3272,"end":3272,"text":"R"}]},{"label":["Skills"],"points":[{"start":3091,"end":3091,"text":"R"}]},{"label":["Education"],"points":[{"start":2938,"end":2943,"text":"B.Tech"}]},{"label":["Skills"],"points":[{"start":2749,"end":2751,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":2595,"end":2603,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":2396,"end":2398,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1994,"end":1994,"text":"R"}]},{"label":["Skills"],"points":[{"start":1848,"end":1856,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":1220,"end":1225,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1175,"end":1183,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":838,"end":846,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":732,"end":732,"text":"R"}]},{"label":["Skills"],"points":[{"start":627,"end":627,"text":"R"}]},{"label":["Skills"],"points":[{"start":570,"end":570,"text":"R"}]},{"label":["Skills"],"points":[{"start":532,"end":534,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":447,"end":447,"text":"R"}]},{"label":["Skills"],"points":[{"start":442,"end":444,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":434,"end":439,"text":"Python"}]},{"label":["Skills"],"points":[{"start":202,"end":202,"text":"R"}]},{"label":["Location"],"points":[{"start":14,"end":22,"text":"Bangalore"}]},{"label":["Name"],"points":[{"start":0,"end":12,"text":"KAVITA PANDEY"}]}],"extras":null,"metadata":{"first_done_at":1532668339000,"last_updated_at":1532668339000,"sec_taken":94,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Udaya Laxmi Ch\n\nEmail : laxmi.udaya@gmail.com\n\n\t\n\n\tPhone: -9740606990\n\t\n\n\n\tSummary\n\n\t· 9.5 years of experience in Software Development.\n· 3.5 years of experience in Machine Learning\n· Primary Skills – Machine Learning, R programming, Lotus Notes.\n· Presently working for Wipro Technologies, Bangalore.\n· Experience in planning, estimation, design, development, and testing object oriented applications.\n· Experience in preparing various technical documents like Functional Specs, HLD, LLD, Flowcharts and Test cases.\n· Sound Knowledge in Object Oriented Design Principles\n· Have Team Handling experience.\n· Domain experience of Manufacturing and Finance.\n· Have Experience in Scrum Agile Model\n· Understand business requirements from clients\n\n\n\n\tTechnical Skills\n\n\tKey skills: \n\tMachine Learning,R Programming, MySQL, PostgreSQL, Microsoft Access, SQL Server, FileMaker, Oracle, RDBMS, dBASE, Clipper, FoxPro, Firebase, Mongodb, Python,  ava, J2EE, Oracle Fusion,Oracle Cloud, Salesforce, Devops Android, Business Analyst, UI Developer, DBAs, Embedded Systems, .NET, Hadoop, SQL Developer, Big Data, Tableau, Networking, Etl, Informatica, Ios, Quality Analyst, Project Manager, Python, Data Science, Python, Machine Learning, SAS, Java, Scala, Hadoop, Hive, Bigdata, Programming, SQL server reporting, Msbi Ssis, Ssrs, Msbi, Sql Reporting, Artificial Intelligence, Pandas, Pyspark, Sklearn, Flask, Django, Map Reduce, Parametric Design, Modeling, Regression, Patterns, Data Mining, Text Mining, Oops, Deep Learning, Web Analytics, Time Series, Regression, Tensorflow, Azure, Linear Regression, Logistic Regression, Decision Tree, Random Forest, Data Structure, Computer Vision, IHS, WAS, Java EE, SQL Server, .NET core, C#, ASP.NET, Rdlc, Linq, Sql, Web Api, Mvc, Javascript, Web Services, Oracle, MS SQL, PHP, Laravel, CodeIgniter, Symfony, Zend, Phalcon, CakePHP, Yii, FuelPHP, React, Vue, Angular, Ember, Backbone, Lotus Notes\n\n\tAlgorithms:\n\tNaïve Bayes, K means clustering,Word Cloud\n\n\tDatabases: \n\tMicrosoft SQL, Mongo DB\n\n\tWeb Technologies: \n\tXML, XSLT, HTML,  JavaScript,  AJAX, JQuery\n\n\tIDE:\n\tR studio,Pycharm\n\n\n\tProfessional Experience\n\n\tCurrent Employer :\n\tWipro Technologies., Bangalore  – (Oct  2010  to till date) – Technical Lead/Data Scientist\n\n\tPrevious Employers :\n\tHSBC Software development , Hyderabad (June  2008  to Sep 2010)  - SE\n\n\n\tQualification\n\n\tDegree\n\tCollege\n\tUniversity/Board\n\tYear\n\tPercentage (%)\n\n\tMCA\n\tNizam College, Basheerbagh,Hyderabad\n\tOsmania University\n\t2008\n\t75\n\n\n\tProject Experience \n\n\tProject 1 : Exploratory Data Analysis:\n\nProject Description:   Performed EDA analysis to analyze the Purchase frequency of vehicles which occurred over past 3 years and try to predict the frequency occurring in the future.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Performed EDA analysis to find the insights of the data. Observed the summary of each and every variable to understand the variables.\n\n· Performed the feature selection using hypothesis testing.\n\n· Identified the outliers using box plot.\n\n· Identified the trend in the purchases using histogram.\n\n\n\n\tProject 2: Word Cloud Analysis:\n\nProject Description:   Performed Word cloud and Sentimental Analysis of the customer feedbacks. Graphically represented the most frequently occurred words through Word cloud. Through sentimental analysis we identified whether a user-generated text expresses positive, negative or neutral opinion.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Created a Corpus using TM package and performed pre-processing of data.\n\n· Removed the punctuations, stemming and stop words which are of no analytical value.\n\n· Built a Document term matrix and identified the most frequently occurring words\n\n· Graphically represented it using  RColorbrewer Package\n\n\n\tProject 3: Sentimental Analysis:\n\nProject Description: Performed Sentimental Analysis of customer feedbacks through Naïve Bayes. Used “e1071” Package for implementing naïve Bayes method.\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· The DTM created using TM package was an input to the Naive Bayes Model.\n\n· As Naive Bayes classifier is typically trained on data with categorical features. We have converted the count of the words into a factor variable that indicates Yes or No whether the word is present or not.\n\n\tProject 4: Clustering Analysis:\n\nProject Description: Classified the customers on the basis of their purchases whether they have purchased low variant or high variant trucks. It in turn helped in building the right customer strategies.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Performed data preparation and Normalization of data using min-max method.\n\n· As K-means algorithm groups a dataset into a user-specified number (k) of clusters. Identified the initial cluster centroids as 3.\n\n· K clusters are creating by associating every observation with the nearest mean.\n\n· Used elbow method to validate the number of clusters such that within-cluster sum of square(wss) is minimized.\n\n\n\n\tProject 5 : Inter Connection Management Tool\nProject Description: Inter-connection Management (IMT) is prototype being developed for Engineering and Sales department to handle customizations of an existing product based on the customer's requirement. Users from engineering department will identify the items, which need to be customized out of the entire product design.\nRole\n\n       : Module Lead\n\nEnvironment\n       : Python, Mongo DB, jQuery\n\nTasks handled:\n\n· Gathering Requirements and providing Project Plan and Effort Estimation details.\n\n· Understanding business requirements and preparing SoU (Statement of Understanding) and Functional/Technical Specification documents.\n\n· Providing Effort & Resource estimations\n\n· Planning for application development and deployment\n\n· Writing and executing Test Cases and Test scenarios\n\n· Creating design elements using Technical Specification.\n\n· Performing Unit testing & Peer Reviews\n\n· Work Allocation and mentoring the team\n\n· Providing Technical guidance to the team. \n\n\tProject 6\n: cvdAEI Application\n\nProject Description\n     : CVDAEI is a web based multilingual application developed for handling the Change Management process in Truck division of Daimler. The change request flows through different phases mainly Initialization, Evaluation, Decision and Conclusion. This application has a configurable workflow where the request flow and the responsible persons can be configured easily at any point of time. \n\nRole\n\n    : Developer/Tester\n\nEnvironment\n     : Lotus Notes, Java, HTML, XML, Java Script, JQuery\n\nTasks handled:\n\n· Gathering Requirements and providing Project Plan and Effort Estimation details.\n\n· Understanding business requirements and preparing SoU (Statement of Understanding) and Functional/Technical Specification documents.\n\n· Providing Effort & Resource estimations\n\n· Planning for application development and deployment\n\n· Writing and executing Test Cases and Test scenarios\n\n· Creating design elements using Technical Specification.\n\n· Performing Unit testing & Peer Reviews\n\n· Work Allocation and mentoring the team\n\n· Providing Technical guidance to the team. \n\n\n\n\tProject Title: Project Management Office \nProject Description: The purpose of this system is to enable the Project Management Office to manage and execute the IT Applications and Operations driven project tasks in  more systematic manner. It will also enable them to efficiently perform a role as a facilitator to coordinate various IT Operations teams and to ensure that project activity enters the department through one common interface. The project tasks will subsequently be dealt with in a common format and in a consistent and appropriate manner, ensuring open and regular communication between all involved parties.\n\nRole\n\n    : Developer/Tester\n\nEnvironment\n     : Lotus Notes, Java, HTML, XML, Java Script, JQuery\n\nTasks Handled :\n\n· Writing and Executing Test cases in client server based environment\n· Individually provided application support","annotation":[{"label":["Skills"],"points":[{"start":7951,"end":7956,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":7938,"end":7948,"text":"Java Script"}]},{"label":["Skills"],"points":[{"start":7933,"end":7935,"text":"XML"}]},{"label":["Skills"],"points":[{"start":7927,"end":7930,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":7921,"end":7924,"text":"Java"}]},{"label":["Skills"],"points":[{"start":7908,"end":7918,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":6645,"end":6650,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":6632,"end":6642,"text":"Java Script"}]},{"label":["Skills"],"points":[{"start":6627,"end":6629,"text":"XML"}]},{"label":["Skills"],"points":[{"start":6621,"end":6624,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":6615,"end":6618,"text":"Java"}]},{"label":["Skills"],"points":[{"start":6602,"end":6612,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":5522,"end":5527,"text":"jQuery"}]},{"label":["Skills"],"points":[{"start":5512,"end":5519,"text":"Mongo DB"}]},{"label":["Skills"],"points":[{"start":5504,"end":5509,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4645,"end":4652,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":4054,"end":4061,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":3941,"end":3951,"text":"Naïve Bayes"}]},{"label":["Skills"],"points":[{"start":3494,"end":3501,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":3132,"end":3141,"text":"Word Cloud"}]},{"label":["Skills"],"points":[{"start":2793,"end":2800,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":2110,"end":2116,"text":"Pycharm"}]},{"label":["Skills"],"points":[{"start":2101,"end":2108,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":2086,"end":2091,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":2080,"end":2083,"text":"AJAX"}]},{"label":["Skills"],"points":[{"start":2067,"end":2076,"text":"JavaScript"}]},{"label":["Skills"],"points":[{"start":2060,"end":2063,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":2054,"end":2057,"text":"XSLT"}]},{"label":["Skills"],"points":[{"start":2049,"end":2051,"text":"XML"}]},{"label":["Skills"],"points":[{"start":2018,"end":2025,"text":"Mongo DB"}]},{"label":["Skills"],"points":[{"start":2003,"end":2015,"text":"Microsoft SQL"}]},{"label":["Skills"],"points":[{"start":1977,"end":1986,"text":"Word Cloud"}]},{"label":["Skills"],"points":[{"start":1958,"end":1975,"text":"K means clustering"}]},{"label":["Skills"],"points":[{"start":1945,"end":1955,"text":"Naïve Bayes"}]},{"label":["Skills"],"points":[{"start":1918,"end":1928,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":1908,"end":1915,"text":"Backbone"}]},{"label":["Skills"],"points":[{"start":1901,"end":1905,"text":"Ember"}]},{"label":["Skills"],"points":[{"start":1892,"end":1898,"text":"Angular"}]},{"label":["Skills"],"points":[{"start":1887,"end":1889,"text":"Vue"}]},{"label":["Skills"],"points":[{"start":1880,"end":1884,"text":"React"}]},{"label":["Skills"],"points":[{"start":1871,"end":1877,"text":"FuelPHP"}]},{"label":["Skills"],"points":[{"start":1866,"end":1868,"text":"Yii"}]},{"label":["Skills"],"points":[{"start":1857,"end":1863,"text":"CakePHP"}]},{"label":["Skills"],"points":[{"start":1848,"end":1854,"text":"Phalcon"}]},{"label":["Skills"],"points":[{"start":1842,"end":1845,"text":"Zend"}]},{"label":["Skills"],"points":[{"start":1833,"end":1839,"text":"Symfony"}]},{"label":["Skills"],"points":[{"start":1820,"end":1830,"text":"CodeIgniter"}]},{"label":["Skills"],"points":[{"start":1811,"end":1817,"text":"Laravel"}]},{"label":["Skills"],"points":[{"start":1806,"end":1808,"text":"PHP"}]},{"label":["Skills"],"points":[{"start":1798,"end":1803,"text":"MS SQL"}]},{"label":["Skills"],"points":[{"start":1790,"end":1795,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":1776,"end":1787,"text":"Web Services"}]},{"label":["Skills"],"points":[{"start":1764,"end":1773,"text":"Javascript"}]},{"label":["Skills"],"points":[{"start":1759,"end":1761,"text":"Mvc"}]},{"label":["Skills"],"points":[{"start":1750,"end":1756,"text":"Web Api"}]},{"label":["Skills"],"points":[{"start":1745,"end":1747,"text":"Sql"}]},{"label":["Skills"],"points":[{"start":1739,"end":1742,"text":"Linq"}]},{"label":["Skills"],"points":[{"start":1733,"end":1736,"text":"Rdlc"}]},{"label":["Skills"],"points":[{"start":1724,"end":1730,"text":"ASP.NET"}]},{"label":["Skills"],"points":[{"start":1720,"end":1721,"text":"C#"}]},{"label":["Skills"],"points":[{"start":1709,"end":1717,"text":".NET core"}]},{"label":["Skills"],"points":[{"start":1697,"end":1706,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":1688,"end":1694,"text":"Java EE"}]},{"label":["Skills"],"points":[{"start":1683,"end":1685,"text":"WAS"}]},{"label":["Skills"],"points":[{"start":1678,"end":1680,"text":"IHS"}]},{"label":["Skills"],"points":[{"start":1661,"end":1675,"text":"Computer Vision"}]},{"label":["Skills"],"points":[{"start":1645,"end":1658,"text":"Data Structure"}]},{"label":["Skills"],"points":[{"start":1630,"end":1642,"text":"Random Forest"}]},{"label":["Skills"],"points":[{"start":1615,"end":1627,"text":"Decision Tree"}]},{"label":["Skills"],"points":[{"start":1594,"end":1612,"text":"Logistic Regression"}]},{"label":["Skills"],"points":[{"start":1575,"end":1591,"text":"Linear Regression"}]},{"label":["Skills"],"points":[{"start":1568,"end":1572,"text":"Azure"}]},{"label":["Skills"],"points":[{"start":1556,"end":1565,"text":"Tensorflow"}]},{"label":["Skills"],"points":[{"start":1544,"end":1553,"text":"Regression"}]},{"label":["Skills"],"points":[{"start":1531,"end":1541,"text":"Time Series"}]},{"label":["Skills"],"points":[{"start":1516,"end":1528,"text":"Web Analytics"}]},{"label":["Skills"],"points":[{"start":1501,"end":1513,"text":"Deep Learning"}]},{"label":["Skills"],"points":[{"start":1495,"end":1498,"text":"Oops"}]},{"label":["Skills"],"points":[{"start":1482,"end":1492,"text":"Text Mining"}]},{"label":["Skills"],"points":[{"start":1469,"end":1479,"text":"Data Mining"}]},{"label":["Skills"],"points":[{"start":1459,"end":1466,"text":"Patterns"}]},{"label":["Skills"],"points":[{"start":1447,"end":1456,"text":"Regression"}]},{"label":["Skills"],"points":[{"start":1437,"end":1444,"text":"Modeling"}]},{"label":["Skills"],"points":[{"start":1418,"end":1434,"text":"Parametric Design"}]},{"label":["Skills"],"points":[{"start":1406,"end":1415,"text":"Map Reduce"}]},{"label":["Skills"],"points":[{"start":1398,"end":1403,"text":"Django"}]},{"label":["Skills"],"points":[{"start":1391,"end":1395,"text":"Flask"}]},{"label":["Skills"],"points":[{"start":1382,"end":1388,"text":"Sklearn"}]},{"label":["Skills"],"points":[{"start":1373,"end":1379,"text":"Pyspark"}]},{"label":["Skills"],"points":[{"start":1365,"end":1370,"text":"Pandas"}]},{"label":["Skills"],"points":[{"start":1340,"end":1362,"text":"Artificial Intelligence"}]},{"label":["Skills"],"points":[{"start":1325,"end":1337,"text":"Sql Reporting"}]},{"label":["Skills"],"points":[{"start":1325,"end":1327,"text":"Sql"}]},{"label":["Skills"],"points":[{"start":1319,"end":1322,"text":"Msbi"}]},{"label":["Skills"],"points":[{"start":1313,"end":1316,"text":"Ssrs"}]},{"label":["Skills"],"points":[{"start":1302,"end":1310,"text":"Msbi Ssis"}]},{"label":["Skills"],"points":[{"start":1302,"end":1305,"text":"Msbi"}]},{"label":["Skills"],"points":[{"start":1280,"end":1299,"text":"SQL server reporting"}]},{"label":["Skills"],"points":[{"start":1267,"end":1277,"text":"Programming"}]},{"label":["Skills"],"points":[{"start":1258,"end":1264,"text":"Bigdata"}]},{"label":["Skills"],"points":[{"start":1252,"end":1255,"text":"Hive"}]},{"label":["Skills"],"points":[{"start":1244,"end":1249,"text":"Hadoop"}]},{"label":["Skills"],"points":[{"start":1237,"end":1241,"text":"Scala"}]},{"label":["Skills"],"points":[{"start":1231,"end":1234,"text":"Java"}]},{"label":["Skills"],"points":[{"start":1226,"end":1228,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1208,"end":1223,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1200,"end":1205,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1186,"end":1197,"text":"Data Science"}]},{"label":["Skills"],"points":[{"start":1178,"end":1183,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1161,"end":1175,"text":"Project Manager"}]},{"label":["Skills"],"points":[{"start":1144,"end":1158,"text":"Quality Analyst"}]},{"label":["Skills"],"points":[{"start":1139,"end":1141,"text":"Ios"}]},{"label":["Skills"],"points":[{"start":1126,"end":1136,"text":"Informatica"}]},{"label":["Skills"],"points":[{"start":1121,"end":1123,"text":"Etl"}]},{"label":["Skills"],"points":[{"start":1109,"end":1118,"text":"Networking"}]},{"label":["Skills"],"points":[{"start":1100,"end":1106,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":1090,"end":1097,"text":"Big Data"}]},{"label":["Skills"],"points":[{"start":1075,"end":1087,"text":"SQL Developer"}]},{"label":["Skills"],"points":[{"start":1067,"end":1072,"text":"Hadoop"}]},{"label":["Skills"],"points":[{"start":1061,"end":1064,"text":".NET"}]},{"label":["Skills"],"points":[{"start":1043,"end":1058,"text":"Embedded Systems"}]},{"label":["Skills"],"points":[{"start":1037,"end":1040,"text":"DBAs"}]},{"label":["Skills"],"points":[{"start":1023,"end":1034,"text":"UI Developer"}]},{"label":["Skills"],"points":[{"start":1005,"end":1020,"text":"Business Analyst"}]},{"label":["Skills"],"points":[{"start":989,"end":1002,"text":"Devops Android"}]},{"label":["Skills"],"points":[{"start":977,"end":986,"text":"Salesforce"}]},{"label":["Skills"],"points":[{"start":963,"end":974,"text":"Oracle Cloud"}]},{"label":["Skills"],"points":[{"start":949,"end":961,"text":"Oracle Fusion"}]},{"label":["Skills"],"points":[{"start":943,"end":946,"text":"J2EE"}]},{"label":["Skills"],"points":[{"start":929,"end":934,"text":"Python"}]},{"label":["Skills"],"points":[{"start":920,"end":926,"text":"Mongodb"}]},{"label":["Skills"],"points":[{"start":910,"end":917,"text":"Firebase"}]},{"label":["Skills"],"points":[{"start":902,"end":907,"text":"FoxPro"}]},{"label":["Skills"],"points":[{"start":893,"end":899,"text":"Clipper"}]},{"label":["Skills"],"points":[{"start":886,"end":890,"text":"dBASE"}]},{"label":["Skills"],"points":[{"start":879,"end":883,"text":"RDBMS"}]},{"label":["Skills"],"points":[{"start":871,"end":876,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":860,"end":868,"text":"FileMaker"}]},{"label":["Skills"],"points":[{"start":848,"end":857,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":830,"end":845,"text":"Microsoft Access"}]},{"label":["Skills"],"points":[{"start":818,"end":827,"text":"PostgreSQL"}]},{"label":["Skills"],"points":[{"start":811,"end":815,"text":"MySQL"}]},{"label":["Skills"],"points":[{"start":798,"end":808,"text":"Programming"}]},{"label":["Skills"],"points":[{"start":796,"end":808,"text":"R Programming"}]},{"label":["Skills"],"points":[{"start":779,"end":794,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":234,"end":244,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":219,"end":231,"text":"R programming"}]},{"label":["Skills"],"points":[{"start":201,"end":216,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":165,"end":180,"text":"Machine Learning"}]},{"label":["Name"],"points":[{"start":0,"end":13,"text":"Udaya Laxmi Ch"}]}],"extras":null,"metadata":{"first_done_at":1579625576000,"last_updated_at":1579626369000,"sec_taken":0,"last_updated_by":"aJOmJy1lvpOYFetVNuqLvFo9Vx42","status":"done","evaluation":"NONE"}}
{"content": "Krish Naik\t\t\t\t\t\t\t\t\t\nE-mail: krishnaik06@gmail.com  \t \t      \t  \t             Mobile :  +91 9899399757\nProfile\n\tSummary: Developer with proven experience in architecting and developing web applications with Algorithms,Data stuctures,Binary tree,Machine Learning,Spark Pyspark,Python with libraries such as Sklearn,numpy,Pandas,Quandl,Seaborn,HDFS,C#,ASP.NET MVC,Sitecore CMS,Solr 5.5.1,MVC , SQL Server, AJAX and XML. I have also done some internal projects in Hadoop Big Data,written Map Reduce frameworks PySpark with python.Recognized by managers, colleagues, and peers as a personable, dedicated performer who demonstrates innovation, communication, and teamwork to ensure quality, timely project completion.\n· 5.9  years of experience in Software Development and Project Implimentation and 3 years experience as Data Scientist Machine Learning Artificial Intelligence NLP and Python.\n· Presently associated Honeywell Technology solution  as Tech Lead\n· Previously associated Sapient Consultancy Limited  as Senior Associate L1.\n· Previously associated with HCL Technologies Limited  as Software Developer.\n· Programming Languages: Python,Machine Learning,Spark, Pyspark,Sklearn Libraries,ASP.NET (v4.6 and prior), C#, Sitecore CMS(8.0,8.1,8.2),SOLR 5.5.1.\n· Databases: Hadoop HDFS,SQL Server 2014/2012/2008/2005,Mysql, Basic knowledge in Oracle.\n· Platforms and Misc: Visual Studio 2017,VS 2016, IIS, Windows XP/W7/W8\n· Other Skills:  All phases of the software development life-cycle (requirements, design, development, testing, release, support), utilizing multiple development methodologies, including Design Patterns, OOD, Extreme Programming, and Structured Programming.\n· Possess good interpersonal skills that have been put to good use in co-coordinating with Project teams and providing customized software solutions.\n· Team player with effective communication skills and proven abilities in resolving complex issues.\n\n\n\nEmployment Scan\n\nDec 17 to Current\t           Honeywell Technology Solution\t\tTech Lead\nApril 14 to Dec 2017\t            Sapient Consultancy  Limited\t\tSenior Associate L1\nDec’ 11\tto April 2014\t\tHCL Technologies  Limited\t\tSoftware Developer\n\nFunctional\n\n· Delivering and implementing the project as per scheduled milestones. Participating in Onsite deployment, customer support and product up-gradation.\n· Interacting with the onshore team for requirements gathering, analysis, and implementations.\n· Structural designing & coding of solution for developing new applications.\n· Designing, coding and validating forms; coding programs and finally integrating them.\nAcademia\n2011\t\tB.Tech (Computer Science Engineering) from PDA College of                       \n                        Engineering,Gulbarga,Karnataka University. Secured 9.24 CGPA\n2007\t\t12th from St Philomena P.U College, Mysore. Secured 74.33%.\n2005\t\t10th from Mount Carmel Convent School, Gulbarga,Karnataka. Secured 83.52%.\n\n\nREPRESENTATIVE PROJECT EXPERIENCE SUMMARY\n\tClient\n\tProject\n\tTechnology\n\tRoles and Responsibilities\n\t  Duration     (in months)\n\n\tHoneywell Portals\n\tHoneywell\n\tMachine Learning, Python,Sklearn,Spark Pyspark,Hadoop,HDFS\n\t· Senior Developer\n\tCurrent project\n\n\tHowdens\n\tHowdens\n\tSitecore 8.2, ASP.net MVC,Solr,Machine Learning,Python\n\t· Senior Developer\n\t8 months\n\n\tGAF\n\tGAF\n\tSitecore 8.1, ASP.net MVC,Solr,Machine Learning,Python\n\t· Senior Developer\n\t4 months\n\n\tSunsuper\n\tSunsuper\n\tSitecore 8.0, ASP.net MVC,Solr,Python,Machine Learning\n\t· Senior Developer\n\t1 year\n\n\tChina Airlines\n\tChina Airlines\n\tMVC5,Asp.net 4.5,SQL server,Sitecore 7.2 CMS,Jquery,Angular js\n\t· Developer\n\t1 year\n\n\tBoston Consulting Group\n\tBCG.com-maintainenece\n\tMVC ,Jquery,Nhibernate,Tridion,Sql Server\n\t· Developer\n\t13\n\n\tCannacord Genuity(U.K)\n\tQuest Plus Maintanence\n\tASP.NET, C#.NET 3.5, MVC,Jquery JavaScript,Sql Server 2008\n\t· Developer\n\t14\n\n\tCooperation Pharmacy\n\tLocum\n\tASP.NET, C#.NET 4.0,Linq,JavaScript,Sql Server 2008\n\t· Developer\n\t6\n\n\tYahoo\n\tMigration of EMEA Websites from Legacy to Lego Platform \n\tJava,PHP,MYSQL,AJAX, JavaScript, HTML, CSS\n\t·  Developer\n\t5\n\n\n\nKey Projects Handled \n\n\n\t1.PROJECT TITLE \n\tHowdens\n\n\n\n\tCLIENT \n\tHowden\n\n\tDURATION \n\tSept 2017- running\n\n\tROLE \n\tData Scientist and Sitecore .net senior developer\n\n\tPROJECT SPECIFIC SKILLS \n\t MVC, C#.NET 4.6,Python, Machine Learning,Sql Server 2014,XML,Sitecore CMS 8.2,SOLR\n\n\n\nDESCRIPTION OF THE PROJECT\nHowdens Joinery can plan your perfect kitchen from over 60 ranges, complete with Lamona appliances, at over 600 depots across the UK via the small builder.\nResponsibilities\n· Interacted with onsite coordinator and gathered requirements.\n· Understanding Client requirements.\n· Designing, coding and validating forms, coding programs and finally integrating them.\n· Involved in designing ER modelling, LLD, HLD.\n· Worked as Offshore Developer and involved in all Phases of CR and Defects.\n· Involved in Unit testing and Unit testing document creation.\n· Involved in Performance tuning and stored procedure optimization activity in SQL Server.\n\n\n\n\t1.PROJECT TITLE \n\tGAF\n\n\n\n\tCLIENT \n\tGAF\n\n\tDURATION \n\tApril 2017- Sept 2017\n\n\tROLE \n\tSitecore .net developer\n\n\tPROJECT SPECIFIC SKILLS \n\t Python,MVC,C#.NET 4.5,Machine Learning,Sql Server 2014,Sitecore CMS 8.1,SOLR\n\n\n\nDESCRIPTION OF THE PROJECT\nRoofing shingles and materials, plus factory-certified roofers (including ratings from real homeowners!) from North America's largest roofing manufacturer\nResponsibilities\n· Interacted with onsite coordinator and gathered requirements.\n· Understanding Client requirements.\n· Designing, coding and validating forms, coding programs and finally integrating them.\n· Involved in designing ER modelling, LLD, HLD.\n· Worked as Offshore Developer and involved in all Phases of CR and Defects.\n· Involved in Unit testing and Unit testing document creation.\n· Involved in Performance tuning and stored procedure optimization activity in SQL Server.\n\n\n\n\t1.PROJECT TITLE \n\tSunsuper\n\n\n\n\tCLIENT \n\tSunsuper\n\n\tDURATION \n\tJune 25 2016-April 2017\n\n\tROLE \n\tData Scientist and Sitecore .net developer\n\n\tPROJECT SPECIFIC SKILLS \n\t Python,Machine Learning,MVC,C#.NET 4.5,Asp .net,Sql Server 2012,XML,Sitecore CMS 8.0,SOLR\n\n\n\nDESCRIPTION OF THE PROJECT\nThis project is a insurance  domain project where we design a web based application where we can do all the functionalities of getting details of insurances and plan our old age in a better way globally.\nResponsibilities\n· Understanding Client requirements.\n· Designing, coding and validating forms, coding programs and finally integrating them.\n· Involved in designing ER modelling, LLD, HLD.\n· Worked as Offshore Developer and involved in all Phases of CR and Defects.\n· Involved in Unit testing and Unit testing document creation.\n· Involved in Performance tuning and stored procedure optimization activity in SQL Server.\n\n\n\t1.PROJECT TITLE \n\tChina Airlines\n\n\n\n\tCLIENT \n\tChina Airlines\n\n\tDURATION \n\tAug 31st 2015-running\n\n\tROLE \n\tDeveloper\n\n\tPROJECT SPECIFIC SKILLS \n\t MVC,Jquery, C#.NET 3.5, JavaScript,Sql Server 2008,XML,Tridian\n\n\n\nDESCRIPTION OF THE PROJECT\nThis project is a travel domain project where we design a web based application where we can do all the functionalities of a ticket booking site which includes searching  flight tickets,book flight, cancel tickets globally.\nResponsibilities\n· Designing, coding and validating forms, coding programs and finally integrating them.\n· Involved in designing ER modelling, LLD, HLD.\n· Worked as Offshore Developer and involved in all Phases of CR and Defects.\n· Involved in Unit testing and Unit testing document creation.\n· Involved in Performance tuning and stored procedure optimization activity in SQL Server.\n· Interacted with onsite coordinator and gathered requirements.\n· Understanding Client requirements.\n\n\n\n\t1.PROJECT TITLE \n\tQuest Plus Maintanence\n\n\n\n\tCLIENT \n\tCannacord Genuity(U.K)\n\n\tDURATION \n\tMarch 5th 2013- April 1st 2014\n\n\tROLE \n\tDeveloper\n\n\tPROJECT SPECIFIC SKILLS \n\tASP.NET,Windows form, C#.NET 3.5, JavaScript,Sql Server 2008,XML,Classic ASP\n\n\n\nDESCRIPTION OF THE PROJECT\nCanaccord Genuity is a global, full-service investment bank focused on growth companies, with operations in 11 countries worldwide and the ability to list companies on 10 stock exchanges .Canaccord Genuity is the global capital markets division of Canaccord Financial Inc. (CF : TSX | CF. : LSE), offering institutional and corporate clients idea-driven investment banking, research, sales and trading services.  \nThis project  deals with the maintainence and development of a website (www.csquest.com) which shows all the information regarding the various stocks of many European companies which helps the client or the registered users to buy stocks based on the analysis of the statistics information. There are much information such as previous stock price, the new stock and the various others factors which helps the user to buy the stocks. This project is based on the Microsoft SQL Server Write Side XML Three Tier Architecture which uses IIS 6 as the web server, Active Server Pages and COM objects to implement the flow and functionality. The primary data format used is XML as this gives a standard data format that is supported by SQL Server 2008.\n\nResponsibilities\n· Interacted with onsite coordinator and gathered requirements.\n· Understanding Client requirements.\n· Designing, coding and validating forms, coding programs and finally integrating them.\n· Involved in designing ER modelling, LLD, HLD.\n· Worked as Offshore Developer and involved in all Phases of CR and Defects.\n· Involved in Unit testing and Unit testing document creation.\n· Involved in Performance tuning and stored procedure optimization activity in SQL Server.\n\n\t2.PROJECT TITLE \n\tLocum\n\n\n\n\tCLIENT \n\tCooperation Pharmacy\n\n\tDURATION \n\t6 months\n\n\tROLE \n\tDeveloper\n\n\tPROJECT SPECIFIC SKILLS \n\tASP.NET, C#.NET 4.0, JavaScript,Sql Server 2008,XML\n\n\n\nDESCRIPTION OF THE PROJECT\nCo-op Pharmacy business operates around 1000 pharmacy shops known as branches. UK PCT governs operation of these branches. According to their rules & regulation, it is compulsory to have at least one pharmacist available in the branches during their operational hours.Co-op has its own employed pharmacist for every branch. They are known as branch managers.\nThis Project is a employee information management system which acts as a central employee database. This enables HR administrators to utilize all employee information productively.This application deals with the management of these employees with respect to their pay, assign supervisors to an employee to identify the reporting structure, view employee details in the employee list and search using different employee information. This Application basically helps the HR to manage the Employees of an organization.\n\nResponsibilities\n· Interacted with onsite coordinator and gathered requirements.\n· Understanding Client requirements.\n· Delivering and implementing the project as per scheduled milestones. \n· Designing, coding and validating forms, coding programs and finally integrating them.\n· Involved in designing ER modelling, LLD, HLD.\n· Worked as Offshore Developer and involved in all Phases of CR and Defects.\n· Involved in Unit testing and Unit testing document creation.\n· Involved in Performance tuning activity and stored procedure optimization  in SQL Server.\n· Involved in Deployment and post deployment support.\n· Developed stored procedures,views,Triggers in SQL Server 2008.\n\n\n\t3.PROJECT TITLE \n\tMigration of EMEA Websites from Legacy to Lego Platform\n\n\n\n\tCLIENT \n\tYahoo\n\n\tDURATION \n\t5 months\n\n\tROLE \n\tDeveloper\n\n\tPROJECT SPECIFIC SKILLS \n\tPHP,MYSQL,AJAX, JavaScript, HTML, CSS\n\n\n\nDESCRIPTION OF THE PROJECT\nThe advertising sites of the yahoo company and it is the ultimate online entertainment destination, connecting fans with the celebrity news, movies, TV shows and music.\nThis project deals with the migration of websites from the Legacy to the Lego platform with the help of PD2 tool (Producer Desktop). In this project we had to create various modules required while designing the websites and it also dealt with mapping the third party vendors for displaying the articles and blogs in the website.\nResponsibilities\n· Interacted with onsite coordinator and gathered requirements.\n· Understanding Client requirements.\n· Delivering and implementing the project as per scheduled milestones. \n· Involved in designing ER modelling, LLD, HLD.\n· Involved in Unit testing and Unit testing document creation.\n· Involved in Deployment and post deployment support\n\nTraining\n\nAttended 6 days workshop on “Rational Application Developer” conducted by IBM.\nAttended 4 days worshop on “ANDROID:A Mobile Device Opertating System” \n\nStrength\t\n\nPositive Attitude: To progress positively under all circumstances with conviction and maturity in approach.\nAdaptability & Flexibility: To adapt accordingly under the application of adverse or pressure conditions without deviating from critical to quality concerns.\nEnthusiasm for Learning: Endlessly strives to learn through different activities.\n\nPersonal Dossier\n\nDate of Birth\t\t:\t24th September 1989\nSex\t\t\t:\tMale\t\t\nFather’s Name\t\t:\tMr. Chandrashekar Naik\nMother’s Name\t: \tMs. Vidya Naik\nPermanent Address\t:\tFlat no G-05, Royal Mist Apartment,Heelalige,Chandapur,Bangalore\nCurrent Address\t:\tFlat no G-05, Royal Mist Apartment,Heelalige,Chandapur,Bangalore\nNationality\t\t:\tIndian\n\nEndorsement\n\nI hereby declare that the information furnished above is complete and true to the best of my knowledge.\n\nDate:\t\t\t\t\nPlace:  \t\t\t\t\t\t\t\t\t\t               Krish.C.Naik","annotation":[{"label":["Location"],"points":[{"start":13363,"end":13371,"text":"Bangalore"}]},{"label":["Location"],"points":[{"start":13280,"end":13288,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":11636,"end":11645,"text":"JavaScript"}]},{"label":["Skills"],"points":[{"start":9852,"end":9854,"text":"Sql"}]},{"label":["Skills"],"points":[{"start":9841,"end":9850,"text":"JavaScript"}]},{"label":["Skills"],"points":[{"start":9829,"end":9834,"text":"C#.NET"}]},{"label":["Skills"],"points":[{"start":9820,"end":9826,"text":"ASP.NET"}]},{"label":["Skills"],"points":[{"start":7983,"end":7985,"text":"Sql"}]},{"label":["Skills"],"points":[{"start":7972,"end":7981,"text":"JavaScript"}]},{"label":["Skills"],"points":[{"start":7960,"end":7965,"text":"C#.NET"}]},{"label":["Skills"],"points":[{"start":7938,"end":7944,"text":"ASP.NET"}]},{"label":["Skills"],"points":[{"start":6999,"end":7001,"text":"Sql"}]},{"label":["Skills"],"points":[{"start":6988,"end":6997,"text":"JavaScript"}]},{"label":["Skills"],"points":[{"start":6976,"end":6981,"text":"C#.NET"}]},{"label":["Skills"],"points":[{"start":6968,"end":6973,"text":"Jquery"}]},{"label":["Skills"],"points":[{"start":6964,"end":6966,"text":"MVC"}]},{"label":["Skills"],"points":[{"start":6120,"end":6122,"text":"Sql"}]},{"label":["Skills"],"points":[{"start":6100,"end":6105,"text":"C#.NET"}]},{"label":["Skills"],"points":[{"start":6096,"end":6098,"text":"MVC"}]},{"label":["Skills"],"points":[{"start":6079,"end":6094,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":5193,"end":5195,"text":"Sql"}]},{"label":["Skills"],"points":[{"start":5176,"end":5191,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":5165,"end":5170,"text":"C#.NET"}]},{"label":["Skills"],"points":[{"start":5161,"end":5163,"text":"MVC"}]},{"label":["Skills"],"points":[{"start":4301,"end":4303,"text":"Sql"}]},{"label":["Skills"],"points":[{"start":4284,"end":4299,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":4265,"end":4270,"text":"C#.NET"}]},{"label":["Skills"],"points":[{"start":4260,"end":4262,"text":"MVC"}]},{"label":["Skills"],"points":[{"start":4027,"end":4036,"text":"JavaScript"}]},{"label":["Skills"],"points":[{"start":3907,"end":3909,"text":"Sql"}]},{"label":["Skills"],"points":[{"start":3896,"end":3905,"text":"JavaScript"}]},{"label":["Skills"],"points":[{"start":3880,"end":3885,"text":"C#.NET"}]},{"label":["Skills"],"points":[{"start":3871,"end":3877,"text":"ASP.NET"}]},{"label":["Skills"],"points":[{"start":3807,"end":3809,"text":"Sql"}]},{"label":["Skills"],"points":[{"start":3796,"end":3805,"text":"JavaScript"}]},{"label":["Skills"],"points":[{"start":3789,"end":3794,"text":"Jquery"}]},{"label":["Skills"],"points":[{"start":3785,"end":3787,"text":"MVC"}]},{"label":["Skills"],"points":[{"start":3773,"end":3778,"text":"C#.NET"}]},{"label":["Skills"],"points":[{"start":3764,"end":3770,"text":"ASP.NET"}]},{"label":["Skills"],"points":[{"start":3686,"end":3688,"text":"Sql"}]},{"label":["Skills"],"points":[{"start":3660,"end":3665,"text":"Jquery"}]},{"label":["Skills"],"points":[{"start":3655,"end":3657,"text":"MVC"}]},{"label":["Skills"],"points":[{"start":3566,"end":3571,"text":"Jquery"}]},{"label":["Skills"],"points":[{"start":3521,"end":3523,"text":"MVC"}]},{"label":["Skills"],"points":[{"start":3442,"end":3457,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":3426,"end":3428,"text":"MVC"}]},{"label":["Skills"],"points":[{"start":3328,"end":3343,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":3319,"end":3321,"text":"MVC"}]},{"label":["Skills"],"points":[{"start":3231,"end":3246,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":3222,"end":3224,"text":"MVC"}]},{"label":["Skills"],"points":[{"start":3084,"end":3099,"text":"Machine Learning"}]},{"label":["Education"],"points":[{"start":2610,"end":2615,"text":"B.Tech"}]},{"label":["Skills"],"points":[{"start":1192,"end":1198,"text":"ASP.NET"}]},{"label":["Skills"],"points":[{"start":1142,"end":1157,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":831,"end":846,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":385,"end":387,"text":"MVC"}]},{"label":["Skills"],"points":[{"start":357,"end":359,"text":"MVC"}]},{"label":["Skills"],"points":[{"start":349,"end":355,"text":"ASP.NET"}]},{"label":["Skills"],"points":[{"start":244,"end":259,"text":"Machine Learning"}]},{"label":["Name"],"points":[{"start":0,"end":9,"text":"Krish Naik"}]}],"extras":null,"metadata":{"first_done_at":1532670612000,"last_updated_at":1532670612000,"sec_taken":137,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Krish Naik\n\n\n\n\n\n\n\n\n\nE-mail: krishnaik06@gmail.com  \n \n      \n  \n             Mobile :  +91 9899399757\nProfile\n\tSummary: Data Scientist with proven experience in architecting applications with Algorithms,Data stuctures,Binary tree,Machine Learning ,Python with libraries such as Sklearn,numpy,Pandas,Quandl,Seaborn,Tableau for Data Visualization,Keras,Tensorflow ,C#,ASP.NET MVC,Sitecore CMS,Solr 5.5.1,MVC , SQL Server, AJAX and XML. I have also done some internal projects as Data Analyst with using tools such as Tableau for Data Visualization and reporting the product owner.Recognized by managers, colleagues, and peers as a personable, dedicated performer who demonstrates innovation, communication, and teamwork to ensure quality, timely project completion.\n· 6+ years of experience in Software Development and Project Implimentation and 3+ years experience as Data Scientist Machine Learning.\n· Presently associated Honeywell Technology solution  as Tech Lead\n· Previously associated Sapient Consultancy Limited  as Senior Associate L1.\n· Previously associated with HCL Technologies Limited  as Software Developer.\n· Programming Languages: Python,Machine Learning,Artificial Intelligence, Deep Neural Networks, Convolutional Neural Network ,Sklearn Libraries,ASP.NET (v4.6 and prior), C#, Sitecore CMS(8.0,8.1,8.2),SOLR 5.5.1.\n· Databases: Hadoop HDFS,SQL Server 2014/2012/2008/2005,Mysql, Basic knowledge in Oracle.\n· Platforms and Misc: Visual Studio 2017,VS 2016, Anaconda,python IIS, Windows XP/W7/W8\n· Other Skills:  All phases of the software development life-cycle (requirements, design, development, testing, release, support), utilizing multiple development methodologies, including Design Patterns, OOD, Extreme Programming, and Structured Programming.\n· Possess good interpersonal skills that have been put to good use in co-coordinating with Project teams and providing customized software solutions.\n· Team player with effective communication skills and proven abilities in resolving complex issues.\n\n\nEmployment Scan\nDec 17 to Current\n           Honeywell Technology Solution\n\nTech Lead\n\nApril 14 to Dec 2017\n            Sapient Consultancy  Limited\n\nSenior Associate L1\nDec’ 11\nto April 2014\n\nHCL Technologies  Limited\n\nSoftware Developer\nFunctional\n· Delivering and implementing the project as per scheduled milestones. Participating in Onsite deployment, customer support and product up-gradation.\n· Interacting with the onshore team for requirements gathering, analysis, and implementations.\n· Structural designing & coding of solution for developing new applications.\n· Designing, coding and validating forms; coding programs and finally integrating them.\nAcademia\n\n2011\n\nB.Tech (Computer Science Engineering) from PDA College of                       \n\n                        Engineering,Gulbarga,Karnataka University. Secured 9.24 CGPA\n2007\n\n12th from St Philomena P.U College, Mysore. Secured 74.33%.\n\n2005\n\n10th from Mount Carmel Convent School, Gulbarga,Karnataka. Secured 83.52%.\n\nREPRESENTATIVE PROJECT EXPERIENCE SUMMARY\n\n\tClient\n\tProject\n\tTechnology\n\tRoles and Responsibilities\n\t  Duration     (in months)\n\n\tHoneywell Portals\n\tHoneywell\n\tMachine Learning, Python,Sklearn, Artificial Intelligence,Neural Networks, Keras,Tensorflow,Tableau for Data Visualization\n\t· Senior Developer\n\tCurrent project\n\n\tHowdens\n\tHowdens\n\tSitecore 8.2, ASP.net MVC,Solr,Machine Learning,Python\n\t· Senior Developer\n\t8 months\n\n\tGAF\n\tGAF\n\tSitecore 8.1, ASP.net MVC,Solr,Machine Learning,Python\n\t· Senior Developer\n\t4 months\n\n\tSunsuper\n\tSunsuper\n\tSitecore 8.0, ASP.net MVC,Solr,Python,Machine Learning\n\t· Senior Developer\n\t1 year\n\n\tChina Airlines\n\tChina Airlines\n\tMVC5,Asp.net 4.5,SQL server,Sitecore 7.2 CMS,Jquery,Angular js\n\t· Developer\n\t1 year\n\n\tBoston Consulting Group\n\tBCG.com-maintainenece\n\tMVC ,Jquery,Nhibernate,Tridion,Sql Server\n\t· Developer\n\t13\n\n\tCannacord Genuity(U.K)\n\tQuest Plus Maintanence\n\tASP.NET, C#.NET 3.5, MVC,Jquery JavaScript,Sql Server 2008\n\t· Developer\n\t14\n\n\tCooperation Pharmacy\n\tLocum\n\tASP.NET, C#.NET 4.0,Linq,JavaScript,Sql Server 2008\n\t· Developer\n\t6\n\n\tYahoo\n\tMigration of EMEA Websites from Legacy to Lego Platform \n\tJava,PHP,MYSQL,AJAX, JavaScript, HTML, CSS\n\t·  Developer\n\t5\n\n\nKey Projects Handled \n\n\t1.PROJECT TITLE \n\tHowdens\n\n\n\tCLIENT \n\tHowden\n\n\tDURATION \n\tSept 2017- running\n\n\tROLE \n\tData Scientist and Sitecore .net senior developer\n\n\tPROJECT SPECIFIC SKILLS \n\t MVC, C#.NET 4.6,Python, Machine Learning,Sql Server 2014,XML,Sitecore CMS 8.2,SOLR\n\n\nDESCRIPTION OF THE PROJECT\nHowdens Joinery can plan your perfect kitchen from over 60 ranges, complete with Lamona appliances, at over 600 depots across the UK via the small builder.\n\nResponsibilities\n· Interacted with onsite coordinator and gathered requirements.\n· Understanding Client requirements.\n· Designing, coding and validating forms, coding programs and finally integrating them.\n· Involved in designing ER modelling, LLD, HLD.\n· Worked as Offshore Developer and involved in all Phases of CR and Defects.\n\n· Involved in Unit testing and Unit testing document creation.\n· Involved in Performance tuning and stored procedure optimization activity in SQL Server.\n\t1.PROJECT TITLE \n\tGAF\n\n\n\tCLIENT \n\tGAF\n\n\tDURATION \n\tApril 2017- Sept 2017\n\n\tROLE \n\tSitecore .net developer\n\n\tPROJECT SPECIFIC SKILLS \n\t Python,MVC,C#.NET 4.5,Machine Learning,Sql Server 2014,Sitecore CMS 8.1,SOLR\n\n\nDESCRIPTION OF THE PROJECT\nRoofing shingles and materials, plus factory-certified roofers (including ratings from real homeowners!) from North America's largest roofing manufacturer\n\nResponsibilities\n· Interacted with onsite coordinator and gathered requirements.\n· Understanding Client requirements.\n· Designing, coding and validating forms, coding programs and finally integrating them.\n· Involved in designing ER modelling, LLD, HLD.\n· Worked as Offshore Developer and involved in all Phases of CR and Defects.\n\n· Involved in Unit testing and Unit testing document creation.\n· Involved in Performance tuning and stored procedure optimization activity in SQL Server.\n\t1.PROJECT TITLE \n\tSunsuper\n\n\n\tCLIENT \n\tSunsuper\n\n\tDURATION \n\tJune 25 2016-April 2017\n\n\tROLE \n\tData Scientist and Sitecore .net developer\n\n\tPROJECT SPECIFIC SKILLS \n\t Python,Machine Learning,MVC,C#.NET 4.5,Asp .net,Sql Server 2012,XML,Sitecore CMS 8.0,SOLR\n\n\nDESCRIPTION OF THE PROJECT\nThis project is a insurance  domain project where we design a web based application where we can do all the functionalities of getting details of insurances and plan our old age in a better way globally.\n\nResponsibilities\n· Understanding Client requirements.\n· Designing, coding and validating forms, coding programs and finally integrating them.\n· Involved in designing ER modelling, LLD, HLD.\n· Worked as Offshore Developer and involved in all Phases of CR and Defects.\n\n· Involved in Unit testing and Unit testing document creation.\n· Involved in Performance tuning and stored procedure optimization activity in SQL Server.\n\t1.PROJECT TITLE \n\tChina Airlines\n\n\n\tCLIENT \n\tChina Airlines\n\n\tDURATION \n\tAug 31st 2015-running\n\n\tROLE \n\tDeveloper\n\n\tPROJECT SPECIFIC SKILLS \n\t MVC,Jquery, C#.NET 3.5, JavaScript,Sql Server 2008,XML,Tridian\n\n\nDESCRIPTION OF THE PROJECT\nThis project is a travel domain project where we design a web based application where we can do all the functionalities of a ticket booking site which includes searching  flight tickets,book flight, cancel tickets globally.\nResponsibilities\n· Designing, coding and validating forms, coding programs and finally integrating them.\n· Involved in designing ER modelling, LLD, HLD.\n· Worked as Offshore Developer and involved in all Phases of CR and Defects.\n\n· Involved in Unit testing and Unit testing document creation.\n· Involved in Performance tuning and stored procedure optimization activity in SQL Server.\n· Interacted with onsite coordinator and gathered requirements.\n· Understanding Client requirements.\n\t1.PROJECT TITLE \n\tQuest Plus Maintanence\n\n\n\tCLIENT \n\tCannacord Genuity(U.K)\n\n\tDURATION \n\tMarch 5th 2013- April 1st 2014\n\n\tROLE \n\tDeveloper\n\n\tPROJECT SPECIFIC SKILLS \n\tASP.NET,Windows form, C#.NET 3.5, JavaScript,Sql Server 2008,XML,Classic ASP\n\n\nDESCRIPTION OF THE PROJECT\nCanaccord Genuity is a global, full-service investment bank focused on growth companies, with operations in 11 countries worldwide and the ability to list companies on 10 stock exchanges .Canaccord Genuity is the global capital markets division of Canaccord Financial Inc. (CF : TSX | CF. : LSE), offering institutional and corporate clients idea-driven investment banking, research, sales and trading services.  \nThis project  deals with the maintainence and development of a website (www.csquest.com) which shows all the information regarding the various stocks of many European companies which helps the client or the registered users to buy stocks based on the analysis of the statistics information. There are much information such as previous stock price, the new stock and the various others factors which helps the user to buy the stocks. This project is based on the Microsoft SQL Server Write Side XML Three Tier Architecture which uses IIS 6 as the web server, Active Server Pages and COM objects to implement the flow and functionality. The primary data format used is XML as this gives a standard data format that is supported by SQL Server 2008.\nResponsibilities\n· Interacted with onsite coordinator and gathered requirements.\n· Understanding Client requirements.\n· Designing, coding and validating forms, coding programs and finally integrating them.\n· Involved in designing ER modelling, LLD, HLD.\n· Worked as Offshore Developer and involved in all Phases of CR and Defects.\n\n· Involved in Unit testing and Unit testing document creation.\n· Involved in Performance tuning and stored procedure optimization activity in SQL Server.\n\t2.PROJECT TITLE \n\tLocum\n\n\n\tCLIENT \n\tCooperation Pharmacy\n\n\tDURATION \n\t6 months\n\n\tROLE \n\tDeveloper\n\n\tPROJECT SPECIFIC SKILLS \n\tASP.NET, C#.NET 4.0, JavaScript,Sql Server 2008,XML\n\n\nDESCRIPTION OF THE PROJECT\nCo-op Pharmacy business operates around 1000 pharmacy shops known as branches. UK PCT governs operation of these branches. According to their rules & regulation, it is compulsory to have at least one pharmacist available in the branches during their operational hours.Co-op has its own employed pharmacist for every branch. They are known as branch managers.\n\nThis Project is a employee information management system which acts as a central employee database. This enables HR administrators to utilize all employee information productively.This application deals with the management of these employees with respect to their pay, assign supervisors to an employee to identify the reporting structure, view employee details in the employee list and search using different employee information. This Application basically helps the HR to manage the Employees of an organization.\nResponsibilities\n· Interacted with onsite coordinator and gathered requirements.\n· Understanding Client requirements.\n· Delivering and implementing the project as per scheduled milestones. \n· Designing, coding and validating forms, coding programs and finally integrating them.\n· Involved in designing ER modelling, LLD, HLD.\n· Worked as Offshore Developer and involved in all Phases of CR and Defects.\n\n· Involved in Unit testing and Unit testing document creation.\n· Involved in Performance tuning activity and stored procedure optimization  in SQL Server.\n· Involved in Deployment and post deployment support.\n· Developed stored procedures,views,Triggers in SQL Server 2008.\n\t3.PROJECT TITLE \n\tMigration of EMEA Websites from Legacy to Lego Platform\n\n\n\tCLIENT \n\tYahoo\n\n\tDURATION \n\t5 months\n\n\tROLE \n\tDeveloper\n\n\tPROJECT SPECIFIC SKILLS \n\tPHP,MYSQL,AJAX, JavaScript, HTML, CSS\n\n\nDESCRIPTION OF THE PROJECT\nThe advertising sites of the yahoo company and it is the ultimate online entertainment destination, connecting fans with the celebrity news, movies, TV shows and music.\n\nThis project deals with the migration of websites from the Legacy to the Lego platform with the help of PD2 tool (Producer Desktop). In this project we had to create various modules required while designing the websites and it also dealt with mapping the third party vendors for displaying the articles and blogs in the website.\nResponsibilities\n· Interacted with onsite coordinator and gathered requirements.\n· Understanding Client requirements.\n· Delivering and implementing the project as per scheduled milestones. \n\n· Involved in designing ER modelling, LLD, HLD.\n· Involved in Unit testing and Unit testing document creation.\n· Involved in Deployment and post deployment support\nTraining\nAttended 6 days workshop on “Rational Application Developer” conducted by IBM.\n\nAttended 4 days worshop on “ANDROID:A Mobile Device Opertating System” \nStrength\n\nPositive Attitude: To progress positively under all circumstances with conviction and maturity in approach.\n\nAdaptability & Flexibility: To adapt accordingly under the application of adverse or pressure conditions without deviating from critical to quality concerns.\n\nEnthusiasm for Learning: Endlessly strives to learn through different activities.\nPersonal Dossier\n\nDate of Birth\n\n:\n24th September 1989\nSex\n\n\n:\nMale\n\n\n\nFather’s Name\n\n:\nMr. Chandrashekar Naik\nMother’s Name\n: \nMs. Vidya Naik\nPermanent Address\n:\nFlat no G-05, Royal Mist Apartment,Heelalige,Chandapur,Bangalore\nCurrent Address\n:\nFlat no G-05, Royal Mist Apartment,Heelalige,Chandapur,Bangalore\nNationality\n\n:\nIndian\nEndorsement\n\nI hereby declare that the information furnished above is complete and true to the best of my knowledge.\nDate:\n\n\n\n\n\nPlace:  \n\n\n\n\n\n\n\n\n\n               Krish.C.Naik","annotation":[{"label":["Location"],"points":[{"start":13496,"end":13504,"text":"Bangalore"}]},{"label":["Location"],"points":[{"start":13413,"end":13421,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":9965,"end":9970,"text":"C#.NET"}]},{"label":["Skills"],"points":[{"start":8099,"end":8104,"text":"C#.NET"}]},{"label":["Skills"],"points":[{"start":7119,"end":7124,"text":"C#.NET"}]},{"label":["Skills"],"points":[{"start":7107,"end":7109,"text":"MVC"}]},{"label":["Skills"],"points":[{"start":6302,"end":6305,"text":"SOLR"}]},{"label":["Skills"],"points":[{"start":6245,"end":6250,"text":"C#.NET"}]},{"label":["Skills"],"points":[{"start":6241,"end":6243,"text":"MVC"}]},{"label":["Skills"],"points":[{"start":6224,"end":6239,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":6217,"end":6222,"text":"Python"}]},{"label":["Skills"],"points":[{"start":5374,"end":5377,"text":"SOLR"}]},{"label":["Skills"],"points":[{"start":5357,"end":5372,"text":"Sitecore CMS 8.1"}]},{"label":["Skills"],"points":[{"start":5341,"end":5355,"text":"Sql Server 2014"}]},{"label":["Skills"],"points":[{"start":5324,"end":5339,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":5313,"end":5318,"text":"C#.NET"}]},{"label":["Skills"],"points":[{"start":5309,"end":5311,"text":"MVC"}]},{"label":["Skills"],"points":[{"start":5302,"end":5307,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4489,"end":4492,"text":"SOLR"}]},{"label":["Skills"],"points":[{"start":4452,"end":4466,"text":"Sql Server 2014"}]},{"label":["Skills"],"points":[{"start":4435,"end":4450,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":4427,"end":4432,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4416,"end":4421,"text":"C#.NET"}]},{"label":["Skills"],"points":[{"start":4411,"end":4413,"text":"MVC"}]},{"label":["Skills"],"points":[{"start":4034,"end":4039,"text":"C#.NET"}]},{"label":["Skills"],"points":[{"start":3939,"end":3941,"text":"MVC"}]},{"label":["Skills"],"points":[{"start":3927,"end":3932,"text":"C#.NET"}]},{"label":["Skills"],"points":[{"start":3809,"end":3811,"text":"MVC"}]},{"label":["Skills"],"points":[{"start":3675,"end":3677,"text":"MVC"}]},{"label":["Skills"],"points":[{"start":3596,"end":3611,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":3589,"end":3594,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3580,"end":3582,"text":"MVC"}]},{"label":["Skills"],"points":[{"start":3499,"end":3504,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3482,"end":3497,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":3473,"end":3475,"text":"MVC"}]},{"label":["Skills"],"points":[{"start":3402,"end":3407,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3385,"end":3400,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":3376,"end":3378,"text":"MVC"}]},{"label":["Skills"],"points":[{"start":3192,"end":3197,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3174,"end":3189,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1322,"end":1325,"text":"SOLR"}]},{"label":["Skills"],"points":[{"start":1154,"end":1169,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1147,"end":1152,"text":"Python"}]},{"label":["Skills"],"points":[{"start":882,"end":897,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":402,"end":404,"text":"MVC"}]},{"label":["Skills"],"points":[{"start":374,"end":376,"text":"MVC"}]},{"label":["Skills"],"points":[{"start":248,"end":253,"text":"Python"}]},{"label":["Skills"],"points":[{"start":230,"end":245,"text":"Machine Learning"}]},{"label":["Name"],"points":[{"start":0,"end":9,"text":"Krish Naik"}]}],"extras":null,"metadata":{"first_done_at":1532680599000,"last_updated_at":1532680599000,"sec_taken":183,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Lohit Kumar\n\n\t\n\t\n\n\n\n\n\t\n\tPage | 3\n\n\n\n\tBangalore\n\tlohit.seek@gmail.com\n\t+91- 9581940099\n\n\nObjective\nTo succeed in an environment of growth and excellence and earn a job which provides me job Satisfaction and self-development and help me achieve personal as well as organization goals.\n\nProfessional Summary: \n· 4years of IT experience in model building and support of business applications Using Python, R & Spark.\n· Experience in NLP, Machine Learning & Deep Learning.\n· Experience in using linear regression, Logistic regression and Decision trees model to help the client in their business.\n· Experience in IoT analytics where in defining the KPI’s based on the client requirement and the data available.\n· Strong knowledge of SDLC and models and has experience in Agile Methodology.\n· Willingness to learn new concepts and technologies. I am excellent team player, always flexible to the team requirements.\n\nWork Experience: \n· Worked as Python Developer in Seek Info mediafrom July 2013 to June 2015.\n· Worked as Data Analyst   in Swayam Infologicfrom July 2015 to October 2016.\n· Working as Data Scientist in L & T from Nov 2016 to till date.\n\nTechnical skills\n· Operating Systems\t  :Windows, LINUX\n· Languages\t  :Python, R, PySpark\n· Database\t  :NoSQL(MongoDB), MySQL, SQL server\n· Machine Learning Techniques:Linear regression, Logistic Regression, Decision Trees,\nRandom forest, SVM\n· NLP Techniques  \n\n\n\n\nProject Profile:\nL&T ECC Analytics \t\t\t\t\t\t\t\nTo analyse the IoT sensor data captured from 1000+ heavy vehicles located at various construction sites across India. Using this data, define some Key Performance Indicators (KPI’s) to analyse the performance of vehicles so that they can take some measures to improve those and hence, their productivity and business. \n\nResponsibilities:\n· Involved in analysing system and business\n· Understanding of data to define possible KPIs. Worked closely with Technical Architect to get better understanding of Attributes\n· Identifying variables which gives a better result after preparation and cleaning of data\n· Statistical Algorithm Building to achieve the defined KPI’s\n· Considered different supervised algorithms on the data which gives closely expected output\n· Applied Random Forest model for identifying the root causes to failure of devices\n· Created a dashboard to showcase vehicles performance\nEnvironment:  Machine Learning, Python, Scikit-learn, Matplot-lib, MongoDB\n\nPhilips HealthCare\nDeveloped an automated tool to categorize text data.Documents will be updated periodically and tool should be able to categorize the text and find new categorization. Extracting data from cluster and Translating all languages into English and summarized each document to segregated data by categorizing and grouping of words, sentences. \nResponsibilities:\n· Understanding business portfolio of healthcare products\n· Extract various types of data and translated all text to English builded a corpus  \n· Created word document dictionary for spell check correction \n· Using Natural Language Processing(NLP) clustering algorithm was applied for the text data\n· Created automated tool to work application in background text analytics algorithm written\nEnvironment:  NLP, Python, Information Extraction, Document Clustering and Concept Extraction. \n\nExxonMobil \nMetadata Extraction from PDF – After image processing, we do spell correction based on the domain corpus which is extracted from Web (and English spell correction check also) and extract the Metadata based on the rules those are given by the domain team.\nResponsibilities:\n· Understanding functional part of oil and gas sector\n· Converting PDF to PNG for Image processing(OCR) docsfor metadata extraction \n· Using tesseract and cv2 libraries in python data was extracted to csv/excel \n· Using Natural Language Processing(NLP) clustering algorithm was applied for the text data\n· Created automated tool to work application in background text analytics algorithm written\nEnvironment:  NLP, Machine Learning, Python, Topic Modelling, Document Clustering. \n\n\n\n\n\nOnline CRM Application                                    \t\n\t\nCustomer Relationship Management was an application which will be tracked by the organization tasks over a long period. Combining machine learning with real-time scoring can empower financial institutions with the insights and protect their customers, and save millions of dollars for their organization.\nResponsibilities:\n· Collecting Documents from various sources to analyse and manage data\n· Analyze data based on trends which were run on campaigns in that period\n· Based on modules with customer history and market analysis algorithm was applied\n· Collaboration with market specialists to optimize the business units  \n· Worked closely with development team to ensure stakeholders and client requirements \nEnvironment:  Machine Learning, Python, R, NoSQL (MongoDB), Supervised Learning. \n\nFraud detection   \t\t\t\t\t\t\t\t\t\t\nThis Data set is related to Bank and as a result, many financial leaders are turning to machine learning to better understand their customer transactions and rapidly detect fraud. By extracting and analysing a variety of disparate data sources, financial leaders can identify cross-channel anomalies in real-time to stop fraudulent activities as they happen.\nRoot Cause Analysis: Supervised Modeling – Logistics Regression &Neural Network.\n\n\nEducation\n· B. Tech(EEE) JNTU - Hyderabad\t\t\t\t\t\t\t             2009-2013\t\n· IPE (+2) – Intermediate Board\t\t\t\t\t\t\t\t\t2007-2009\n· S.S.C – State Board                                                                                                                           2006-2007\n\t\nPersonal Information\n· Name\t\t\t\t: \tLohit Kumar\n· Date of Birth\t\t\t\t:\t27-Jun-1992\t\t\n· Languages Known\t\t\t\t:\tEnglish, Hindi, Telugu\nDeclaration\nI hereby declare that above written are true to the best of my knowledge and belief.\nDate: \nPlace: Bangalore\tLohit Kumar","annotation":[{"label":["Name"],"points":[{"start":5916,"end":5926,"text":"Lohit Kumar"}]},{"label":["Location"],"points":[{"start":5906,"end":5914,"text":"Bangalore"}]},{"label":["Name"],"points":[{"start":5702,"end":5712,"text":"Lohit Kumar"}]},{"label":["Education"],"points":[{"start":5401,"end":5414,"text":" B. Tech(EEE) "}]},{"label":["Skills"],"points":[{"start":5360,"end":5360,"text":"R"}]},{"label":["Skills"],"points":[{"start":5307,"end":5307,"text":"R"}]},{"label":["Skills"],"points":[{"start":4876,"end":4876,"text":"R"}]},{"label":["Skills"],"points":[{"start":4868,"end":4873,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4430,"end":4430,"text":"R"}]},{"label":["Skills"],"points":[{"start":4134,"end":4134,"text":"R"}]},{"label":["Skills"],"points":[{"start":4071,"end":4071,"text":"R"}]},{"label":["Skills"],"points":[{"start":4011,"end":4016,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3679,"end":3679,"text":"R"}]},{"label":["Skills"],"points":[{"start":3560,"end":3560,"text":"R"}]},{"label":["Skills"],"points":[{"start":3215,"end":3220,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2787,"end":2787,"text":"R"}]},{"label":["Skills"],"points":[{"start":2386,"end":2391,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2225,"end":2225,"text":"R"}]},{"label":["Skills"],"points":[{"start":1776,"end":1776,"text":"R"}]},{"label":["Skills"],"points":[{"start":1371,"end":1371,"text":"R"}]},{"label":["Skills"],"points":[{"start":1343,"end":1343,"text":"R"}]},{"label":["Skills"],"points":[{"start":1231,"end":1235,"text":"Spark"}]},{"label":["Skills"],"points":[{"start":1226,"end":1226,"text":"R"}]},{"label":["Skills"],"points":[{"start":1218,"end":1223,"text":"Python"}]},{"label":["Skills"],"points":[{"start":940,"end":945,"text":"Python"}]},{"label":["Skills"],"points":[{"start":406,"end":410,"text":"Spark"}]},{"label":["Skills"],"points":[{"start":402,"end":402,"text":"R"}]},{"label":["Skills"],"points":[{"start":394,"end":399,"text":"Python"}]},{"label":["Location"],"points":[{"start":37,"end":45,"text":"Bangalore"}]},{"label":["Name"],"points":[{"start":0,"end":10,"text":"Lohit Kumar"}]}],"extras":null,"metadata":{"first_done_at":1532676643000,"last_updated_at":1532676643000,"sec_taken":67,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Resume\n\nMadhavv Jagdishbhai Kapadia\nSoftware Developer[Sr python Developer]\n\tMobile: “+91 8433627395,+9187792 46582\nEmail: madhavkapadiya@gmail.com\n\n\t\n\n\n\n\nPROFESSIONAL SUMMARY\n· 6.7 yearsof experience in the IT industry working on IT Development, Sales Products, Microsoft and other Open SourceTechnologies.\n· Workedas “SoftwareDeveloper “with Smylengine Private Limited, Kandiwali[w],Mumbai.\n· Expertise in software development, designed architecture.\n· Wideexperience in OpenSource Technologylearnt Microsoft Technology such as ASP.net, C#, SQL Server, etc.\n· Experience in different project methodologies like Waterfall and Agile methodology (SCRUM). \n· Hands on experience with SELLING OF SARAL Brand productsto CAs and Tax Consultants.\nACADEMICS DETAIL\n· Master ofComputer Application (M.C.A, Mumbai University), Mumbai.) in dec 2012\n· Bachelor of Computer Application (B.C.A,Sardar Patel University), VallabhVidyanagar, Gujarat in apr 2007\nCERTIFICATION & ACHIEVEMENTS\t\n· Diploma in Java from NIIT,Bharuch, Gujarat ,India from oct 2012 to jan 2013.\n· Selected for Semi final Round at Noida among 4 Best Team ​in Zee Business’s “Aspire” Music toMoney Challenge Competition​during MCA in Mumbai november 2009\nTECHNICAL SK\nProgramming Languages  ->Python,Java,HTML5,CSS3,JS, R language(beginner)\n                                         Machine learning with   Python(Beginner),\nFrameworks \t\t->Django,Mezzanine,odoo Functionality Knew\nRDBMS                    \t->Oracle 10g\nDeveloper Tools                  ->Sublime Eclipse,VSStudio,Pycharm ,Netbeans IDE,Testing Tools,\nMethodology                      ->Agile Methodology\n\tOrganization\n\tJob Title\n\tDuration\n\n\n\tSpeakwell pvt ltd\n\tIT Developer and Coordinator\n\tMarch 2017 –july 2017\n\n\tSmylengine PVT LTD, Kandiwali[w]\n\tPython Developer\n\tJan 2016 to Jan 2017\n\n\tZWeb Solution PVT ltd ,Ankleshwar\n\tPython Developer and Business Developer\n\tJuly, 2015 -Jan, 2015\n\n\tRelyon Softest pvt ltd , Ahmedabad\n\tSales Officer -Taxation\n\tMarch, 2013–Oct, 2014\n\n\tSheen technology pvt ltd ,Bharuch\n\tSoftware Engineer(php with python)\n\tMarch 2011– Oct, 2012\n\n\nWORK EXPERIENCE\nROLES & RESPONSIBILITIES HELD\n\n1Tigi Foundation [admin panel site for Animal lovers],Mumbai, India.(apr 2016 to Continue)\n· Involved in SDLC of Project.\n· Involved in technical decision of project.\n· Involved in task assignments, code review\n· Technology used python,django,mezzanine framework\n2 Software Developer in Birla Sun Life Insurance Project, Gcorp, Thane[w], Mumbai, India(2 month)(sep 2016 to nov 2016)\n· Participating in daily standup meetings.\n· Worked on UAT and Emerge Module of Birla Sun life Insurance \n· Solving Ticketing Issues.\n· MaintainingDocuments related of Work.\n· Making sure to stay up to date to latest releases.\n· Liaising with offshore teams\n· Ensure timely delivery of project work to clients. \nTechnology used pythond,django,jquery,jsHTML5,jquery framework.(2 month)\n3 conversion of wordpress to Django(dec 2016 t0 jan 2017)\n· Rajkot based company’s project outsoursed to us,as we converted it to Django.\n· Technology used python,django framework.\n4christian community project.(1 month)(oct 2016 to nov 2016)\n· Logo designing and coding was done.\n· Technology used Django and python.\n5 Software Development and Sales at Zweb Solution, Ankleshwar, Gujarat, India\n· Understanding the Business requirements and translating them into technical solutions.\n· Designing and creating the underlying data structure and data flows to support application build or development.\n· Participating in performance tuning of old and new applications which are not up to mark.\n· Responsibilities include Designing software architecture, Project management, Resource management, Quality management.\n· Technology used php,Pythonhtml5,js,css3,bootstrap.\n6 Sales Officer at Relyon Software pvt ltd, Ahmedabad,Gujarat, India(mar 2013 to aug 2014)\n· Making referral partner and channel partner.\n· Liaising with offshore teams.\n· Industrial Visit of Companies for increasing sales of Software Products of Saral Brand.\n· Participate in presales by preparing and presenting Customer Demos, estimating effort and timely Response of Demos to them.\n· Lead generation from different sites and Negotiation Skills to sell software in competitive market.\n7 Animal husbandry project, bharuch.gujrat.\n· Gather requirements and design quality solutions - ensure that solutions are fit for purpose.\n· Making CRUD Application for their Project\n· Involved in task assignments, code review.\n· Maintaining Hardware Related Issues[like page setup while printing page]\n· Participating in daily standup meetings.\nTechnology used php,mysql,html,css3.\n8Making mobile website of easyfe.com,bharuch,gujray\nGathering requirements for mobile app development.\nMaking android mobile app for this portal.\nAnalysing bugs in web portal with team.\nGetting Awareness for all mobile platform for that portal.\n\n\n\n*There are many other projects which I have worked onrather than this.\n\nDate of Birth\t:  18 April 1987\nSex\t\t:  Male\nMarital Status\t:  Single\nAddress: 402,la patit building,near orlem church,malad(west),Mumbai\n\nDeclaration\nI hereby declare that the above- mentioned information is true to the best of my knowledge.\n\n\nDate: 10/08/2017\tPlace: Mumbai\n\n(Madhav J Kapadia)\n\n\t\tPage 1 of 3","annotation":[{"label":["Location"],"points":[{"start":5233,"end":5238,"text":"Mumbai"}]},{"label":["Location"],"points":[{"start":5095,"end":5100,"text":"Mumbai"}]},{"label":["Skills"],"points":[{"start":3742,"end":3747,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2875,"end":2879,"text":"HTML5"}]},{"label":["Location"],"points":[{"start":2478,"end":2483,"text":"Mumbai"}]},{"label":["Location"],"points":[{"start":2194,"end":2199,"text":"Mumbai"}]},{"label":["Skills"],"points":[{"start":1848,"end":1853,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1772,"end":1777,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1364,"end":1369,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1278,"end":1287,"text":"R language"}]},{"label":["Skills"],"points":[{"start":1274,"end":1275,"text":"JS"}]},{"label":["Skills"],"points":[{"start":1269,"end":1272,"text":"CSS3"}]},{"label":["Skills"],"points":[{"start":1263,"end":1267,"text":"HTML5"}]},{"label":["Skills"],"points":[{"start":1258,"end":1261,"text":"Java"}]},{"label":["Skills"],"points":[{"start":1251,"end":1256,"text":"Python"}]},{"label":["Location"],"points":[{"start":1192,"end":1197,"text":"Mumbai"}]},{"label":["UNKNOWN"],"points":[{"start":1185,"end":1187,"text":"MCA"}]},{"label":["Skills"],"points":[{"start":989,"end":992,"text":"Java"}]},{"label":["Location"],"points":[{"start":818,"end":823,"text":"Mumbai"}]},{"label":["Location"],"points":[{"start":798,"end":803,"text":"Mumbai"}]},{"label":["Location"],"points":[{"start":385,"end":390,"text":"Mumbai"}]},{"label":["Name"],"points":[{"start":8,"end":34,"text":"Madhavv Jagdishbhai Kapadia"}]}],"extras":null,"metadata":{"first_done_at":1532671699000,"last_updated_at":1532671699000,"sec_taken":113,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Madhu Nettem\nEmail: madhusdn25@gmail.com\n  Mobile: +91-7406900500\n\n\n\tProfessional Summary\n\t\n\n\t· Over 6.8 years of experience in Design, Development, and Maintenance of  \nEnterprise Applications\n\n· Good work experience on Banking, Financial ,Corporate Entity Data,Power and Manufacturing domains. \n\n· Strong working experience in Scrum and Agile practices\n· Strong experience with Python, DJango using REST API\n· Good experience in Core Java and J2EE  technologies like Servlets and JSP\n· Strong experience in using open source technology frameworks like RESTful WebServices \n· Strong work experience in writing unit tests using Junit and Mockito\n· Strong experience in using tools like GIT, Bamboo ,Stash,SourceTree,JIRA\n· Good working knowledge on Linux operating system\n· Proficient in programming by using the IDE’s such as Eclipse,PyCharm\n· Experience  in using the tools like MobaXTerm,Putty,Winscp,Tortoise SVN\n· Good experience in using build tools like Ant and Maven \n· Good experience with web/application servers like Tomcat, WebLogic, Karaf\n· Excellent analytical and problem solving skills ability to handle multiple tasks \n· Ability to work well in both team environment and individual environment \n\n\n\tEducational Qualifications\n\n\t· B.Tech(ECE),2009 from JNTU, Hyderabad with aggregate of 66%\n\n· Intermediate(MPC),2005 from Board of Intermediate with 93%\n\n· SSC,2003 from Board of Secondary Education with 90%\n\n\n\n\tProfessional Summary\n\n\t· Currently working as Sr. Software Engineer in Prove International, Chennai \n\nfrom August 2017 to till date\n\n· Previously worked as Sr. Technical Analyst  in  Fidelity (FIS) , Bangalore , from Mar 2016 to July 2017\n\n· Previously worked as Staff Consultant in  Oracle Financial Services Software Ltd.,  Bangalore from Jan 2014 to March 2016\n\n· Previously worked  as  Technical Associate  in Evoke Technologies ,  Hyderabad  from Jan 2011 to Aug 2013\n\n\n\tAchievements\n\n\t· Achieved Best Excellence for the month of Feb 2013\n\n· Received Pratibha Award for Best performer in S.S.C\n\n· State Topper in Mathematics and Telugu language in S.S.C 2003\n\n\tTechnical Skills\n\t\n\n\tProgramming Languages\n\t Python, Core Java\n\n\tOperating Systems\n\tLinux, Windows\n\n\tFrameworks\n\t REST API, DJango\n\n\tWeb Technologies\n\tServlets,JSP\n\n\tDatabases\n\tOracle 11g, MySQL\n\n\tTools\n\tMobaxTerm, Bamboo, SourceTree, JIRA , Putty, WinSCP, Ant, Apache Camel, ActiveMQ\n\n\tServers\n\tTomcat 7.0, WebLogic, Apache Karaf\n\n\tUnit Testing\n\tJUnit, Mockito\n\n\tScripting Languages\n\tJavaScript\n\n\tClient Side Technologies\n\tHTML, CSS\n\n\nPROJECTS\n\n\t7. XISOT\n\t Aug 2017 to Till Date\n\n\tClient\n\tWorld Fuel Services\n\n\tRole\n\tSenior Software Engineer \n\n\tEnvironment\n\tPython, DJango, MySQL, Bamboo, JIRA, SourceTree,   Eclipse, MogoDB, REST API\n\n\nDescription:\n   \n\n                       World Fuel Services provide energy procurement advisory services, supply fulfillment, and transaction and payment management solutions to commercial and industrial customers, principally in Aviation,Marine and Land transportation industries.Under this Xisot application deals with Electricity module.For Generators usage this application will provide data analytics for Power Genration,RealTime,Forecast,Actual Load graphs.Internally it uses PJM services for calculations.\nResponsibilities:\n\n· Involved in client interactions and status meetings\n\n· Involved in implementing code using Python with DJango frameworks.\n· Interacted with client for Requirement Analysis,Design\n· Involved in implementing RESTful API from server side\n\n· Invovled in Code Reviews and Code Refactoring.\n\n\t6. Profile Integration \n\tMar 2016 to Aug 2017\n\n\tClient\n\tIndia Markets(Bandhan,ESAF,Suryoday,FINO,Disha Banks)\n\n\tRole\n\tTech Lead\n\n\tEnvironment\n\tPython, DJango, REST API,Apache Camel, Karaf\n\n\nDescription:\n\n                          Profile Integration Team used Apache Camel Integration tool which helps to integrate the different platforms and works as medium. It is concrete implementations of all the widely used Enterprise Integration Patterns (EIPs). It is easy to use Domain Specific Languages (DSLs) to wire EIPs and transports together.\n\nResponsibilities:\n\n· Involved in client interactions and status meetings\n\n· Involved in implementing the enhancements as per the design\n\n· Involved in writing Python scripts for OTP and SMS functionality\n· Involved in implementing RESTful API with Python,DJango from server side\n\n\t5. TRIMS(Titan)\n\tJan 2014 to Mar 2016\n\n\tClient\n\tCITI Bank\n\n\tRole\n\tStaff Consultant\n\n\tEnvironment\n\tPython,Django,Oracle,RESTful WS, Core Java\n\n\nDescription :\n\n                              Trade Record Information Management System (TRIMS) is used for Trade Processing in GTS (Global Transaction Services) of Citigroup.  TRIMS application consists of two parts viz. TRIMS processing and TRIMS Imaging.  TRIMS Processing provides the business functionality of processing of trade products based on an automated workflow, electronic message handling, customer service, transaction repository and reporting. TRIMS imaging, being the image database and repository, provides scanning, faxing, bar-coding and an automated workflow.\n\nResponsibilities :\n\n· Developed the persistence logic , business logic using Spring framework\n\n· Involved in Designing  and Coding using Python,Django\n\n· Followed Agile/Scrum methodology and actively participated in Sprint calls to complete the sprints\n\n· Involved in implementing critical enhancements as per the client requirements.\n\n· Involved in implementing RESTful API from server side.\n\n\t4. MACH\n\tMarch 2013 to Aug 2013\n\n\tClient\n\tSyniverse Technologies\n\n\tRole\n\tSenior Software Engineer\n\n\tEnvironment\n\tPython,Linux,MySQL\n\n\nDescription:\n   \n\n                            MACH SDP(Service Delivery Platform) is a platform which orchestrates services like Prepaid data hub (real time data charging system for the prepaid subscribers), Data Fuse (Online charging system for Post paid subscribers), Service aware charging (charging based on content), Real time re-rating (rating based on visiting location.\n\n                   MACH SDP is a data roaming based service delivery platform for controlling roaming subscriber’s data sessions in real-time. It hosts services like prepaid data hub (PPH), data fuse (DF), service aware charging etc and interacts with roaming user’s home IN/OCS systems.  \n\n Responsibilities:\n\n· Involved in client interactions and status meetings\n\n· Involved in implementing RESTful API from server side.\n\n· Monitoring the server log files during project release and writing code for success and failure cases.\n\n\t3. EM RENEWALS\n\t Jun 2012 to Feb 2013\n\n\tClient\n\tCSC\n\n\tRole\n\tTechnical Associate \n\n\tEnvironment\n\tPython ,Temporal Expressions, Core Java,Junit,Mockito, XML,Web Services(RESTful)\n\n\nDescription:\n   \n\n                       As a new application that wants to use the scheduler service, application should go through process of classifying the attributes. The attributes can be defined at different levels like Event level ,Schedule level and Schedule instance level attributes. With the events creation CSC user can create his own events like     every first week of every year with time and period. At event level he can directly cancel the events. At Schedule level, client should verify any coincidence is happening or not. As an EM user he can create, update, delete the events.\n\nResponsibilities:\n\n· Involved in client interactions and status meetings\n\n· Planning and Scheduling the iterations, coordinating with QA and business team\n\n· Interacted with client for requirements gathering\n\n· Involved writing Unit Tests using JUnit with Mockito framework in TDD environment\n· Involved in implementing RESTful API from server side.\n\n\t2. Organization Charts\n\t Sep 2011 to May 2012\n\n\tClient\n\tCSC\n\n\tRole\n\tSoftware Engineer \n\n\tEnvironment\n\tCore Java ,Servlets,Spring,Hibernate,IBM ILOG JViews, Junit, Mockito ,XML,CSS,Web Services(RESTful)\n\n\nDescription:\n   \n\n                               An organizational chart (often called Org. Chart) is a diagram that shows the structure of an organization and the relationships and relative ranks of its parts and positions/jobs. A company's organizational chart typically illustrates relations between people within an organization.\n\n                    The objective of the project is to get the data from database and show the information of different legal entities through Org Chart Diagram for Ownership and Hierarchy types. It gives the information about parent child relationships between different entities in same jurisdiction.  Majorly it gives instructions and advices for related entities.\n\nResponsibilities: \n\n· Participated in requirements analysis and preparing Functional specification and Design documents\n\n· Responsible for development plan, development, unit test and smoke test\n\n· Developed the UI using with JQuery,Javascript \n\n· Involved in writing Unit Tests in Test Driven Development environment\n\n· Involved in POC's for Org Chart Diagrammer concepts, Rules execution\n\n· Involved in implementing RESTful API from server side.\n\n· Developed the Client side validations and Server side validations for the application\n\n\t1. iStore\n\tJan 2011 to Aug 2011\n\n\tClient\n\tClopay Garage Doors\n\n\tRole\n\tAssociate Trainee\n\n\tEnvironment\n\tCore Java,JSP,Servlets,Spring,Hibernate,Oracle,Oracle Applications(ERP), Web Services(RESTful)\n\n\nDescription:\n \n\n                                Clopay manufactures both Building and Plastic products. It is famous for its Garage Doors. iStore is an application where dealers can order these garage doors. In this, dealers can configure garage doors according to customer requirements. \n\nThe main objective of the project is to check the process flow of the order from iStore to Order Management till it is got shipped. We will also check the performance of the application in different browsers.\n\nResponsibilities:\n\n· Involved in estimation for new features and Problem Logs\n\n· Involved in the Development and Integration of modules\n\n· Preparing the Test Plan and Test Cases for the functionality of the application. \n\n· Involved in Build and Deployment for the application\n\n· Developed the Client side validations and Server side validations for the application\n\n· Involved in validating sales prices from front end to Oracle Applications   \n\nDeclaration:\n\n                           I here by declare that all the above mentioned details are true to the best of my knowledge.\n\n                                                                                                  Madhu Nettem\n\n                                                                                             Chennai","annotation":[{"label":["Location"],"points":[{"start":10609,"end":10615,"text":"Chennai"}]},{"label":["Name"],"points":[{"start":10502,"end":10513,"text":"Madhu Nettem"}]},{"label":["Skills"],"points":[{"start":9225,"end":9233,"text":"Core Java"}]},{"label":["Skills"],"points":[{"start":7777,"end":7785,"text":"Core Java"}]},{"label":["Skills"],"points":[{"start":6669,"end":6677,"text":"Core Java"}]},{"label":["Skills"],"points":[{"start":6639,"end":6644,"text":"Python"}]},{"label":["Skills"],"points":[{"start":5612,"end":5617,"text":"Python"}]},{"label":["Skills"],"points":[{"start":5273,"end":5277,"text":"Scrum"}]},{"label":["Skills"],"points":[{"start":5241,"end":5246,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4509,"end":4517,"text":"Core Java"}]},{"label":["Skills"],"points":[{"start":4476,"end":4481,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4352,"end":4357,"text":"DJango"}]},{"label":["Skills"],"points":[{"start":4345,"end":4350,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4256,"end":4261,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3704,"end":3709,"text":"DJango"}]},{"label":["Skills"],"points":[{"start":3696,"end":3701,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3369,"end":3374,"text":"DJango"}]},{"label":["Skills"],"points":[{"start":3357,"end":3362,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2660,"end":2665,"text":"DJango"}]},{"label":["Skills"],"points":[{"start":2652,"end":2657,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2217,"end":2222,"text":"DJango"}]},{"label":["Skills"],"points":[{"start":2146,"end":2154,"text":"Core Java"}]},{"label":["Skills"],"points":[{"start":2138,"end":2143,"text":"Python"}]},{"label":["Location"],"points":[{"start":1519,"end":1525,"text":"Chennai"}]},{"label":["Education"],"points":[{"start":1246,"end":1251,"text":"B.Tech"}]},{"label":["Skills"],"points":[{"start":445,"end":448,"text":"J2EE"}]},{"label":["Skills"],"points":[{"start":431,"end":439,"text":"Core Java"}]},{"label":["Skills"],"points":[{"start":388,"end":393,"text":"DJango"}]},{"label":["Skills"],"points":[{"start":380,"end":385,"text":"Python"}]},{"label":["Skills"],"points":[{"start":329,"end":333,"text":"Scrum"}]},{"label":["Name"],"points":[{"start":0,"end":11,"text":"Madhu Nettem"}]}],"extras":null,"metadata":{"first_done_at":1532669929000,"last_updated_at":1532669929000,"sec_taken":72,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "MALLIKARJUN CHAULAGI\nBRITISH TELECOM Pvt.Ltd +91 9611513825   chaulagi.mallikarjun@gmail.com\n\nSenior Data Scientist\n\nSkills\n\nMachine Learning\n\nDecision Trees (Classification and Regression Tree), Segmentation/Clustering (K-means), Random Forest, Ensemble Modelling, SVM, Logistic Regression, and Condition Probability - Naive Bayes, KNN Classification, Recommendation System\nDBMS & Datawarehouse\n\nOracle, ETL - Informatica Power Center , Star Schema, ER Model and Dimensional Model, OLAP\nProgramming Skills\n\nSQL, Python, R, PL/SQL\n\nProfessional Summary\n\n· Have over 10.10 years of experience in Software Designing, Development and in Descriptive Analytics & Predictive Analytics.\n· Proficient in understanding the business pain areas and requirements from SME and converting them to explainable and concluding business models and dashboards.\n· Expertise in Solution Architect on End to End Solution like Defining and Developing Data Model, Dimensional Model and Analytics.\n· Experienced Individual Contributor and proposed new ideas to Predicting the customer who are more likely to leave the service (Churning) Predicting the Students Risk level\n· Have experience in across industries like Telecommunication and Banking.\n· Implemented Proof of Concepts - Telco Customer segmentation, Predictive analysis on the revenue collection  - Using CART ,RF , SVM & AI\n· Sentiment Analysis\n· Proficient in \"Communicating the findings\" of data patterns and optimizing Models.\n· Worked on Data migration project (Migrating data to Finacle core banking system).\nEducation\n\n2001 -2005 Bachelor of Engineering (B.E.) in Electronics and Communication.\nVTU Belagum.\n\t\n\t\n\tWork experience\n\t\n\t\n\n\t\n\t\n\t\n\t\n\t\n\n\t\n\t\n\t\n\t\n\t\n\n\tJun,2014 - till date\n\tSenior Consultant( Data Scientist )- BAL & eServe Billing Application \n\t\n\n\t\n\tBritish Telecom Pvt.Ltd\n\t\n\n\t\n\tDescription:   BAL & eServe Applications are solutions to Telecom Billing Application . It provides a single point of access to the billing system, and allows for the provision/modification/cessation of customers, accounts and products, and the ability to obtain up to date billing information at any time. It would support managing Payments, adjustments, invoices etc.\n\n\t\n\n\t\n\t· Built Decision Tree CART model to find billing risk levels of customers.\n· Built recommendation system to recommend the required content for the customers who are predicted as \"At Risk\".\n· Applied Time Series model to predict the DB table space usage.\n· Created separate denormalized tables and defined ETL Scripts to read required data.\n· Data cleaning was done during the ETL process like missing scores, null values\n· Designed and Developed BI Interactive Dashboards and Mobile analysis\n· Developed Clutering model on customer segmentation.\n· Developed regression model for the billing application.\n· Developed EDA for different models.\nEnvironment:\nHardware: HP                                                Operating System: UNIX            \n      Languages: Python, R ,SQL &PL/SQL          Back End: Oracle 11g\n\n\t\n\n\t\n\t\n\t\n\n\t\n\t\n\t\n\n\t\n\t\n\t\n\n\t\n\t\n\t\n\n\t\n\t\n\t\n\n\t\n\t\n\t\n\n\t\n\t\n\t\n\n\t\n\t\n\t\n\n\t\n\t\n\t\n\n\t\n\t\n\t\n\n\tOct,2011 - Jun,2014\n\tDB Developer and Data Scientist — Market Bond Project SG-India.\n\t\n\n\t\n\tSociete Generale, Pvt.Ltd Bangalore.\n\t\n\n\nDescription:   SG has initiated new business capabilities by allowing short sale of Government securities. The Bank will ensure that the short position is covered within a period of 90 days. For this requirement, we need to generate new Daily Short Sale Report, Implementation of new Bonds revaluation report for short sale of Government securities, New accounting schema development to handle short sale of securities.\nAs a Senior Oracle Developer (with team size of 4) responsible for  - \n· Requirement gathering scoping, effort estimation, tracking client communication & presentation.\n· Involved in high level design, coding and development, Manage UT and SIT, debugging and troubleshooting.\n· Design and Develop Oracle Database objects for Market application. \n· Create, Quality Assure and Tune SQL for Market application developers. \n· Worked on Descriptive & Exploratory data analysis on Market Bond data.\nEnvironment:\nHardware: HP                                                Operating System: UNIX            \n      \n\n\nLanguages:  R, SQL &PL/SQL                       Back End: Oracle 11\nSep,2010 - Oct,2011     Senior Consultant CSS Corp Chennai.\n Client :Societe Generale.\nApr,2007 - Sep,2007     Senior Software Engineer Qwest Telecom Software Services","annotation":[{"label":["Skills"],"points":[{"start":4321,"end":4326,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":3949,"end":3954,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":3664,"end":3669,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":3014,"end":3019,"text":"Oracle"}]},{"label":["Education"],"points":[{"start":1572,"end":1594,"text":"Bachelor of Engineering"}]},{"label":["Skills"],"points":[{"start":595,"end":612,"text":"Software Designing"}]},{"label":["Skills"],"points":[{"start":405,"end":434,"text":"ETL - Informatica Power Center"}]},{"label":["Skills"],"points":[{"start":397,"end":402,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":125,"end":140,"text":"Machine Learning"}]},{"label":["Name"],"points":[{"start":0,"end":19,"text":"MALLIKARJUN CHAULAGI"}]}],"extras":null,"metadata":{"first_done_at":1532666838000,"last_updated_at":1532666838000,"sec_taken":161,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Manikandan D\n\nMobile: +91 9629131529\nEmail: manikandanflex@gmail.com\n\n\nProfile Summary:\n\n· Having 6 Years of experience in analysis, design and development of Web Client/Server Based Applications and windows application for industrial, CRM, Communications, Applying principles and techniques of computer science, engineering, and mathematical analysis.\n· Having good working knowledge in ASP.net core, MVC Framework, ASP.net, C#.Net, RABBITMQ, Python 3,  django, Elastic Search 6, Apache Solr 2.0 and SQL Server 2012/2016.\n· Proficient in Web Services, WCF, Web API, XML, AJAX, Angular JS, Knockout JS, J Query and JavaScript.\n· Experienced in using HTML, CSS and Bootstrap beta4.\n· Having good working knowledge in OOPS and RDBMS Concepts.\n· Experienced in Normalization, Stored Procedures, Functions, Triggers, Jobs, Asynchronous and Views.\n· Advise customer on perform and maintenance of software systems.\n\n· Coordinating the installation of software system in the company.\n\n· Store, retrieve, and manipulate data for analysis of system capabilities and requirements.\n\n· Directing software programming and development of documentation.\n\n· Prepare reports and correspondence concerning project specifications, activities and status.\n\n· Modify existing software to correct errors.\n\nObjective:\n\nI am seeking for a challenging environment where I can use my skills for a growth of an organization.\nSkills and Interests:\n\n      Object Oriented Design       : ASP.NET, MVC Framework, ASP.NET core\n      Language\n\n           : ASP.Net, C#.\n\n      Database                     : SQL Server 2008/2015\n\n      Web Enabled Language   : JavaScript, J Query, Angular JS, HTML, CSS, XML and         \n\n                                          Bootstrap Beta 4.                                                                                                                                                                \n      Version Control Tool       : Team Foundation Server, SVN, Scrum\nEducation:\n\n\nB.TECH (Information Technology) in Bannari Amman Institute of technology - Anna \n\nUniversity in Chennai - 2011-70%.\n\nDiploma (Computer Engineering) in AJJK Sampoorani Polytechnic - Board of Tamilnadu in Chennai - 2008 -87%.\n\nHSC - Board of Tamilnadu in chennai - 2005-70%.\n\nSSLC - Board of Tamilnadu in chennai - 2003-72%.\n\nProfessional Experience:\n· Worked as Software Engineer at Winceron Software Technology in Bangalore (Dec 2011 to Dec 2014).\n· Working as Senior Software Engineer at Skybridge Infotech Private Limited in Coimbatore (Jan 2015 to May 2017).\n· Working as Senior Programmer at Path finder business analysis Pvt Ltd in Coimbatore (Jun 2017 to Till Date).\nProject Profile:\nProject: 1\n\nTitle \n\n: Research Utility\nFront End \n: ASP.Net MVC 5.0, Knockout JS, J Query, Bootstrap Beta 4.0 and                 ASP.Net Core Web API.\nBack End \n: SQL Server 2016 and Elastic Search 6\nTeam Size \n: Five\nProject Description:\n\nResearch utility is a searching tool. User can access module based on him role. This application contains two role super admin and user. Super admin can give access to users and allocate research data to user. User can login this application using windows authentication then research them allocated records. User can search property and contact information. \nProject: 2\n\nTitle \n\n: Build Operate Transfer (BOT)\n\nFront End \n: ASP.Net Core and RABBITMQ Service.\nBack End \n: SQL Server 2016 and Elastic Search 6\nTeam Size \n: Five\nProject Description:\n\nBOT is an overall scheduled process to move records source to destination database using RABBITMQ. Expectation from this process is to move records from source to destination without lose and fast. This tool contains two processes READER and WRITER.\nREADER – Read the records from source database table and will be inserted from particular RABBITMQ queue.\n\nWRITER – Read the records from RABBITMQ and will be insert or update from destination table.\n\nProject: 3\nTitle \n\n: Devos\n\nFront End \n: ASP.Net MVC 5.0, Bootstrap3.3, Angular JS and Web API\nBack End \n: SQL Server 2016\n\nTeam Size \n: Four\n\nProject Description:\n\nDEVOS is a powerful, multifunction lives and on demand streaming video delivery system for offices, schools, corporations, departments, government agencies and other enterprises.\n\nIntegrate audio, video, and content from a computer into powerful lessons and presentations that provide users with a repeatable and timely learning experience. Discover video allows all viewers, even from remote locations or at home, to easily watch classes live and on-demand by leveraging your network and the power and each of the internet.\n\nProject: 4\nTitle \n\n: LeadsTrax\nFront End \n: ASP.Net MVC 5.0, Bootstrap3.3, Angular JS and Web API\nBack End \n: SQL Server 2016\nTeam Size \n: Five\n\nProject Description:\n\nLeadsTrax is Automotive CRM application for sales consultants in a car dealership that helps to make sure important activities and conversations are not dropped. This application also helps the other team members (Team Lead, Branch Manager, General Manager – Sales, CEO) in the dealership to track all the leads and ensure that sales consultant follows-up with all the potential customers on time.  \n\nIf a potential lead is not followed up on time, Team lead and Branch manager is notified via SMS within an hour. LeadsTrax streamlines the sales process and brings discipline to the sales teams. Effective use of the tool will result in huge increased revenue of the car dealership. \n\nProject: 5\nTitle \n\n: LeapEdge\nFront End \n: Python 3 and Django. \nBack End \n: SQL Server 2012, Apache Solr 2.0\nTeam Size \n: Three\n\nProject Description:\n\n        This is an Online Job Portal for Senior Level Jobseekers across all Industries. This portal is also for Recruiters who seek high qualified experience candidates. Recruiters can Post the Jobs and Search Jobseekers. \nJobseeker can enrol their profile with this portal and they can Network with the recruiter across the world and apply for a job. Search is built in such a way that it searches the keywords with Accuracy and displays the result based on Ranking. \n\nSolr Search is used for Searching Jobs, Recruiters and Jobseekers within the Portal. It has an Extensive mailing component for sending job alerts to jobseeker and for all communication between Jobseeker and Recruiter. \nProject: 6\nTitle \n\n: HealthCare Management System                                              \n\nFront End \n: ASP.Net web form, Bootstrap3.3, J query and Web API\nBack End \n: SQL Server 2008\n\nTeam Size \n: Five\n\nProject Description:\n\n        The main aim of this health care management system is to implement an online software application for maintaining drugs information, patient’s information, nurse information and doctor’s information in a single application. Doctors and patient can view this data from anywhere which save time. This application is also useful for pharmacist to inquire about the drugs and update information about drugs to database.\n\nOverall Project Roles and Responsibilities:\n· Requirement analysis.\n\n· Design and development of web applications.\n\n· Coded modules following the design specifications and standards.\n\n· Involved in table designing and written stored procedures, views, etc.\n\n· Functionality checking before giving it for Testing.\n\n· Responsible for maintenance of the code and fixing the bugs.\n\n· Handled end to end release of the application. \n· Assign task to team members in TFS.\n\n· Create development bugs token in TFS and assign to team member .\n\n· Writing email for client queries.\n\n· Do team members code re view.\n\n· Preparing for application technical knowledge transfer document.\n\n· Schedule project status and technical issues discussion meeting with TL.\n\n· Give production support to client.\n\nPersonal Profile: \n\nDate of Birth\n\n\n:   5th April 1987\n\nPermanent Address\n\n: Thandhai Periyar colony, \n   MSM nagar, Pooluvatti, Tirupur-641602\n\nGender                \n\n:  Male.\nLanguages Known               : English and Tamil\nI hereby declare that the information furnished above is true to the best of my knowledge and belief. \n                                                                                                           (D.Manikandan)","annotation":[{"label":["Location"],"points":[{"start":7880,"end":7886,"text":"Tirupur"}]},{"label":["Skills"],"points":[{"start":6461,"end":6467,"text":"Web API"}]},{"label":["Skills"],"points":[{"start":5509,"end":5516,"text":"Python 3"}]},{"label":["Skills"],"points":[{"start":4704,"end":4710,"text":"Web API"}]},{"label":["Skills"],"points":[{"start":4010,"end":4016,"text":"Web API"}]},{"label":["Skills"],"points":[{"start":2825,"end":2831,"text":"Web API"}]},{"label":["Education"],"points":[{"start":1992,"end":1998,"text":"B.TECH "}]},{"label":["Skills"],"points":[{"start":1670,"end":1673,"text":" XML"}]},{"label":["Skills"],"points":[{"start":1465,"end":1478,"text":" MVC Framework"}]},{"label":["Skills"],"points":[{"start":572,"end":575,"text":"AJAX"}]},{"label":["Skills"],"points":[{"start":566,"end":569,"text":" XML"}]},{"label":["Skills"],"points":[{"start":558,"end":564,"text":"Web API"}]},{"label":["Skills"],"points":[{"start":552,"end":555,"text":" WCF"}]},{"label":["Skills"],"points":[{"start":539,"end":550,"text":"Web Services"}]},{"label":["Skills"],"points":[{"start":444,"end":451,"text":"Python 3"}]},{"label":["Skills"],"points":[{"start":416,"end":423,"text":" ASP.net"}]},{"label":["Skills"],"points":[{"start":401,"end":414,"text":" MVC Framework"}]},{"label":["Skills"],"points":[{"start":388,"end":399,"text":"ASP.net core"}]},{"label":["Skills"],"points":[{"start":387,"end":394,"text":" ASP.net"}]},{"label":["Name"],"points":[{"start":0,"end":11,"text":"Manikandan D"}]}],"extras":null,"metadata":{"first_done_at":1532689723000,"last_updated_at":1532689723000,"sec_taken":141,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Manish Sharma\nPhone: +91-9772058333\n Email:  s.maneesh1986@gmail.com\n\n\nOBJECTIVE\n\nA career as Data science and Machine Learning Engineer for an organization and contribute to its growth along with exploring my potentials.\n\nPROFESSIONAL SUMMARY\n\n\n· Experience of working over projects from specification to closure.\n\n· Experience in analyzing the BI needs & Business data flow.\n\n· Experience in client interactions, analyzing clients’ business requirements, developing reports and delivering the project.\n\n· Self-motivated, diligent and goal-oriented with a high degree of flexibility, creativity, resourcefulness, commitment and optimism.\n\n· Enriched with the ability to learn and assimilate new concepts & technology within a short span of time.\n\nPROFESSIONAL WORK DETAIL\n\n·  Cellarch Technologies Pvt. Ltd\n\n\n\n \n\nFrom Sept-2016\n Role: Data Scientist and Machine Learning Engineer\n\n Tools / Skill Set: R, R-Studio, Python, Spark, Tableau, Mongo DB, MySQL\n· Preparing the project documents based CRISP-DM, KDD Process.\n\n· Liaising with client for updates and work progress.\n\n· Knowledge of model deployment. \n\n· Modelling using Regression, K-NN, Naive Bayes classifier, Decision Tree, Random Forest.\n\n· Hands on Experience with Microsoft Azure ML.\n\n· Implemented Machine Learning algorithms to Text Mining, and knowledge of social media mining.\n\n· Performed exploratory data analysis on dataset and its visualisation.\n\n· Designed and developed Tableau reports, dash boarding, & visualization (Scatter plots/Pie charts/Bar Charts/cross tabs etc.) for data analysis.\n\n· Knowledge of Regression, Supervised Learning, Classification, and Machine Learning Algorithms.\n\n· CSIR-CEERI\n\n\n\n\n\n\n\n\nMarch 2016 to Aug 2016\nRole: Senior Project Fellow\n\nTools / Skill Set: Machine Learning\n· Project Funded by Ministry of Electronics and Information Technology (MEITY), Govt. of India\n· Involved in the algorithm development for Implementation for Design of an Embedded System for Low Cost Haptic Rendering of Emotion Expressions to the Blind.\n\n· Pace Infotech\n\n\n\n\n\n\n\n\nSept 2013 to Feb 2016\nRole: Testing Engineer\n\n· Handwritten Character Recognition in English of Cursive writing.\n\nInvolved in implementation through development of pre-processing of text images for segmentation of characters.\n\n· Ethernet packet loopback design Test and Verification.\n\nDescription: Design checks the incoming Ethernet packets at the receive interface for CRC, SOF errors, etc. As part of this design verification we developed test bench with generate all types of Ethernet packets.\n\nTools used: Questasim (Mentor Graphics)\n\n· Responsibilities: Test plan development, developing test bench architecture, Coding Test bench \n\n· Experience as an Instructor in RCEW Jaipur \n\n\n\nAug 2009 to Dec 2010\n· Responsibilities: \n\n· Instructor in Project Lab of Electronics and Communication Department.\n\n· Delivered courses and Conducted workshops for ECE Dept.\n\n· Test Engineer at Ericsson India Pvt Ltd\n\n\n\n\nOct-2008 to March 2009\n· Responsibilities: \n\n· Testing of Ericsson’s AXE hardware: BSC, MSC and APG and Prepared logs and reports \n\n· Initialization of the cards by connecting it through the Ericsson software Verified the testing criteria.\n\n\nACADEMIC GROUND\n\n· Cleared GRE and TOEFL.\n\n· Qualified GATE-2011 in Electronics and Communication.\n\n· M.Tech in ECE from Jagannath University \n\n· B.E in E.C.E from University of Rajasthan\n\n· Sr Secondary and Secondary from Board of Secondary Education Rajasthan \n\n\nTRAINING and SEMINAR\n\n· Certificate of Participation in MHRD sponsored GIAN course at MNIT from 25 to 29 July 2017.\n\n· Attended training module on R language. \n\n· Academic Training on Power Line Carrier Communication at RRVPNL, Jaipur.                                          \n\n· Academic Training on Digital Design Using VHDL at CSIR-CEERI \n\nPERSONAL DOSSIER\n\n· Father’s Name:\nLate Mr. D. P. Sharma\n\n· Mother’s Name:\nMrs. Lalita Sharma\n\n· Date of Birth\n:\n19 June, 1986\n\nManish Sharma","annotation":[{"label":["Name"],"points":[{"start":3940,"end":3952,"text":"Manish Sharma"}]},{"label":["Education"],"points":[{"start":3305,"end":3310,"text":"M.Tech"}]},{"label":["Skills"],"points":[{"start":3008,"end":3014,"text":"Testing"}]},{"label":["Skills"],"points":[{"start":2079,"end":2085,"text":"Testing"}]},{"label":["Skills"],"points":[{"start":1755,"end":1770,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1633,"end":1648,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1262,"end":1277,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1227,"end":1244,"text":"Microsoft Azure ML"}]},{"label":["Skills"],"points":[{"start":949,"end":953,"text":"MySQL"}]},{"label":["Skills"],"points":[{"start":939,"end":946,"text":"Mongo DB"}]},{"label":["Skills"],"points":[{"start":855,"end":870,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":111,"end":126,"text":"Machine Learning"}]},{"label":["Name"],"points":[{"start":0,"end":12,"text":"Manish Sharma"}]}],"extras":null,"metadata":{"first_done_at":1532667661000,"last_updated_at":1532667661000,"sec_taken":238,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Manjunath\nBhat\n\t\n\t9538779029\t\n\n\tmanjubhat89@gmail.com\t\n\n\thttps:/www.linkedin.com/in/manjunath-bhat-76678946\t\n\n\t\n\t\n\n\n\n\n\n\t\n\tObjective\n\n\nSeeking a challenging position in the Data Science, where I can apply and expand my knowledge, skills to carve out a career path for myself and to effectively contribute towards the goals of the organization.\n\t\n\tEducation\n\n\nBachelor of Engineering (B.E) | Visveswaraya Technological University\n2007 – 2011\n\nPre-University | Vijaya PU College\n2005 – 2007\n\n\t\n\tExperience\n\n\nGlobal Services Business Specialist | Brocade Communication Systems Pvt Ltd\nDec 2015 – Till Date\nCurrently managing a team of 3 people who work on the procurement & support of Mobile Devices for EMEA. Worked on different stake holder’s data sets to forecast & predict on the Telecom project in EMEA. Data Visualization using BO & Tableau is also a part of my job.\nTeam Member | Timken Engineering & Research India Pvt Ltd\nMay 2014 – Dec 2015\nProvided second level of support to internal employees. Have worked as a Mobile Support Admin & SharePoint Admin.\nTechnical Support Associate | IBM India Pvt Ltd\nJUL 2011 – Aug 2012\nProvided the first level of support for end users. Facilitated various vendors by providing technical support and troubleshooting. \n\t\n\tSkills\n\n\n\tR Programming\nMachine Learning Algorithms (including Linear & Logistic Regression, Clustering, Naïve Bayes, Random Forest (Decision Trees & CHAID))\n\tDetecting outliers in data and how to handle outliers, checking multicollinearity, missing values in data and data preparation\nAbility to handle huge data sets \n\n\n\n\t\n\tActivities\n\n\n· Excellent knowledge in performing predictive analysis using supervised and unsupervised machine learning algorithms.\n· Excellent knowledge in machine learning algorithms – Linear & Logistic Regression, Clustering, Naïve Bayes, Random Forest (Decision Trees & CHAID)\n· Good experience in programming using RStudio and excellent knowledge in determining on which Machine Learning algorithms to apply for a specific business problem.\n· Good knowledge on how to handle huge data sets.\n· Excellent knowledge on how to detect outliers in data and how to handle outliers.\n· Checking Multicollinearity in data, missing values in data and data preparation.\n· Good experience in developing reports & dashboards from SAP Business Objects XI & Tableau 10.1 from different data sources like Oracle 11i, SQL Server.\n\t\n\tAchievements\n\n\n· Recently got awarded by $200 for taking up new initiatives for the team to automate some of the manual tasks.\n· Have been awarded twice with the “Consistent Customer Service” Awards for the best customer service for the First Half of 2015 and Q3 of 2015.\n· Was awarded with the “CSAT Champ” with 100% CSAT for the 17 surveys received.\n· Worked on 593 pending tickets of the team. Followed up with the resolver team or followed up with the user and made sure to finish the task in no less than a week.\n· Have always provided continuous improvement plans for our team to increase productivity of our associates and also to reduce the non-value added work by automating the tasks and save cost / time that we invest for it.\n\t\n\tPersonal Profile\n\n\nAddress: No.31, 1st Avenue, Teacher’s colony, Koramangala, Bangalore – 560034.\nDate of Birth: 24th June, 1989.\nFather’s Name: Ishwar Ganesh Bhat.\nLanguages Known: Kannada, English and Hindi.\nLeisure Interests: Numismatics, Philately, Playing and watching football.\nNationality: Indian.\nGender: Male.\n\nI hereby declare that the particulars furnished above are true to the best of my knowledge and belief.\n\n\nDate: \nPlace: Bangalore.      \t\t\t\t\t               [Manjunath Bhat]\t\n2","annotation":[{"label":["Location"],"points":[{"start":3590,"end":3598,"text":"Bangalore"}]},{"label":["Location"],"points":[{"start":3229,"end":3237,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":1288,"end":1314,"text":"Machine Learning Algorithms"}]},{"label":["Skills"],"points":[{"start":1274,"end":1286,"text":"R Programming"}]},{"label":["Education"],"points":[{"start":358,"end":386,"text":"Bachelor of Engineering (B.E)"}]},{"label":["Name"],"points":[{"start":0,"end":13,"text":"Manjunath\nBhat"}]}],"extras":null,"metadata":{"first_done_at":1532669557000,"last_updated_at":1532669557000,"sec_taken":65,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Midhun M\n\t\n\n\n\nMidhun M\nIT Software Engineer\nPhone +91-9400272807, +91-7907220727\nE-mail  midhun4munna@gmail.com\n\nExperience Summary\nTechnology Specialist with 4.6 Years (Cognizant 1.2Year, Geojit technologies 3.3Year) of Experience, involving all the phases of the Software Development Life Cycle predominantly in Java/J2EE technologies and moderately in JavaScript technologies. Currently working as a Full Stack Developer with Hands On experience in latest AWS Cloud technologies and moderate knowledge in DevOps. Developed and deployed applications for financial trading with a significant knowledge about cash and derivative markets(NSE , BSE ,NSEFO etc).\n\tEducation & Certifications\n\n\n· Bachelor of Engineering in Computer Science and Engineering (2008-12)\n· CUSAT University (College of Engineering Vadakara)\n\tTechnical Skills\n\n\tProgramming Languages\n\t\nCore Java, J2EE ,JavaScript,  JQuery , CSS, HTML\n\n\tFrameworks and Libraries\n\nAWS \n\tAngularJS, Nodejs, Jasmine, Mocha, Spring Framework, Hibernate, Spring Boot \n\nEC2, Alexa, Lex, RDS, Lambda, aws machine learning etc.\n\n\n\tDatabases\n\nServers\n\nTools\n\tDB2, MySQL, H2, MongoDB\n\nWebLogic, Tomcat, JBOSS, GlassFish \n\nGrunt, Gulp, Karma, VS Code, Eclipse, Netbeans, SVN, GIT, STS, Maven, GitHub\n\n\n\t\n\t\n\n\tRelevant Project Experience\n\n\n\nOrganization:   Cognizant Technology Solutions \nPeriod:             Aug 2016 - Current          \nDesignation:     Associate Projects   \n\nIn Cognizant I am part of the Insurance Technology Consulting Group. For past 1.3 years, I have been working as a Technology consultant which mainly focuses on developing next generation solutions in Insurance domain for Cognizant, mainly in the digital area (Cloud Technologies, Docker, AWS, etc.) and  in javascript based frameworks (Angularjs1,Angularjs2 , NodeJs etc).\n\nProject: Lex Chat Bot for Farmers Insurance (AWS Lex, NodeJS, JavaScript)\n\nLex Chat Bot is a chat service leveraging the latest AMAZON AI  Lex Service. Lex Chat bot can intelligently answer some chat queries from client using AWS Lex if Lex is not able to handle the chat request from user it will delegate the request to Salesforce Live Agent Service.  \nRole and Responsibilities\nInvolved in:\n· Developing the nodejs application from the scratch.\n· Developing user stories and fixing defects in nodejs and javascript  etc..\n· Developing and configuring aws Lex Bot. \n\nProject: Alexa-FrameWork (Spring Boot,AWS Alexa, MySql)\n\nAlexa- lex FrameWork handles all the request types from Amazon alexa (Amazon Echo device) Using this frameWork we can easily implement any AWS alexa use Cases.\nRole and Responsibilities\nInvolved in:\n· Developing and fixing defects in Alexa- lex FrameWork using.\n\nProject: Lifely (angularjs 1, Nodejs, loopback)\nRole and Responsibilities\nInvolved in:\n· Developing user stories and fixing defects in web-app using Angular js1, Nodejs, loopback.\n· Creating grunt task for automating build.\n· Creating unit test using node-jasmine,supertest  and karma.\n\n\n\nOrganization:   Geojit Technologies Pvt Lmt\nPeriod:             May 2013 – Aug 2016          \nDesignation:     Software Engineer   \n \t\n\n\n\n\n\nProject: Flip Enterprise – Order Management System(java,spring, hibernate, weblogic)\nOrder Management System manages all the Authentication and Orders in the Flip Environment. This system is responsible for all the business logics in Flip. The OMS accepts requests from Different Front-End such as desktop and web applications via TibcoRV messaging. These requests are then subjected to a series of validations and processes such as user validation, security validation, buying power booking process etc.. , and if all processes are successful, the order is passed on to the Exchange Connector and then to the Exchange.\nRole and Responsibilities\nInvolved in:\n· Implemented  change requests  and necessary business rules including exchange mandatory changes for trading through exchanges like NSE, BSE, NSEFO, NSECD etc.\n· Supported clients by going at the client site to understand their concerns and ensured the timely solution for their grievances. \n· Deploying and configuring Order Management System in live environment.\n\nProject: Flip Enterprise – Risk Management System (java , H2db)\nRisk Management System is a standalone Java application which does real time analysis on current portfolio and recent activities by user to find the risk created by him and take necessary actions.\nRole and Responsibilities\nInvolved in:\n· Added mailing and SMS features on RMS.\n· Implemented  change requests  and necessary business rules.\n\nProject: FlipUltimate – Order Management System(java, spring, hibernate, JBoss)\nFlipUltimate-OMS is an open source flavor of Order Management System with customer specific Business Changes. The working of FlipUltimate-OMS is same as FlipEnterprise-OMS.\nRole and Responsibilities\nInvolved in:\n· Implemented  change requests  and necessary business rules including exchange mandatory changes for trading through exchanges like NSE, BSE, NSEFO, NSECD etc.\n· Supported clients by going at the client site to understand their concerns and ensured the timely solution for their grievances. \n\n\n\n\t\n\tPage 1 of 3\n\tDated: 10/18/17","annotation":[{"label":["Skills"],"points":[{"start":2560,"end":2562,"text":"AWS"}]},{"label":["Skills"],"points":[{"start":2402,"end":2404,"text":"AWS"}]},{"label":["Skills"],"points":[{"start":2021,"end":2023,"text":"AWS"}]},{"label":["Skills"],"points":[{"start":1857,"end":1866,"text":"JavaScript"}]},{"label":["Skills"],"points":[{"start":1840,"end":1842,"text":"AWS"}]},{"label":["Skills"],"points":[{"start":1709,"end":1711,"text":"AWS"}]},{"label":["Skills"],"points":[{"start":942,"end":950,"text":"AngularJS"}]},{"label":["Skills"],"points":[{"start":936,"end":938,"text":"AWS"}]},{"label":["Skills"],"points":[{"start":903,"end":906,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":898,"end":900,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":889,"end":894,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":876,"end":885,"text":"JavaScript"}]},{"label":["Skills"],"points":[{"start":870,"end":873,"text":"J2EE"}]},{"label":["Skills"],"points":[{"start":859,"end":867,"text":"Core Java"}]},{"label":["Skills"],"points":[{"start":459,"end":461,"text":"AWS"}]},{"label":["Skills"],"points":[{"start":355,"end":364,"text":"JavaScript"}]},{"label":["Skills"],"points":[{"start":319,"end":322,"text":"J2EE"}]},{"label":["Name"],"points":[{"start":14,"end":21,"text":"Midhun M"}]},{"label":["Name"],"points":[{"start":0,"end":7,"text":"Midhun M"}]}],"extras":null,"metadata":{"first_done_at":1532687951000,"last_updated_at":1532687951000,"sec_taken":132,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Serving notice period, LWD 27th April18.\n\nMOHAMED AFSAL PARAVAKKAL\n\tafsalparavakkal@gmail.com\n\n\tParavakkkal House\n\t+91 9809043240\n\n\t\n\t\n\n\tChappanangadi PO, Kottakkal\n\t\n\n\tMalappuram, Kerala,\n\t\n\n\tIndia – 676503\n\t\n\n\n\nSUMMARY\n\nA talented post graduate in computer application (MCA) with 6 years of experience in design, development and implementation of software applications, experience in open/free source technologies like Linux, Python, Java\n\nTECHNICAL SKILLS\n\n\tLanguages\n\t: Python (6 years), Java (1 year)\n\t\n\n\tFrameworks\n\t: Django, Flask, Turbogears, SQL Alchemy, Celery, Boto, Spring, Hibernate\n\n\tRDBMS\n\t: PostgreSQL, MySql\n\t\n\n\tData Stores\n\t: Cassandra, Zookeeper, Redis ,InfluxDB,\n\t\n\n\tMessage broker\n\t: RabbitMQ\n\t\n\n\tIntegration with\n\t: AWS S3, AWS SQS, SendGrid, Facebook, Twitter, LinkedIn\n\n\tExperience with\n\t: HTML, CSS, JavaScript, J Query , Angular JS ,Nginx, Heroku, Microsoft\n\n\t\n\t\n\tAzure, AWS EC2 .\n\t\n\n\tApplication/Tools\n\t: Subversion, GIT, JIRA, NetBeans, Pycharm, IntelliJ Idea, Postman,\n\n\tGunicorn\n\t\n\t\n\t\n\t\n\n\tOperating Systems\n\t: Windows, GNU/Linux\n\t\n\n\tPROFESSIONAL EXPERIENCE:\n\t\n\t\n\n\t1. Devicedriven , Technopark , Trivandrum\n\tFebruary 2017 –Present\n\n\t\n\t\n\t\n\t\n\n\tRole : Senior Python developer\n\t\n\n\tDuties and Responsibilities\n\t\n\n\n· Responsible for the development of a high-performance server-side API that interfaces with a range of technologies at the back-end\n\n· Interfacing with a team of web developers who will consume the APIs\n\n· Assisting technical architect and project manager by contributing ideas and thoughts for the development of multi-tired scalable applications\n\n· Responsible for coordinating client call for requirements gathering and clarifications\n\n· Representing the team in weekly review meeting of the projects\n· PROJECTS\n\n1. DBM Cloud (http://www.dbmclouds.com)\n\nDBM Cloud Systems' DBM Object Manager Engine (DOME) seamlessly moves data from on-premises to one or more cloud environments without the hassle, risk and complexity of data translation or the need for complete migration at every instance.\n\nReap the benefits of DOME for your overall cloud data strategy and improve your business continuity, use the right data for wider application success, and exceed performance expectations, all while maintaining policy compliance and cost controls.\n\nThe software platform can be installed on virtual nodes or bare metal servers and has three components:\n\n1) Storage Nodes\n\n2) Database Nodes\n\n3) Replication Engine/UI Nodes\n\nDBM Cloud DOME provides administration of access rights, user roles/permissions, and robust user-defined policy rules, status of nodes, performance alerts, reporting and analytics. DOME supports moving object data bi-directionally between on-premises and the following cloud service platforms:\n\n1) Amazon S3\n\n2) Microsoft Azure\n\n3) IBM Cloud\n\n4) Oracle Cloud\n\n5) Alibaba Cloud\n\nTechnology: Python, Flask, Gevent, Boto3, AWS SQS, Celery, RabbitMQ, Postgresql, Cassandra, Zookeeper, Redis, Elasticsearch, Logstash , AWS CLI , S3 Browser, Dragon Disk\n\nRole: Back-End Developer and Implemented Replication Engine.\n\n2. Advo.Ninja - Marketing automation software (http://advo.ninja)\n\nAdvo.Ninja is a cloud based Employee Advocacy platform that helps include employees in corporate marketing. Employees spread the word by sharing their company’s articles and assets on their social networks.\n\nModules\n\n1) Social Publishing :\n\nScheduling and publishing posts to Facebook, Twitter and LinkedIn at the same time and when the audience is most active.\n\n2) Employee Advocacy :\n\nIncluding employees in a controlled omni-channel marketing activity that strengthens employee social profiles.\n\n3) Social Analytics :\n\nTracking every click and engagement from all the audience and mapping those activity to each employee contribution. A leaderboard helps reward employees for their participation.\n\nTechnology : Python,Flask,SQL Alchemy ,Celery, Gunicorn, PostgreSQL, AngularJs, Jquery, CSS, Bootstrap, SendGrid, AWS S3, Embedly .\n\nRole: Back-End and Front-end Developer.\n\n3. Reporting for Juniper Networks\n\nJuniper has an application that predict life and capcity of Routers and Switches based on some forecasting variables (VRF Counts,BGP Routes,OSPF Neighbors etc) provided .\n\nAnd this application expose api to fetch data like memory percentage prediction,Significant factor analysis and Impact curve . REporting engine calls this api and supplies to gui to produce graph and heat maps . It is under developement and the system is keep changing.\n\nTechnology : Python3, Flask, Postgresql, SqlAlchemy, Gunicorn\n\n4. Reporting for DiskProphet (http://www.prophetstor.com)\n\nDiskProphet is a patented and intelligent data analytics solution that addresses the problem of data loss prevention in a unique way. With DiskProphet™, data is continuously collected from hard disks and solid state disks to not only predict behavior but to also provide prescriptive actions.\n\nReporting module depicts state and health of its storage infrastructure,CPU Trend data, Network IO , System load by fetching data from InfluxDB which is sharing with DiskProphet.\n\nTechnology : Java, Spring, MySQL, InfluxDB, Apache Ignite, AngularJS, HTML, CSS, Bootstrap,\n\nHighCharts\n\nRole: Back-End-Developer.\n\n4. Education Content Management Platform\n\nAn application that is used to create personalized content education platform for young children. The application provides a back-end for content creators to create content based on mapped structures in a graph database. The platform aims to automate most aspects of the content generation process by using a combination of a content graph, intelligent image processing and PDF templating.\n\nTechnology: Fabric.js, Jquery, HTML, CSS, Spring, Hibernate, iText, Neo4J, MySQL\n\nRole: Back-End and Front-end Developer. The application is implemented using Jquery also makes extensive use of in-browser SVG manipulation using the Fabric.JS library. It interfaces with the back-end Spring REST API’s using AJAX.\n\n2. Implemer Technologies, Calicut\nJanuary 2012 - January 2017\n\nRole : Senior Python developer\nDuties and Responsibilities\n\n· Responsible for design and development in Python and Turbogears\n\n· Responsible for database design using PostgreSQL\n\n· Creating solution designs for new modules/features\n\n· Debug existing source code and polish feature sets\n\n· Python Scripting for different applications\n\n· Database Migrations\n\n· Code Reviewing\n\n· Coordinate with the Technical director on current programming tasks\n\n· Collaborate with other programmers to design and implement features\n\nPROJECTS\n\n1. CAPSULE (EMR Software)\n\nIt is a hospital management software that is being used by several medical centers\n\nin Qatar , Oman and hospitals in India. CAPSULE addresses all the functional requirements with respect to the core business activities of Health Industry.\n\nTechnology: Python ,Turbogears, PostgreSQL, Java Script, CSS, SQL Alchemy, JQuery\n\nRole: Back-End Developer\n\n2. CAPSULE – SEHA\n\nIt is a tool for generating MDS (Patient Minimum Sata Set) from Capsule as a part of the SEHA (Insurance Package to Qatari Nationals ) by Qatar Govt . It is responsible for automating claiming and reclaiming of MDSs to SEHA .\n\nTechnology: Python , Turbogears, PostgreSQL, Java Script, CSS, SQL Alchemy, Jquery\n\nRole: Back-End Developer\n\n3. Document Management System\n\nIt provides some of the most basic functionality to content management, imposing controls and management capabilities onto otherwise “dumb” documents. Docmo makes it so that when you have documents and need to use them, you are able to do so.\n\nTechnology: Python , Django, PostgreSQL, AWS S3, Java Script, Jquery\n\nRole: Back-End Developer\n\n4. EQUALS\n\nIt is a accounting and inventory management software , that integrated with Capsule also . Technology: Python , PostgreSQL ,SqlAlchemy, HTML, Javascript, Genshi, Turbogears Role: Back-End Developer\n\n5. ABUZZ\n\nIt is a standalone application of EQUALS and it is completely replaced with . Technology: Python , PostgreSQL ,PyGTK , ReportLab,GLADE Technology Role: UI and Back-End Developer\n6. IHRMS\n\nIt is a web application for managing Employee Attendance, Leave, and Salary Technology: Python , PostgreSQL ,SqlAlchemy, HTML, Javascript, Genshi, Turbogears Role: Back-End Developer\n\n7. RESTful Web services Using Flask\n\nScripting for providing APIs to mobile applications that is used by Doctors other staffs to upload scanned documents consents etc to Capsule.\n\nTechnology: Python,Falsk\n\nEDUCATION\n\n· MCA (Master of computer Application), Calicut University, India, 2011, First Class (64%)\n\n· Bsc Physics with Computer Application , Calicut University, India, 2008, First Class (83%)\n\n· +2 Science , Board Of Higher Secondary Education Kerala (75%)\n\nPERSONAL DETAILS\n\n\tDate of birth\n\t: 28th November 1987\n\n\tMarital Status\n\t: Married\n\n\tDetails as per Notificaton\n\n\t\n\t\n\t\n\n\tAlternate Contact No : 0483-2706839 (H), 08976148278(Brother)\n\n\tReason for change\n\t: Need more professional exposure and opportunities for improvement in my\n\n\t\n\tcareer and better salary.\n\n\tJob location\n\t: Ready to relocate to anywhere in South India.\n\n\nDate : 05/02/2018\n\nPlace : Trivandrum","annotation":[{"label":["Location"],"points":[{"start":9118,"end":9127,"text":"Trivandrum"}]},{"label":["Location"],"points":[{"start":8703,"end":8708,"text":"Kerala"}]},{"label":["Education"],"points":[{"start":8468,"end":8470,"text":"MCA"}]},{"label":["Skills"],"points":[{"start":8441,"end":8446,"text":"Python"}]},{"label":["Skills"],"points":[{"start":8192,"end":8195,"text":"Java"}]},{"label":["Skills"],"points":[{"start":8162,"end":8171,"text":"PostgreSQL"}]},{"label":["Skills"],"points":[{"start":8153,"end":8158,"text":"Python"}]},{"label":["Skills"],"points":[{"start":7976,"end":7985,"text":"PostgreSQL"}]},{"label":["Skills"],"points":[{"start":7967,"end":7972,"text":"Python"}]},{"label":["Skills"],"points":[{"start":7810,"end":7813,"text":"Java"}]},{"label":["Skills"],"points":[{"start":7780,"end":7789,"text":"PostgreSQL"}]},{"label":["Skills"],"points":[{"start":7771,"end":7776,"text":"Python"}]},{"label":["Skills"],"points":[{"start":7610,"end":7613,"text":"Java"}]},{"label":["Skills"],"points":[{"start":7590,"end":7599,"text":"PostgreSQL"}]},{"label":["Skills"],"points":[{"start":7573,"end":7578,"text":"Python"}]},{"label":["Skills"],"points":[{"start":7221,"end":7224,"text":"Java"}]},{"label":["Skills"],"points":[{"start":7209,"end":7218,"text":"PostgreSQL"}]},{"label":["Skills"],"points":[{"start":7188,"end":7193,"text":"Python"}]},{"label":["Skills"],"points":[{"start":6865,"end":6868,"text":"Java"}]},{"label":["Skills"],"points":[{"start":6853,"end":6862,"text":"PostgreSQL"}]},{"label":["Skills"],"points":[{"start":6833,"end":6838,"text":"Python"}]},{"label":["Skills"],"points":[{"start":6316,"end":6321,"text":"Python"}]},{"label":["Skills"],"points":[{"start":6194,"end":6203,"text":"PostgreSQL"}]},{"label":["Skills"],"points":[{"start":6131,"end":6136,"text":"Python"}]},{"label":["Skills"],"points":[{"start":6041,"end":6046,"text":"Python"}]},{"label":["Skills"],"points":[{"start":5098,"end":5101,"text":"Java"}]},{"label":["Skills"],"points":[{"start":4502,"end":4507,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3894,"end":3903,"text":"PostgreSQL"}]},{"label":["Skills"],"points":[{"start":3850,"end":3855,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2848,"end":2853,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1185,"end":1190,"text":"Python"}]},{"label":["Location"],"points":[{"start":1125,"end":1134,"text":"Trivandrum"}]},{"label":["Skills"],"points":[{"start":825,"end":828,"text":"Java"}]},{"label":["Skills"],"points":[{"start":619,"end":623,"text":"MySql"}]},{"label":["Skills"],"points":[{"start":607,"end":616,"text":"PostgreSQL"}]},{"label":["Skills"],"points":[{"start":492,"end":495,"text":"Java"}]},{"label":["Skills"],"points":[{"start":474,"end":479,"text":"Python"}]},{"label":["Skills"],"points":[{"start":436,"end":439,"text":"Java"}]},{"label":["Skills"],"points":[{"start":428,"end":433,"text":"Python"}]},{"label":["Education"],"points":[{"start":272,"end":274,"text":"MCA"}]},{"label":["Name"],"points":[{"start":42,"end":65,"text":"MOHAMED AFSAL PARAVAKKAL"}]}],"extras":null,"metadata":{"first_done_at":1532666513000,"last_updated_at":1532666513000,"sec_taken":132,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Mohini Shrivastava\nmohini.shrivastavaa@gmail.com\n+91-7829747356\n\nSummary\n· Over 7.5 years of IT experience and Technical proficiency in building Telecom solutions using C/C++, Oracle PL/SQL, Unix Shell Scripting and Machine Learning in R & Python for large Telecom providers.\n· Good conceptual knowledge of Descriptive Analysis, Predictive Analysis, Prescriptive Analysis and Optimization.\n· Excellent code writing abilities in Python with good exposure to APIs like numpy, pandas, sklearn using Jupyter Notebook.\n· Created interactive applications using R-Shiny, Python-bokeh and Python-Dash.\n· Hands on experience on Statistical Techniques in handling large datasets.\n· Good exposure to Data Visualization, Predictive modeling and Machine Learning Algorithms.\n· Ability to test Hypothesis from raw data sets, draw meaningful conclusions, and effectively communicate results verbally, in writing, and through effective visualization.\n· Good knowledge of Recommender Systems, Stochastic models, Bayesian Modelling, Classification Models and Cluster Analysis (KMeans, Hierarchical).\n· Good exposure to Deep Learning, NLP, Markov Decision Process and Markov Chain.\n· Good exposure to Regression (linear regression, MLR), Decision trees, Random forest, Text Analytics and Optimization algorithms.\n· In Depth knowledge of Hadoop Architecture.\n· Hands on Experience in pyspark.\n· Good exposure in analysis of Time-Series Data (Forecasting Techniques).\n· Exposure to Big Data query using Google Cloud.\n· Advanced Proficiency in MS Excel.  \n· Involved in Requirement gathering/Analysis, Fit gap analysis, High Level Design, Detailed Design and Estimations.\n· Involved in Full Lifecycle Development of various projects, including requirement gathering, System designing, Application Development, enhancement, Deployment, maintenance and support. \n· Hands on experience in Application Development using Web services, Design Patterns, OCI, and CURL, APIs.\n· Extensive development experience and highly skilled in Coding in C/C++ and PL/SQL.\n· Expertise in Troubleshooting, Analyzing, Performance Tuning and Testing.\n· Well versed in working with relational database systems such as Oracle and Sybase.\n· Hands on experience in using the Kenan APIs for C programs.\n· Very good understanding of software development life-cycle (SDLC) process, exclusive knowledge in Identification of User requirements, System Design, writing Program specifications, Coding, Reviews and implementation of the Systems.\n· Excellent communication and inter personnel skills with an ability to lead a team, Dedicated team player with excellent analytical, problem solving skills and enjoy learning new Technologies and Tools.\n· Strong commitment towards quality, experience in ensuring experience in ensuring compliance to coding standards and review process.\n· Good experience in coding of PL SQL elements such as stored procedures, Triggers, functions and Packages.\n· Good working experience in Consuming Enterprise Web services using SOAP.\n· Strong experience in using Version Control Systems such as SVN, IBM Rational Clear Case, PVCS to manage the source code of the applications.\n· Exposure to tools like Control M, QC (Quality Centre).\n· Successfully delivered projects under strict schedules and quality control.\n· Conducting Peer-Reviews/ Team Lead Review of the deliverables prepared by the Team.\n· Responsible for inter-team Coordination to eliminate impediments, communication with Management and Stake-holders for Project Planning.\n· Involved in Resource Tracking and Resource Planning.\n· Estimating the Design/Development of the Business Requirements based on complexity and availability of Resources.\n· Excellent exposure of Project Planning using MPP.\n· Active participation as an Empaneled Interviewer for External recruitment within Organization.\n· Involved in Training and Evaluation of the Fresh IT Associates.\n\n\n\nEducation:\n· Pursuing Big Data Analytics Certification Course (A Data Science Program) from IIM, Bangalore (Aug-17 to Jul-18). \n· Completed Bachelor of Engineering in Computer Science Discipline with Hons. from Rajiv Gandhi Proudyogiki Vishwavidyalaya, Bhopal (Aug – 2006 to Jun – 2010)\n\n\n\n\n\nOrange Spain \t\t\t\t\t\t\t Jun 2011 – Till date\nTelecom\t\t\t   \t                 \t       Accenture\n  \nOrange is a leading network service provider of Spain. It deals with providing various services like mobile communication, internet, IP TV and VOIP to its customers. \nAccenture handles the Operation Support System(OSS) and Business Support System(BSS) to add business values to Orange and facilitate its end customers. It has enhanced the performance of various existing processes to improve, optimize and add new features in “Provisioning”, “Mediation” and “Billing” systems of Orange. \nDeals with Handling / analyzing the data generated on a daily basis to gain meaningful insights on the same.                      \n\n\nResponsibilities:\n\n· Involved in Full Lifecycle Development of a Data Science Project which includes:\n· Defining the Goal.\n· Data Collection and management.\n· Data Modelling\n· Model Evaluation\n· Presentation & Documentation\n· Model Deployment and maintenance.\n\n· Applying Data Mining Techniques (i.e. Classification & Clustering, Time Series Forecasting).\n· Work independently and also to manage Team.\n· Data Modelling, Forecasting and Automation using R/Python.\n· Statistical Modelling experience along with Unsupervised and Supervised Learning.\n· Extracting and Analysis of data to get deeper insights in network and Customer behavior, their service usage, patterns, preferences, incidents, problems and interests in real-time thereby helping Orange to monetize their vast reserves of data.\n· Involved in Requirement analysis, Low level Design and development of Enhancements/ Change Requests.\n· Building new solutions and doing Proof of Concepts on C/C++\n· Involved in Development in C, C++, Pro *C, Shell Scripting using VI on Unix and Oracle PL/SQL.\n· Fix/ Resolve technical challenges of the team.\n· Extensively used the “dbx” tool for de-bugging.\n· Involved in Upgrading the Kenan System used in Orange which included the following:\n1.) Kenan FX 9.1’ to ‘Kenan FX 12.0’\n2.) HP-UX to ‘AIX 7.0’\n3.) Sybase to Oracle 11g.\n· Defect tracking using RTC, sending defect status, Defect assignment to the application owner.\n· Involved in gathering business requirement, modelling development approach based on customization.\n· Handling the “Order Entry” mechanism of Orange which involved interaction with Java Adapters.\n· Involved in consuming the integrated solution with TIBCO AFS (third party systems).\n· Extensively used the XML Parsing Techniques to parse the XMLs and validate them against the XSDs (schemas).\n· Mentoring team on technology, C/C++ concepts, and best practices for design, implementation and other processes.\n· Delivering the components in SVN and PVCS.\n· Involved in Release Planning, Estimation and Defect tracking.\n· Automated the Regression Test Suite using Unix Shell Scripting and C(Unix) to Test the Provisioning Application used in Orange which reduced the Testing effort spent on every release to 90%.\n· Created an Automation Testing Framework using Jenkins which included the following:\nCode Review (via cppCheck) -> Build -> Regression Test Suite -> Deployment.\n\n\n\n\n\nTelefonica (Spain)\t\t\t\t\t\t  Sep 2010 – Jun 2011\nTelecom\t\t  \t\t\t\t   \t  Accenture Services\n  \nTelefonica Multi-cycle: Earlier Billing of all the Customers used to be done on a specific date of every month. Due to high number of Customers, this takes long time. So, based on the date of Connection taken, Customers will be assigned with different Billing Cycle. Based on the Billing Cycle, different Customers will be billed on different days. Hence, the project deals with the conversion of Monocycle Billing to Multicycle Billing System. The Project Components are designed in C, C++, Pro C, PL/SQL.\n\nResponsibilities\n\n· Responsible for Build, Testing Phase of the Requirement.\n· Development and Production Support done in C, C++, Shell Scripting on Unix and Windows Platform using VI on Unix.\n· Involved in Unit Testing of the Enhancements.\n· Debuggers worked on are GDB on UNIX.\n· Involved in developing Procedures / Packages using PL/SQL.\n· Exposure to Embedded – SQL.\n\n\n\nExtra–Curricular Activities:\n· Runners-up in the Badminton Premier League held at Accenture.\n· Participated in the Cricket Tournament in Accenture at Project-level.\n· Organizing fun-activities as a part of GPTW (Great Place to Work) initiative at Accenture.\n· Participated in 10 kms run in Puma Urban Stampede – Runners for Life.\n\n\n\n\n\nCertifications and Awards:                                                               \n· Awarded with Accenture’s Ace Award in FY 2016-17 and 2017-18. \n· Awarded with Accenture’s Apex Award in FY 2014-15 and 2015-16.\n· Completed Designer Certification with Accenture Solutions Delivery Academy Program – MIT.\n\n\n\n\t\t PAGE 1","annotation":[{"label":["Skills"],"points":[{"start":8236,"end":8241,"text":"PL/SQL"}]},{"label":["Skills"],"points":[{"start":8090,"end":8093,"text":"Unix"}]},{"label":["Skills"],"points":[{"start":8052,"end":8055,"text":"Unix"}]},{"label":["Skills"],"points":[{"start":7894,"end":7899,"text":"PL/SQL"}]},{"label":["Skills"],"points":[{"start":7017,"end":7020,"text":"Unix"}]},{"label":["Skills"],"points":[{"start":6990,"end":6993,"text":"Unix"}]},{"label":["Skills"],"points":[{"start":6754,"end":6758,"text":"C/C++"}]},{"label":["Skills"],"points":[{"start":5954,"end":5959,"text":"PL/SQL"}]},{"label":["Skills"],"points":[{"start":5938,"end":5941,"text":"Unix"}]},{"label":["Skills"],"points":[{"start":5859,"end":5863,"text":"C/C++"}]},{"label":["Education"],"points":[{"start":4040,"end":4062,"text":"Bachelor of Engineering"}]},{"label":["Skills"],"points":[{"start":2023,"end":2028,"text":"PL/SQL"}]},{"label":["Skills"],"points":[{"start":2013,"end":2017,"text":"C/C++"}]},{"label":["Skills"],"points":[{"start":428,"end":434,"text":"Python "}]},{"label":["Skills"],"points":[{"start":240,"end":246,"text":"Python "}]},{"label":["Skills"],"points":[{"start":191,"end":194,"text":"Unix"}]},{"label":["Skills"],"points":[{"start":183,"end":188,"text":"PL/SQL"}]},{"label":["Skills"],"points":[{"start":169,"end":173,"text":"C/C++"}]},{"label":["Name"],"points":[{"start":0,"end":17,"text":"Mohini Shrivastava"}]}],"extras":null,"metadata":{"first_done_at":1532670304000,"last_updated_at":1532670304000,"sec_taken":92,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Udaya Laxmi Ch\n\nEmail : laxmi.udaya@gmail.com\n\n\t\n\n\tPhone: -9740606990\n\t\n\n\n\tSummary\n\n\t· 9.5 years of experience in Software Development.\n· 3.5 years of experience in Machine Learning\n· Primary Skills – Machine Learning, R programming, Lotus Notes.\n· Presently working for Wipro Technologies, Bangalore.\n· Experience in planning, estimation, design, development, and testing object oriented applications.\n· Experience in preparing various technical documents like Functional Specs, HLD, LLD, Flowcharts and Test cases.\n· Sound Knowledge in Object Oriented Design Principles\n· Have Team Handling experience.\n· Domain experience of Manufacturing and Finance.\n· Have Experience in Scrum Agile Model\n· Understand business requirements from clients\n\n\n\n\tTechnical Skills\n\n\tKey skills: \n\tMachine Learning,R Programming, MySQL, PostgreSQL, Microsoft Access, SQL Server, FileMaker, Oracle, RDBMS, dBASE, Clipper, FoxPro, Firebase, Mongodb, Python,  ava, J2EE, Oracle Fusion,Oracle Cloud, Salesforce, Devops Android, Business Analyst, UI Developer, DBAs, Embedded Systems, .NET, Hadoop, SQL Developer, Big Data, Tableau, Networking, Etl, Informatica, Ios, Quality Analyst, Project Manager, Python, Data Science, Python, Machine Learning, SAS, Java, Scala, Hadoop, Hive, Bigdata, Programming, SQL server reporting, Msbi Ssis, Ssrs, Msbi, Sql Reporting, Artificial Intelligence, Pandas, Pyspark, Sklearn, Flask, Django, Map Reduce, Parametric Design, Modeling, Regression, Patterns, Data Mining, Text Mining, Oops, Deep Learning, Web Analytics, Time Series, Regression, Tensorflow, Azure, Linear Regression, Logistic Regression, Decision Tree, Random Forest, Data Structure, Computer Vision, IHS, WAS, Java EE, SQL Server, .NET core, C#, ASP.NET, Rdlc, Linq, Sql, Web Api, Mvc, Javascript, Web Services, Oracle, MS SQL, PHP, Laravel, CodeIgniter, Symfony, Zend, Phalcon, CakePHP, Yii, FuelPHP, React, Vue, Angular, Ember, Backbone, Lotus Notes\n\n\tAlgorithms:\n\tNaïve Bayes, K means clustering,Word Cloud\n\n\tDatabases: \n\tMicrosoft SQL, Mongo DB\n\n\tWeb Technologies: \n\tXML, XSLT, HTML,  JavaScript,  AJAX, JQuery\n\n\tIDE:\n\tR studio,Pycharm\n\n\n\tProfessional Experience\n\n\tCurrent Employer :\n\tWipro Technologies., Bangalore  – (Oct  2010  to till date) – Technical Lead/Data Scientist\n\n\tPrevious Employers :\n\tHSBC Software development , Hyderabad (June  2008  to Sep 2010)  - SE\n\n\n\tQualification\n\n\tDegree\n\tCollege\n\tUniversity/Board\n\tYear\n\tPercentage (%)\n\n\tMCA\n\tNizam College, Basheerbagh,Hyderabad\n\tOsmania University\n\t2008\n\t75\n\n\n\tProject Experience \n\n\tProject 1 : Exploratory Data Analysis:\n\nProject Description:   Performed EDA analysis to analyze the Purchase frequency of vehicles which occurred over past 3 years and try to predict the frequency occurring in the future.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Performed EDA analysis to find the insights of the data. Observed the summary of each and every variable to understand the variables.\n\n· Performed the feature selection using hypothesis testing.\n\n· Identified the outliers using box plot.\n\n· Identified the trend in the purchases using histogram.\n\n\n\n\tProject 2: Word Cloud Analysis:\n\nProject Description:   Performed Word cloud and Sentimental Analysis of the customer feedbacks. Graphically represented the most frequently occurred words through Word cloud. Through sentimental analysis we identified whether a user-generated text expresses positive, negative or neutral opinion.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Created a Corpus using TM package and performed pre-processing of data.\n\n· Removed the punctuations, stemming and stop words which are of no analytical value.\n\n· Built a Document term matrix and identified the most frequently occurring words\n\n· Graphically represented it using  RColorbrewer Package\n\n\n\tProject 3: Sentimental Analysis:\n\nProject Description: Performed Sentimental Analysis of customer feedbacks through Naïve Bayes. Used “e1071” Package for implementing naïve Bayes method.\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· The DTM created using TM package was an input to the Naive Bayes Model.\n\n· As Naive Bayes classifier is typically trained on data with categorical features. We have converted the count of the words into a factor variable that indicates Yes or No whether the word is present or not.\n\n\tProject 4: Clustering Analysis:\n\nProject Description: Classified the customers on the basis of their purchases whether they have purchased low variant or high variant trucks. It in turn helped in building the right customer strategies.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Performed data preparation and Normalization of data using min-max method.\n\n· As K-means algorithm groups a dataset into a user-specified number (k) of clusters. Identified the initial cluster centroids as 3.\n\n· K clusters are creating by associating every observation with the nearest mean.\n\n· Used elbow method to validate the number of clusters such that within-cluster sum of square(wss) is minimized.\n\n\n\n\tProject 5 : Inter Connection Management Tool\nProject Description: Inter-connection Management (IMT) is prototype being developed for Engineering and Sales department to handle customizations of an existing product based on the customer's requirement. Users from engineering department will identify the items, which need to be customized out of the entire product design.\nRole\n\n       : Module Lead\n\nEnvironment\n       : Python, Mongo DB, jQuery\n\nTasks handled:\n\n· Gathering Requirements and providing Project Plan and Effort Estimation details.\n\n· Understanding business requirements and preparing SoU (Statement of Understanding) and Functional/Technical Specification documents.\n\n· Providing Effort & Resource estimations\n\n· Planning for application development and deployment\n\n· Writing and executing Test Cases and Test scenarios\n\n· Creating design elements using Technical Specification.\n\n· Performing Unit testing & Peer Reviews\n\n· Work Allocation and mentoring the team\n\n· Providing Technical guidance to the team. \n\n\tProject 6\n: cvdAEI Application\n\nProject Description\n     : CVDAEI is a web based multilingual application developed for handling the Change Management process in Truck division of Daimler. The change request flows through different phases mainly Initialization, Evaluation, Decision and Conclusion. This application has a configurable workflow where the request flow and the responsible persons can be configured easily at any point of time. \n\nRole\n\n    : Developer/Tester\n\nEnvironment\n     : Lotus Notes, Java, HTML, XML, Java Script, JQuery\n\nTasks handled:\n\n· Gathering Requirements and providing Project Plan and Effort Estimation details.\n\n· Understanding business requirements and preparing SoU (Statement of Understanding) and Functional/Technical Specification documents.\n\n· Providing Effort & Resource estimations\n\n· Planning for application development and deployment\n\n· Writing and executing Test Cases and Test scenarios\n\n· Creating design elements using Technical Specification.\n\n· Performing Unit testing & Peer Reviews\n\n· Work Allocation and mentoring the team\n\n· Providing Technical guidance to the team. \n\n\n\n\tProject Title: Project Management Office \nProject Description: The purpose of this system is to enable the Project Management Office to manage and execute the IT Applications and Operations driven project tasks in  more systematic manner. It will also enable them to efficiently perform a role as a facilitator to coordinate various IT Operations teams and to ensure that project activity enters the department through one common interface. The project tasks will subsequently be dealt with in a common format and in a consistent and appropriate manner, ensuring open and regular communication between all involved parties.\n\nRole\n\n    : Developer/Tester\n\nEnvironment\n     : Lotus Notes, Java, HTML, XML, Java Script, JQuery\n\nTasks Handled :\n\n· Writing and Executing Test cases in client server based environment\n· Individually provided application support","annotation":[{"label":["Skills"],"points":[{"start":7951,"end":7956,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":7938,"end":7948,"text":"Java Script"}]},{"label":["Skills"],"points":[{"start":7933,"end":7935,"text":"XML"}]},{"label":["Skills"],"points":[{"start":7927,"end":7930,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":7921,"end":7924,"text":"Java"}]},{"label":["Skills"],"points":[{"start":7908,"end":7918,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":6645,"end":6650,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":6632,"end":6642,"text":"Java Script"}]},{"label":["Skills"],"points":[{"start":6627,"end":6629,"text":"XML"}]},{"label":["Skills"],"points":[{"start":6621,"end":6624,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":6615,"end":6618,"text":"Java"}]},{"label":["Skills"],"points":[{"start":6602,"end":6612,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":5522,"end":5527,"text":"jQuery"}]},{"label":["Skills"],"points":[{"start":5512,"end":5519,"text":"Mongo DB"}]},{"label":["Skills"],"points":[{"start":5504,"end":5509,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4645,"end":4652,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":4054,"end":4061,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":3941,"end":3951,"text":"Naïve Bayes"}]},{"label":["Skills"],"points":[{"start":3494,"end":3501,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":3132,"end":3141,"text":"Word Cloud"}]},{"label":["Skills"],"points":[{"start":2793,"end":2800,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":2110,"end":2116,"text":"Pycharm"}]},{"label":["Skills"],"points":[{"start":2101,"end":2108,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":2086,"end":2091,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":2080,"end":2083,"text":"AJAX"}]},{"label":["Skills"],"points":[{"start":2067,"end":2076,"text":"JavaScript"}]},{"label":["Skills"],"points":[{"start":2060,"end":2063,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":2054,"end":2057,"text":"XSLT"}]},{"label":["Skills"],"points":[{"start":2049,"end":2051,"text":"XML"}]},{"label":["Skills"],"points":[{"start":2018,"end":2025,"text":"Mongo DB"}]},{"label":["Skills"],"points":[{"start":2003,"end":2015,"text":"Microsoft SQL"}]},{"label":["Skills"],"points":[{"start":1977,"end":1986,"text":"Word Cloud"}]},{"label":["Skills"],"points":[{"start":1958,"end":1975,"text":"K means clustering"}]},{"label":["Skills"],"points":[{"start":1945,"end":1955,"text":"Naïve Bayes"}]},{"label":["Skills"],"points":[{"start":1918,"end":1928,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":1908,"end":1915,"text":"Backbone"}]},{"label":["Skills"],"points":[{"start":1901,"end":1905,"text":"Ember"}]},{"label":["Skills"],"points":[{"start":1892,"end":1898,"text":"Angular"}]},{"label":["Skills"],"points":[{"start":1887,"end":1889,"text":"Vue"}]},{"label":["Skills"],"points":[{"start":1880,"end":1884,"text":"React"}]},{"label":["Skills"],"points":[{"start":1871,"end":1877,"text":"FuelPHP"}]},{"label":["Skills"],"points":[{"start":1866,"end":1868,"text":"Yii"}]},{"label":["Skills"],"points":[{"start":1857,"end":1863,"text":"CakePHP"}]},{"label":["Skills"],"points":[{"start":1848,"end":1854,"text":"Phalcon"}]},{"label":["Skills"],"points":[{"start":1842,"end":1845,"text":"Zend"}]},{"label":["Skills"],"points":[{"start":1833,"end":1839,"text":"Symfony"}]},{"label":["Skills"],"points":[{"start":1820,"end":1830,"text":"CodeIgniter"}]},{"label":["Skills"],"points":[{"start":1811,"end":1817,"text":"Laravel"}]},{"label":["Skills"],"points":[{"start":1806,"end":1808,"text":"PHP"}]},{"label":["Skills"],"points":[{"start":1798,"end":1803,"text":"MS SQL"}]},{"label":["Skills"],"points":[{"start":1790,"end":1795,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":1776,"end":1787,"text":"Web Services"}]},{"label":["Skills"],"points":[{"start":1764,"end":1773,"text":"Javascript"}]},{"label":["Skills"],"points":[{"start":1759,"end":1761,"text":"Mvc"}]},{"label":["Skills"],"points":[{"start":1750,"end":1756,"text":"Web Api"}]},{"label":["Skills"],"points":[{"start":1745,"end":1747,"text":"Sql"}]},{"label":["Skills"],"points":[{"start":1739,"end":1742,"text":"Linq"}]},{"label":["Skills"],"points":[{"start":1733,"end":1736,"text":"Rdlc"}]},{"label":["Skills"],"points":[{"start":1724,"end":1730,"text":"ASP.NET"}]},{"label":["Skills"],"points":[{"start":1720,"end":1721,"text":"C#"}]},{"label":["Skills"],"points":[{"start":1709,"end":1717,"text":".NET core"}]},{"label":["Skills"],"points":[{"start":1697,"end":1706,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":1688,"end":1694,"text":"Java EE"}]},{"label":["Skills"],"points":[{"start":1683,"end":1685,"text":"WAS"}]},{"label":["Skills"],"points":[{"start":1678,"end":1680,"text":"IHS"}]},{"label":["Skills"],"points":[{"start":1661,"end":1675,"text":"Computer Vision"}]},{"label":["Skills"],"points":[{"start":1645,"end":1658,"text":"Data Structure"}]},{"label":["Skills"],"points":[{"start":1630,"end":1642,"text":"Random Forest"}]},{"label":["Skills"],"points":[{"start":1615,"end":1627,"text":"Decision Tree"}]},{"label":["Skills"],"points":[{"start":1594,"end":1612,"text":"Logistic Regression"}]},{"label":["Skills"],"points":[{"start":1575,"end":1591,"text":"Linear Regression"}]},{"label":["Skills"],"points":[{"start":1568,"end":1572,"text":"Azure"}]},{"label":["Skills"],"points":[{"start":1556,"end":1565,"text":"Tensorflow"}]},{"label":["Skills"],"points":[{"start":1544,"end":1553,"text":"Regression"}]},{"label":["Skills"],"points":[{"start":1531,"end":1541,"text":"Time Series"}]},{"label":["Skills"],"points":[{"start":1516,"end":1528,"text":"Web Analytics"}]},{"label":["Skills"],"points":[{"start":1501,"end":1513,"text":"Deep Learning"}]},{"label":["Skills"],"points":[{"start":1495,"end":1498,"text":"Oops"}]},{"label":["Skills"],"points":[{"start":1482,"end":1492,"text":"Text Mining"}]},{"label":["Skills"],"points":[{"start":1469,"end":1479,"text":"Data Mining"}]},{"label":["Skills"],"points":[{"start":1459,"end":1466,"text":"Patterns"}]},{"label":["Skills"],"points":[{"start":1447,"end":1456,"text":"Regression"}]},{"label":["Skills"],"points":[{"start":1437,"end":1444,"text":"Modeling"}]},{"label":["Skills"],"points":[{"start":1418,"end":1434,"text":"Parametric Design"}]},{"label":["Skills"],"points":[{"start":1406,"end":1415,"text":"Map Reduce"}]},{"label":["Skills"],"points":[{"start":1398,"end":1403,"text":"Django"}]},{"label":["Skills"],"points":[{"start":1391,"end":1395,"text":"Flask"}]},{"label":["Skills"],"points":[{"start":1382,"end":1388,"text":"Sklearn"}]},{"label":["Skills"],"points":[{"start":1373,"end":1379,"text":"Pyspark"}]},{"label":["Skills"],"points":[{"start":1365,"end":1370,"text":"Pandas"}]},{"label":["Skills"],"points":[{"start":1340,"end":1362,"text":"Artificial Intelligence"}]},{"label":["Skills"],"points":[{"start":1325,"end":1337,"text":"Sql Reporting"}]},{"label":["Skills"],"points":[{"start":1325,"end":1327,"text":"Sql"}]},{"label":["Skills"],"points":[{"start":1319,"end":1322,"text":"Msbi"}]},{"label":["Skills"],"points":[{"start":1313,"end":1316,"text":"Ssrs"}]},{"label":["Skills"],"points":[{"start":1302,"end":1310,"text":"Msbi Ssis"}]},{"label":["Skills"],"points":[{"start":1302,"end":1305,"text":"Msbi"}]},{"label":["Skills"],"points":[{"start":1280,"end":1299,"text":"SQL server reporting"}]},{"label":["Skills"],"points":[{"start":1267,"end":1277,"text":"Programming"}]},{"label":["Skills"],"points":[{"start":1258,"end":1264,"text":"Bigdata"}]},{"label":["Skills"],"points":[{"start":1252,"end":1255,"text":"Hive"}]},{"label":["Skills"],"points":[{"start":1244,"end":1249,"text":"Hadoop"}]},{"label":["Skills"],"points":[{"start":1237,"end":1241,"text":"Scala"}]},{"label":["Skills"],"points":[{"start":1231,"end":1234,"text":"Java"}]},{"label":["Skills"],"points":[{"start":1226,"end":1228,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1208,"end":1223,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1200,"end":1205,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1186,"end":1197,"text":"Data Science"}]},{"label":["Skills"],"points":[{"start":1178,"end":1183,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1161,"end":1175,"text":"Project Manager"}]},{"label":["Skills"],"points":[{"start":1144,"end":1158,"text":"Quality Analyst"}]},{"label":["Skills"],"points":[{"start":1139,"end":1141,"text":"Ios"}]},{"label":["Skills"],"points":[{"start":1126,"end":1136,"text":"Informatica"}]},{"label":["Skills"],"points":[{"start":1121,"end":1123,"text":"Etl"}]},{"label":["Skills"],"points":[{"start":1109,"end":1118,"text":"Networking"}]},{"label":["Skills"],"points":[{"start":1100,"end":1106,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":1090,"end":1097,"text":"Big Data"}]},{"label":["Skills"],"points":[{"start":1075,"end":1087,"text":"SQL Developer"}]},{"label":["Skills"],"points":[{"start":1067,"end":1072,"text":"Hadoop"}]},{"label":["Skills"],"points":[{"start":1061,"end":1064,"text":".NET"}]},{"label":["Skills"],"points":[{"start":1043,"end":1058,"text":"Embedded Systems"}]},{"label":["Skills"],"points":[{"start":1037,"end":1040,"text":"DBAs"}]},{"label":["Skills"],"points":[{"start":1023,"end":1034,"text":"UI Developer"}]},{"label":["Skills"],"points":[{"start":1005,"end":1020,"text":"Business Analyst"}]},{"label":["Skills"],"points":[{"start":989,"end":1002,"text":"Devops Android"}]},{"label":["Skills"],"points":[{"start":977,"end":986,"text":"Salesforce"}]},{"label":["Skills"],"points":[{"start":963,"end":974,"text":"Oracle Cloud"}]},{"label":["Skills"],"points":[{"start":949,"end":961,"text":"Oracle Fusion"}]},{"label":["Skills"],"points":[{"start":943,"end":946,"text":"J2EE"}]},{"label":["Skills"],"points":[{"start":929,"end":934,"text":"Python"}]},{"label":["Skills"],"points":[{"start":920,"end":926,"text":"Mongodb"}]},{"label":["Skills"],"points":[{"start":910,"end":917,"text":"Firebase"}]},{"label":["Skills"],"points":[{"start":902,"end":907,"text":"FoxPro"}]},{"label":["Skills"],"points":[{"start":893,"end":899,"text":"Clipper"}]},{"label":["Skills"],"points":[{"start":886,"end":890,"text":"dBASE"}]},{"label":["Skills"],"points":[{"start":879,"end":883,"text":"RDBMS"}]},{"label":["Skills"],"points":[{"start":871,"end":876,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":860,"end":868,"text":"FileMaker"}]},{"label":["Skills"],"points":[{"start":848,"end":857,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":830,"end":845,"text":"Microsoft Access"}]},{"label":["Skills"],"points":[{"start":818,"end":827,"text":"PostgreSQL"}]},{"label":["Skills"],"points":[{"start":811,"end":815,"text":"MySQL"}]},{"label":["Skills"],"points":[{"start":798,"end":808,"text":"Programming"}]},{"label":["Skills"],"points":[{"start":796,"end":808,"text":"R Programming"}]},{"label":["Skills"],"points":[{"start":779,"end":794,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":234,"end":244,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":219,"end":231,"text":"R programming"}]},{"label":["Skills"],"points":[{"start":201,"end":216,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":165,"end":180,"text":"Machine Learning"}]},{"label":["Name"],"points":[{"start":0,"end":13,"text":"Udaya Laxmi Ch"}]}],"extras":null,"metadata":{"first_done_at":1579625576000,"last_updated_at":1579626369000,"sec_taken":0,"last_updated_by":"aJOmJy1lvpOYFetVNuqLvFo9Vx42","status":"done","evaluation":"NONE"}}
{"content": "Monesh Kumar P\n \n\nHyderabad\n\nE-mail: monesh.pasupureddy@gmail.com\n Contact: 9603626311\nObjective:\nTo obtain a position with a progressive Web Development or Software Development Company with a strong focus on creativity and problem solving. To find a position that is challenging, rewarding and provides an opportunity to expand my knowledge and abilities in creating client centric solutions.\nEducation:\n· Bachelor of Technology in Computer Science (2008-2012) from Aditya Engineering College affiliated to Jawaharlal Nehru Technological University Kakinada, Kakinada, Andhra Pradesh with 66% aggregate.\n· Intermediate (2006-2008) from Sri Chaitanya Junior College, Rajahmundry, Andhra Pradesh with 92% aggregate.\n· SSC (2006) from Netaji Public School, Rajahmundry, Andhra Pradesh, with 83% aggregate.\nAreas of Profession:\nMore than 5 years of experience in software development. Created complex back-end management systems including customer relations, communication interfaces and e-Commerce websites.  Python, PHP, PHPUnit, MySQL, MongoDB, JQuery, AJAX, JSON, JavaScript, HTML, CSS are used.\nI have worked in the following areas:\n· Application Development, Design, Implementation and Maintenance of web based applications.\n· Hands on developing MVC architecture applications.\n· E-Commerce websites development.\n· Payment gateway integrations (Paypal, ccAvenue).\n· WebServices (REST, SOAP).\n· Experience in Team management and Client management\n· Unit testing for the Classes and Traits in PSR2 standards.\nProfessional Skills:\n· Operating systems/platforms\n· Windows 2000/XP/7 (more than 3 years of experience)\n· Unix/Linux (more than 1 year experience in Ubuntu)\n· Programming Languages/Technologies\n· Python (2 years of experience)\n· PHP (3 years of experience)\n· JQuery (2 years of experience)\n· AJAX (2 years of experience)\n· JavaScript (2 years of experience)\n· HTML (3 years of experience)\n· CSS (3 years of experience)\n· WebServices (8 months of experience in REST, SOAP)\n· PHPUnit (more than 1 year experience)\n· PHPDoc\n· SVN, GIT\n· Frameworks\n· Django (8 months of experience)\n· OXID (1 year and 3 months of experience)\n· Symfony2 (3 months of experience)\n· Template Engines\n· DTL (8 months of experience)\n· Smarty (1 year and 3 months of experience)\n· Twig (3 months of experience)\n· Databases\n· MySQL (3 years of experience)\n· MongoDB (5 months of experience)\n· PostgreSQL (2 months of experience)\n· Unit Testing\n· PHPUnit (more than 1 year experience)\nProfessional Experience:\nPresent:\n(from June-2016 to till date)\nSoftware Engineer in ValueLabs LLP, Hitech City Phase 2, Hyderabad.\nPrevious:\n(from August-2014 to June-2016)\nAssistant Software developer in Devblaze HighPerformance e-Commerce Pvt Ltd., Road No. 10, Jubilee Hills, Hyderabad.\nPrevious:\n(from Nov-2012 to July-2014)\nPHP/MySQL web developer in Stee Consulting and Software Technologies Pvt Ltd., Madhura Nagar, S.R.Nagar, Hyderabad.\nWorked Projects:\nProject: OUP-EMS\nRole: Developer\nProject Description: Purpose of the project is to maintain users, Articles and their revisions, Authors and maintain article workflow. Application implemented in Django framework. Users will be assigned to articles in the product and after assigning user has to accept invitation. Article relations, versions and signatures will be maintained. According to user permissions components will be accessible. Article versions will be created and grouping will be maintained based on master Ids. Bulk operations for all modules has been implemented. Iterative testing and code reviews through development of the application has been done. Responsible for Daily & Weekly status updates showing the progress of development.\nTechnologies Used:\nPython(Django), MySQL\nProject: Ferratum\nRole: Developer\n\nImplemented unit tests for the module CLHS which involves classes, abstract classes and traits.\nProject Description: Project is to handle the ledgers, loans and loan application status for the users. This project was developed by Slovakians using the PSR2 standards. Now we have implemented the unit/functional tests for these modules using the PHPUnit and improved the code coverage for them.\nTechnologies Used:\nPHP, Python, MySQL, PHPUnit\nProject: MOXWS (Mobile OXID WebService)\nRole: Developer (WebService)\n\nComplete WebService development in OXID framework for the Android App ShopManager.\nProject Description: ShopManager is an Android app for the e-Commerce retailers to manage the products, product categories, orders, customers, and emails. So this app connects to OXID framework through our webservice MOXWS. MOXWS is a Webservice developed in OXID framework which processes request and response in JSON format.\nTechnologies Used:\nPHP, MySQL\nFrameworks involved:\nOXID\nReferenec Links:\nhttps://modstore.io/en/modules/admin-dealer-tools/167/shop-connector-installation-licence-for-oxid-shop-manager\nProject: senioinfo24.de (2 months)\nRole: Tester, Bug Fixing (both Template and Functional bugs), Integrating Symfony2 with ODOO.\n\nInvolved in testing and fixing bugs (both Template and Functional). Integrated Symfony2 with ODOO for data synchronization through ODOO’s XML-RPC webservice and some internal PHP scripts.\nProject Description: Senioinfo24 is a CMS website which provides branding for various Companies which provides services to old age people. And it also involves some minor functionalities like partner registration, contact forms.\nTechnologies Used:\nPHP, Python, MySQL, PostgreSQL, Twig, Jquery, AJAX, HTML, CSS\nFrameworks involved:\nSymfony2\nERP integration:\nODOO\nReference link:\n\nhttp://senioinfo24.de/\nProject: e-Commerce Websites (Involved in multiple e-Commerce websites development)\nRole: Template developer, Module developer, Tester, Bug Fixing\n\nInvolved in various e-Commerce websites with different roles in variant timelines.\nProject Description: We developed HighPerformance e-Commerce websites using the Frameworks OXID and Shopware.\nTechnologies Used:\nPHP, MySQL, Python, Smarty, Jquery, AJAX, HTML, CSS\nFrameworks involved:\nOXID, Shopware\nReference links:\nhttp://www.sonnenkind.ch/\nhttp://www.novaHYPERLINK \"http://www.novavida.ch/\"vida.ch/\nhttps://www.alpaca-onlineshop.com/\nhttps://www.alpaca-onlineshop.ch/\nProject:  http://refeHYPERLINK \"http://referenceglobe.com/\"renceglobe.com\nRole: Developer\n\nComplete backend development using PHP-MySQL along with some frontend development using HTML, JQUERY, CSS, AJAX, and JSON.\nProject Description:Referenceglobe.com is an on-going global reference provider with thousands of references across globe. It offers a platform for every career aspirant in choosing suitable profession and challenging career. It also provides a platform for every education aspirant to connect online with best universities and colleges.\nTechnologies Used:\nHTML, CSS, JavaScript, JQUERY, AJAX(Front-End development)\n\n\n\nPHP, MySQL (Back-End development)\nSeeking:\nFull Time\nWill Relocate:\nYes\nPersonal Information:\nDate of Birth: 27-06-1991\nAge: 26\nSex: Male\nMarital Status: Unmarried\nDeclaration:\nI hereby declare that all the details furnished are genuine and can be subjected to verification at any time.\nPlace: Hyderabad\n\n\n\n\n\n\n\n\n\n yours sincerely\n(Monesh Kumar. P)","annotation":[{"label":["Location"],"points":[{"start":7129,"end":7137,"text":"Hyderabad"}]},{"label":["Skills"],"points":[{"start":6803,"end":6807,"text":" AJAX"}]},{"label":["Skills"],"points":[{"start":6784,"end":6793,"text":"JavaScript"}]},{"label":["Skills"],"points":[{"start":6779,"end":6781,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":6773,"end":6776,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":6399,"end":6403,"text":" AJAX"}]},{"label":["Skills"],"points":[{"start":6395,"end":6397,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":6381,"end":6384,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":5991,"end":5993,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":5985,"end":5988,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":5978,"end":5982,"text":" AJAX"}]},{"label":["Skills"],"points":[{"start":5955,"end":5960,"text":"Python"}]},{"label":["Skills"],"points":[{"start":5487,"end":5489,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":5481,"end":5484,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":5474,"end":5478,"text":" AJAX"}]},{"label":["Skills"],"points":[{"start":5434,"end":5439,"text":"Python"}]},{"label":["Skills"],"points":[{"start":5168,"end":5171,"text":"PHP "}]},{"label":["Skills"],"points":[{"start":4190,"end":4196,"text":"PHPUnit"}]},{"label":["Skills"],"points":[{"start":4175,"end":4180,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4102,"end":4108,"text":"PHPUnit"}]},{"label":["Skills"],"points":[{"start":3700,"end":3705,"text":"Python"}]},{"label":["Location"],"points":[{"start":2903,"end":2911,"text":"Hyderabad"}]},{"label":["Location"],"points":[{"start":2748,"end":2756,"text":"Hyderabad"}]},{"label":["Location"],"points":[{"start":2589,"end":2597,"text":"Hyderabad"}]},{"label":["Skills"],"points":[{"start":2430,"end":2436,"text":"PHPUnit"}]},{"label":["Skills"],"points":[{"start":1985,"end":1991,"text":"PHPUnit"}]},{"label":["Skills"],"points":[{"start":1932,"end":1942,"text":"WebServices"}]},{"label":["Skills"],"points":[{"start":1902,"end":1904,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":1871,"end":1874,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":1834,"end":1843,"text":"JavaScript"}]},{"label":["Skills"],"points":[{"start":1802,"end":1806,"text":" AJAX"}]},{"label":["Skills"],"points":[{"start":1770,"end":1775,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":1740,"end":1743,"text":"PHP "}]},{"label":["Skills"],"points":[{"start":1707,"end":1712,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1369,"end":1379,"text":"WebServices"}]},{"label":["Skills"],"points":[{"start":1083,"end":1085,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":1077,"end":1080,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":1065,"end":1074,"text":"JavaScript"}]},{"label":["Skills"],"points":[{"start":1052,"end":1056,"text":" AJAX"}]},{"label":["Skills"],"points":[{"start":1045,"end":1050,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":1020,"end":1026,"text":"PHPUnit"}]},{"label":["Skills"],"points":[{"start":1007,"end":1012,"text":"Python"}]},{"label":["Education"],"points":[{"start":407,"end":428,"text":"Bachelor of Technology"}]},{"label":["Location"],"points":[{"start":18,"end":26,"text":"Hyderabad"}]},{"label":["Name"],"points":[{"start":0,"end":13,"text":"Monesh Kumar P"}]}],"extras":null,"metadata":{"first_done_at":1532694395000,"last_updated_at":1532694395000,"sec_taken":103,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Mrutyunjaya Jena \nEmail: mjena48@gmail.com \nMobile: (+91)-9658407504 \n\nObjective \n\nHaving the ability to quickly learn new technology, language and platform makes me extremely flexible \nfor any organization. As a professional I always look forward to improve my work by acquiring more \nknowledge and using the best possible practices and resources and simultaneously enhance my skills in \nwhich ever nature of work I come across. I apply my knowledge and gained skills towards building the \ngrowth of the company as well as my personal growth as an professional within the organization. \n\nAcademic Profile \n\n B. Tech from Silicon Institute Of Technology, Odisha in ET & TC stream, completed in the year 2012, \n\nwith an CGPA of 8.4 \n\n Diploma from Nilachal Polytechnic, Odisha in ET & TC stream, completed in the year 2009, with an \n\naggregate of 87%. \n\n B.S.E from Govt. High School, completed in the year 2004 with 60.1%. \n\nWork Experience \n\n I'm an IBM certified Cloud Application Developer having all around knowledge on all levels of a \n\nsoftware development. I'm currently working as an Integration Consultant with Nexright Software \n\nSolutions Pvt. Ltd. since March 2016. \n\n Previously worked as Senior Systems Engineer with Infosys Ltd. from April 2013 - March 2016 \n\nTechnical Proficiency \n\nCognitive Solutions \n\n Responsible for designing models and application framework for Cognitive solutions. \n\n Have hands on experience on multiple cognitive solutions provided by IBM Watson as \n\n Conversation service \n\n Natural Language Classifier \n\n Natural Language Understanding \n\n Personality Insights \n\n Tone Analyser \n\n Speech-to-Text \n\n Text-to-Speech \n\n \n\n Have hands on experience on various cognitive solutions and integrating them with existing \n\nNode.js and/or Java based applications. \n\n Have also trained multiple custom models using Watson Knowledge Studio and deployed those \n\nmodels to Natural Language Understanding service. \n\n Developed varieties of Chat bots using Watson Conversation service along with Natural Language \n\nClassifier Service and integrating them with a Node.JS based applications as well as Mobile \n\napplications. \n\n Have created custom skill for Amazon Alexa and integrated it with the Conversation service of \n\nWatson and deployed the application on Amazon Lambda. \n\n Worked for a brief period of time on developing IOT based application using Node RED. \n\n \n\n \n\n\n\nCloud Application Development \n\n I'm an IBM Certified Cloud Application Developer. \n\n Hands on knowledge on cloud computing solution Cloud Foundry which provides a Platform as a \n\nService (PaaS). \n\n Proficient knowledge on various cloud offerings available on IBM cloud offering platform Bluemix \n\nwhich is an Open Cloud Architecture by IBM and is based on Cloud Foundry.  \n\n A Full stack application developer with good knowledge on all areas of software development.  \n\n Have configured, developed and deployed applications to Bluemix and using multiple cloud based \n\nservices in the applications via web service calls or by using provided SDKs. \n\n \n\nServer Side/ Back End  Development \n\n Good working knowledge on Node.JS and also following of design pattern like MEAN stack. \n\n Working knowledge on both SQL and NoSQL databases like Oracle, PostgreSQL, MongoDB, \n\nCloudant DB. \n\n Knowledge on Java, Core Java, J2EE. \n\n Plenty of knowledge in invoking various services by making web service calls by making REST \n\ncalls. \n\n Good amount of knowledge on Server side Coding and following best practices. \n\n Knowledge on MVC framework. \n\n Good knowledge on project version control on Git. \n\nWeb app/Front End  Development \n\n Working knowledge on HTML5, JavaScript and CSS. \n\n Have also used other front-end technologies like Angular JS, JQuery. \n\n Working knowledge on Testing/Debugging using Browser developer tools. \n\n \n\nMobility Development \n\n Along with Cloud based application development, I've been simultaneously working  as a IBM \n\nMobileFirst Developer. IBM MobileFirst is a mobility enterprise solution that provide an environment \n\nto develop, integrate and test mobile apps. \n\n Knowledge on Apache Cordova, a Hybrid Mobile Application development framework. \n\n Developed applications on both Android and iOS platform using hybrid framework. \n\n Working knowledge on Mobile development framework like Ionic 1 and Ionic 2. \n\n Proficiency in all stages of application development. \n\n Working knowledge on Angular JS 1 and 2. \n\nOthers \n\n Good knowledge on REST and SOAP web service calls. \n\n Working knowledge on both Relational and Non relational databases like Oracle, PostgreSQL, \n\nCloudant DB, Mongo DB. \n\n Competent in dealing with data interchange formats like XML and JSON. \n\n Proficient in all aspects of Software Development Life Cycle (SDLC) \n\n \n\n \n\n \n\n \n\n\n\nProject Roles and Experiences \n\n Designing applications for Cloud Platform and consulting various clients on different available best \n\npractices for Cloud. \n\n Being an Integration Consultant requires me to understand the functionality of a service and/or \n\napplication from depth and harnessing it's power by integrating it into other application. \n\n Delivered Hybrid Mobile application for an Australian based client on both Android and iOS. \n\n Designed and Developed multiple Integration of FAQ based chatbot using Watson Conversation \n\nservice into an existing Mobile as well as a .NET based application. \n\n Integrated various services with existing web based applications on Node.js as well as mobile \n\napplications. \n\n Have also been involved in multiple pre-sales activity where I've created sample applications on \n\nmultiple platforms and using different services and given working demos/presentations to clients and \n\npossible clients for Integration, Mobile and Cognitive applications. \n\n Previously worked as a developer for Finacle Mobile Banking. \n\n Worked as a developer for Finacle Workflow Integrator (FWI). \n\n Worked on eBanking and some other banking solutions provided by Finacle which is a product of \n\nInfosys. \n\n \n\nResponsibilities \n\n Current job role requires me to investigate the requirement and provide the client with the best \n\npossible solution in Mobility as well as Cloud platform. \n\n Communicate directly with Client in order to gather all information that might be needed for the \n\ndevelopment and provide them with the appropriate solution for their need. \n\n Have singlehandedly managed the whole application when needed. \n\n Analyze and solve all minor, major and critical issues. \n\n Enhancement the functionality of existing frameworks.","annotation":[{"label":["Skills"],"points":[{"start":2475,"end":2502,"text":" Cloud Application Developer"}]},{"label":["Skills"],"points":[{"start":1485,"end":1494,"text":"IBM Watson"}]},{"label":["Skills"],"points":[{"start":968,"end":995,"text":" Cloud Application Developer"}]},{"label":["Education"],"points":[{"start":610,"end":616,"text":"B. Tech"}]},{"label":["Name"],"points":[{"start":0,"end":15,"text":"Mrutyunjaya Jena"}]}],"extras":null,"metadata":{"first_done_at":1532676740000,"last_updated_at":1532676740000,"sec_taken":95,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "He has used IBM watson on his previous organisation whch is HCL Technologies  \n\nHe is part part of the project done for KPMG\nOne Year experience using IBM watson\nNamasya Das\nEmail: laltudas.java@gmail.com\nMobile: +91 7406773717\nCareer Objective:\nTo be associated with a progressive organization which gives me scope to apply my knowledge and skills as well as develop them further. Would like to perform on the global panorama to fulfill and thereby exceed the commitments for the position I would work for.\n\nExperience Summary:\n\n· 3.2  years of experience in Full stack Development of JAVA, J2EE based Web applications.\n· Hand on experience in UI development.\n· Good knowledge of Object Oriented Programming concepts.\n\n· Strong implementation knowledge of Java and J2EE .\n· Proficient in various IDEs including Eclipse and My Eclipse.\n· Hands on experience on IBM Watson Data Explorer.\n· Hands on experience on MongoDB and ElasticSearch.\n· Hands on experience using application servers including Apache Tomcat and Web logic.\n· Knowledge in selenium testing.\n· Excellent Communication and Organizational skills with zeal to learn new technologies, willing to adapt to new challenges.\n\n· Proactive worker with multi tasking capabilities in different streams.\nAcademic Profile:\n\n· B.Tech.  from Ajaya Binay Institute For Technology, Cuttack, BPUT, Orissa with 6.6 CGPA in the year  2011.\n\nExperience Profile:\n\n· Working in Cognizant Technology solons from OCT 2016 to till date.\n\n· Worked in Hcl Technology from July 2014 To OCT 2016.\n\nTechnical Profile:\n\n\tSKILLS\n\tEXPERIENCED\n\t\n\n\tProgramming Languages\n\tJava, XML, XSLT, XPATH, WSDL\n\t\n\n\tOperating Systems\n\tWindows XP/7\n\n\n\t\n\n\tDatabase Softwares\n\tOracle 10g\n\t\n\n\tWeb Technologies\n\tHTML,CSS, JavaScript, Angular JS(Basic)\n\t\n\n\tJSE Technologies\n\tJDBC\n\t\n\n\tJEE Technologies\n\tServlets , JSP\n\t\n\n\tServers\n\tTomcat, Weblogic \n\t\n\n\tFrameworks\n\tSpring 4.2.0\n\t\n\n\tORM Software\n\tHibernate\n\t\n\n\tBigData Technologies\n\n\n\t MongoDB,\n\n IBM Watson Data Explorer, ElasticSearch\n\t\n\n\tTools\n\tIBM Watson Data Explorer, MongoDB, SOAP UI\n\t\n\n\tIDEs\n\tEclipse , MyEclipse\n\t\n\n\nProject Profile:\n\nProject #1\n\n\n\n\n\n\n\n\n  \n\nTitle\n\n: BigDecision\n\n\n\n\nRole\n\n: Full Stack Developer\n\nEnvironment   : Core Java, Spring Boot, maven,HTML, css, java Script, Angular JS\n\n                         SQL, MongoDB , Big Data\nDuration         : Nov-2016 To Till date\n\nDescription:\n\n· Cognizant’s Big Decisions Business Solutions Platform enables organizations to improve their customer experience, optimize their business processes and reap benefits of the emerging digital economy through data driven insights. Big Decisions’ platform features, functionality and relevant business applications can provide rapid value to your business and accelerate your digital transformation journey.\n\nAnalytical Sandbox management\n\n• Data Discovery and\n\nBI Workbench – Selfserve\n\nAnalytics & BI\n\non the fly\n\n• Infrastructure\n\nOptions – Cloud,\n\nMulti-Tenant Hosted\n\nAnd On-Premise\n\n• Data injestion –\n\nIndustrializing data injestion with\n\nAutomation and big data feature\n\n• Comprehensive best - of - breed\n\nProduct partner ecosystem\n\n• Profile book\n\nResponsibilities:\n\n· Develop software solutions by studying information needs; conferring with users; studying systems flow, data usage and work processes; investigating problem areas; following the software development lifecycle.\n\n· Determine operational feasibility by evaluating analysis, problem definition, requirements, solution development and proposed solutions.\n\n· Work with UI team for UI development, bug fixing and UI enhancement and development.\n\n· Provide information by collecting, analyzing and summarizing development and service issues.\n· Make informed decisions quickly and taking ownership of services and applications at scale.\n\n· Wrote JUNIT test cases for various modules and testing the application end to end.\n\n· Work collaboratively with others to achieve goals.\n\n· Provided support for bug fixing and production day support for the application of \n\n            Almost all modules associated with the T-mob application.\n\nProject #2\n\n\n\n\n\n\n\n\n  \n\nTitle\n\n: RSP\n\nClient              : T-Mobile\n\n\n\n\nRole\n\n: Developer\n\nEnvironment   : Core Java, Web Services, Spring, Dozer,  \n\n                        SQL, Oracle Web logic 10.3.6, ANT \n\nDuration         : march-2015 To Sept 2016\n\nDescription:\n\n· T-Mobile USA, is an American mobile-network operator, that provides wireless voice, messaging and data services.\n\n· Retail Services Platform is a Web services based middleware platform interfacing different UI and Backend systems( such as billing system, handset upgrade web service engine, etc). Project involves development, unit testing and support for new/modification of existing web services.\n\n Responsibilities:\n\n· Understanding business requirement and technical specification provided by client and responsible for designing and implementation of the same.\n\n· Involved in developing some back end web services.\n\n· Has Experience on working Production server Critical Issues.\n\n· Unit testing and providing support for integration testing, QA testing and production deployment.\n\n· Provided support for bug fixing and production day support for the application of \n\n            almost all modules associated with the T-mob application.\n\nProject #3\n\n\n\n\n\n\n\n\n  \n\nTitle\n\n: TMAG\n\nClient              :T-Mobile\n\nRole\n\n: Developer\nEnvironment\n: JDK 1.6, Core Java, JSP, Servlets, HTML, JavaScript,  Web Logic 11g ,     \n\n                         Oracl10g\nConfiguration control :  Accurev5.5\n\nDuration         : july-2014 To march-2015\n\nDescription:\n\n· T-Mobile USA, is an American mobile-network operator, that provides wireless voice, messaging and data services.\n\n· For  T-Mobile , HCL  Offshore  supports and  develops  various Postpaid Applications on Java/J2EE Platform and  also  provides  End to  End  Support  to achieve  T-mobile market strategies.\n\n· T-Mobile Activation Gateway (TMAG) is a web-based application, involves in the activation process of Voice and Broad Band Lines for New personal/business customers and existing customers. \n· Few main functionalities of TMAG are customer credit check, personal coverage check,allowed lines calculation, filtration of rate plans and features, billing preferences, mode of  payment, activation, and generating service agreements.     \n\n Responsibilities:\n\n· Understanding business requirement and technical specification provided by client and responsible for designing and implementation of the same.\n\n· Participate in all phases of development from definition and design through implementation, debugging, testing and deployment to ensure development is consistent across all layers .\n\n· Provided support for bug fixing and production day support for the application of \n\n            almost all modules associated with the TMAG application.\n\n· Testing the application.\n\n· Played an active role in development and testing of the different modules also involved in creating  design and understanding documents.                                 \n\nPersonal Profile:\n\nGender\n\n\n: Male\n\nMarital Status\n\n: Single\n\nDate of Birth\n\n: 9th June 1990\n\nLanguage Known\n: English, Hindi, Oriya\n\nDec​​​​​​​​laration: \n\n I do hereby declare that the above-mentioned statements are true to the best of my    knowledge and I bear the responsibility for the correctness of the above mentioned particulars.         \n\n Place:  Bangalore                                                                                     Namasya Das","annotation":[{"label":["Name"],"points":[{"start":7496,"end":7506,"text":"Namasya Das"}]},{"label":["Location"],"points":[{"start":7402,"end":7411,"text":"Bangalore "}]},{"label":["Skills"],"points":[{"start":5801,"end":5804,"text":"J2EE"}]},{"label":["Skills"],"points":[{"start":2294,"end":2300,"text":"MongoDB"}]},{"label":["Skills"],"points":[{"start":2035,"end":2041,"text":"MongoDB"}]},{"label":["Skills"],"points":[{"start":2009,"end":2018,"text":"IBM Watson"}]},{"label":["Skills"],"points":[{"start":1984,"end":1996,"text":"ElasticSearch"}]},{"label":["Skills"],"points":[{"start":1958,"end":1967,"text":"IBM Watson"}]},{"label":["Skills"],"points":[{"start":1947,"end":1953,"text":"MongoDB"}]},{"label":["Education"],"points":[{"start":1279,"end":1284,"text":"B.Tech"}]},{"label":["Skills"],"points":[{"start":924,"end":936,"text":"ElasticSearch"}]},{"label":["Skills"],"points":[{"start":912,"end":918,"text":"MongoDB"}]},{"label":["Skills"],"points":[{"start":861,"end":870,"text":"IBM Watson"}]},{"label":["Skills"],"points":[{"start":766,"end":769,"text":"J2EE"}]},{"label":["Skills"],"points":[{"start":592,"end":595,"text":"J2EE"}]},{"label":["Skills"],"points":[{"start":586,"end":589,"text":"JAVA"}]},{"label":["Name"],"points":[{"start":162,"end":172,"text":"Namasya Das"}]}],"extras":null,"metadata":{"first_done_at":1532672820000,"last_updated_at":1532672820000,"sec_taken":175,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Nandini Murthy\nMob:  +91-9741941042/9886331411 \n\n Mail:  nandinimurthy10@gmail.com\nSummary\n\nSoftware engineer with 10 years of hands on experience in product development in the Storage domain. Attentive to details and thrives on challenges every day.\n\nEngineer with a new found liking towards Data science and Machine Learning. Currently on a sabbatical and actively seeking new opportunities.\n\nCore competencies\n\nDemonstrable programming aptitude and experience in Python/Java/C++.\n\nExpertise in Web technologies like GWT, HTML, JavaScript, CSS, JSON and XML . Hands on experience in UI design and prototyping.\n\nIntermediate level exposure to Data analysis using R and Python.\n\nEducation Profile:\n\nB.E, Information Science. CGPA – 7.5 2002-2006\n\nMOOC Certification Courses:\n\nData Scientist’s Toolbox, Coursera, Nov 2016 Introduction to R, Datacamp, Mar 2017 Intermediate R, Datacamp, Apr 2017 Importing Data in R, May 2017\n\nR Programming, Coursera, May 2017\n\nData driven astronomy, Coursera, (Pursuing) Machine Learning, Coursera, (Pursuing)\n\nAlgorithms, Princeton University, Coursera (Pursuing).\n\nOnline presence\n\ngithub.com/nandinimurthy twitter.com/nandinimurthy\n\nE M P L O Y M E N T H I S T O R Y\n\nBroadcom (LSI Technologies, India) Oct 2010 – Sep-2016\n\nProducts contributed to:\n\nMSM (MegaRAID Storage Manager) and LSA (LSI Storage Authority): Storage array management software\n\nDesigned, developed and maintained core features in LSI’s (now Broadcom) flagship storage array management applications.\n\nParticipated in multiple code refactoring efforts to optimize existing algorithms for efficiency. Interfaced with product management and UI design teams.\n\nLed the defect management of the products using SCRUM.\n\nTechnology Stack:\n\nJava, JavaScript, GWT, HTML,CSS, Nginix WebServer\n\nEMC\nJun 2006 –  Oct-2010\nProducts contributed to:\nVPLEX : Distributed Federation solution, that can enable a single copy of data to be shared, accessed and relocated over distance.\nInvista is a Storage Virtualization which helps in virtualizing heterogeneous storage arrays.\nDesign and development of new commands in CLI. Developed GUI for the product based on ECUE standards\nPiloted process improvement initiatives in the project resulting in increase in quality\nTechnology stack:\nC++, Core Java, JSP, JUnit ,HTML, CSS, Python, Git","annotation":[{"label":["Skills"],"points":[{"start":2309,"end":2314,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2298,"end":2301,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":2280,"end":2283,"text":"Java"}]},{"label":["Skills"],"points":[{"start":2270,"end":2272,"text":"C++"}]},{"label":["Skills"],"points":[{"start":1760,"end":1763,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":1755,"end":1757,"text":"GWT"}]},{"label":["Skills"],"points":[{"start":1743,"end":1746,"text":"Java"}]},{"label":["Skills"],"points":[{"start":1737,"end":1740,"text":"Java"}]},{"label":["Education"],"points":[{"start":699,"end":701,"text":"B.E"}]},{"label":["Skills"],"points":[{"start":670,"end":675,"text":"Python"}]},{"label":["Skills"],"points":[{"start":530,"end":533,"text":"Java"}]},{"label":["Skills"],"points":[{"start":524,"end":527,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":519,"end":521,"text":"GWT"}]},{"label":["Skills"],"points":[{"start":478,"end":480,"text":"C++"}]},{"label":["Skills"],"points":[{"start":473,"end":476,"text":"Java"}]},{"label":["Skills"],"points":[{"start":466,"end":471,"text":"Python"}]}],"extras":null,"metadata":{"first_done_at":1532668556000,"last_updated_at":1532668556000,"sec_taken":92,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "`\nNARESH KUMAR            Viman Nagar, Near Inorbit, Pune-411006\n                                                                                                +919704261686 ● nareshkommoju6@gmail.com\n\n                                                                                                             \nPROFESIONAL SUMMARY          \n\n3.5 years of experience in software industry of different application platforms.Experience in Data Science using R, SQL, Machine learning and implementing models as well. Currently working as, a Data Scientist.\n\n· Experienced professional with 2 years of experience working across analytics & Machine learning domain\n· Proven experience in predictive modelling using Statistical tool R, familiarity with Python and sound knowledge in relational database(Sql)\n· Good in machine learning and data mining techniques- Regression, Classification,clustering  \n· Excellent understanding in Statistics and having good knowledge of various analytical approaches \n· Experience in Investor& Treasury servies, wealth management & Telecom Industry as well.\n· Good experience in visualization tools like Tableau and also with ggplot package in R.\n\n\n· Basic knowledge of Natural Language processing(NLP) and Text mining and also good in problem solving and analytical skills.\n· Extensive experience in Data Analysis - Skilled in uncovering insights and identifying patterns.\n· Excellent communication and presentation skills and ability to explain your analysis clearly\n· Passion for learning and always improving myself and the team around me.\n\nPRIOR WORK EXPERIENCE        \nGlobal Step        (August 2017 – Till Now)                                                          Data Scientist\nCapgemini India (May 2014 - May2017)                                                                SSE / Data Scientist    \n\nEDUCATION\nJNTU Kakinada University Apr. 2009 - Apr. 2013 \nBachelors of Technology (Specialization in Electronics & Communications)\nGraduated with 74.66%\n\nKEY SKILLS\n            Soft Skills                        Hard Skills\n            Team Player                     R Language\n            Time Management            Database: Oracle, MySQL\n            Team Leadership              Machine Learning Techniques                   \n            Communication                Tableau, Python & Text mining Basics(NLP)                              \n          \nPROJECTS\nProject #1\t:  Boxing Analytics                                              \nClient\t               :  HBO  \nTool                     :  R Studio 3.3.2,Machine Learning, Video Analytics, SQL\nDescription\t: In competitive combat sporting environments like boxing, will apply the statistics on a boxer's performance, including the amount and type of punches thrown, provide a valuable source of data and feedback which is routinely used for coaching and performance improvement purposes. This project presents a robust framework for the automatic Classification of a boxer's punches. Results demonstrate the effectiveness of the proposed approach, with the classification yielding a 96% accuracy, signifying its suitability for analysing athletes punches in boxing bouts.\n\nProject #2\t:  Churn in and out predictions                                              \nClient\t               :  Kuwait Based Telecom-Oreedoo  \nTool                     :  R Studio 3.3.2,  Predictive Modelling\nDescription\t: Providing the data in which number of customers who decided to stop using the service offered by the company and willing to port to another company, usually because it offers a better service or price. So targeting those customers and providing best offers for them based upon their needs, Predicting those possible churners and then utilize the limited resources to retain those customers\n\nProject #3\t: Scorecard Home Loan Tool \nClient\t               : RBC  \nTool\t\t: R studio 3.3.2, R shiny\nDescription\t: Developing the dashboard for a multinational Canada based banking Company\n\nProject #4\t: Customer Analytics \nTool                     :  R Studio 3.3.2, Tableau, MS – Excel\nClient                  :  Internal project\nDescription\t: This project is to increase the revenue of the client using Customer analytics.\n\nProject #5  \t: PRISM\nClient                  :  RBC\nLanguage    \t: Pega PRPCV7.1.5, Oracle, Core Java, Websphere\nDatabase     \t: Oracle\nDescription \t: The objectives of the project are as follows:\n1. Replace the OPENS (URM0) and MessageNet (NZ00) applications which are approaching end of life and   \n    consolidate into one new Workflow application :\n● OPENS is a front-end that is used for the Case Workflow Management system for problem resolution \n    between the Branch and Operations support teams\n● Message Net is a front-end which provides a means of workflow management, in support of DS Wealth \n    Management Business.  The system provides forms to collect, detail and track business activity\n\nCERTIFICATIONS\n● Certified R programmer, Data camp\n● Regression Certification, Data camp\n● Data Cleaning and Data manipulation, Data camp\n● Machine Learning Certification, Stanford University (In progress)\n\t\nAWARDS & RECOGNITIONS at Work\nReceived a number of appreciation mails and ARBIE award from the client for continuous good performance and also within the organization\n\n\n\n\n\n\n`\n \nNA\nRESH \nKU\nMAR\n \n           \nViman\n \nNagar\n, \nNear Inorbit\n, \nPune\n-\n411006\n \n                                                                                                \n+91\n9704261686 \n?\n \nnareshkommoju6@gmail.com\n \n \n                                                            \n                                                 \n \nPROFESIONAL SUMMARY\n          \n \n \n3\n.5\n \nyears\n \nof experience in software \nindustry of different application platforms.\nE\nxperience in \nData \nScien\nce \nusing R\n, SQL\n, Machine learning\n \nand implementing models as well\n. Currently \nworking as, a Data \nScientist\n.\n \n \n-\n \nE\nxperience\nd professional with 2\n \nyears \nof experience working across analytics & \nMachine learning domain\n \n-\n \nProven experience in predictive \nmodelling using\n \nStatistical tool \nR, \nfamiliarity w\nith Python \nand sound knowledge in relational database(Sql)\n \n-\n \nGood in machine learning and data mining techniques\n-\n \nRegression, Classification,clustering  \n \n-\n \nExcellent \nunderstanding in Statistics\n \nand having good knowledge of various analytical \napproaches \n \n-\n \nExperience in Investor& Treasury servies, wealth management & Telecom Industry as well.\n \n-\n \nGood experience in visualization tools like Tableau and also with ggplot package in R.\n \n \n \n-\n \nBasic\n \nknowledge of\n \nNatural Language processing(NLP) and Text mining and also good in \np\nroblem solving and analytical skills\n.\n \n-\n \nExtensive experience in Data Analysis \n-\n \nSkilled in uncovering insights and identifying \npatterns.\n \n-\n \nExcellent\n \ncommunication\n \nand presentation\n \nskills and ability to explain your analysis clearly\n \n-\n \nPassion for learning and always improving myself and the team around me.\n \n \nPRIOR WORK EXPERIENCE\n        \n \nGlobal Step\n        \n(\nAugust 2017 \n–\n \nTill Now\n)                                \n                          \nData Scientist\n \nCapgemini India\n \n(\nMay 2014 \n-\n \nMay2017\n)\n \n                                                          \n     \nSSE / Data \nScientist\n    \n \n \nEDUCATION\n \nJNTU Kakinada University\n \nApr. 2009 \n-\n \nApr. 2013 \n \nBachelors of Technology \n(Specialization in Electronics & Communications)\n \nGraduated with 74.66%\n \n \nKEY SKILLS\n \n            \nSoft Skills                        Hard Skills\n \n            \nTeam Player                   \n  \nR Language\n \n            \nTime Management         \n   \nDatabase: Oracle\n, \nMySQL\n \n            \nTea\nm Leadership           \n   \nMachine Learning Techniques \n                  \n \n            \nCommunication\n               \n \nTableau,\n \nPython\n \n& Text mining Basics\n(NLP)\n                              \n \n       \n   \n \nPROJECTS\n \nProject #1\n \n:\n \n \nBoxing Analytics\n \n                                             \n \nClient\n \n               \n:\n \n \nHBO  \n \nTool                     \n:\n  \nR \nStudio 3.\n3.2,\nMachine Learning, \nVideo Analytics\n, SQL\n \nDescription\n \n:\n \nIn competitive combat sporting environments like boxing, \nwill app\nly \nthe statistics on a \nboxer's performance, including the amount and type of punches thrown, provide a valuable source of data and \nfeedback which is routinely used for coaching and performance improvement purposes. This \nproject\n \npresents a \nrobust framework for the automatic Classification of a boxer's punches\n.\n \nResults demonstrate the effectiveness of \nthe proposed \napproach, with the classification\n \nyielding a 96% accuracy, signifying its suitability for analysing \nathletes\n \npunches i\nn boxing bouts\n.","annotation":[{"label":["Skills"],"points":[{"start":8151,"end":8153,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":7846,"end":7851,"text":"Python"}]},{"label":["Skills"],"points":[{"start":7835,"end":7841,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":7689,"end":7691,"text":"SQL"}]},{"label":["Education"],"points":[{"start":7388,"end":7410,"text":"Bachelors of Technology"}]},{"label":["Skills"],"points":[{"start":6616,"end":6647,"text":"Natural Language processing(NLP)"}]},{"label":["Skills"],"points":[{"start":6579,"end":6580,"text":" R"}]},{"label":["Skills"],"points":[{"start":6540,"end":6546,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":6130,"end":6135,"text":"Python"}]},{"label":["Skills"],"points":[{"start":6009,"end":6024,"text":"Machine learning"}]},{"label":["Skills"],"points":[{"start":5820,"end":5835,"text":"Machine learning"}]},{"label":["Skills"],"points":[{"start":5814,"end":5816,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":5809,"end":5810,"text":" R"}]},{"label":["Location"],"points":[{"start":5375,"end":5378,"text":"Pune"}]},{"label":["Skills"],"points":[{"start":5143,"end":5144,"text":" R"}]},{"label":["Skills"],"points":[{"start":4979,"end":4980,"text":" R"}]},{"label":["Skills"],"points":[{"start":4953,"end":4954,"text":" R"}]},{"label":["Skills"],"points":[{"start":4420,"end":4421,"text":" R"}]},{"label":["Skills"],"points":[{"start":4268,"end":4269,"text":" R"}]},{"label":["Skills"],"points":[{"start":4062,"end":4068,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":4045,"end":4046,"text":" R"}]},{"label":["Skills"],"points":[{"start":3887,"end":3888,"text":" R"}]},{"label":["Skills"],"points":[{"start":3871,"end":3872,"text":" R"}]},{"label":["Skills"],"points":[{"start":3857,"end":3858,"text":" R"}]},{"label":["Skills"],"points":[{"start":3351,"end":3352,"text":" R"}]},{"label":["Skills"],"points":[{"start":2989,"end":2990,"text":" R"}]},{"label":["Skills"],"points":[{"start":2596,"end":2598,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":2545,"end":2546,"text":" R"}]},{"label":["Skills"],"points":[{"start":2327,"end":2332,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2318,"end":2324,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":2185,"end":2187,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":2114,"end":2115,"text":" R"}]},{"label":["Education"],"points":[{"start":1905,"end":1927,"text":"Bachelors of Technology"}]},{"label":["Skills"],"points":[{"start":1200,"end":1231,"text":"Natural Language processing(NLP)"}]},{"label":["Skills"],"points":[{"start":1173,"end":1174,"text":" R"}]},{"label":["Skills"],"points":[{"start":1134,"end":1140,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":857,"end":858,"text":" R"}]},{"label":["Skills"],"points":[{"start":748,"end":753,"text":"Python"}]},{"label":["Skills"],"points":[{"start":727,"end":728,"text":" R"}]},{"label":["Skills"],"points":[{"start":637,"end":652,"text":"Machine learning"}]},{"label":["Skills"],"points":[{"start":465,"end":480,"text":"Machine learning"}]},{"label":["Skills"],"points":[{"start":460,"end":462,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":456,"end":457,"text":" R"}]},{"label":["Location"],"points":[{"start":53,"end":56,"text":"Pune"}]},{"label":["Name"],"points":[{"start":2,"end":13,"text":"NARESH KUMAR"}]}],"extras":null,"metadata":{"first_done_at":1532682236000,"last_updated_at":1532682236000,"sec_taken":170,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "NEERAJKUMAR\nneeraj0583@gmail.com___________________________________________________________________90351 24351 / 78997 77351\n\nEXPERIENCE SUMMARY\n· Data Science professional with an experience of 6.0 years is software industry, delivering business solutions to international and Indian customers.\n· Experiences working with Statistical Modeling (Linear Regression, Logistic Regression, Random Forest, Clustering, Survival Analysis and other Advance Machine Learning algorithms.)\n· Worked with different Statistical Software like R/ R Studio Programming tool\n· Worked with different RDBMS like MS SQL2005/2008 and Oracle / Alteryx\n· Worked with different Reporting tool like Tableau/Spotfire\n· Experienced in Data Collection, Variable Preparation, Modeling, and Publishing Results over market and Measure their performance.\n· Achievement/Award includes:‘Accenture core value’ and ‘On-Time Deliver’, Got 10|10 award, Team A award\nSKILL SETS\n\tOperating Systems\n\tWindows and Linux\n\n\tProgramming Languages\n\tR :  RStudio,\nRDBMS:MS SQL 2005/2008, My SQL / Alteryx\n\n\tData Mining\n\n\tRetail: Cross Selling, UP Selling, RFM analysis, Market Segmentation etc.\nPredictive Asset Maintenance (PAM): Component Failure modeling, Survival Analysis, Optimization\nTelecom: Fraud Detection\n\n\tAnalytics and Machine Learning\n\tRandom Forest, Logistic Regression, Linear Regression, SVM, Partial dependence Plots etc.\n\n\tOther Tools\n\tBasics of Tableau and Spotfire\n\n\n\n\n\n\n\n\n\n\n\t\n\t\n\t\n\n\nEXPERIENCE\nAnalytics Analyst Data Science,2015 – till date\nAccenture Digital, Bangalore\n\nHelped to increase the efficiency of Compressor to achieve maximum benefits for large cement group company in Thailand\n· Worked on data crunching and data formatting using R tool and SQL\n· Used Linear regression and Random forest model to optimize compressor section\n· Used R and different packages for visualization\nProvided Predictive Asset Maintenance solution to Major LNG in Australia\n· Worked on data crunching and data formatting using R Tooland SQL\n· Used logistic regression model to predict the failure of the components\n· Used R packages for modeling, data exploration and advanced visualization.\nHelped to find the probability of a vehicle becoming a Buyback for Car manufacturer company in UK\n· Prepared huge data of client in R and Excel\n· Used logisticregression model to predict the buyback of the cars\n· Used Confusion matrix, sensitivity, specificity and ROC curve for model validation\n· Used R and different packages for visualization\n\nHave developed the framework which would help to detect the fraud in procurement, specifically in the areas of duplicate payments and duplicate vendors.\n· The tool has been developed using Open RToolas a core engine and SQL/ Excel as backend databases.\n· Used Fuzzy, Phonetic, Geolocation, Bayesian and Random Forest etc. to developed the framework.\n\nForecasted the demand of the products for larger Distributor in US\n· Worked on data crunching and data formatting using Alteryx\n· Used STL and 2.5SD techniques to detect the outlier in R Tool\n· Used different forecasting models (UCM, Arima, naïve seasonal etc.) to generate their basic regular and promotional forecast in R.\n\nSenior Analyst, Innominds Software     \t\t\t\t\t\t\t\t2014-2015\nConsultant - Deloitte, Bangalore\n\nConvergeHEALTH\nConvergeHEALTH is a platform and solutions which can uniquely support our health care and life sciences clients\n\n· Worked on EDA for Breast Cancer patient using R Tool\n· Used Decision Tree / regression to classify the Breast Cancer Patients\n· Created own packages for given Algorithm using R Tool\n· Developed Markov chain model to predict the length of stay (LOS) of surgical patient based on their possible transitions in health state including death. Transitions are Admitted ->Transferred, Admitted -> Discharged etc.\n· Done allocation of minimum physician across all the practitioners\n\nSenior Software Engineer, Mindtree Ltd\t\t\t\t\t\t\t\t2011-2014\nAVIS BUDGET GROUP (ABG US) Online Marketing Analytics\nAVIS/BUDGET is a car rental company,Project is mainly focused on data work and analytically improvises the AVIS/BUDGET Customer development team and help them to find most likely customer to rent.\n· Handled huge data of AVIS/BUDGET using Oracle.\n· Creation of variable across multiple dimensions for Scorecard modelling in R Tool.\n· Experience on RFM modelling.\n· Developed many custom analytical reports using TIBCO Spotfire and Excel\n\nHindustan Unilever\nHindustan Unilever is the India’s largest Fast Moving Consumer Goods Company. \nProject is mainly focused on analytically improvise the HUL Customer development team and help them in taking key business decisions.\nPractical exposure: Selling the best possible product for an outlet according to that area basket\n· Done Cross Sellingfor products and developed Scorecard modeling for its survival.\n· Practical experience on RFM modeling.\n· Creation of variable across multiple dimensions for Scorecard modeling.\n· Experience in Score Card Modeling using T-SQL and R Tool.\n· Developed many custom analytical reports using T-SQLand Excel\n· Worked on different strategies for pushing Seasonality Products across India\n\n\n\n\n\n\n\n\nPersonal Information\n· Current Employer\t: Accenture Digital, Bangalore\n· Position             \t\t: Analytics Analyst\n· Date of Birth\t\t: 08 Feb, 1989\n· Sex/Marital Status        \t: Male/Single\n· Languages Known       \t: English, Hindi\n\nEducation Profile\n\n\tDegree/Board\n\tName of the Institute, Place\n\tYear of Pass out\n\tPercentage/CGPA\n\n\t10th / BSEB\n\tAnugrah High School Madanapur, Aurangabad Bihar\n\t2004\n\t71.85\n\n\t12th/ BIEC \n\tAnugrah NarayanCollege, Patna, Bihar\n\t2006\n\t61.44\n\n\tB.E. /VTU\n\tB.V.B.C.E.T, Hubli Karnataka\n\t2011\n\t/ 8.34\n\n\n\nDeclaration\nI hereby declare that all the above information is true as per best of my knowledge.\nPlace: Bangalore\t\t\t\t\t\t\t\t\t\t Neeraj Kumar","annotation":[{"label":["Location"],"points":[{"start":5794,"end":5802,"text":"Bangalore"}]},{"label":["Education"],"points":[{"start":5633,"end":5636,"text":"B.E."}]},{"label":["Location"],"points":[{"start":5219,"end":5227,"text":"Bangalore"}]},{"label":["Location"],"points":[{"start":3256,"end":3264,"text":"Bangalore"}]},{"label":["Location"],"points":[{"start":1533,"end":1541,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":1283,"end":1298,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":612,"end":627,"text":"Oracle / Alteryx"}]},{"label":["Skills"],"points":[{"start":592,"end":607,"text":"MS SQL2005/2008 "}]},{"label":["Skills"],"points":[{"start":448,"end":463,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":323,"end":342,"text":"Statistical Modeling"}]},{"label":["Name"],"points":[{"start":0,"end":10,"text":"NEERAJKUMAR"}]}],"extras":null,"metadata":{"first_done_at":1532677401000,"last_updated_at":1532677401000,"sec_taken":129,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Niranjan Kasi\n                                                            Jr.Data Scientist\nE-mail: niranjankasi452@gmail.com\nCell: +91-9741977834\n\t\t\t\t\t\nCareer Objective:\n\nTo become a contributing Data Scientist, in an organization for its success, by applying the best business practices through innovative solutions and constantly updating my skills.\n\nProfessional Summary: \n\n· 3 years and 1 month experience in R, Machine learning and Tableau which covers in-depth understanding of data cleaning and model building.\n· Excellent mathematics, statistics and calculation skills put into practice on a daily basis.\n· Ability to create good visualization by using R programming for the client’s proposed business processes.\n· Worked on data manipulation.\n· Building, publishing customized interactive reports and dashboards, report scheduling on Tableau server.\n· Communicating with other team members, collaborating effectively to complete research and information.\n· Understanding client requirements, provide solutions, functional specifications and\nconfigure the system accordingly.\n· Excellent verbal and written communication skills, to facilitate business/ technical\ndiscussions, document solutions and work well with people at all levels of the\norganization.\n· Self- starting team member with demonstrated proficiency in organizing\ncomplex projects, defining project priorities, resolving challenging issues, and\ndelegating tasks.\n\n               Skill Set \n· R\n· Tableau\n· Machine Learning\n\n   Database\n\n· SQL\n\nEducation:\n\nBachelor of Technology: (2010-2014)\nSiddarth Institute of Engineering & Technology, Puttur, Andhra Pradesh, India.\n\nWork Experience:\n\nProject-1                                                                                              Jan 2015- Feb 2016\n\n\nOrganization      :  DMC IT Services                                                                                      Client                 : V C Fortune Magazine Pvt Ltd.\nDesignation        :  Jr.Data Scientist\n\nDescription:\n\n VC Firm is venture capital Investment Company constantly monitoring start-ups and other companies to find the prospective companies to invest and fund. They have been following a manual process of decision making in deciding to choose the companies to invest in which has increasingly become unreliable due to the nature of business and the decisions being made out of the research were unaccountable. Their objective is to automate the decision making based on advanced analytical and statistical modelling techniques using data instead of merely using the empirical experience and also to be accountable and to be able to expand in the future. They have been constantly looking for ways to improve the decision making using better ways which are more accountable and reliable.\n\nRoles and Responsibilities:\n\n· Worked on Data pre-processing stage which involved cleaning of data using R \n· Created various dummy variables from the data using R \n· Used data imputation techniques such as MICE for missing data. \n· Involved in coming up with various visualizations using ggplot \n· Involved in cleaning up various discrepancies in data to make it analysis ready using R \n· Analyzed and used advanced analytical techniques such as Linear Regression & Random forests in comparing the accuracies which help in decision making of companies to invest in. \n\nProject-2                                                                                                Apr 2016 – Till\n\nOrganization: DMC IT Services\nClient:  Aus Coal Miner Pvt. Ltd.\nDesignation:  Jr. Data Scientist\n\nProject Description:\n\nAC Miner is a coal mining company based out of Australia and is one of the largest coal miners in the world. They use 100s of heavy machinery which are very expensive (in $Millions) and needed a way to constantly monitor the downtime to get an idea of the resource utilization of various machines used in coal mining. A small downtime of any of these machines would have an impact of thousands to million dollars a day and wanted to find ways to predict if any of the machines were about to fail as part of their predictive maintenance strategy.\n\nRoles and Responsibilities:\n\n· Supplied data is provided in csv formats which is the outputs of sensor data hooked up with the machines \n· Cleaned and pre-processed data using R \n· Created various visualizations using ggplot based on data which would help the business users understand the utilization of machines to be able to do predictive maintenance.\n\nReferences: Will be provided on request \n\n                                                                                                                              Regards,\n                                                                                                                             Niranjan. K","annotation":[{"label":["Skills"],"points":[{"start":4683,"end":4683,"text":"R"}]},{"label":["Skills"],"points":[{"start":4515,"end":4515,"text":"R"}]},{"label":["Skills"],"points":[{"start":4335,"end":4335,"text":"R"}]},{"label":["Skills"],"points":[{"start":4169,"end":4169,"text":"R"}]},{"label":["Skills"],"points":[{"start":4159,"end":4159,"text":"R"}]},{"label":["Skills"],"points":[{"start":3268,"end":3268,"text":"R"}]},{"label":["Skills"],"points":[{"start":3255,"end":3255,"text":"R"}]},{"label":["Skills"],"points":[{"start":3186,"end":3186,"text":"R"}]},{"label":["Skills"],"points":[{"start":2963,"end":2963,"text":"R"}]},{"label":["Skills"],"points":[{"start":2906,"end":2906,"text":"R"}]},{"label":["Skills"],"points":[{"start":2811,"end":2811,"text":"R"}]},{"label":["Skills"],"points":[{"start":2801,"end":2801,"text":"R"}]},{"label":["Education"],"points":[{"start":1530,"end":1551,"text":"Bachelor of Technology"}]},{"label":["Skills"],"points":[{"start":1470,"end":1476,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":1466,"end":1466,"text":"R"}]},{"label":["Skills"],"points":[{"start":844,"end":850,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":662,"end":662,"text":"R"}]},{"label":["Skills"],"points":[{"start":438,"end":444,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":417,"end":432,"text":"Machine learning"}]},{"label":["Skills"],"points":[{"start":414,"end":414,"text":"R"}]},{"label":["Name"],"points":[{"start":0,"end":12,"text":"Niranjan Kasi"}]}],"extras":null,"metadata":{"first_done_at":1532668768000,"last_updated_at":1532668768000,"sec_taken":80,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "NIRMAL KANNAN.A  PAGE 1 OF 4 \n\nNIRMALKANNAN.A            \n__________________________________________________________________________________________                                                                                                    \n\nnirmalkannan.a@gmail.com |  +91 9810259925 | Bangalore, India                                                                                                                                                                                                                                                                                            \n\n                                 \nObjective: \n \n To be able to work in your organization as a Machine Learning Expert  where I can fully utilize          \nmy skills in Machine Learning  Algorithms, Python, NumPy, Pandas, Scipy, Natural Language Processing, \nDjango with having more than 9+ years of IT industry experience and managed multi-crore projects               \nindependently. \n \n\nExperience & Skills  : \n \n Around 9+ years of experience in systems analysis, design, development and implementation of IT pro-\n\njects and Management for various clients including multi-crore projects such as PFMS (CPSMS) , Hero \nMotor Corp, Bharti Airtel, CGA , CAG , Indian Meteorological Dept. numerical weather prediction on \nCRAY X1E Super Computer  using COROBOR. \n \n\n Experienced in Machine Learning- supervised and unsupervised algorithms: - Natural Language Pro-\ncessing (NLP), Sentiment Analysis,  Forecasting, Time Series Analysis, Classification, Data/Text Min-\ning, Image Processing ,Decision Trees and Algorithms, Random Forest, Search Algorithms. \n\n Build and train scalable models using best practices, enabling re-use for future real world problems us-\ning Python, NumPy, Pandas, Scipy,Matplotlib, Machine Learning Algorithms , NLTK, SpaCy, Gensim \nTF-IDF,Django, Magento Openstack,  MySQL and SQLite. \n\n NLP / Deep NLP & text mining: tagging (based on a trigram HMM), syntactic parsing (based on a \nPCFG), feature engineering and dimensionality reduction, multi-label classification, word sense disam-\nbiguation, Twitter hashtag decomposition, relevance engine, topic modeling; sentiment analysis, con-\ntextual text mining. \n\n \n\nNatural Language Processing(NLP) using Python dossier : \n \n\n Able to visualize and develop a business model using NLP techniques for Plagiarism Detection - using  \nCosine Similarity to identify the similarity detection between text documents. \n\no Usability :  \n Legal contracts , Medical Records , Bugs Similarity and much more. \n\n \n Utilized Lexical based approach or machine learning techniques like topic modelling & word segmen-\n\ntation for feature engineering and  sentiment analysis for social media by analyzing hashtags, posts, \ncomments and replies. \n\no Usability :  \n Track brand sentiment by identifying relevant content in Twitter. \n Reviews on Products/Movies/Restaurants based on web articles. \n\n Have been building my own Chatbot system using Python-NLTK where user can type messages and \nthe system replies based on the user's text. \n \n\n Classified the tweets based on sports, business, politics, entertainment etc and detect trending tweets in \nthose domain using NLP techniques SpaCy,gensim,NLTK etc. \n\nmailto:nirmalkannan.a@gmail.com\n\n\n                                                                                                                                \n\nNIRMAL KANNAN.A  PAGE 2 OF 4 \n\n Experience  in analyzing complex problems by identifying trends, patterns, and outliers in data. \n \n \nDjango – Ecommerce dossier: \n \n\n Involved in designing database Model, API's, Views using Python-Django to build an interactive web \nbased solution.  \n \n\n Having strong experience in developing web applications and implementing Model-View-\nControl/Template (MVCT) architectures using Django  server side application . \n\n \n Generated Python Django Forms to record data of online users.  \n\n \n Able to design URLs for Django web-applications using Python regular expression . \n\n \n Designed and developed custom login with authentication / authorization using Django custom/ So-\n\ncial authentication such as Oauth2.0 , Facebook, Google and Twitter.  \n \n Having strong knowledge in integrating E-Commerce with secure payment processing ( PayPal / \n\nCCAvenue). \n \n Designed a webportal with Solr  Search Engine and haystack. \n\n \n Familiar with JSON based webservices and Python  REST API Framework. \n\n \n Designed and implemented End –to-End E-Commerce application using Python /Django Framework \n\nwith Celery / RabbitMQ. \n \n Worked on various applications with python integrated IDEs Jupyter,SublimeText, PyCharm, Brackets \n\n& atom. \n \n\nCareer Contour:  \n \nOrganization              : IBM India, New Delhi                         \nDuration                     :  September 2013 to Present. \nDesignation                : Business Manager    \n  \n\nRoles and Responsibilities:  \n \n\n Excelled in guiding the work of technical teams. Articulated project goals and scope, translated \n\nbusiness needs into technical terms, prepared detailed work breakdown structures (WBS) and in-\n\nstilled shared accountability for achieving project milestones. \n\n Created cost-benefit analyses and ROI assessments that were used as the basis for decision-making \n\non proposed IT implementation projects. \n\n To take assigned project from original concept through final implementation.  \n\n Meeting client requirement with organization assets and capability framework. \n\n\n\n                                                                                                                                \n\nNIRMAL KANNAN.A  PAGE 3 OF 4 \n\n Internal Co-ordination with practice teams and technical presales team to generate quality proposals \n\naddressing customer’s requirements. \n\n  Co-ordination for prices, negotiations for terms of supply/ service suited to my organization so as \n\nto ensure optimal and planned cash flows thus avoiding negative cash flows.  \n\n \nOrganization             : CMC Limited (A TATA Enterprise), New Delhi                         \nBusiness Group        : Tata Consultancy Services Limited (TCS Ltd) \nDuration                   : April ’08 – October ’09 & September 2010 – August 2013. \nDesignation             : Business Analyst/Development   \n\n \n\nCMC Limited is a leading IT solutions company and a subsidiary of Tata Consultancy Services Limited (TCS \nLtd), one of the world's leading information technology consulting, services and business process outsourcing \norganizations. And part of Tata group, India's best-known business conglomerate. \n \n\nRoles and Responsibilities:  \n \n\n Understand the Client requirement with organization assets and capability framework. \n\n Internal Co-ordination with practice teams and technical presales team to generate quality proposals \n\naddressing customer’s requirements. \n\n  Co-ordination for prices, negotiations for terms of supply/ service suited to my organization so as \n\nto ensure optimal and planned cash flows thus avoiding negative cash flows.  \n\n \n\nOrganization        : RememME.com [Nomad Publications], New Delhi      \nDuration               : November 2009 - September 2010. \nDesignation          : Business Analyst. \n \n\nRememME.com is a part of Nomad Publications an entrepreneurial venture and built in a way that it shall be \nperceived and branded as a strong and valuable global knowledge community by users and competition. \n \nThis online community is for people who passionate about writing. Here people can freely express and share \ntheir knowledge, thoughts and experiences of life in the form of a scoop. \n \n\nRoles and Responsibilities: \n\n Designed, developed the workflow and made an appropriate recommendation that has                    \nimpacted operational effectiveness. \n\n To take assigned project from original concept through final implementation.  \n\n To review project deliverables and deadlines. \n\n Ensure the operational effectiveness and excellence of the business unit. \n\n Ensure optimal and planned cash flows thus avoiding negative cash flows. \n\n Built the relationships for tie-ups & partnership with the organizations. \n\n \n\n \n\nhttp://www.tcs.com/\nhttp://www.tcs.com/\nhttp://www.tata.com/\nhttp://rememme.com/\n\n\n                                                                                                                                \n\nNIRMAL KANNAN.A  PAGE 4 OF 4 \n\nEducational Qualifications: \n \n\nDegree/ Course Institution University / Board \nYear of \n\nPassing \n\nPGDM (Marketing & IT \n\nSystems) \n\nInstitute of Marketing and \n\nManagement \nIMM, New Delhi 2008 \n\nB.Tech (Information \n\nTechnology) \n\nPSNA College of Engineering \n\nand Technology \nAnna University 2006 \n\n                         \n\nExtramural Engagements: \n Served as an active Coordinator & Member for: \n\n IT Club during the MBA programme. \n\n The Indus Entrepreneurship [TIE]. \n\n Proactively participated in Entrepreneurship Summit organized by IIT Delhi & in other events con-\n\nducted by NASSCOM.","annotation":[{"label":["Education"],"points":[{"start":8532,"end":8536,"text":"PGDM "}]},{"label":["Name"],"points":[{"start":8402,"end":8417,"text":"NIRMAL KANNAN.A "}]},{"label":["Name"],"points":[{"start":5649,"end":5664,"text":"NIRMAL KANNAN.A "}]},{"label":["Skills"],"points":[{"start":4545,"end":4550,"text":"Django"}]},{"label":["Skills"],"points":[{"start":4537,"end":4542,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4537,"end":4541,"text":"Pytho"}]},{"label":["Skills"],"points":[{"start":4437,"end":4442,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4437,"end":4441,"text":"Pytho"}]},{"label":["Skills"],"points":[{"start":4125,"end":4130,"text":"Django"}]},{"label":["Skills"],"points":[{"start":4013,"end":4018,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4013,"end":4017,"text":"Pytho"}]},{"label":["Skills"],"points":[{"start":3983,"end":3988,"text":"Django"}]},{"label":["Skills"],"points":[{"start":3907,"end":3912,"text":"Django"}]},{"label":["Skills"],"points":[{"start":3900,"end":3905,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3900,"end":3904,"text":"Pytho"}]},{"label":["Skills"],"points":[{"start":3850,"end":3855,"text":"Django"}]},{"label":["Skills"],"points":[{"start":3662,"end":3667,"text":"Django"}]},{"label":["Skills"],"points":[{"start":3655,"end":3660,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3655,"end":3659,"text":"Pytho"}]},{"label":["Skills"],"points":[{"start":3564,"end":3569,"text":"Django"}]},{"label":["Name"],"points":[{"start":3429,"end":3444,"text":"NIRMAL KANNAN.A "}]},{"label":["Skills"],"points":[{"start":3001,"end":3006,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3001,"end":3005,"text":"Pytho"}]},{"label":["Skills"],"points":[{"start":2276,"end":2281,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2276,"end":2280,"text":"Pytho"}]},{"label":["Skills"],"points":[{"start":2237,"end":2263,"text":"Natural Language Processing"}]},{"label":["Skills"],"points":[{"start":1900,"end":1905,"text":"SQLite"}]},{"label":["Skills"],"points":[{"start":1890,"end":1894,"text":"MySQL"}]},{"label":["Skills"],"points":[{"start":1870,"end":1886,"text":"Magento Openstack"}]},{"label":["Skills"],"points":[{"start":1862,"end":1867,"text":"Django"}]},{"label":["Skills"],"points":[{"start":1804,"end":1820,"text":"Machine Learning "}]},{"label":["Skills"],"points":[{"start":1763,"end":1768,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1763,"end":1767,"text":"Pytho"}]},{"label":["Skills"],"points":[{"start":855,"end":860,"text":"Django"}]},{"label":["Skills"],"points":[{"start":825,"end":851,"text":"Natural Language Processing"}]},{"label":["Skills"],"points":[{"start":795,"end":800,"text":"Python"}]},{"label":["Skills"],"points":[{"start":765,"end":781,"text":"Machine Learning "}]},{"label":["Skills"],"points":[{"start":691,"end":707,"text":"Machine Learning "}]},{"label":["Location"],"points":[{"start":295,"end":303,"text":"Bangalore"}]},{"label":["Name"],"points":[{"start":0,"end":15,"text":"NIRMAL KANNAN.A "}]}],"extras":null,"metadata":{"first_done_at":1532693946000,"last_updated_at":1532693946000,"sec_taken":180,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Udaya Laxmi Ch\n\nEmail : laxmi.udaya@gmail.com\n\n\t\n\n\tPhone: -9740606990\n\t\n\n\n\tSummary\n\n\t· 9.5 years of experience in Software Development.\n· 3.5 years of experience in Machine Learning\n· Primary Skills – Machine Learning, R programming, Lotus Notes.\n· Presently working for Wipro Technologies, Bangalore.\n· Experience in planning, estimation, design, development, and testing object oriented applications.\n· Experience in preparing various technical documents like Functional Specs, HLD, LLD, Flowcharts and Test cases.\n· Sound Knowledge in Object Oriented Design Principles\n· Have Team Handling experience.\n· Domain experience of Manufacturing and Finance.\n· Have Experience in Scrum Agile Model\n· Understand business requirements from clients\n\n\n\n\tTechnical Skills\n\n\tKey skills: \n\tMachine Learning,R Programming, MySQL, PostgreSQL, Microsoft Access, SQL Server, FileMaker, Oracle, RDBMS, dBASE, Clipper, FoxPro, Firebase, Mongodb, Python,  ava, J2EE, Oracle Fusion,Oracle Cloud, Salesforce, Devops Android, Business Analyst, UI Developer, DBAs, Embedded Systems, .NET, Hadoop, SQL Developer, Big Data, Tableau, Networking, Etl, Informatica, Ios, Quality Analyst, Project Manager, Python, Data Science, Python, Machine Learning, SAS, Java, Scala, Hadoop, Hive, Bigdata, Programming, SQL server reporting, Msbi Ssis, Ssrs, Msbi, Sql Reporting, Artificial Intelligence, Pandas, Pyspark, Sklearn, Flask, Django, Map Reduce, Parametric Design, Modeling, Regression, Patterns, Data Mining, Text Mining, Oops, Deep Learning, Web Analytics, Time Series, Regression, Tensorflow, Azure, Linear Regression, Logistic Regression, Decision Tree, Random Forest, Data Structure, Computer Vision, IHS, WAS, Java EE, SQL Server, .NET core, C#, ASP.NET, Rdlc, Linq, Sql, Web Api, Mvc, Javascript, Web Services, Oracle, MS SQL, PHP, Laravel, CodeIgniter, Symfony, Zend, Phalcon, CakePHP, Yii, FuelPHP, React, Vue, Angular, Ember, Backbone, Lotus Notes\n\n\tAlgorithms:\n\tNaïve Bayes, K means clustering,Word Cloud\n\n\tDatabases: \n\tMicrosoft SQL, Mongo DB\n\n\tWeb Technologies: \n\tXML, XSLT, HTML,  JavaScript,  AJAX, JQuery\n\n\tIDE:\n\tR studio,Pycharm\n\n\n\tProfessional Experience\n\n\tCurrent Employer :\n\tWipro Technologies., Bangalore  – (Oct  2010  to till date) – Technical Lead/Data Scientist\n\n\tPrevious Employers :\n\tHSBC Software development , Hyderabad (June  2008  to Sep 2010)  - SE\n\n\n\tQualification\n\n\tDegree\n\tCollege\n\tUniversity/Board\n\tYear\n\tPercentage (%)\n\n\tMCA\n\tNizam College, Basheerbagh,Hyderabad\n\tOsmania University\n\t2008\n\t75\n\n\n\tProject Experience \n\n\tProject 1 : Exploratory Data Analysis:\n\nProject Description:   Performed EDA analysis to analyze the Purchase frequency of vehicles which occurred over past 3 years and try to predict the frequency occurring in the future.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Performed EDA analysis to find the insights of the data. Observed the summary of each and every variable to understand the variables.\n\n· Performed the feature selection using hypothesis testing.\n\n· Identified the outliers using box plot.\n\n· Identified the trend in the purchases using histogram.\n\n\n\n\tProject 2: Word Cloud Analysis:\n\nProject Description:   Performed Word cloud and Sentimental Analysis of the customer feedbacks. Graphically represented the most frequently occurred words through Word cloud. Through sentimental analysis we identified whether a user-generated text expresses positive, negative or neutral opinion.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Created a Corpus using TM package and performed pre-processing of data.\n\n· Removed the punctuations, stemming and stop words which are of no analytical value.\n\n· Built a Document term matrix and identified the most frequently occurring words\n\n· Graphically represented it using  RColorbrewer Package\n\n\n\tProject 3: Sentimental Analysis:\n\nProject Description: Performed Sentimental Analysis of customer feedbacks through Naïve Bayes. Used “e1071” Package for implementing naïve Bayes method.\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· The DTM created using TM package was an input to the Naive Bayes Model.\n\n· As Naive Bayes classifier is typically trained on data with categorical features. We have converted the count of the words into a factor variable that indicates Yes or No whether the word is present or not.\n\n\tProject 4: Clustering Analysis:\n\nProject Description: Classified the customers on the basis of their purchases whether they have purchased low variant or high variant trucks. It in turn helped in building the right customer strategies.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Performed data preparation and Normalization of data using min-max method.\n\n· As K-means algorithm groups a dataset into a user-specified number (k) of clusters. Identified the initial cluster centroids as 3.\n\n· K clusters are creating by associating every observation with the nearest mean.\n\n· Used elbow method to validate the number of clusters such that within-cluster sum of square(wss) is minimized.\n\n\n\n\tProject 5 : Inter Connection Management Tool\nProject Description: Inter-connection Management (IMT) is prototype being developed for Engineering and Sales department to handle customizations of an existing product based on the customer's requirement. Users from engineering department will identify the items, which need to be customized out of the entire product design.\nRole\n\n       : Module Lead\n\nEnvironment\n       : Python, Mongo DB, jQuery\n\nTasks handled:\n\n· Gathering Requirements and providing Project Plan and Effort Estimation details.\n\n· Understanding business requirements and preparing SoU (Statement of Understanding) and Functional/Technical Specification documents.\n\n· Providing Effort & Resource estimations\n\n· Planning for application development and deployment\n\n· Writing and executing Test Cases and Test scenarios\n\n· Creating design elements using Technical Specification.\n\n· Performing Unit testing & Peer Reviews\n\n· Work Allocation and mentoring the team\n\n· Providing Technical guidance to the team. \n\n\tProject 6\n: cvdAEI Application\n\nProject Description\n     : CVDAEI is a web based multilingual application developed for handling the Change Management process in Truck division of Daimler. The change request flows through different phases mainly Initialization, Evaluation, Decision and Conclusion. This application has a configurable workflow where the request flow and the responsible persons can be configured easily at any point of time. \n\nRole\n\n    : Developer/Tester\n\nEnvironment\n     : Lotus Notes, Java, HTML, XML, Java Script, JQuery\n\nTasks handled:\n\n· Gathering Requirements and providing Project Plan and Effort Estimation details.\n\n· Understanding business requirements and preparing SoU (Statement of Understanding) and Functional/Technical Specification documents.\n\n· Providing Effort & Resource estimations\n\n· Planning for application development and deployment\n\n· Writing and executing Test Cases and Test scenarios\n\n· Creating design elements using Technical Specification.\n\n· Performing Unit testing & Peer Reviews\n\n· Work Allocation and mentoring the team\n\n· Providing Technical guidance to the team. \n\n\n\n\tProject Title: Project Management Office \nProject Description: The purpose of this system is to enable the Project Management Office to manage and execute the IT Applications and Operations driven project tasks in  more systematic manner. It will also enable them to efficiently perform a role as a facilitator to coordinate various IT Operations teams and to ensure that project activity enters the department through one common interface. The project tasks will subsequently be dealt with in a common format and in a consistent and appropriate manner, ensuring open and regular communication between all involved parties.\n\nRole\n\n    : Developer/Tester\n\nEnvironment\n     : Lotus Notes, Java, HTML, XML, Java Script, JQuery\n\nTasks Handled :\n\n· Writing and Executing Test cases in client server based environment\n· Individually provided application support","annotation":[{"label":["Skills"],"points":[{"start":7951,"end":7956,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":7938,"end":7948,"text":"Java Script"}]},{"label":["Skills"],"points":[{"start":7933,"end":7935,"text":"XML"}]},{"label":["Skills"],"points":[{"start":7927,"end":7930,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":7921,"end":7924,"text":"Java"}]},{"label":["Skills"],"points":[{"start":7908,"end":7918,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":6645,"end":6650,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":6632,"end":6642,"text":"Java Script"}]},{"label":["Skills"],"points":[{"start":6627,"end":6629,"text":"XML"}]},{"label":["Skills"],"points":[{"start":6621,"end":6624,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":6615,"end":6618,"text":"Java"}]},{"label":["Skills"],"points":[{"start":6602,"end":6612,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":5522,"end":5527,"text":"jQuery"}]},{"label":["Skills"],"points":[{"start":5512,"end":5519,"text":"Mongo DB"}]},{"label":["Skills"],"points":[{"start":5504,"end":5509,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4645,"end":4652,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":4054,"end":4061,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":3941,"end":3951,"text":"Naïve Bayes"}]},{"label":["Skills"],"points":[{"start":3494,"end":3501,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":3132,"end":3141,"text":"Word Cloud"}]},{"label":["Skills"],"points":[{"start":2793,"end":2800,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":2110,"end":2116,"text":"Pycharm"}]},{"label":["Skills"],"points":[{"start":2101,"end":2108,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":2086,"end":2091,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":2080,"end":2083,"text":"AJAX"}]},{"label":["Skills"],"points":[{"start":2067,"end":2076,"text":"JavaScript"}]},{"label":["Skills"],"points":[{"start":2060,"end":2063,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":2054,"end":2057,"text":"XSLT"}]},{"label":["Skills"],"points":[{"start":2049,"end":2051,"text":"XML"}]},{"label":["Skills"],"points":[{"start":2018,"end":2025,"text":"Mongo DB"}]},{"label":["Skills"],"points":[{"start":2003,"end":2015,"text":"Microsoft SQL"}]},{"label":["Skills"],"points":[{"start":1977,"end":1986,"text":"Word Cloud"}]},{"label":["Skills"],"points":[{"start":1958,"end":1975,"text":"K means clustering"}]},{"label":["Skills"],"points":[{"start":1945,"end":1955,"text":"Naïve Bayes"}]},{"label":["Skills"],"points":[{"start":1918,"end":1928,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":1908,"end":1915,"text":"Backbone"}]},{"label":["Skills"],"points":[{"start":1901,"end":1905,"text":"Ember"}]},{"label":["Skills"],"points":[{"start":1892,"end":1898,"text":"Angular"}]},{"label":["Skills"],"points":[{"start":1887,"end":1889,"text":"Vue"}]},{"label":["Skills"],"points":[{"start":1880,"end":1884,"text":"React"}]},{"label":["Skills"],"points":[{"start":1871,"end":1877,"text":"FuelPHP"}]},{"label":["Skills"],"points":[{"start":1866,"end":1868,"text":"Yii"}]},{"label":["Skills"],"points":[{"start":1857,"end":1863,"text":"CakePHP"}]},{"label":["Skills"],"points":[{"start":1848,"end":1854,"text":"Phalcon"}]},{"label":["Skills"],"points":[{"start":1842,"end":1845,"text":"Zend"}]},{"label":["Skills"],"points":[{"start":1833,"end":1839,"text":"Symfony"}]},{"label":["Skills"],"points":[{"start":1820,"end":1830,"text":"CodeIgniter"}]},{"label":["Skills"],"points":[{"start":1811,"end":1817,"text":"Laravel"}]},{"label":["Skills"],"points":[{"start":1806,"end":1808,"text":"PHP"}]},{"label":["Skills"],"points":[{"start":1798,"end":1803,"text":"MS SQL"}]},{"label":["Skills"],"points":[{"start":1790,"end":1795,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":1776,"end":1787,"text":"Web Services"}]},{"label":["Skills"],"points":[{"start":1764,"end":1773,"text":"Javascript"}]},{"label":["Skills"],"points":[{"start":1759,"end":1761,"text":"Mvc"}]},{"label":["Skills"],"points":[{"start":1750,"end":1756,"text":"Web Api"}]},{"label":["Skills"],"points":[{"start":1745,"end":1747,"text":"Sql"}]},{"label":["Skills"],"points":[{"start":1739,"end":1742,"text":"Linq"}]},{"label":["Skills"],"points":[{"start":1733,"end":1736,"text":"Rdlc"}]},{"label":["Skills"],"points":[{"start":1724,"end":1730,"text":"ASP.NET"}]},{"label":["Skills"],"points":[{"start":1720,"end":1721,"text":"C#"}]},{"label":["Skills"],"points":[{"start":1709,"end":1717,"text":".NET core"}]},{"label":["Skills"],"points":[{"start":1697,"end":1706,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":1688,"end":1694,"text":"Java EE"}]},{"label":["Skills"],"points":[{"start":1683,"end":1685,"text":"WAS"}]},{"label":["Skills"],"points":[{"start":1678,"end":1680,"text":"IHS"}]},{"label":["Skills"],"points":[{"start":1661,"end":1675,"text":"Computer Vision"}]},{"label":["Skills"],"points":[{"start":1645,"end":1658,"text":"Data Structure"}]},{"label":["Skills"],"points":[{"start":1630,"end":1642,"text":"Random Forest"}]},{"label":["Skills"],"points":[{"start":1615,"end":1627,"text":"Decision Tree"}]},{"label":["Skills"],"points":[{"start":1594,"end":1612,"text":"Logistic Regression"}]},{"label":["Skills"],"points":[{"start":1575,"end":1591,"text":"Linear Regression"}]},{"label":["Skills"],"points":[{"start":1568,"end":1572,"text":"Azure"}]},{"label":["Skills"],"points":[{"start":1556,"end":1565,"text":"Tensorflow"}]},{"label":["Skills"],"points":[{"start":1544,"end":1553,"text":"Regression"}]},{"label":["Skills"],"points":[{"start":1531,"end":1541,"text":"Time Series"}]},{"label":["Skills"],"points":[{"start":1516,"end":1528,"text":"Web Analytics"}]},{"label":["Skills"],"points":[{"start":1501,"end":1513,"text":"Deep Learning"}]},{"label":["Skills"],"points":[{"start":1495,"end":1498,"text":"Oops"}]},{"label":["Skills"],"points":[{"start":1482,"end":1492,"text":"Text Mining"}]},{"label":["Skills"],"points":[{"start":1469,"end":1479,"text":"Data Mining"}]},{"label":["Skills"],"points":[{"start":1459,"end":1466,"text":"Patterns"}]},{"label":["Skills"],"points":[{"start":1447,"end":1456,"text":"Regression"}]},{"label":["Skills"],"points":[{"start":1437,"end":1444,"text":"Modeling"}]},{"label":["Skills"],"points":[{"start":1418,"end":1434,"text":"Parametric Design"}]},{"label":["Skills"],"points":[{"start":1406,"end":1415,"text":"Map Reduce"}]},{"label":["Skills"],"points":[{"start":1398,"end":1403,"text":"Django"}]},{"label":["Skills"],"points":[{"start":1391,"end":1395,"text":"Flask"}]},{"label":["Skills"],"points":[{"start":1382,"end":1388,"text":"Sklearn"}]},{"label":["Skills"],"points":[{"start":1373,"end":1379,"text":"Pyspark"}]},{"label":["Skills"],"points":[{"start":1365,"end":1370,"text":"Pandas"}]},{"label":["Skills"],"points":[{"start":1340,"end":1362,"text":"Artificial Intelligence"}]},{"label":["Skills"],"points":[{"start":1325,"end":1337,"text":"Sql Reporting"}]},{"label":["Skills"],"points":[{"start":1325,"end":1327,"text":"Sql"}]},{"label":["Skills"],"points":[{"start":1319,"end":1322,"text":"Msbi"}]},{"label":["Skills"],"points":[{"start":1313,"end":1316,"text":"Ssrs"}]},{"label":["Skills"],"points":[{"start":1302,"end":1310,"text":"Msbi Ssis"}]},{"label":["Skills"],"points":[{"start":1302,"end":1305,"text":"Msbi"}]},{"label":["Skills"],"points":[{"start":1280,"end":1299,"text":"SQL server reporting"}]},{"label":["Skills"],"points":[{"start":1267,"end":1277,"text":"Programming"}]},{"label":["Skills"],"points":[{"start":1258,"end":1264,"text":"Bigdata"}]},{"label":["Skills"],"points":[{"start":1252,"end":1255,"text":"Hive"}]},{"label":["Skills"],"points":[{"start":1244,"end":1249,"text":"Hadoop"}]},{"label":["Skills"],"points":[{"start":1237,"end":1241,"text":"Scala"}]},{"label":["Skills"],"points":[{"start":1231,"end":1234,"text":"Java"}]},{"label":["Skills"],"points":[{"start":1226,"end":1228,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1208,"end":1223,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1200,"end":1205,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1186,"end":1197,"text":"Data Science"}]},{"label":["Skills"],"points":[{"start":1178,"end":1183,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1161,"end":1175,"text":"Project Manager"}]},{"label":["Skills"],"points":[{"start":1144,"end":1158,"text":"Quality Analyst"}]},{"label":["Skills"],"points":[{"start":1139,"end":1141,"text":"Ios"}]},{"label":["Skills"],"points":[{"start":1126,"end":1136,"text":"Informatica"}]},{"label":["Skills"],"points":[{"start":1121,"end":1123,"text":"Etl"}]},{"label":["Skills"],"points":[{"start":1109,"end":1118,"text":"Networking"}]},{"label":["Skills"],"points":[{"start":1100,"end":1106,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":1090,"end":1097,"text":"Big Data"}]},{"label":["Skills"],"points":[{"start":1075,"end":1087,"text":"SQL Developer"}]},{"label":["Skills"],"points":[{"start":1067,"end":1072,"text":"Hadoop"}]},{"label":["Skills"],"points":[{"start":1061,"end":1064,"text":".NET"}]},{"label":["Skills"],"points":[{"start":1043,"end":1058,"text":"Embedded Systems"}]},{"label":["Skills"],"points":[{"start":1037,"end":1040,"text":"DBAs"}]},{"label":["Skills"],"points":[{"start":1023,"end":1034,"text":"UI Developer"}]},{"label":["Skills"],"points":[{"start":1005,"end":1020,"text":"Business Analyst"}]},{"label":["Skills"],"points":[{"start":989,"end":1002,"text":"Devops Android"}]},{"label":["Skills"],"points":[{"start":977,"end":986,"text":"Salesforce"}]},{"label":["Skills"],"points":[{"start":963,"end":974,"text":"Oracle Cloud"}]},{"label":["Skills"],"points":[{"start":949,"end":961,"text":"Oracle Fusion"}]},{"label":["Skills"],"points":[{"start":943,"end":946,"text":"J2EE"}]},{"label":["Skills"],"points":[{"start":929,"end":934,"text":"Python"}]},{"label":["Skills"],"points":[{"start":920,"end":926,"text":"Mongodb"}]},{"label":["Skills"],"points":[{"start":910,"end":917,"text":"Firebase"}]},{"label":["Skills"],"points":[{"start":902,"end":907,"text":"FoxPro"}]},{"label":["Skills"],"points":[{"start":893,"end":899,"text":"Clipper"}]},{"label":["Skills"],"points":[{"start":886,"end":890,"text":"dBASE"}]},{"label":["Skills"],"points":[{"start":879,"end":883,"text":"RDBMS"}]},{"label":["Skills"],"points":[{"start":871,"end":876,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":860,"end":868,"text":"FileMaker"}]},{"label":["Skills"],"points":[{"start":848,"end":857,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":830,"end":845,"text":"Microsoft Access"}]},{"label":["Skills"],"points":[{"start":818,"end":827,"text":"PostgreSQL"}]},{"label":["Skills"],"points":[{"start":811,"end":815,"text":"MySQL"}]},{"label":["Skills"],"points":[{"start":798,"end":808,"text":"Programming"}]},{"label":["Skills"],"points":[{"start":796,"end":808,"text":"R Programming"}]},{"label":["Skills"],"points":[{"start":779,"end":794,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":234,"end":244,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":219,"end":231,"text":"R programming"}]},{"label":["Skills"],"points":[{"start":201,"end":216,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":165,"end":180,"text":"Machine Learning"}]},{"label":["Name"],"points":[{"start":0,"end":13,"text":"Udaya Laxmi Ch"}]}],"extras":null,"metadata":{"first_done_at":1579625576000,"last_updated_at":1579626369000,"sec_taken":0,"last_updated_by":"aJOmJy1lvpOYFetVNuqLvFo9Vx42","status":"done","evaluation":"NONE"}}
{"content": "Pallavi Shetty\n\t                                                             Address for correspondence:\nPallavi Shetty\n                                                                                          #B002, Oman Topaz Apartment,\n                                                                                          Agara Sarjapur road,\n                                                                                          Bangalore- 560102\n                                                                                          Email: pallavishetty657@gmail.com       \n                                                                                          Mobile: 9980549142                                                                                                                                                                                     \n\n\n\tOBJECTIVE\n\n\n\nA professional with 9.5+ years of experience, I am seeking position to utilize my skills and abilities that offers professional growth and will help me to explore myself fully and realize my potential. \n\n\tPROFESSIONAL SUMMARY\n\n\n\n· Working as Advisory Consulting Engineer and having experience in Development and Implementation of Object oriented modules using Java technologies.\n· IBM Certified Application Developer - Cúram V6.0.4.\n· Oracle Certified Associate, Java SE 7 programmer\n· Versatile result oriented performer having experience in analysis, design, development, implementation, coding, testing and maintenance.\n· Worked as lead, Individual Contributor and a team player.\n\n\n\tExperience Summary:\n\n\n\n· Working as Advisory Consultant Engineer in IBM Software Labs (Joined IBM as part of Curam Software International Pvt Ltd acquisition) from Sep 2011.\n· I worked as Software Engineer in Yodlee InfoTech Pvt Ltd, from May 2008 to August 2011. \n\n\n\n\n\tEDUCATIONAL QUALIFICATIONS:\n\n\n\n· Bachelor of Engineer (Computer Science) – BEC College of Engineering under VTU University with an aggregate of 63.78%\n· (Computer Science Branch)\n· PUC – RLS PU College Belgaum with an aggregate of 78.33%.\n· SSLC- P.P.E.A.M School Rampur with an aggregate of 89.76 %.\n\n\n\tSOFTWARE SKILLS:\n\n\n\nLanguages                                 :        JAVA, SQL, HTML, JavaScript, XML     \nJ2EE Technologies                    :       JSP, Servlets\nFramewroks /Platforms          :      Spring 4.0, Hibernate 4.0, Cúram 6.0.4, \n                                                            Bluemix with  Watson APIs\nWeb Services                            :        REST, SOAP\nDBMS Used\t\t            :        IBM DB2, Oracle 10G,H2\n             Tools/IDE                                   :        Eclipse, RSA\n             Version Controls                      :        RTC, SVN, Perforce, GIT\n\n\n\tPROJECT DETAILS:\n\n\n\nProject I:\n\n\tProject Title\n\tAMS\n\n\tClient\n\tAustria\n\n\tRole\n\tIndividual Contributor\n\n\tTeam Size\n\t22\n\n\n\nDescription:\n\t\n\tThe new Job platform for Austria’s Public Employment Service which aims to become the best in Europe. The solution is based on IBM Curam and WCC/Elise(matching engine).This involves implementation of new solution CEMS (Curam      Employment management system) model for CURAM Product \n\nResponsibilities:\n\n● Requirement analysis, designing, implementation, unit and functional testing.\n● Implementation of business logic, server and client side validations, exception handling for the solution.\n● Implemented REST client for Elise.\n● Developed tools which automates the repetitive work.\n\n\nProject II:\n\n\tProject Title\n\tJUS-IT\n\n\tClient\n\tJugendhilfe, Sozialhilfe und Wohngeld Hamburg\n\n\tRole\n\tModule Lead\n\n\tTeam Size\n\t25\n\n\n\n\nDescription:\n\t\n       This application helps children to protect from abuse and youth to get the benefits they are entitled from the government. Project aims to create better child service and youth service for citizens to get the benefits they are entitled for.\n\nResponsibilities:\n\n● Worked as module lead.\n● Got the knowledge transfer from German team on the requirements.\n● Worked on design, implementation and testing of various modules.\n● Took sessions to the technical team members on some of the complex\n   Modules and best practices.\n● Won award for timely and quality delivery from German Team.\n\nProject III:\n\n\tProject Title:\n\tPersonal Independence Payment\n\n\tClient:\n\tDepartment for Work and Pensions\n\n\tRole:\n\tSenior Java Developer\n\n\tTeam Size:\n\t20\n\n\nDescription:\n\t\n               Curam application is online solution for social enterprise Management for Department of Work and Pension. This application helps user to claim for the benefits they are entitled from the government. \n\nResponsibilities:\n\n· Involved in customization of Curam v6.\n· Involved in mapping the business requirement to the solution.\n· Involved in technical designing and coding as per business requirements.\n· Designed and developed the inbound curam webservice to provide details of evidence and payment details to third party tool.\n· Involved in unit testing for all the methods and all business scenarios.\n\n\nProject IV:\n\n\tProject Title\n\tMoney Center\n\n\tClient\n\tFidelity, ANZ, Ally bank, Bank of America, Yodlee\n\n\tRole\n\tJava Developer\n\n\tTeam Size\n\t14\n\n\n\nDescription:\n\t\n\tThe application was designed to help manage and analyze user spending, expenses and income. This application helps user to add all the bank, investment, credit card account and maintain all his financials at one place.\n\nResponsibilities:\n\n· Analyze the site for the required info which depends on the containers (bank, credit card, investment etc) and map it to the relevant fields that should be shown to the corresponding customer.\n· Handling the complex navigation issues involved in the sites using javascript\n· Interacting with the clients on call to understand the requirements/\n Troubleshooting / updates on deliveries.\n· Fixing client reported issues and doing enhancement.\n· Code reviews and mentoring peers on lessons learnt.","annotation":[{"label":["Skills"],"points":[{"start":2255,"end":2257,"text":"XML"}]},{"label":["Skills"],"points":[{"start":2243,"end":2252,"text":"JavaScript"}]},{"label":["Skills"],"points":[{"start":2237,"end":2240,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":2232,"end":2234,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":2226,"end":2229,"text":"JAVA"}]},{"label":["Education"],"points":[{"start":1884,"end":1922,"text":"Bachelor of Engineer (Computer Science)"}]},{"label":["Name"],"points":[{"start":105,"end":118,"text":"Pallavi Shetty"}]},{"label":["Name"],"points":[{"start":0,"end":13,"text":"Pallavi Shetty"}]}],"extras":null,"metadata":{"first_done_at":1532677180000,"last_updated_at":1532677180000,"sec_taken":105,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "OBJECTIVE \nA dedicated and competent   \n\ndeveloper with more than 6 \n\nyears of experience, I aim to \n\nadd value and strength to \n\nmy organization using my \n\ntechnical skills. My analysis \n\nand understanding of the \n\nproblem, keen interest,  \n\nswift implementation and \n\nability to involve people in \n\nteam decisions, I believe, \n\nhelps me execute strategies \n\nbetter and brings overall \n\ncredibility to the \n\norganization. \n\n \n\n \n\n \n \n\nSOFTWARE SKILLS \nMachine Learning, Natural \nLanguage Processing(Spacy), \nTextacy, Spark, Jazz, Deep \nLearning(Keras), \nGraphDB(orientDB), Python, \nC/C++, Linux, SVN, Git, IBM \nDOORS \n \n\n   \n\nPhaneendra Kumar Gunda \nMachine Learning & NLP Engineer \n\nMob: 09052011361 |Email: phaneendrakumar.gunda@gmail.com \n \n\nPROFESSIONAL EXPERIENCE \nWIPRO TECHNOLOGIES, BANGALORE                                 (June 2016 – present)                                                      \nProduct Developer for Machine Learning and NLP Applications \n\n \nProject           :  DEFT(Deep Extraction Framework for Text) \n\nDuration        :  June 2016 - Present \n\nClient          :  Wipro HOLMES \n\nTechnologies  : Machine Learning, Natural Language Processing(NLP), Deep \nLearning(Keras), AWS, Hadoop, Spark \n\nPackages        :  Spacy, Python, Textacy, GloVe, OpenNLP, Flask \n\nDescription    :  Information extraction from the PDF/word documents. By using \nthe DEFT Framework, extract the following features \n\n➢ Named Entities(NER) \n➢ Entity Relations(SVO’s) \n➢ MultiWord Expression \n➢ Semantic Extraction \n➢ Semantic Roles(SRL) extraction \n➢ Key Terms and their rank Extraction \n➢ Coreference  \n\nCreate a Rest End Service for the above features for the consumers. By using \nOrientDB we can represent the output in graphical view and to use it as search \nquery from the Orientdb. \n\nFor the scalability, Same framework implemented in Hadoop in AWS cluster \nenvironment by using Spark. \n\nMy Role: \n\n➢ Work on the most of the features listed above \n➢ Handling the scrum meetings and conduct Retro meetings. \n➢ Guiding the new Engineers. \n➢ Support in running DEFT in Hadoop environment \n\n \nProject          :  Custom Named Entity Recognition(NER) \n\nDuration        :  June 2017 - Present \n\nClient           :  PWC, UBS \n\nTechnology    :  Spacy, Python \n\nDescription    :  Annotate the given customer data and generate the training data. \nGenerate the custom NER model with the new entity types given by the customer. \nIdentify those entities from the extracted PDF/word documents and replace with \nthe entity types. Generate the cross-validation matrix to get the accuracy of the \nmodel. \n\n \n\nProject         :  Classification and Work assignment model \n\nDuration       :  June 2016 - November 2016 \n\nClient          :  BAT(British American Tobacco) \n\nTechnology   :  Python - SciKit  \n\nDescription   :  BAT is tobacco company. Analyze the data and build a \nclassification model for auto categorization and work assignment through various \nmodels and predict the tickets are raised getting classified correctly. \n\n \n \n \n\n\n\n \n \n     \n      \n     PERSONAL SKILL \n \n- Flexible across \ntechnologies and platforms \n- Coordinating between \nteams \n- Swift Execution \n- Interpersonal Skills \n- Multitasking \n \n \n \n \n \n\n \n            \n  \n           PROFILE \n\n \nLinkedIn \nhttps://www.linkedin.com/\nprofile/view?id=AAIAAAmDSH\nUB7y5VgfIzzKOS2stpYq9Q3sa\nfZMg&trk=nav_responsive_ta\nb_profile \n \n \n \n \n \n\n \n \n \n \n \n\nGENERAL INFO \n \n\nSEX: Male \nNATIONALITY: Indian \nDATE OF BIRTH: Feb 26, \n1989 \nMARITAL STATUS:    Single \nLANGUAGES KNOWN: \nEnglish \nTelugu \nHindi \n \n \n\n          \n           \n \n\n \n \nROCKWELL COLLINS Pvt. Ltd., HYDERABAD                 (August 2011 – May 2016)     \nEmbedded Software Engineer \n                                     \nProject          :  Platform Software \n\nDuration        :  August 2015 - Present \n\nClient          :  Boeing 737 Max \n\nDescription   : Platform software of Boeing 737 Max is combination of \nBootloader, Device Drivers, Core BSP, Flash File System, Data load,   HMA(Health \nMonitor) and TFTP library.  \n\nMy Role: \n\n➢ Analyze, design, develop and unit test using C for TFTP library. \n\n➢ Involved in all phases of Software Development life Cycle for this module. \n\n➢ Conducting team meetings and monitoring progress of work. \n\n➢ Mentoring New Engineers and giving knowledge share sessions. \n\n \n\n \n\nProject         :  Head Up Display (HUD) \n\nDuration       :  January 2013 – August 2015 \n\nClient         :  Boeing 737 Max, EEJ \n\nDescription  : HUD is any transparent display that presents data without \nrequiring users to look away from their usual viewpoints. The origin of the name \nstems from a pilot being able to view information with the head positioned \"up\" \nand looking forward, instead of angled down looking at lower instruments. \nTypical aircraft HUDs display airspeed, altitude, a horizon line, turn/bank \na slip/skid indicators. \n\nMy Role: \n\n➢ Analyze, design, develop and unit test using C++. \n\n➢ Involved in all phases of Software Development life Cycle for this module. \n\n➢ Conducting team meetings and monitoring progress of work. \n\n➢ Mentoring New Engineers and giving knowledge share sessions. \n\n \n\n \n\nProject  :  Onboard Maintenance Systems (OMS) \n\nDuration :  August 2011 - December 2012 \n\nClient  :  Boeing, EEJ, MRJ, C-Series \n\nDescription :  Onboard Maintenance System is an application which will \nmonitor the faults and generates the reports upon user request. Mechanic will \nuse these reports as a reference to fix the root cause of the failures when the \naircraft is landing on the ground and Pilot can also use these reports incase when \nhe needs to know the detail information about the faults. \n\nMy Role: \n\n➢ Implemented the code in C and part of the Integration team to test the \napplications on target environment. \n\n➢ Involvement in NCT, VCT, PCT. \n\n➢ Familiar with writing software Remote procedure call in distributed \nprocess communications (using XML-RPC libraries) \n\n \n \n\n                            EDUCATION \n \n\n➢ Center for Development of Advance computing(C-DAC) (March 2011 - July 2011) \nCOURSE - PG Diploma in Embedded Systems - 74%  \n\n➢ Narasaraopeta Engineering College, Guntur, A.P    (2006 -2010) \nCOURSE - Electronics &  Communication Engineering  -  Percentage : 78%                                                \n\n➢ Sarada Junior College, Narasaraopet    (2004 - 2006) \n\nhttps://www.linkedin.com/profile/view?id=AAIAAAmDSHUB7y5VgfIzzKOS2stpYq9Q3safZMg&trk=nav_responsive_tab_profile\nhttps://www.linkedin.com/profile/view?id=AAIAAAmDSHUB7y5VgfIzzKOS2stpYq9Q3safZMg&trk=nav_responsive_tab_profile\nhttps://www.linkedin.com/profile/view?id=AAIAAAmDSHUB7y5VgfIzzKOS2stpYq9Q3safZMg&trk=nav_responsive_tab_profile\nhttps://www.linkedin.com/profile/view?id=AAIAAAmDSHUB7y5VgfIzzKOS2stpYq9Q3safZMg&trk=nav_responsive_tab_profile\nhttps://www.linkedin.com/profile/view?id=AAIAAAmDSHUB7y5VgfIzzKOS2stpYq9Q3safZMg&trk=nav_responsive_tab_profile\n\n\n \n \n \n \n \n \n         \n           HOBBIES \n- Exploring cuisines, cultures \nand places \n- Music, Cooking \n- TT, Gym, Watching Cricket \n- Being updated on new \ntechnology \n\nCBSE CLASS XII    -  91% \n\n➢ Sindhu school, Narasaraopet   (2004) \nCBSE CLASS X      -  86%                                     \n\n \n\n                                       \n\n                       POSITIONS OF RESPONSIBILITY                                      \n➢ Technical Point of contact for all customer interactions \n➢ Showcasing demos for prospective clients for Wipro CTO \n\n \n                          AREA OF INTEREST \n\n➢ Completed ‘Machine Learning’ course by Andrew Ng in Coursera \n➢ Exploring ‘Deep Learning’ course by Andrew Ng in Coursera \n➢ My area of interest is work on image/Text in Deep Learnning \n\n                               \n                               ACADEMIC PROJECTS \n Project : Playing a word game between two hosts on a TCP network \nLanguages        : C \nCourse Work    : CDAC Pune \nDescription :  It is a network based word program. Player 'A' picks up a word \nfrom a dictionary and ask player 'B' to guess the same. Player 'A' also conveys the \ntotal number of alphabets in the word. Player 'B' has to guess one alphabet at a \ntime. If the alphabet belongs to the word then player 'A' will notify accordingly \nalong with its position. If player 'B' gives 6 wrong alphabets the game is up. \nMultiple occurrence of a selected alphabet in word is also notified to the player \n'B'. An alphabet cannot be selected twice. On a successful guess, its now turn of \nplayer 'B' to pick up a word from a dictionary and player 'A' has to guess it. \n\n \n\n \n\n                                     LEAN IDEAS \nIdea                  : Checkout/update/Switch repositories of the projects by using         \nGUI tool. \nLanguages         : Bash Scripting, C# \nTools required  : SVN, Visual Studio. \nDescription       : In SVN, each repository contains branches, tags, trunk. Project \ncontains so many applications and libraries and each contains so many branches \nand tags. when project checkout it will checkout all branches, tags and trunk but \nall are not necessary to check out for a programmer. It also takes a lot of time to \ncheckout (based on project size) and occupies lot of system memory. In order to \nsave checkout time and system memory, I come up with this lean idea. \n                               \n\n.","annotation":[{"label":["Skills"],"points":[{"start":7538,"end":7553,"text":"Machine Learning"}]},{"label":["Education"],"points":[{"start":6196,"end":6235,"text":"Electronics &  Communication Engineering"}]},{"label":["Skills"],"points":[{"start":1128,"end":1143,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":931,"end":946,"text":"Machine Learning"}]},{"label":["Location"],"points":[{"start":791,"end":799,"text":"BANGALORE"}]},{"label":["Skills"],"points":[{"start":651,"end":666,"text":"Machine Learning"}]},{"label":["Name"],"points":[{"start":627,"end":649,"text":"Phaneendra Kumar Gunda "}]},{"label":["Skills"],"points":[{"start":470,"end":498,"text":" Natural \nLanguage Processing"}]},{"label":["Skills"],"points":[{"start":453,"end":468,"text":"Machine Learning"}]}],"extras":null,"metadata":{"first_done_at":1532666676000,"last_updated_at":1532666676000,"sec_taken":161,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Piyush Sharma \nMobile: +91-9654623107\n\nE- Mail: - psharma0908@gmail.com\nIM: -      Piyush.sharma889 (Skype)\n\nDOB: - 09 Aug 1988\nTo work in a dynamic and challenging environment in the domain of Software, where I can blend my skills and knowledge and use the experience obtained to achieve organizational goals and personal growth. And could build a strong foundation for my career at its infancy.\n\nCAREER CONTOUR\n\nSince March 2016 to Present                 Rsystems International Ltd.\n                  \n    Sr. Software Engineer\nRole:\n\n\nSr. Software Engineer.\n\nJob Responsibilities:      Worked on all phase of Software development like design, development , vcs & maintenance.\n                                             the change request we recieve from client, unit testing the code, then pushing code using git.we also work on the the maintenance work given by the client.\nLocation:                         Noida\n\nSince 18 Aug 2014 to Mar. 2016            Rockstand Digital Pvt. Ltd.\n               Sr. Software Engineer\n\nRole:\n\n\nSr. Sofware Engineer.\n\nJob Responsibilities:     Worked on all phase of Software development like design, development , vcs & maintenance. Development of code, unit testing the code pushing code using hg, reviewing the code and leading a team of 4 members.\nLocation:                      New Delhi\n\nSince Feb 2013 to Aug 2014\n                      Primary Modules Inc.                                 Software Engineer\n\nRole:\n\n\nSoftware Engineer \n\nJob Responsibilities:     Worked on all phase of Software development like design, development & maintenance.\n\nLocation:                      Greater Noida\n\nACADEMIC CREDENTIALS\n\n· B.Tech. From R.D Engineering College affiliated to U.P.T.U. Passed Out in 2012 Scored 70 percent marks.\n\n· 12th From Sarvodaya Co-Ed Sr. Secondary School, Anand Vihar, Delhi affiliated to C.B.S.E Board. Passed Out in 2007, Scored 76 percent marks.\n\n· 10th From St. Mary’s Convent School, Ghaziabad affiliated to I.C.S.E  Board. Passed Out in 2005, Scored 76 percent marks.\n\nIT FORTE\n\n· Specialization: Python, Django == 1.4.8, OpenERP V6.0, V6.1, V7.0\n· Operating System: Linux, Mac, Windows\n\n· Markup Languages: HTML, XML\n\n· Scripting Languages: JavaScript, Jquery\n\n· IDES: Eclipse, Pycharm, Komodo, Gedit, Vim, Netbeans\n\n· Database: MySQL, PL/Sql, Mongodb\n\n· Version Control Systems: hg, GIT, SVN\n\n· Servers:  AWS (EC2), Apache, Netmagic\n\nWORKING PROJECT\n\nApplication Available on Play Store:\n\nTitle:\n\n\nIPTV( April 2016 to present)\nCompany:\n\nR systems International Ltd.\nTechnology:                   Python,xml \nDescription:                 Internet Protocol television (IPTV) is a system through which television services are delivered using the Internet protocol suite over a packet-switched network such as a LAN or the Internet, instead of being delivered through traditional terrestrial, satellite signal, and cable television formats. Unlike downloaded media, IPTV offers the ability to stream the media in smaller batches, directly from the source. As a result, a client media player can begin playing the data (such as a movie) before the entire file has been transmitted. This is known as streaming media.\nTitle:\n\n\nTAG ( March 2016 to April 2016)\nCompany:\n\nJaarwis Labs Ltd.\n\nTechnology:                   Django 1.7, Python\nApplication link:\nhttp://www.tag.care/\n\nDescription:                 TAG is a Global Real-Time Location Identification device – all that means is that                                                                                 it keeps an eye on what matters most to you. From your little ones after school, your elderly parents alone in retirement, to your suitcase whilst traveling. Look after them with TAG – from anywhere, at any time!\n\nTitle:\n\n\nRockstand mLearning App ( Aug 2014 to March 2016)\n\nCompany:\n\nRockstand Digital Pvt. Ltd.\n\nTechnology:                   Django 1.4.8, Python\nApplication link:\nhttps://play.google.com/store/apps/details?id=com.handygo.rockasap&hl=en\n\nDescription:                 Rockstand is the only marketplace for Test preparation community in the world. Our focus is on providing quality Test Prep material only from authentic sources. We                                                                                                                                                                                  \nprovide all magazines, Books ,newspapers and flashcards too.\nTitle:\n\n\nRockstand Website ( Aug 2014 to Mar 2016)\n\nCompany:\n\nRockstand Digital Pvt. Ltd.\n\nTechnology:                   Django 1.4.8, Python, HTML 5, CSS3, Javascript\nApplication link:\nhttps://www.rockstand.in/\nDescription: \n\nIt is a showcase of our Rockstand application work for users feedback, showcasings. Blogs and other internal purposes.\n\nTitle:\n\n\nMaaxframe (Apr 2014 to Aug 2014)\n\nCompany:\n\nPrimary Modules Inc.\n\nTechnology:                   PHP ,Mysql, javascript.\n\nApplication link:\nwww.maaxframe.com\n\nDescription:\n            It is an CRM,ERP,Customer Application Platform which provides all in one solution.\n\nTitle:\n\n\nPhoneGap Apps(IOS,Android,Windows) ( Feb 2014 to Apr 2014)\n\nCompany:\n\nPrimary Modules Inc.\n\nTechnology:                   PhoneGap,HTML5,CSS\n\nApplication link:\nhttp://android4samsung.com/Download-Android_MaaxFrame_for-Samsung.html\nDescription:                 This is the App which is built in order to support our ERP,Maaxframe\n\nTitle:\nDelivery Carriers and Spots Computation( Oct 2013 to Feb 2014)\n\nCompany:\n             Primary Modules Inc.\n\nTechnology:                   ERP(Python,Psql)\n\nApplication link:\nhttps://ww.cubep.com\n\nDescription: \n            This is the ERP project which helps in delivering and\n\n                                       computation of all the expenses involved in it.\n\nTitle:\n\n\nCuBEp Plastic ERP( Feb 2013 to Oct 2013)\n\nCompany:\n\nPrimary Modules Inc.\n\nTechnology:                   OpenERP(Python,Psql)\n\nApplication link:\nhttps://erp.cubep.com\n\nDescription                 This is ERP software for Cubep Plastics company based in Canada,\n\n                                   We build following modules for this company.Warehouse, Manufacturing,\n\n                                   Sales, Purchase, HR, Accounting\n\nMy Technical Projects\n\n· Project of “Installation of Campus Wide Network” in which . we have established a network consisting\n\n      of 100 nodes (approx.) in which TCP/IP protocol suit was made and Enterprise Level Anti Virus Solution to       \ntest the different modules, while doing Internship in BHEL India.\n\n· Academic project deals with the online property application. The application. Deals with sailing,buying of property anywhere in Delhi, NCR with 5-10% part of the margin will comes as the profit.ind\n\nACHIEVEMENTS & AWARDS\n\n· Certified Python Developer\n\n· Team Lead a team of 5 members\n\n· Development of new functionality, unit testing and UI modifications.\n\n· Development of new modules.\n\n· Client support, demos and documentation related to my expertise.\n\n· System integration , testing and deployment on live server.\n\n· Participate in client interaction and understanding the user-case and extraction of product - backlogs\n\nSNAPSHOT\n\n· Ability in learning new concepts quickly, working well under pressure and communicating ideas.\n\n· Keen interest in developing and maintaining the mobile projects.\n\n· Self motivated and a good team player, with excellent interpersonal skill.\n\nPERSONAL DOSSIER\n\nName                            : Piyush Sharma\n\nFather Name                  : Mr. Rajveer Sharma\n\nMother Name                 : Mrs. Usha Sharma\n\nDate of Birth \n\n: 09 Aug, 1988\nCorresponds Address\n: Plot no. 271, G-1, Gyan Khand-1, Indirapuram,Ghaziabad\n\nLanguages Known \n: English, Hindi , Spanish\n\nI hereby declare that the above-mentioned information is true to the best of my knowledge.\n\nDate:                                                                                                             Piyush sharma","annotation":[{"label":["Location"],"points":[{"start":7659,"end":7667,"text":"Ghaziabad"}]},{"label":["Skills"],"points":[{"start":6750,"end":6755,"text":"Python"}]},{"label":["Skills"],"points":[{"start":5878,"end":5883,"text":"Python"}]},{"label":["Skills"],"points":[{"start":5534,"end":5539,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4558,"end":4563,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4544,"end":4549,"text":"Django"}]},{"label":["Skills"],"points":[{"start":3892,"end":3897,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3878,"end":3883,"text":"Django"}]},{"label":["Skills"],"points":[{"start":3297,"end":3302,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3285,"end":3290,"text":"Django"}]},{"label":["Skills"],"points":[{"start":2570,"end":2575,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2398,"end":2405,"text":"Netmagic"}]},{"label":["Skills"],"points":[{"start":2390,"end":2395,"text":"Apache"}]},{"label":["Skills"],"points":[{"start":2379,"end":2387,"text":"AWS (EC2)"}]},{"label":["Skills"],"points":[{"start":2077,"end":2082,"text":"Django"}]},{"label":["Skills"],"points":[{"start":2069,"end":2074,"text":"Python"}]},{"label":["Location"],"points":[{"start":1955,"end":1963,"text":"Ghaziabad"}]},{"label":["Education"],"points":[{"start":1667,"end":1672,"text":"B.Tech"}]},{"label":["Name"],"points":[{"start":0,"end":13,"text":"Piyush Sharma "}]}],"extras":null,"metadata":{"first_done_at":1532691127000,"last_updated_at":1532691127000,"sec_taken":155,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Poornima Sridhar\n          \n\n\n\n\n\n\n\n\n\n________________________         \nProfile\n\n· Highly-skilled Software professional bringing in 11 years of experience in Software Design & Development.\n\n· Excellent Technical & Leadership skills.\n\n· Extensive experience in  analysis, design, development, customizations and implementation of software applications\n\n· Worked in Cloud, Cognitive, Mobile & Mainframe Projects.\n\n· Experience in Leading Technical teams. Handled multiple roles such as Team Lead, Developer and RACF Administrator\n\n· Executed software projects for IBM Human Resource and Finance Accounts\n\n· Good communication skills, interpersonal skills, self-motivated, quick learner, team player.\n\nSkills Tools:\n\nAngular, Python, Node.js, C, JAVA, HTML, IBM Bluemix, COBOL, PL/I, AWS, Containers,\nJCL, DB2 (IBM Certified DBA), IMS, Cloudant (NoSQL DB), Git, RTC, Eclipse, Maven, Websphere, Jenkins, IBM Watson\nProcesses:\n\nAgile Methodology, Rational Team Concert, Waterfall Methodology, SDLC \n\nTSRM, Manage Now, Service Now (Change & Problem Management)\n\nCloud POC (Proof of Coding)\n\nUpload files to Object Storage on Bluemix:\n\nCreated an API to upload any kind of file into Bluemix Object Storage using Nodejs. This URL can be used to store files and download them at per user’s convenience from Cloud.\n\nInsert records into DashDB using Nodejs\n\nCreated an API to insert records into the DashDB on Bluemix using Nodejs. There are lots of options available in DashDB to load data but to load data row by row is unique and this application can be used in real time application. This is a pilot code that I have coded and implemented using Nodejs and Bluemix.\n\nProfessional Experience\n\nMay 17 – Till Date          \n\nDesignation:  Technical Team Lead      \n\nProject Name: Business Partner \n\nOrganization:  IBM India Pvt. Ltd. India\n\nBusiness Partner migrating for Lotus notes to Bluemix. There are 5 major Lotus notes forms used by the Business Partner which we be moved to Bluemix. The application is coded on Advanced Angular. Node.js, Cloudant (No SQL) & DB2.\n\nMy Role:\n\n· As a Lead developer I lead the team and work on complicated Stories.\n\n· Implemented CI/CD for our application.\n\n· Deliver new and complex high quality solutions to clients in response to varying Business requirements\n\n· Responsible for managing scope, planning, tracking, change control, aspects of the Project\n\n· Responsible for effective communication between the project team and the customer. Provide day to day direction to the project team and regular project status to the customer\n\n· Translate customer requirements into formal requirements and design documents, establish specific solutions, and leading the efforts including programming and testing that culminate in client acceptance of the results\n\n· Utilize in-depth knowledge of functional and Technical experience and other leading-edge products and technology in conjunction with industry and business skills to deliver solutions to customer\n\n· Establish meets quality goals Quality Procedure for the team and continuously monitor and audit to ensure team \nEnvironment:   Angular, Nodejs, JavaScript, Cloudant (NoSQL), DB2 \nTeam Size:   5 \n\nSep 11 – May 2017          \n\nDesignation:  Technical Team Lead      \n\nProject Name: Travel @ IBM \n\nOrganization:  IBM India Pvt. Ltd. India\n\nTravel@IBM is a world class, integrated Travel and Expense for IBM using the Concur Cloud based SAAS solution. It operates on one global platform and supports 10 different languages. This tool is a replacement for WWER (World Wide Expense Reimbursement) tool.\n\nTravel Bot is a Web application used to provide feedback about the Travel@IBM. This tool is currently used across IBM and by Leaders to understand the request flow and the status of each and every request .Travel @IBM is a new tool and the focus is on resolving the queries quickly and efficiently. \n\nMy Role:\n\nAs a Technical Lead responsible for Analysis, design, development, testing and implementation of customized solutions for new Development and enhancement work.\n\n· Responsible for leading Project team in delivering solution to customer.\n\n· Deliver new and complex high quality solutions to clients in response to varying Business requirements\n\n· Responsible for managing scope, planning, tracking, change control, aspects of the Project\n\n· Responsible for effective communication between the project team and the customer. Provide day to day direction to the project team and regular project status to the customer\n\n· Translate customer requirements into formal requirements and design documents, establish specific solutions, and leading the efforts including programming and testing that culminate in client acceptance of the results\n\n· Utilize in-depth knowledge of functional and Technical experience and other leading-edge products and technology in conjunction with industry and business skills to deliver solutions to customer\n\n· Establish meets quality goals Quality Procedure for the team and continuously monitor and audit to ensure team \n\nEnvironment:   Python, Nodejs, JavaScript, Angular, Watson, ZOS DB2, REXX, MQ, JCL\n\nTeam Size:   5 \n\nOct 2016 – Jan 2017 \n\nDesignation: Data Analytic        \n\nProject Name: Cognitive Recommendation Engine (CORE)  \n                                                                    Organization:  IBM India Pvt. Ltd. India\nChief Analytics Office and IBM Research have launched a joint initiative to build and deploy best-of-breed Cognitive Recommendation Engine.\n\nI worked as a Data Analyst and did annotation for Banking Solution, we used the IBM Watson Knowledge Studio tool.\n\nJul 08 – Sep 11\n\nDesignation:  Application Developer      \n\nProject Name: Financial Information warehouse\n\nOrganization:  IBM India Pvt. Ltd. India               \n\nFIW-MC/LR (Financial Information Warehouse Mega Center / Ledger Reporting) is an Information Warehouse. It receives financial data from the ledger system, FDW (Financial Data Warehouse) and non-financial reference data from other sources. FIW-MC/LR will process this data (combining, enriching, summarizing, etc.) to provide a reliable and accurate reporting environment separate from the operational ledger environment (CLS-FDW). FIW-MC/LR EMEA sends accounting close this is at the end of each month, enriched financial data to FIW-C, the corporate counterpart of FIW-MC/LR.\n\nMy Role\n\n· Work with the Client in understanding the requirement and be instrumental in delivering the requirement in the most optimized way\n\n· Create Internal design document\n\n· Work in translating Business requirements into Functional Requirement\n\n· Perform extensive coding and unit testing.\n\n· Work on test system and Production support\n\n· Work with QA to create test scripts and scenarios for enhancements and customization to the core product\n\n· Communicate activities/progress to project managers, business development, business analysts and clients\n\n· Develop implementation and test plans, build software acceptance criteria, coordinate and work with clients to\n\n· oversee the acceptance and dissemination process\n\nEnvironment:   ZOS, DB2, REXX, MQ & JCL\n\nTeam Size:  6\n\nJan 06 – Jul 08\n\nDesignation:  RACF Administrator \n\nOrganization: IBM India Pvt. Ltd. India\n\nThe RACF Administrator is responsible for the Security and Compliance management of the MVS systems. My role was to administer IBM EMEA location.\n\nMy Role \n\n· Managed all the 100 MVS systems alone.\n\n· Create, modify, maintain & delete user Profile\n\n· Run regular batches for compliance check and take necessary action.\n\n· Worked on German Secure system to maintain the security and compliance.\n\nEnvironment: JCL, REXX, DB2 & IMS\n\nTeam Size: 1\n\nCertification & Training:\n\n· Completed Cloud Developer training. Received a Cloud Developer badge for the same\n\n· Bluemix Garage Workshop\n\n· Preparing for the TOGAF IT Architect Certification\n\n· 730 - IBM Certified Database Associate - DB2 9 Fundamentals\n\n· 733 - IBM DB2 9 Application Developer\n\n· 732- IBM Certified Database Administrator for Z/OS V9\n\n· 041- IBM Certified Application Developer - Programming with IBM Enterprise PL/I\n\n· 042-Developing with IBM Enterprise PL/I\n\nEducation:\n\nBachelor of Science: Electronics & Communication 2006\n\nVisvesvaraya Technological University (SAIT) – Bangalore\n\nMBA: Information Technology 2009\n\nSymbiosis Centre for Distance learning - Distance learning\n\nAchievements:\n\nReceived Manager’s Choice Award \n\nEminence & Excellence Award \nOrion Award \nBravo Award \nCognitive Build Project \n\nWork on CAMSS (Cloud Analytics Mobile Social Security) initiative for IBM Internal Account and contributed immensely.\n\nDeclaration\n\nI do hereby declare that all the details given above are true to the best of my knowledge and belief.\n\n\n\n\nEmail: � HYPERLINK \"mailto:poornima.sridhar1@gmail.com\" ��poornima.sridhar1@gmail.com�\t\n\nPhone No: +91-9945145549\n\nAddress: #665,25th Cross, 9th Main, 7th Sector, HSR Layout, Bangalore -560102\n\n\n\n\n\n#","annotation":[{"label":["Location"],"points":[{"start":8921,"end":8929,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":8880,"end":8880,"text":"C"}]},{"label":["Skills"],"points":[{"start":8523,"end":8523,"text":"C"}]},{"label":["Skills"],"points":[{"start":8516,"end":8516,"text":"C"}]},{"label":["Skills"],"points":[{"start":8482,"end":8482,"text":"C"}]},{"label":["Skills"],"points":[{"start":8412,"end":8412,"text":"C"}]},{"label":["Skills"],"points":[{"start":8328,"end":8328,"text":"C"}]},{"label":["Education"],"points":[{"start":8284,"end":8286,"text":"MBA"}]},{"label":["Location"],"points":[{"start":8273,"end":8281,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":8206,"end":8206,"text":"C"}]},{"label":["Skills"],"points":[{"start":8044,"end":8044,"text":"C"}]},{"label":["Skills"],"points":[{"start":7987,"end":7987,"text":"C"}]},{"label":["Skills"],"points":[{"start":7946,"end":7949,"text":" DB2"}]},{"label":["Skills"],"points":[{"start":7914,"end":7917,"text":" DB2"}]},{"label":["Skills"],"points":[{"start":7884,"end":7884,"text":"C"}]},{"label":["Skills"],"points":[{"start":7857,"end":7857,"text":"C"}]},{"label":["Skills"],"points":[{"start":7755,"end":7755,"text":"C"}]},{"label":["Skills"],"points":[{"start":7718,"end":7718,"text":"C"}]},{"label":["Skills"],"points":[{"start":7708,"end":7708,"text":"C"}]},{"label":["Skills"],"points":[{"start":7679,"end":7679,"text":"C"}]},{"label":["Skills"],"points":[{"start":7653,"end":7656,"text":" DB2"}]},{"label":["Skills"],"points":[{"start":7644,"end":7644,"text":"C"}]},{"label":["Skills"],"points":[{"start":7643,"end":7645,"text":"JCL"}]},{"label":["Skills"],"points":[{"start":7436,"end":7436,"text":"C"}]},{"label":["Skills"],"points":[{"start":7294,"end":7294,"text":"C"}]},{"label":["Skills"],"points":[{"start":7241,"end":7241,"text":"C"}]},{"label":["Skills"],"points":[{"start":7175,"end":7175,"text":"C"}]},{"label":["Skills"],"points":[{"start":7123,"end":7123,"text":"C"}]},{"label":["Skills"],"points":[{"start":7122,"end":7124,"text":"JCL"}]},{"label":["Skills"],"points":[{"start":7105,"end":7108,"text":" DB2"}]},{"label":["Skills"],"points":[{"start":6814,"end":6814,"text":"C"}]},{"label":["Skills"],"points":[{"start":6506,"end":6506,"text":"C"}]},{"label":["Skills"],"points":[{"start":6387,"end":6387,"text":"C"}]},{"label":["Skills"],"points":[{"start":6355,"end":6355,"text":"C"}]},{"label":["Skills"],"points":[{"start":6318,"end":6318,"text":"C"}]},{"label":["Skills"],"points":[{"start":6220,"end":6220,"text":"C"}]},{"label":["Skills"],"points":[{"start":6205,"end":6205,"text":"C"}]},{"label":["Skills"],"points":[{"start":6028,"end":6028,"text":"C"}]},{"label":["Skills"],"points":[{"start":5832,"end":5832,"text":"C"}]},{"label":["Skills"],"points":[{"start":5789,"end":5789,"text":"C"}]},{"label":["Skills"],"points":[{"start":5471,"end":5471,"text":"C"}]},{"label":["Skills"],"points":[{"start":5364,"end":5364,"text":"C"}]},{"label":["Skills"],"points":[{"start":5247,"end":5247,"text":"C"}]},{"label":["Skills"],"points":[{"start":5214,"end":5214,"text":"C"}]},{"label":["Skills"],"points":[{"start":5121,"end":5121,"text":"C"}]},{"label":["Skills"],"points":[{"start":5120,"end":5122,"text":"JCL"}]},{"label":["Skills"],"points":[{"start":5104,"end":5107,"text":" DB2"}]},{"label":["Skills"],"points":[{"start":5084,"end":5090,"text":"Angular"}]},{"label":["Skills"],"points":[{"start":5056,"end":5061,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3404,"end":3404,"text":"C"}]},{"label":["Skills"],"points":[{"start":3397,"end":3397,"text":"C"}]},{"label":["Skills"],"points":[{"start":3156,"end":3159,"text":" DB2"}]},{"label":["Skills"],"points":[{"start":3139,"end":3139,"text":"C"}]},{"label":["Skills"],"points":[{"start":3110,"end":3116,"text":"Angular"}]},{"label":["Skills"],"points":[{"start":2159,"end":2159,"text":"C"}]},{"label":["Skills"],"points":[{"start":2156,"end":2156,"text":"C"}]},{"label":["Skills"],"points":[{"start":2053,"end":2056,"text":" DB2"}]},{"label":["Skills"],"points":[{"start":2034,"end":2034,"text":"C"}]},{"label":["Skills"],"points":[{"start":2025,"end":2031,"text":"Node.js"}]},{"label":["Skills"],"points":[{"start":2016,"end":2022,"text":"Angular"}]},{"label":["Skills"],"points":[{"start":1346,"end":1346,"text":"C"}]},{"label":["Skills"],"points":[{"start":1297,"end":1297,"text":"C"}]},{"label":["Skills"],"points":[{"start":1128,"end":1128,"text":"C"}]},{"label":["Skills"],"points":[{"start":1075,"end":1075,"text":"C"}]},{"label":["Skills"],"points":[{"start":1063,"end":1063,"text":"C"}]},{"label":["Skills"],"points":[{"start":1055,"end":1055,"text":"C"}]},{"label":["Skills"],"points":[{"start":1025,"end":1025,"text":"C"}]},{"label":["Skills"],"points":[{"start":990,"end":990,"text":"C"}]},{"label":["Skills"],"points":[{"start":955,"end":955,"text":"C"}]},{"label":["Skills"],"points":[{"start":860,"end":860,"text":"C"}]},{"label":["Skills"],"points":[{"start":832,"end":832,"text":"C"}]},{"label":["Skills"],"points":[{"start":811,"end":811,"text":"C"}]},{"label":["Skills"],"points":[{"start":801,"end":804,"text":" DB2"}]},{"label":["Skills"],"points":[{"start":798,"end":798,"text":"C"}]},{"label":["Skills"],"points":[{"start":797,"end":799,"text":"JCL"}]},{"label":["Skills"],"points":[{"start":785,"end":785,"text":"C"}]},{"label":["Skills"],"points":[{"start":767,"end":767,"text":"C"}]},{"label":["Skills"],"points":[{"start":739,"end":739,"text":"C"}]},{"label":["Skills"],"points":[{"start":730,"end":736,"text":"Node.js"}]},{"label":["Skills"],"points":[{"start":722,"end":727,"text":"Python"}]},{"label":["Skills"],"points":[{"start":713,"end":719,"text":"Angular"}]},{"label":["Skills"],"points":[{"start":510,"end":510,"text":"C"}]},{"label":["Skills"],"points":[{"start":370,"end":370,"text":"C"}]},{"label":["Skills"],"points":[{"start":363,"end":363,"text":"C"}]},{"label":["Name"],"points":[{"start":0,"end":15,"text":"Poornima Sridhar"}]}],"extras":null,"metadata":{"first_done_at":1532690190000,"last_updated_at":1532690190000,"sec_taken":239,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Pradeep Kumar MJ                  \n\nMobile:+919741470298\nEmail\nmjpradeep77@gmail.com\nSummary:\n\n· As a Data Scientist I will be Performing quantitative analysis to communicate data driven insights out of structured and  unstructured  data.  Leveraging mathematical techniques and applied statistics with visualization along with healthy sense of exploration. I have completed professional training's in the field of  data science to  have broad  understanding  of the statistical  concepts  which  can be applied to any  use case required\nCareer Path:\n\n· Working as a Senior Software Engineer (SSE) in ACCENTURE in Bangalore from OCT 2010 to till date.\nPROFESSIONAL SUMMARY\n· Having 7 years of experience and working in Artificial Intelligence(IBM Watson, Dialogflow(api.ai), Bluemix DevOps, MongoDB, Node.js, GIT,), Data Scientist using Python(Machine learning, NLP,) and also worked in Doucmentum, eDiscovery tool Autonomy, Legal Matter Management application TeamConnect, IBM Websphere server,Jenkins.\nPROFESSIONAL EXPERIENCE:\n\nPROJECT SUMMARY\nArtificial Intelligence (AI) Capability:\nProject Description:\nAI is an Accenture artificially intelligence team, which is working to create chatbots to all the Accenture clients.\nResponsibilities and Details:\n· Interact with various stake holders with in Accenture and Build Cognitive Use cases by applying Data Mining, Machine Learning and Statistical Techniques. \n\n· Integrated IBM Watson Conversation, Text-To-Speech and Discovery services and created a Watson chatbots for Accenture clients on Bluemix environment.\n· Integrated IBM Watson Conversation and Discovery services and created a HR Watson chatbot.\n\n· Integrated IBM Watson Knowledge studio with NLU and Discovery services.\n· Worked on IBM Watson Visual recognition service.\n· Created java/node.js applications in Bluemix cloud.\n· Created projects in Git and imported code in it.\n\n· Worked on api.ai and created agents.\n· Worked on MongoDB and integrated with chat bots.\n\n· Created Watson utilities in NODE.js programming language.\n\n\nSTARWOOD\n\n\nDescription\nStarwood Hotels and Resorts Worldwide, LLC is a subsidiary of Marriott International. It was one of the world's largest hotel companies that owns, operates, franchises and manages hotels, resorts, spas, residences, and vacation ownership properties under its 11 owned brands. \n\nResponsibilities and Details:\n· Built a personalized, highly intelligent Hybrid hotel Recommender engine model for Starwood hotels.\n· Implemented Twitter sentiment analysis model for Starwood brands.\n\n·  Using K-Means algorithm built a customer segmentation model.\n\n· Created Keyword Extraction model for user reviews data.\n· Used K Means algorithm and built to classify unlabeled emails based on their message body.\n\n· Unsupervised Machine learning models (k-means, hierarchical) on 2 year historical data of IDC projects. \n\n\n\nASTELLAS\n\nProject Description:\nAstellas is a pharmaceutical company dedicated to improving the health of people around the world through the provision of innovative and reliable pharmaceutical products.\n\nResponsibilities and Details:\n\n\n· Created resources like JDBC providers, data sources, JMS resources and Connection factory (QCF name, JNDI name, Host Name, QMGR name, Port Number, Channel Name) at cell, Node, cluster and server levels.\n\n· Deployed various profiles which have EAR, JAR mappings to various environments including Component Integration testing boxes, Staging, QA and Prod environments and ensuring environment readiness for testing after each latest deploys.\n\n· Involved major incidents proactively and worked in Emergency releases in Prod environment.\n Worked closely with testing and development teams to resolve test outages in time there by improving execution turnaround time for their test scenarios.\n\n· Troubleshoot Admin Server start-up issues, Java code defects after deployment and class path issues by checking the JVM logs, plug-in logs and the Webserver logs\n\n· Tracked all CAB changes approved by change advisory board (CAB) and coordinating with concern teams to have the code changes available in all environments.\n\n· Worked on Out-of-Cycle deploys for various environments as an immediate fix to avoid impact for release testing teams and regression testing teams.\n\n· Involved in pre and post maintenance activities for WAS servers coordinating with Midrange server maintenance teams.\n\n· Worked with the scheduler jobs configuration and work mangers configuration\n\n· Good at troubleshooting by analyzing server logs and enabling trace components for further analysis.\n· Provided 100 percent availability as on-call support and delivered continuous support to the customers.\n· Planning, Designing & Documenting Enterprise Archiving Solution (EAS) 6.1.1\n· Perform Technical Support, System Administration, Planning & installation, Network Management of Autonomy Archiving.\n\n· Practice continuous improvement with respect to process development, documentation, maintenance, and adherence to ensure the department aligns with industry best practices.  \n\n· Ensure all escalations and coordination efforts between Service Desk, Desk side and other support teams and vendors are occurring and being reviewed on a regular basis\n\n· Administration & Support of ALH e-discovery for Legal Hold Orders.\n\n· Delegating tasks to subordinates/direct reports as per priority & act as escalation point.\n· Responsible to Co-chair and lead scheduled meetings with key IT partners related to Service Desk services for Autonomy.\n· Work to jointly develop remediation plans for any Service Desk service not meeting or exceeding expected Service Levels.\n· Troubleshooting Enterprise Archive Solution (EAS).\n· Performing PST collection, PST Ingestion and PST Stub migration.\n· Exporting Legal Hold data using EAS storage manager.\n· Performed On boarding/Off-boarding activities for new and terminated employees in Autonomy.\n· Performed active purging of archived data as per Legal directions.\n· Generating reports on User Stats, Message Size per user, and Message Size per reference.\n· Health Check of Autonomy Parent & Child Server, Document Store, SQL Database.\n· Migration of Autonomy users from Exchange 2007 to Exchange 2010 environment.\n· Trained onsite and offshore subordinates on Autonomy system and operational activity as part of project transitioning.\n·  Monitoring Archiving threshold and network utilization.\n· Automating process using Power shell Scripts.\n· Developing Custom Reports using Power Shell, SQL etc.\n· Duly following ITIL Call, Incident, Change and Problem Management.\n· Provided 100 percent availability as on-call support and delivered continuous support to the customers.\n· Deployed various profiles which have EAR, JAR mappings to various environments including Component Integration testing boxes, Staging, QA and Prod environments and ensuring environment readiness for testing after each latest deploys.\nDate: 24/01/2018                                                                                  \n\nPlace: Bangalore                                                                                                Pradeep Kumar MJ","annotation":[{"label":["Name"],"points":[{"start":7132,"end":7147,"text":"Pradeep Kumar MJ"}]},{"label":["Location"],"points":[{"start":7027,"end":7035,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":995,"end":1001,"text":"Jenkins"}]},{"label":["Skills"],"points":[{"start":974,"end":993,"text":"IBM Websphere server"}]},{"label":["Skills"],"points":[{"start":899,"end":922,"text":"eDiscovery tool Autonomy"}]},{"label":["Skills"],"points":[{"start":837,"end":866,"text":"Python(Machine learning, NLP,)"}]},{"label":["Skills"],"points":[{"start":719,"end":772,"text":"Artificial Intelligence(IBM Watson, Dialogflow(api.ai)"}]},{"label":["Location"],"points":[{"start":614,"end":622,"text":"Bangalore"}]},{"label":["Name"],"points":[{"start":0,"end":15,"text":"Pradeep Kumar MJ"}]}],"extras":null,"metadata":{"first_done_at":1532686712000,"last_updated_at":1532686712000,"sec_taken":0,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Praveen Kumar Telugu\n E-mail id: praveenkumar.datascientist@gmail.com    \nPraveen.telugu88@gmail.com         \nMobile: +91-9908762979\nObjective\nLooking forward to make a difference in the gamut of technology. Passionate about Big Data technologies, statistical modeling and design thinking for problem solving.  A machine learning enthusiast.\nProfessional Summary\n\n· Having 3 years of experience in developing variety of software applications and solutions using BigData (MapReduce, Pig, Hive, Oozie, Sqoop) and Java Technologies\n· Developed applications for processing and validation of large amount of data using MapReduce Framework\n\n· Developed applications for  Data statistics and aggregations using Pig Latin and Hive\n· Excellent experience with Databases such as  Oracle, SQL, HBASE\n· Implemented solutions for business using optimize and feasible  Algorithms\n\n· Ability to convert business requirements in to functional and technical specifications.\n\n· Highly flexible and capable of learning new technologies\n\n· Understanding business problem, client requirements and represent the problem in a problem definition\n\n· Framework preparation and analysis of large datasets using data warehousing tools and big data technologies\n\n· Creation of analytical solutions using statistical analysis and machine learning\n\n· Having knowledge over NLP(Natural Language Processing), Deep Learning techniques\n\n· Team player with good interpersonal skills and the ability to work in critical situation\n\nCertifications\n\n· Certified in R programming by Datacamp\n· Cognizant certified professional in Hadoop frame work\n· Has been participating in Kaggle competitions with the id  https://www.kaggle.com/praveenkumartelugu\nWork Experience\n\n· Current Employer: Cognizant Technology solutions(CTS), Hyderabad \n\n· Current Experience: 3 Years \n\n· Total Experience: 3 Years \n\nEducational Qualifications\n\n· B.Tech (Computer Science and Engineering) at JTNU Hyderabad in Sree nidhi Institute of Science and Technology, Yamnampet, Ghatkesar, 2012 with 68.24%\n· HSC from Sri Sai Chaitanya junior college, Ongole, 2007\n· SSC from A.P.Residential School, Mahabubnagar, 2005\nTechnical Skills\n\nProgramming Languages  :\nJava, Python, R, Scala and C\n\nScripting Languages           :     Shell Scripting\nBig Data Technologies        :     Hadoop, MapReduce, Hive, Pig, Oozie, Sqoop and Spark\nOperating Systems\n        :     Linux, windows\nDatabases\n\n        :\n MySQL, Oracle, HBASE\n\nML Algorithms                      :    Classification, Regression, Clustering techniques\n\nVisualizations                        :    Tableu, ggplot, matplotlib\nML Tools                                :    AzureML studio, Notebook (Databricks)  \n\nIDE\n\n\n        :     Eclipse, Rstudio, Anaconda\nVersion Controls\n        :\n SVN, git\nProject Experience\n\nProject #1:\n\nTitle                            :      IM-BA (Information Management and Business Analytics)\n\nClient                         :       Fortune 500 Consulting Firm\n\n\nDuration                    :       July 2016 to Present\n\nAlgorithms                :        ML Algorithms- Naïve Bayes, K-means Clustering, SVM, Decision Trees,   \n\n                                             NLP (Natural Language Processing), Deep Learning Techniques \nTechnologies             :       Python, R, Azure ML Studio                                  \nPlatform                    :       Windows, Linux \n\nDescription:\n\nClient is one of the world's leading management consulting firms. It works with top executives to help them make better decisions, convert those decisions to actions and deliver the sustainable success they desire. For more than 40 years, has been passionate about achieving better results for their clients—results that go beyond financial and are uniquely tailored, pragmatic, holistic and enduring\nResponsibilities:\n\n· Designed and developed data model for applying the Machine learning algorithms\n· Analyzed the data sets and imported necessary libraries to work upon\n· Preprocessed the data by importing ‘sci-kit learn’ and ‘Caret’  packages in python and R respectively and used the necessary modules for  feature scaling and encoding the categorical data\n\n· Built the models  using  ‘Gretl’ (GNU, Regression, Econometrics, Library) an open source library \n\n· Applied Naïve Bayes, Support Vector Machines(SVM) and Decision tree algorithms for classification  \n\n· Applied K-means clustering for customer segmentation\n\n· Created Bag of words model for analyzing the text documents in Natural Language Processing\n· Sentiment analysis of the tweets on Demonetization in India\n\n· Applied Artificial neural networks and convolutional neural network techniques on the datasets in Deep Learning\n\n· Visualize the trained and test models using the matplotlib and ggplot packages \n\n· Compared the different algorithms based on the accuracy of trained and test models\n\n· Improved the performance of algorithms using the parameters optimization , kernels specification\n\nProject #2:\n\nTitle                            :      RAMP (Rapid Analytics & modeling Platform) (SAS-to-Hadoop)\n\nClient                         :       American Express\n\n\nDuration                    :       March 2016 to July 2016\nTechnologies            :       Hadoop (Hive, MapReduce, Oozie, Spark), Shell scripting and Java\nPlatform                    :       Windows, Linux \nDescription:\nRapid Analytics & Modeling Platform (RAMP) is used by power users for ad hoc analysis and model development. It deals with all types of Amex cards transactions information captured from multiple vendors who are authorized users of Amex. Implemented all the SAS model functionalities in Hadoop Eco System with Hive and Oozie components. \nResponsibilities:\n\n· Developed SAS model functionality in Hadoop using Hive Scripts.\n· Developed Extraction Framework in java to extract data from cornerstone warehouse.\n· Automated the Hive framework to create tables for the extracted feeds on daily/weekly and scheduled basis.\n· Validating the Processed data by capturing the results through hive tables and comparing with the SAS results.\n· Developed Custom UDF’s for Hive.\n· Scheduled Hive scripts through Oozie.\nProject #3:\n\nTitle                            :      BlueLight Migration Project (SQL Server-to-Hadoop)\nClient                         :       American Express\n\n\nDuration                    :       August 2015 to March 2016\nTechnologies            :       Hadoop (PIG, Hive, MapReduce, Shell scripting, Oozie) \nPlatform                    :       Windows, Linux\nDescription:\nThe objective for BlueLight Migration Project is to replicate the SQL Server functionality into the Hadoop Eco System. By utilizing the Hadoop components like Pig, Hive and Oozie. It is dealing with credit card holders and their usage of reward points and usage of benefits provided by the American Express.\nResponsibilities:\n\n· Convert the SQL Server stored procedures into the pig scripts.\n· Data Profiling for the raw data from Source System (IDN).\n· Developed Custom UDF’s for Pig and Hive.\n· Validating the Processed data through pig by creating hive external tables for every script and comparing the results with SQL Server output.\n· Data storage and processing in MapR environment\n· Scheduled Pig and Shell scripts through Oozie.\n· Data visualization using tableau.\nProject #4:\n\nTitle                            :      Premium Benefits\n\nClient                         :       American Express\n\n\nDuration                    :       April 2015 to July 2015\n\nTechnologies            :       Hadoop (PIG, Hive, MapReduce, Shell scripting, Oozie) and Java\n\nPlatform                    :       Windows, Linux\n\nDescription:\nThe objective for Premium Benefits project is to help American Express Business team to visualize the usage behaviour of different benefits that are applicable to Premium Credit Card holders. Premium Credit card holders means Customers who have either PLATINUM Credit Card or CENTURION Credit Card.\nResponsibilities:\n\n· Data Profiling for the raw data from Source System (CMDL).\n· Developed Pig scripts for every Benefit that is provided by the AMEX.\n· Testing the Processed data through pig by creating hive external tables for every script.\n· Data storage and processing in MapR environment.\n· Scheduled Pig and Shell scripts through Oozie.\n· Data Visualization done through tableau.\nProject #5:\n\nTitle                            :      Talcott Resolution\nClient                         :       The Hartford\n\n\nDuration                    :       May 2014 to April 2015\n\nRole                            :        ETL Developer\nTechnologies            :       Oracle Warehouse Builder(OWB), SAP BO(XIR 3.1) ,Oracle 11g\n\nPlatform                    :       Windows, Unix\nClient Description:\nThe Hartford Financial Services Group, Inc., usually known as The Hartford, is a United States-based investment and insurance company that is part of the Fortune 500 list. Headquartered in Hartford , Connecticut.\n The primary objective of the Talcott IM Team is to help provide an integrated data platform and a comprehensive environment that delivers timely information without any data issues .The business customers would like to get more data, delivered quicker – without having any inconsistencies to allow them to make more informed decisions. The IM team helps leverage the information asset to users of systems, including but not limited to, Vista, Mutual Funds, Wealth Management  and Individual Life Sales.\nResponsibilities:\nProduction Support: Production support involves tasks including the batch monitoring, resolving failures in the batch and incident analysis that raised in conjunction with data miss-matches\n\n \n\nApplication Enhancement: This involves enhancement tasks that are required for a successful batch run as per the SLA. Enhancements includes regulatory and break-fix trackers that will be created in conjunction with the batch failures which is not due to data errors.\n\n \n\nApplication Development: This includes development of new project when new business functionality is added to business. Involved in OWB (Oracle Warehouse Builder) migration to PL/SQL .Converted 106 OWB mappings to PL/SQL packages which includes testing of the mappings\n\nPersonal Information\n\nDate of Birth\n\n: 05-05-1990 \n\nMarital status\n\n: Single \n\nLanguages known\n: Telugu, English\nNationality\n\n: Indian \n\nDeclaration\n\nI do hereby declare that the information furnished above is true to the best of my knowledge and brief.\n\n                                                                                                                PRAVEEN KUMAR TELUGU","annotation":[{"label":["Location"],"points":[{"start":1938,"end":1947,"text":"Hyderabad "}]},{"label":["Education"],"points":[{"start":1888,"end":1893,"text":"B.Tech"}]},{"label":["Location"],"points":[{"start":1784,"end":1793,"text":"Hyderabad "}]},{"label":["Skills"],"points":[{"start":1376,"end":1399,"text":"Deep Learning techniques"}]},{"label":["Skills"],"points":[{"start":1342,"end":1373,"text":"NLP(Natural Language Processing)"}]},{"label":["Skills"],"points":[{"start":1300,"end":1315,"text":"machine learning"}]},{"label":["Skills"],"points":[{"start":462,"end":468,"text":"BigData"}]},{"label":["Skills"],"points":[{"start":313,"end":328,"text":"machine learning"}]},{"label":["Name"],"points":[{"start":0,"end":19,"text":"Praveen Kumar Telugu"}]}],"extras":null,"metadata":{"first_done_at":1532677271000,"last_updated_at":1532677271000,"sec_taken":89,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Udaya Laxmi Ch\n\nEmail : laxmi.udaya@gmail.com\n\n\t\n\n\tPhone: -9740606990\n\t\n\n\n\tSummary\n\n\t· 9.5 years of experience in Software Development.\n· 3.5 years of experience in Machine Learning\n· Primary Skills – Machine Learning, R programming, Lotus Notes.\n· Presently working for Wipro Technologies, Bangalore.\n· Experience in planning, estimation, design, development, and testing object oriented applications.\n· Experience in preparing various technical documents like Functional Specs, HLD, LLD, Flowcharts and Test cases.\n· Sound Knowledge in Object Oriented Design Principles\n· Have Team Handling experience.\n· Domain experience of Manufacturing and Finance.\n· Have Experience in Scrum Agile Model\n· Understand business requirements from clients\n\n\n\n\tTechnical Skills\n\n\tKey skills: \n\tMachine Learning,R Programming, MySQL, PostgreSQL, Microsoft Access, SQL Server, FileMaker, Oracle, RDBMS, dBASE, Clipper, FoxPro, Firebase, Mongodb, Python,  ava, J2EE, Oracle Fusion,Oracle Cloud, Salesforce, Devops Android, Business Analyst, UI Developer, DBAs, Embedded Systems, .NET, Hadoop, SQL Developer, Big Data, Tableau, Networking, Etl, Informatica, Ios, Quality Analyst, Project Manager, Python, Data Science, Python, Machine Learning, SAS, Java, Scala, Hadoop, Hive, Bigdata, Programming, SQL server reporting, Msbi Ssis, Ssrs, Msbi, Sql Reporting, Artificial Intelligence, Pandas, Pyspark, Sklearn, Flask, Django, Map Reduce, Parametric Design, Modeling, Regression, Patterns, Data Mining, Text Mining, Oops, Deep Learning, Web Analytics, Time Series, Regression, Tensorflow, Azure, Linear Regression, Logistic Regression, Decision Tree, Random Forest, Data Structure, Computer Vision, IHS, WAS, Java EE, SQL Server, .NET core, C#, ASP.NET, Rdlc, Linq, Sql, Web Api, Mvc, Javascript, Web Services, Oracle, MS SQL, PHP, Laravel, CodeIgniter, Symfony, Zend, Phalcon, CakePHP, Yii, FuelPHP, React, Vue, Angular, Ember, Backbone, Lotus Notes\n\n\tAlgorithms:\n\tNaïve Bayes, K means clustering,Word Cloud\n\n\tDatabases: \n\tMicrosoft SQL, Mongo DB\n\n\tWeb Technologies: \n\tXML, XSLT, HTML,  JavaScript,  AJAX, JQuery\n\n\tIDE:\n\tR studio,Pycharm\n\n\n\tProfessional Experience\n\n\tCurrent Employer :\n\tWipro Technologies., Bangalore  – (Oct  2010  to till date) – Technical Lead/Data Scientist\n\n\tPrevious Employers :\n\tHSBC Software development , Hyderabad (June  2008  to Sep 2010)  - SE\n\n\n\tQualification\n\n\tDegree\n\tCollege\n\tUniversity/Board\n\tYear\n\tPercentage (%)\n\n\tMCA\n\tNizam College, Basheerbagh,Hyderabad\n\tOsmania University\n\t2008\n\t75\n\n\n\tProject Experience \n\n\tProject 1 : Exploratory Data Analysis:\n\nProject Description:   Performed EDA analysis to analyze the Purchase frequency of vehicles which occurred over past 3 years and try to predict the frequency occurring in the future.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Performed EDA analysis to find the insights of the data. Observed the summary of each and every variable to understand the variables.\n\n· Performed the feature selection using hypothesis testing.\n\n· Identified the outliers using box plot.\n\n· Identified the trend in the purchases using histogram.\n\n\n\n\tProject 2: Word Cloud Analysis:\n\nProject Description:   Performed Word cloud and Sentimental Analysis of the customer feedbacks. Graphically represented the most frequently occurred words through Word cloud. Through sentimental analysis we identified whether a user-generated text expresses positive, negative or neutral opinion.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Created a Corpus using TM package and performed pre-processing of data.\n\n· Removed the punctuations, stemming and stop words which are of no analytical value.\n\n· Built a Document term matrix and identified the most frequently occurring words\n\n· Graphically represented it using  RColorbrewer Package\n\n\n\tProject 3: Sentimental Analysis:\n\nProject Description: Performed Sentimental Analysis of customer feedbacks through Naïve Bayes. Used “e1071” Package for implementing naïve Bayes method.\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· The DTM created using TM package was an input to the Naive Bayes Model.\n\n· As Naive Bayes classifier is typically trained on data with categorical features. We have converted the count of the words into a factor variable that indicates Yes or No whether the word is present or not.\n\n\tProject 4: Clustering Analysis:\n\nProject Description: Classified the customers on the basis of their purchases whether they have purchased low variant or high variant trucks. It in turn helped in building the right customer strategies.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Performed data preparation and Normalization of data using min-max method.\n\n· As K-means algorithm groups a dataset into a user-specified number (k) of clusters. Identified the initial cluster centroids as 3.\n\n· K clusters are creating by associating every observation with the nearest mean.\n\n· Used elbow method to validate the number of clusters such that within-cluster sum of square(wss) is minimized.\n\n\n\n\tProject 5 : Inter Connection Management Tool\nProject Description: Inter-connection Management (IMT) is prototype being developed for Engineering and Sales department to handle customizations of an existing product based on the customer's requirement. Users from engineering department will identify the items, which need to be customized out of the entire product design.\nRole\n\n       : Module Lead\n\nEnvironment\n       : Python, Mongo DB, jQuery\n\nTasks handled:\n\n· Gathering Requirements and providing Project Plan and Effort Estimation details.\n\n· Understanding business requirements and preparing SoU (Statement of Understanding) and Functional/Technical Specification documents.\n\n· Providing Effort & Resource estimations\n\n· Planning for application development and deployment\n\n· Writing and executing Test Cases and Test scenarios\n\n· Creating design elements using Technical Specification.\n\n· Performing Unit testing & Peer Reviews\n\n· Work Allocation and mentoring the team\n\n· Providing Technical guidance to the team. \n\n\tProject 6\n: cvdAEI Application\n\nProject Description\n     : CVDAEI is a web based multilingual application developed for handling the Change Management process in Truck division of Daimler. The change request flows through different phases mainly Initialization, Evaluation, Decision and Conclusion. This application has a configurable workflow where the request flow and the responsible persons can be configured easily at any point of time. \n\nRole\n\n    : Developer/Tester\n\nEnvironment\n     : Lotus Notes, Java, HTML, XML, Java Script, JQuery\n\nTasks handled:\n\n· Gathering Requirements and providing Project Plan and Effort Estimation details.\n\n· Understanding business requirements and preparing SoU (Statement of Understanding) and Functional/Technical Specification documents.\n\n· Providing Effort & Resource estimations\n\n· Planning for application development and deployment\n\n· Writing and executing Test Cases and Test scenarios\n\n· Creating design elements using Technical Specification.\n\n· Performing Unit testing & Peer Reviews\n\n· Work Allocation and mentoring the team\n\n· Providing Technical guidance to the team. \n\n\n\n\tProject Title: Project Management Office \nProject Description: The purpose of this system is to enable the Project Management Office to manage and execute the IT Applications and Operations driven project tasks in  more systematic manner. It will also enable them to efficiently perform a role as a facilitator to coordinate various IT Operations teams and to ensure that project activity enters the department through one common interface. The project tasks will subsequently be dealt with in a common format and in a consistent and appropriate manner, ensuring open and regular communication between all involved parties.\n\nRole\n\n    : Developer/Tester\n\nEnvironment\n     : Lotus Notes, Java, HTML, XML, Java Script, JQuery\n\nTasks Handled :\n\n· Writing and Executing Test cases in client server based environment\n· Individually provided application support","annotation":[{"label":["Skills"],"points":[{"start":7951,"end":7956,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":7938,"end":7948,"text":"Java Script"}]},{"label":["Skills"],"points":[{"start":7933,"end":7935,"text":"XML"}]},{"label":["Skills"],"points":[{"start":7927,"end":7930,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":7921,"end":7924,"text":"Java"}]},{"label":["Skills"],"points":[{"start":7908,"end":7918,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":6645,"end":6650,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":6632,"end":6642,"text":"Java Script"}]},{"label":["Skills"],"points":[{"start":6627,"end":6629,"text":"XML"}]},{"label":["Skills"],"points":[{"start":6621,"end":6624,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":6615,"end":6618,"text":"Java"}]},{"label":["Skills"],"points":[{"start":6602,"end":6612,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":5522,"end":5527,"text":"jQuery"}]},{"label":["Skills"],"points":[{"start":5512,"end":5519,"text":"Mongo DB"}]},{"label":["Skills"],"points":[{"start":5504,"end":5509,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4645,"end":4652,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":4054,"end":4061,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":3941,"end":3951,"text":"Naïve Bayes"}]},{"label":["Skills"],"points":[{"start":3494,"end":3501,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":3132,"end":3141,"text":"Word Cloud"}]},{"label":["Skills"],"points":[{"start":2793,"end":2800,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":2110,"end":2116,"text":"Pycharm"}]},{"label":["Skills"],"points":[{"start":2101,"end":2108,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":2086,"end":2091,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":2080,"end":2083,"text":"AJAX"}]},{"label":["Skills"],"points":[{"start":2067,"end":2076,"text":"JavaScript"}]},{"label":["Skills"],"points":[{"start":2060,"end":2063,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":2054,"end":2057,"text":"XSLT"}]},{"label":["Skills"],"points":[{"start":2049,"end":2051,"text":"XML"}]},{"label":["Skills"],"points":[{"start":2018,"end":2025,"text":"Mongo DB"}]},{"label":["Skills"],"points":[{"start":2003,"end":2015,"text":"Microsoft SQL"}]},{"label":["Skills"],"points":[{"start":1977,"end":1986,"text":"Word Cloud"}]},{"label":["Skills"],"points":[{"start":1958,"end":1975,"text":"K means clustering"}]},{"label":["Skills"],"points":[{"start":1945,"end":1955,"text":"Naïve Bayes"}]},{"label":["Skills"],"points":[{"start":1918,"end":1928,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":1908,"end":1915,"text":"Backbone"}]},{"label":["Skills"],"points":[{"start":1901,"end":1905,"text":"Ember"}]},{"label":["Skills"],"points":[{"start":1892,"end":1898,"text":"Angular"}]},{"label":["Skills"],"points":[{"start":1887,"end":1889,"text":"Vue"}]},{"label":["Skills"],"points":[{"start":1880,"end":1884,"text":"React"}]},{"label":["Skills"],"points":[{"start":1871,"end":1877,"text":"FuelPHP"}]},{"label":["Skills"],"points":[{"start":1866,"end":1868,"text":"Yii"}]},{"label":["Skills"],"points":[{"start":1857,"end":1863,"text":"CakePHP"}]},{"label":["Skills"],"points":[{"start":1848,"end":1854,"text":"Phalcon"}]},{"label":["Skills"],"points":[{"start":1842,"end":1845,"text":"Zend"}]},{"label":["Skills"],"points":[{"start":1833,"end":1839,"text":"Symfony"}]},{"label":["Skills"],"points":[{"start":1820,"end":1830,"text":"CodeIgniter"}]},{"label":["Skills"],"points":[{"start":1811,"end":1817,"text":"Laravel"}]},{"label":["Skills"],"points":[{"start":1806,"end":1808,"text":"PHP"}]},{"label":["Skills"],"points":[{"start":1798,"end":1803,"text":"MS SQL"}]},{"label":["Skills"],"points":[{"start":1790,"end":1795,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":1776,"end":1787,"text":"Web Services"}]},{"label":["Skills"],"points":[{"start":1764,"end":1773,"text":"Javascript"}]},{"label":["Skills"],"points":[{"start":1759,"end":1761,"text":"Mvc"}]},{"label":["Skills"],"points":[{"start":1750,"end":1756,"text":"Web Api"}]},{"label":["Skills"],"points":[{"start":1745,"end":1747,"text":"Sql"}]},{"label":["Skills"],"points":[{"start":1739,"end":1742,"text":"Linq"}]},{"label":["Skills"],"points":[{"start":1733,"end":1736,"text":"Rdlc"}]},{"label":["Skills"],"points":[{"start":1724,"end":1730,"text":"ASP.NET"}]},{"label":["Skills"],"points":[{"start":1720,"end":1721,"text":"C#"}]},{"label":["Skills"],"points":[{"start":1709,"end":1717,"text":".NET core"}]},{"label":["Skills"],"points":[{"start":1697,"end":1706,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":1688,"end":1694,"text":"Java EE"}]},{"label":["Skills"],"points":[{"start":1683,"end":1685,"text":"WAS"}]},{"label":["Skills"],"points":[{"start":1678,"end":1680,"text":"IHS"}]},{"label":["Skills"],"points":[{"start":1661,"end":1675,"text":"Computer Vision"}]},{"label":["Skills"],"points":[{"start":1645,"end":1658,"text":"Data Structure"}]},{"label":["Skills"],"points":[{"start":1630,"end":1642,"text":"Random Forest"}]},{"label":["Skills"],"points":[{"start":1615,"end":1627,"text":"Decision Tree"}]},{"label":["Skills"],"points":[{"start":1594,"end":1612,"text":"Logistic Regression"}]},{"label":["Skills"],"points":[{"start":1575,"end":1591,"text":"Linear Regression"}]},{"label":["Skills"],"points":[{"start":1568,"end":1572,"text":"Azure"}]},{"label":["Skills"],"points":[{"start":1556,"end":1565,"text":"Tensorflow"}]},{"label":["Skills"],"points":[{"start":1544,"end":1553,"text":"Regression"}]},{"label":["Skills"],"points":[{"start":1531,"end":1541,"text":"Time Series"}]},{"label":["Skills"],"points":[{"start":1516,"end":1528,"text":"Web Analytics"}]},{"label":["Skills"],"points":[{"start":1501,"end":1513,"text":"Deep Learning"}]},{"label":["Skills"],"points":[{"start":1495,"end":1498,"text":"Oops"}]},{"label":["Skills"],"points":[{"start":1482,"end":1492,"text":"Text Mining"}]},{"label":["Skills"],"points":[{"start":1469,"end":1479,"text":"Data Mining"}]},{"label":["Skills"],"points":[{"start":1459,"end":1466,"text":"Patterns"}]},{"label":["Skills"],"points":[{"start":1447,"end":1456,"text":"Regression"}]},{"label":["Skills"],"points":[{"start":1437,"end":1444,"text":"Modeling"}]},{"label":["Skills"],"points":[{"start":1418,"end":1434,"text":"Parametric Design"}]},{"label":["Skills"],"points":[{"start":1406,"end":1415,"text":"Map Reduce"}]},{"label":["Skills"],"points":[{"start":1398,"end":1403,"text":"Django"}]},{"label":["Skills"],"points":[{"start":1391,"end":1395,"text":"Flask"}]},{"label":["Skills"],"points":[{"start":1382,"end":1388,"text":"Sklearn"}]},{"label":["Skills"],"points":[{"start":1373,"end":1379,"text":"Pyspark"}]},{"label":["Skills"],"points":[{"start":1365,"end":1370,"text":"Pandas"}]},{"label":["Skills"],"points":[{"start":1340,"end":1362,"text":"Artificial Intelligence"}]},{"label":["Skills"],"points":[{"start":1325,"end":1337,"text":"Sql Reporting"}]},{"label":["Skills"],"points":[{"start":1325,"end":1327,"text":"Sql"}]},{"label":["Skills"],"points":[{"start":1319,"end":1322,"text":"Msbi"}]},{"label":["Skills"],"points":[{"start":1313,"end":1316,"text":"Ssrs"}]},{"label":["Skills"],"points":[{"start":1302,"end":1310,"text":"Msbi Ssis"}]},{"label":["Skills"],"points":[{"start":1302,"end":1305,"text":"Msbi"}]},{"label":["Skills"],"points":[{"start":1280,"end":1299,"text":"SQL server reporting"}]},{"label":["Skills"],"points":[{"start":1267,"end":1277,"text":"Programming"}]},{"label":["Skills"],"points":[{"start":1258,"end":1264,"text":"Bigdata"}]},{"label":["Skills"],"points":[{"start":1252,"end":1255,"text":"Hive"}]},{"label":["Skills"],"points":[{"start":1244,"end":1249,"text":"Hadoop"}]},{"label":["Skills"],"points":[{"start":1237,"end":1241,"text":"Scala"}]},{"label":["Skills"],"points":[{"start":1231,"end":1234,"text":"Java"}]},{"label":["Skills"],"points":[{"start":1226,"end":1228,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1208,"end":1223,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1200,"end":1205,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1186,"end":1197,"text":"Data Science"}]},{"label":["Skills"],"points":[{"start":1178,"end":1183,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1161,"end":1175,"text":"Project Manager"}]},{"label":["Skills"],"points":[{"start":1144,"end":1158,"text":"Quality Analyst"}]},{"label":["Skills"],"points":[{"start":1139,"end":1141,"text":"Ios"}]},{"label":["Skills"],"points":[{"start":1126,"end":1136,"text":"Informatica"}]},{"label":["Skills"],"points":[{"start":1121,"end":1123,"text":"Etl"}]},{"label":["Skills"],"points":[{"start":1109,"end":1118,"text":"Networking"}]},{"label":["Skills"],"points":[{"start":1100,"end":1106,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":1090,"end":1097,"text":"Big Data"}]},{"label":["Skills"],"points":[{"start":1075,"end":1087,"text":"SQL Developer"}]},{"label":["Skills"],"points":[{"start":1067,"end":1072,"text":"Hadoop"}]},{"label":["Skills"],"points":[{"start":1061,"end":1064,"text":".NET"}]},{"label":["Skills"],"points":[{"start":1043,"end":1058,"text":"Embedded Systems"}]},{"label":["Skills"],"points":[{"start":1037,"end":1040,"text":"DBAs"}]},{"label":["Skills"],"points":[{"start":1023,"end":1034,"text":"UI Developer"}]},{"label":["Skills"],"points":[{"start":1005,"end":1020,"text":"Business Analyst"}]},{"label":["Skills"],"points":[{"start":989,"end":1002,"text":"Devops Android"}]},{"label":["Skills"],"points":[{"start":977,"end":986,"text":"Salesforce"}]},{"label":["Skills"],"points":[{"start":963,"end":974,"text":"Oracle Cloud"}]},{"label":["Skills"],"points":[{"start":949,"end":961,"text":"Oracle Fusion"}]},{"label":["Skills"],"points":[{"start":943,"end":946,"text":"J2EE"}]},{"label":["Skills"],"points":[{"start":929,"end":934,"text":"Python"}]},{"label":["Skills"],"points":[{"start":920,"end":926,"text":"Mongodb"}]},{"label":["Skills"],"points":[{"start":910,"end":917,"text":"Firebase"}]},{"label":["Skills"],"points":[{"start":902,"end":907,"text":"FoxPro"}]},{"label":["Skills"],"points":[{"start":893,"end":899,"text":"Clipper"}]},{"label":["Skills"],"points":[{"start":886,"end":890,"text":"dBASE"}]},{"label":["Skills"],"points":[{"start":879,"end":883,"text":"RDBMS"}]},{"label":["Skills"],"points":[{"start":871,"end":876,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":860,"end":868,"text":"FileMaker"}]},{"label":["Skills"],"points":[{"start":848,"end":857,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":830,"end":845,"text":"Microsoft Access"}]},{"label":["Skills"],"points":[{"start":818,"end":827,"text":"PostgreSQL"}]},{"label":["Skills"],"points":[{"start":811,"end":815,"text":"MySQL"}]},{"label":["Skills"],"points":[{"start":798,"end":808,"text":"Programming"}]},{"label":["Skills"],"points":[{"start":796,"end":808,"text":"R Programming"}]},{"label":["Skills"],"points":[{"start":779,"end":794,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":234,"end":244,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":219,"end":231,"text":"R programming"}]},{"label":["Skills"],"points":[{"start":201,"end":216,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":165,"end":180,"text":"Machine Learning"}]},{"label":["Name"],"points":[{"start":0,"end":13,"text":"Udaya Laxmi Ch"}]}],"extras":null,"metadata":{"first_done_at":1579625576000,"last_updated_at":1579626369000,"sec_taken":0,"last_updated_by":"aJOmJy1lvpOYFetVNuqLvFo9Vx42","status":"done","evaluation":"NONE"}}
{"content": "Praveen Kumar\n\nB.TECH. | Electronics and Communication Engg. | praveen.kmr21@gmail.com | +91 9880324924\n\n\n4 years of experience with Accenture in technology division as Data Analyst, Business Analytics and Release Management of project using agile methodologies. A data enthusiast, I enjoy finding insights & creating value for business.\n\n\t Professional Summary                                                                                  \n\n\n\n· Certified Business Analyst, granted by BCS, The Chartered Institute for IT.\n\n· Engaged Data Analytics tools like R Programming, Tableau and Splunk to visualize and analyze the data. Built various data models using Random Forest, Regression, clustering, XGBoost and other analytics ML concepts using R programming.\n\n· Used Service Now, Tealeaf, WinSCP, Introscope, Akamai, JCA and Putty as part of daily work. Other Programming skills are HTML, CSS, Bootstrap and Java Script.\n\n· Release Management, was responsible for whole non-production environment with more than 60 applications deployed on the same. Convened war-rooms & lead multi-application teams to triage critical issues.\n\t Projects                                                                                  \n\n\n\n· Built a predictive model for an insurance client to help them find the target buyers of their insurance policies. Logistic Regression and SVM classification techniques were used to build this model.\n \n· Assisted HR team in finding the salary of prospect employee. Polynomial Regression and Random Forecasting Regression techniques were used. To visualize, ggplot2 package was used.  \n\n· Employed multiple linear regression to build a model for an investment firm to help them in understanding the factors they should be considering while investing in firms.\n\n· System Capacity Analysis\n· Analysis of property growth and trends of all reservation channels of a hotel. \n· Analysis of capacity of different engines and proposed recommendation.\n\n· Branded Web – Website of a premier Hotels chain. \n· Analysis, development and maintenance of Website and related data. \n· This included preventing hacking activity, identify and fixing defects, assist deployment and purging data on Akamai.\n· Issues analysis using Introscope, TeaLeaf and other tools.\n\n\t Achievements and People Engagement Activities\n\n\n\n· Team award for the FY14-Q3.\n· Organized and anchored Agile day Events.\n· Won first prize in GPAT(people engagement activity) which was conducted at global level.\n· Participated in dances and fashion shows during corporate annual function.\n· Gold Medal in swimming at regional level.\n\n\n\tPersonal Info                                                                                 \n\n\n\nMarital Status: Single\t                 Passport: Yes\nHobbies: Traveling, Cooking, Photography and Swimming.","annotation":[{"label":["UNKNOWN"],"points":[{"start":1472,"end":1609,"text":"f prospect employee. Polynomial Regression and Random Forecasting Regression techniques were used. To visualize, ggplot2 package was used."}]},{"label":["Skills"],"points":[{"start":589,"end":594,"text":"Splunk"}]},{"label":["Skills"],"points":[{"start":577,"end":583,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":562,"end":574,"text":"R Programming"}]},{"label":["Skills"],"points":[{"start":183,"end":200,"text":"Business Analytics"}]},{"label":["Education"],"points":[{"start":15,"end":20,"text":"B.TECH"}]},{"label":["Name"],"points":[{"start":0,"end":12,"text":"Praveen Kumar"}]}],"extras":null,"metadata":{"first_done_at":1532676868000,"last_updated_at":1532676868000,"sec_taken":127,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Preetam Sethi\nEmail: preetamsethi11@gmail.com \n\nPhone: +91-9654118331\n\nElectronic City Phase-2, Banglore \n\nObjective\n\nTo acquire proficiency and excellence in my field of information and technology, and subsequently employ these skills so as to further the cause of technology. To utilize my soft skills and technical abilities to achieve professional growth while being resourceful, innovative and flexible.\n\nCareer Profile\n\n\tOrganization\n\tRole\n\tDuration\n\n\tHCL Technologies Ltd, India\n\tSoftware Engineer\n\tFrom August  2013 till present\n\n\nWork Experience Summary \n\n· Overall 4 years of IT industry experience in Requirement Gathering, analysis, design and implementation.\n\n· Expertise in Python Scripting.\n\n· Experience working with Pandas DataFrame.\n· Knowledge of Hadoop Framework\n\n· Hands on Experience in Django Framework.\n\n· Experience in Selenium webdriver.\n\n· Hands on experience in RESTful API testing using Python.\n· Experience in Version Controlling tools GIT, SVN Tortoise.\n\n· Good Knowledge of HTML.\n\n· Good Knowledge of JSON and XML. \n\n· Experienced working in Agile methodology.\n\n· Hands-on in agile tools like Qmetry and Rally.\n\n· Hands-on in bug reporting tool JIRA.\n\n· Hands-on in code collaborator tool.\n\n· Hands-on Experience in working on C, SNMP protocol, Bash Shell Script.\n\n· Strong analytical and problem solving skills along with good written and verbal communication skills. \n\n· Basic understanding in Networking Domain.\n\nTechnical Skills\n\nBelow is a list of important hardware, software products, tools and methods that I have worked with.\n\n\tLANGUAGES \n\tPython, C, HTML\n\n\tOS\n\tWINDOWS, LINUX\n\n\tTOOLS & UTILITIES \n\tSelenium Webdriver,\n\nPostman,\n\nXML,\n\nJSON,\n\nEclipse,\n\nSikuli,\n\n Jira , \n\n Qmetry,\n\nSVN tortoise\n\nRally, \n\ncode collaborator \n\n\n\n\tDATABASE\n\tMySQL\n\n\t\n\t\n\n\nAssignments\n\n\tProject\n\tFEDEX CASCADE- Analytics and Big Data\n\n\tCustomer\n\tFEDEX\n\n\tPeriod\n\t6 months continuing \n\n\tDescription\n\tThe Project aims at making customer experience for FedEx better by using Data Analytics and Machine Learning algorithm to precisely predict HSCodes for international shipment with minimal manual efforts and thereby tackle the critical problem of caging in international shipment.\n\n\n\n\tRole\n\tPython Developer\n\n\tResponsibility\n\tAs a Python Developer my responsibilities include:\n· Creating framework for the source code we are developing, implementing all the OOPs concepts.\n\n· Developing Python script using Pandas DataFrame package to clean up Huge set of data and make it suitable for data analytics.\n\n· Implementing Machine learning algorithm viz. Supervisor learning to be used for elastic search.\n\n· Unit Testing of developed methods.\n\n\n\n\tEnvironment\n\tWindows Operating system\n\n\tTools\n\tAnaconda, Spyder, Hive, SQL, Excel.\n\n\n\tProject\n\tDELL ASM \n\n\tCustomer\n\tDell\n\n\tPeriod\n\t1 year 6 months \n\n\tDescription\n\tASM - Active System Manager, a Dell product used for deployment, provisioning and management of IT Resources, like servers, clusters, storage and VM.\n\nThe project aims at developing automation test script using Selenium webdriver and Python to test the GUI functionality of ASM.\n\n\n\n\tRole\n\tPython Developer\n\n\tResponsibility\n\tAs the Lead Automation Test Engineer my responsibilities include:\n\n· Working on Development of various featured apps of Dell ASM using Django Framework.\n\n· Analysing the requirements and understanding the design frameworks and methodologies.\n\n· Coding for the assigned Functionalities.\n\n· Reviewing Automation Testscripts of Team members.\n\n· Unit Testing of developed functionalities.\n\n· Defect Fixing.\n\n· Reporting product bugs.\n\n· Interacting with client, updating progress.\n\n· Discussing new requirements on the project.\n\n· Delivering value add ideas on product and code level.\n\n· Mentoring new members in the Team\n\n\n\n\tEnvironment\n\tWindows Operating system\n\n\tTools\n\tEclipse, SourceTree, Github, Vmware-Vshere, Jira, Qmetry, putty, Postman\n\n\tProject\n\tHarrisVCS21_Automation\n\n\tCustomer\n\tHarris Co-operation Ltd.\n\n\tPeriod \n\t1 year 2 months\n\n\tDescription\n\tHarris VCS21 (Voice Communication System for 21st Century) provides VoIP capability of   Air Traffic Management Domain. The system comprises of two parts (a)Embedded part (b)web-based application part. The Management Subsystem is a web-based application and is responsible for configuring the communication system with desired parameters. Test scripts are developed to perform the desired configuration and verify the functionality accordingly, on automation.\n\n\n\n\tRole\n\tAutomation Test Engineer\n\n\tResponsibility\n\tAs Automation Test Engineer my responsibilities include:\n\n· Analysing the requirements and understanding the design frameworks and methodologies.\n\n· Coding for the assigned Functionalities.\n\n· Unit Testing of developed functionalities.\n\n· Updating Rally as per agile process.\n\n· Defect Fixing.\n\n· Reporting product bugs.\n\n· Interacting with client, updating progress.\n\n\n\n\tEnvironment \n\tWindows Operating System\n\n\tTools\n\tEclipse, Sikuli, SVN Tortoise, Rally, code collaborator \n\n\n\tProject\n\tHarrisVCS21_Dev\n\n\tCustomer\n\tHarris Co-operation Ltd.\n\n\tPeriod\n\t6 Months\n\n\tDescription\n\tThe Air Traffic Control System, Harris VCS21 has several equipment in the network to facilitate effective communication between pilot and Air Traffic Controller. These equipment in the network are monitored and managed through SNMP protocols.\nPolling scripts were developed to ensure proper functioning of the entire system.\n\n\n\n\tRole\n\tJunior Developer\n\n\tResponsibilities\n\tAs junior developer my responsibilities include:\n\n· Analyse Polling Scripts already available in Bash language.\n\n· Converting Polling Script from Bash to C. \n\n· Manually test and confirm connectivity of all network resources using SNMP commands.\n\n· Report Bug on script.\n\n· Updating Rally and Code-Collaborator\n\n\tEnvironment \n\tLinux (CentOS)\n\n\tTools\n\tGNU compiler, Rally, Code Collaborator\n\n\nCareer Highlights\n\n· Received HCL O-infinity award 2014-15, for marking consecutively two times outstanding rating.\n\n\n· Spot award for the month of April16, for client appreciation.\n\n\n· Excellent performance Award for the quarter Jul-Aug-Sep ’16.\n\nEducation Qualification:\n\n\tDegree & Branch\n\tUniversity/ Board\n\tYear of Passing\n\n\tB.Tech (Electronics & Communication Engineering)\n\tSOA University, Bhubaneswar\n\t2012\n\n\tIntermediate\n\tCBSE\n\t2008\n\n\tMatric\n\tCBSE\n\t2006\n\n\nPersonal Details\n\n\tDate of Birth\n\t16 Feb 1991\n\n\tSex\n\tMale\n\n\tFather’s Name\n\tPramod Kumar Sethi\n\n\tPAN Number\n\tEEIPS4798B\n\n\n\n\tPassport No.\n\tJ9371219\n\n\n\n\tMobile No.\n\t9654118331\n\n\tEmail Id\n\tpreetamsethi11@gmail.com\n\n\nDeclaration \n\n      I hereby declare that the information furnished above is true to the best of my knowledge.\n\nDate:  \nPlace: New Delhi\n                                                                                          Preetam Sethi","annotation":[{"label":["Name"],"points":[{"start":6757,"end":6769,"text":"Preetam Sethi"}]},{"label":["Location"],"points":[{"start":6657,"end":6665,"text":"New Delhi"}]},{"label":["Education"],"points":[{"start":6184,"end":6189,"text":"B.Tech"}]},{"label":["Skills"],"points":[{"start":4952,"end":4955,"text":"SVN "}]},{"label":["Skills"],"points":[{"start":3282,"end":3287,"text":"Django"}]},{"label":["Skills"],"points":[{"start":3112,"end":3117,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3057,"end":3062,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2403,"end":2408,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2247,"end":2252,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2207,"end":2212,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1723,"end":1726,"text":"SVN "}]},{"label":["Skills"],"points":[{"start":1677,"end":1680,"text":"JSON"}]},{"label":["Skills"],"points":[{"start":1671,"end":1673,"text":"XML"}]},{"label":["Skills"],"points":[{"start":1581,"end":1586,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1042,"end":1044,"text":"XML"}]},{"label":["Skills"],"points":[{"start":1033,"end":1036,"text":"JSON"}]},{"label":["Skills"],"points":[{"start":971,"end":974,"text":"SVN "}]},{"label":["Skills"],"points":[{"start":966,"end":968,"text":"GIT"}]},{"label":["Skills"],"points":[{"start":916,"end":921,"text":"Python"}]},{"label":["Skills"],"points":[{"start":809,"end":814,"text":"Django"}]},{"label":["Skills"],"points":[{"start":688,"end":693,"text":"Python"}]},{"label":["Location"],"points":[{"start":96,"end":103,"text":"Banglore"}]},{"label":["Name"],"points":[{"start":0,"end":12,"text":"Preetam Sethi"}]}],"extras":null,"metadata":{"first_done_at":1532690435000,"last_updated_at":1532690435000,"sec_taken":0,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Pruthvi NSRSR\nMobile No: 8897300588\n\nE-Mail: pruthvi.nsrsr@gmail.com\n\n\nOBJECTIVE:  To achieve heights to the best in Data Analytics with RPA and to associate with one of the best organization, which encourages creativity, innovation, provides opportunities for growth and continuous learning.\n\nEXPERIENCE SUMMARY:\n\n· Total 4 years 8 months of experience in the Software development involving leading, development, testing and maintenance.\n\n· Currently associated with Capgemini India as Associate Consultant in Financial Services.\n\n· Working with Data Science and RPA on a daily basis, applying both statistical and machine learning techniques for model development & validation, model implementation for Big Data solutions.\n\n· Capable to delve into the Emerging Technologies.\n· Analytical and quality-oriented professional with an eye for detail.\n\nPROFESSIONAL SKILL SET:\n\n\t               Skill Name \n\t                               Proficiency\n\n\tPython , R \n\t                               Hands on\n\n\tHive, Pig, Spark, HDFS,Kafka\n\tProficient\n\n\tMachine Learning\n\t                               Beginner\n\n\tSQL,Unix (Shell scripting),Informatica\n\tProficient\n\n\tBlueprism,UiPath,Automation Anywhere\n\t                               Hands on\n\n\nEDUCATIONAL QUALIFICATIONS:\n\n\tExamination\n\tBoard\\University\n\tYear\n\tAggregate(CGPA)\n\n\tM. Tech\n\tBITS \n\t2016\n\t8.78\n\n\tB. Tech\n\tSRM University\n\t2011\n\t8.57\n\n\nCERTIFICATIONS:\n\n· Certificated in Big Data Analytics & Optimization at International School of Engineering \n\nTRAININGS:\n\n· All India Data Science Congress Meetup 2017 in Mumbai by Aegis School.\n\n· 5th Big Data Summit 2017 in Hyderabad by Nasscom.\n\n· DATACON Meetup by TechMahindra, Analytics Vidhya and UpxAcademy.\n\n  WORK EXPERIENCE:\n\n\tCompany Name\n\tDuration\n\n\tCapgemini India Pvt Ltd\n\tJanuary 2013 - Till Present\n\n\nPROJECTS: \n\nProject #1:\n\nProject Name \n:  Jewelers Mutual Insurance\nClient \n:  Jewelers Mutual Insurance Group Limited\nEnvironment              \n:  Windows server 2012 machines\nDuration                                              :  July 2016-Tilldate\n\nRole                                                      :  RPA Developer\n\nDescription:\n \n\n             Jewelers Mutual Insurance is to use to automate the Insurance claims process of JMI mutual by using Blue prism. Different workflows will be involved in different queues of claim processing system. Claims processing automation will be achieved by different automation methods involved in workflows. This deals with the Jewelers insurance which is compulsory for Jewels in United States of America.\nResponsibilities:\n· Gathering detailed requirements from Client for business requirements.\n\n· Updating the design document about the automation process.\n\n· Involved in discussing the project progress and the future development or enhancement activities such as change request management, design, reviews and deployment. \n\n· Checking the feasibility and exactly analyzing the process opportunities for RPA.\n\n· Involved in deployment of automation in users environment.\n\n· Deployment of Application on Test and Production Server.\n\n· Created various processes for client using Blue Prism.\n\n· Created Environment variables in the all Business Objects for all the applications where ever required for authentication purposes\n\n· Workflow developed for automating drive mapping based on the request.\n\n· Fixing bugs and attending calls with Blue Prism team if any tickets we raised.\n\n· Have taken the responsible of status calls with the clients on updating the Development progress weekly.\n\n· Interacting with client to understand the business on daily basis.\n\nProject #2:\n\nProject Name \n:  Streaming Data Analysis\n\nClient \n:  RSVPs Meetup\nEnvironment                   \n:  Apache Hadoop, Flume, Kafka, Hive, Spark and Unix Shell scripting\n\nDuration                                              :  January 2016-June 2016\n\nRole                                                      :  Senior Developer\n\nDescription:\n\n\n            This project is based to process streams of data and update databases in real-time utilizing using parallel processing of live streaming data. Ingest the streaming data for analysis using Apache Flume. Use a streaming framework to find number and type of events per geography. Create a visualization on a geo-map that can show at different snapshots in time, the number and type of events.\n\nResponsibilities:\n· As a Big Data Developer, Performed complete operations of data mapping, extracting and loading.\n\n· Developed code to ingest meetup data into flume, process the data using pyspark shell and visualize meetup using geocode. Also, Responsible for doing peer review, unit testing of others’ code before passing it to the Quality.\n\n· Coordinating and working closely with the core team on the big data solutions on large amount of analytical data.\n\nProject #3:\n\nProject Name \n:  Azure Insurance \n\nClient \n:  Azure Insurance Group Limited\nEnvironment              \n:  R, Machine Learning Techniques (Decision trees, Logistc Regression, CART and Random\n\n                                                                  Forests), Tableau     \n\nDuration                                              :  August 2014-December 2015 \n\nRole                                                      :  Senior Developer\n\nDescription:\n \n\n             This project involves defining the metrics to analyse agent performance based on several attributes like demography, products sold, new business, so on. Azure is interested in improving existing knowledge for agent segmentation in a supervised predictive framework.\n\nResponsibilities:\n· As a Senior Developer, performed operations such as collecting data, examining and pre-processing it as required; estimated additional features required for models\n· Planned and applied statistical techniques for descriptive statistics and prepared reports containing plots & patterns.\n\n· Abstracted samples for training and test data for building and testing machine learning algorithms. Generated final reports and published the model and the results, on an ongoing basis.\n\nProject #3:\n\nProject Name \n:  Integrated Data Warehousing\nClient \n:  QBE Insurance Group Limited\nEnvironment              \n:  Apache Hadoop, Pig, Hive, Oozie, Sqoop, HDFS, HBase\nDuration                                              :  June 2014-July 2014 \n\nRole                                                      :  Senior Developer\n\nDescription:\n \n\n             The IDW is a scalable BI platform that can adapt to the speed of the business by providing relevant, accessible, timely, connected, and accurate data. The IDW and its data lake is purposely built to consume more data in scale and the data latency to me measured in hours. Main focus is on users who can perform cross functional analysis through integrated data sets.\nResponsibilities:\n· Responsible for data loading and mapping from the QBE Data Lake to the QBE Internal Core Tables.\n\n· Developing code for data transfer to the core internal tables by Pig scripting, Hive, HBase and Scoop.\n\n· Responsible for writing the workflow in Oozie. \n\n· Responsible for writing the User Stories.\n\n· Responsible for doing unit testing before passing it to the QA.\n\n· Provide big data solutions and experimenting on large amount of analytical data.\n\n· Responsible for interacting with the On-Site Team on the various issues related QBE data via Query log sheet. Coordinate with the subordinates on the task completion on time.\n\n· Identifying issues related to data loading process and maintaining the run book and the process change related documents.\n\nProject #4:\n\nProject Name \n:  Ease Integration \n\nClient \n:  AXA Hong Kong\nEnvironment              \n:  Informatica, Apache Hadoop, Pig, Hive, Oozie, Sqoop, HDFS, HBase\nDuration                                              :  June 2013-May 2014 \n\nRole                                                      :  Data Analyst\n\nDescription:\n \n\n            AXA Hong Kong has been offering a wide range of life, health, property and casualty protection, as well as wealth management and retirement solutions to help customers achieve stability and prosperity.\nResponsibilities:\n· Responsible for data loading and mapping; system setup and configuration; and functional processes within the AXA Solution packages by ensuring that the requirements presented for customer data and systems are accurate and follow standard operational processes. \n\n· Responsible for Setting up customer configurations and developing SQL queries.\n\n· Collecting data from clients, Involved in the analysis and design of the system.\n\n· Handle Slowly Changing Dimension to maintain the complete history of the data.\n\n· Develop all mappings according to the design document.\n\n· Involve in unit testing of the mapping before passing it to QA.\n\nProject #5:\n\nProject Name \n:  L70\nClient \n:  AXA \nEnvironment              \n:  SQL Server 2008\n\nDuration                                              :  January 2013-June 2013\n\nRole                                                      :  Junior Developer\n\nDescription:\n \n\n             AXA US is mainframe Insurance based application, it has multiple interfaces integration and payment gateways.\n\nResponsibilities:\n\n· Responsible for Setting up customer configurations and developing SQL queries.\n\n· Collecting data from clients, Involved in the analysis and design of the system.\n\n· Handle Slowly Changing Dimension to maintain the complete history of the data.\n\n· Develop all mappings according to the design document.\n\n· Involve in unit testing of the mapping before passing it to QA.\n\nPERSONAL PROFILE:\n\nFather’s Name\n   \n\n: N L N Rao\n\nNationality\n   \n\n: Indian\n\nPassport  \n            \n \n: H4754772\n\nLanguage Proficiency \n\n: English, Hindi, Telugu\n\nAddress                                       : 13-1-105/5 Plot No 6c Mothinagar, Hyderabad-500018\n\nThe above statements are true to the best of my knowledge and belief.\n\nNSRSR PRUTHVI \n\nPlace: Hyderabad\n\nDate: 16-09-2017","annotation":[{"label":["Location"],"points":[{"start":9950,"end":9958,"text":"Hyderabad"}]},{"label":["Location"],"points":[{"start":9838,"end":9846,"text":"Hyderabad"}]},{"label":["Skills"],"points":[{"start":9636,"end":9637,"text":" R"}]},{"label":["Skills"],"points":[{"start":9286,"end":9288,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":9219,"end":9220,"text":" R"}]},{"label":["Skills"],"points":[{"start":8882,"end":8884,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":8498,"end":8500,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":8431,"end":8432,"text":" R"}]},{"label":["Skills"],"points":[{"start":8165,"end":8166,"text":" R"}]},{"label":["Skills"],"points":[{"start":7751,"end":7755,"text":"HDFS,"}]},{"label":["Skills"],"points":[{"start":7751,"end":7754,"text":"HDFS"}]},{"label":["Skills"],"points":[{"start":7731,"end":7734,"text":"Hive"}]},{"label":["Skills"],"points":[{"start":7725,"end":7728,"text":" Pig"}]},{"label":["Skills"],"points":[{"start":7698,"end":7708,"text":"Informatica"}]},{"label":["Skills"],"points":[{"start":7293,"end":7294,"text":" R"}]},{"label":["Skills"],"points":[{"start":7142,"end":7143,"text":" R"}]},{"label":["Skills"],"points":[{"start":7097,"end":7098,"text":" R"}]},{"label":["Skills"],"points":[{"start":7046,"end":7047,"text":" R"}]},{"label":["Skills"],"points":[{"start":7021,"end":7024,"text":"Hive"}]},{"label":["Skills"],"points":[{"start":7005,"end":7008,"text":" Pig"}]},{"label":["Skills"],"points":[{"start":6840,"end":6841,"text":" R"}]},{"label":["Skills"],"points":[{"start":6255,"end":6259,"text":"HDFS,"}]},{"label":["Skills"],"points":[{"start":6255,"end":6258,"text":"HDFS"}]},{"label":["Skills"],"points":[{"start":6235,"end":6238,"text":"Hive"}]},{"label":["Skills"],"points":[{"start":6229,"end":6232,"text":" Pig"}]},{"label":["Skills"],"points":[{"start":5034,"end":5035,"text":" R"}]},{"label":["Skills"],"points":[{"start":5013,"end":5014,"text":" R"}]},{"label":["Skills"],"points":[{"start":4957,"end":4958,"text":" R"}]},{"label":["Skills"],"points":[{"start":4623,"end":4624,"text":" R"}]},{"label":["Skills"],"points":[{"start":3766,"end":3771,"text":" Spark"}]},{"label":["Skills"],"points":[{"start":3761,"end":3764,"text":"Hive"}]},{"label":["Skills"],"points":[{"start":3754,"end":3758,"text":"Kafka"}]},{"label":["Skills"],"points":[{"start":3684,"end":3685,"text":" R"}]},{"label":["Skills"],"points":[{"start":2965,"end":2966,"text":" R"}]},{"label":["Skills"],"points":[{"start":2123,"end":2124,"text":" R"}]},{"label":["Location"],"points":[{"start":1617,"end":1625,"text":"Hyderabad"}]},{"label":["Skills"],"points":[{"start":1133,"end":1143,"text":"Informatica"}]},{"label":["Skills"],"points":[{"start":1110,"end":1131,"text":"Unix (Shell scripting)"}]},{"label":["Skills"],"points":[{"start":1106,"end":1108,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1026,"end":1030,"text":"Kafka"}]},{"label":["Skills"],"points":[{"start":1021,"end":1024,"text":"HDFS"}]},{"label":["Skills"],"points":[{"start":1013,"end":1018,"text":" Spark"}]},{"label":["Skills"],"points":[{"start":1008,"end":1011,"text":" Pig"}]},{"label":["Skills"],"points":[{"start":1003,"end":1006,"text":"Hive"}]},{"label":["Skills"],"points":[{"start":956,"end":957,"text":" R"}]},{"label":["Skills"],"points":[{"start":948,"end":954,"text":"Python "}]},{"label":["Skills"],"points":[{"start":563,"end":564,"text":" R"}]},{"label":["Skills"],"points":[{"start":136,"end":137,"text":" R"}]},{"label":["Name"],"points":[{"start":0,"end":12,"text":"Pruthvi NSRSR"}]}],"extras":null,"metadata":{"first_done_at":1532694681000,"last_updated_at":1532694681000,"sec_taken":149,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "RAGHAVENDRA RAO V     Mobile   :   +91 8050006255 \n\nMail    :   raghav1057@gmail.com \n\nPlace  :   Bangalore \n\nCareer Objective: \n\nExperienced and skilled Software Developer with a strong record of excellent teamwork and \n\nsuccessful project management. Specializes in problem identification and proposal of alternative solutions. \n\nAdept at working on multiple projects simultaneously. Focused mainly on building text based search \n\nsolution using NLP, NLU and machine learning techniques. \n\nCareer summary: \n\n Having 4+ years of IT experience in the area of Software Research and Development and Architecture. \n\n Expertise in building solutions based on NLP and NLU components. \n\n Expertise in building text based search solutions. \n\n Expertise in Server – Side programming using Python. \n\n Good understanding of Algorithms and Data Structures. \n\n Exceptional skills in Agile Development and Test Driven Development \n\n Quick adaptability to the any new technology and deliver as requirement. \n\n Oracle Certified Programmer for the Core Java. \n\n Good analytical and programming capabilities coupled with excellent decision making skills. \n\n Excellent team player and ability to perform well under extreme pressure. \n\n Excellent written and oral communication skills. \n\nProfessional Experience \n\nCompany Position Duration \n\nWipro Limited Senior Software Engineer  Aug 2016 - Present \n\nXoriant Solutions India Pvt Ltd Software Engineer II Jan 2016 – Aug 2016 \n\nTAS Information Intelligence Software Engineer June 2014 - Jan 2016 \n\n Pyramid IT Solutions Pvt Ltd at \n\nAccenture Services Pvt Ltd, Bangalore \n\nAssociate Software Engineer \n\n \n\nJuly  2013 - Feb 2014  \n\n\n\n  \n\nEducational Qualification \n\nQualification Stream College Pass out Percentage \n\n     BE CSE HKBK College of Engineering , Bangalore 2013 63% \n\nDiploma CSE S J Polytechnic , Bangalore 2009 68% \n\n     10th SSLC Jyothi School, Bangalore 2005  87 % \n\n \n\nTechnical Skills: \n\n    Languages and Technologies     Python, DJango, Java, C,  C++ \n\n    Operating System      Linux , Windows \n\n    Web Technologies     RestAPI, Java Script, HTML, XML \n\n    Database     MySQL, MongoDB , Postgres, Influxdb \n\nProfessional Summary \n\nOrganization 1:  Wipro Limited \n\nDuration: Aug 2016 – Present \n\nProject Name:  Holmes  \n\nDomain: Text Analytics, Cognitive Search, NLP, NLU, Machine Learning, Deep Learning \n\nTechnology Used:  Python, Theano, Tensorflow, Java, MongoDB, Elastic Search \n\nRoles and Responsibilities:  \n\n Member of research and development team, focused on building components for Cognitive \n\nsearch solution using, NLP, NLU components and Deep Learning algorithms. \n\n Leading Cognitive Search core team of size 6. \n\n Involved in Complete Software Life Cycle to build Cognitive Search Tool. Including \n\narchitecture and development of complete solution from scratch. \n\n Identification of technical issues and providing alternate solutions to other team members. \n\n Code Review, bug fixes and optimization code. \n\n Worked on POC of Cognitive search for multiple clients. \n\nCertificate Institute Year Grade \n\n        Oracle Certification for Core Java. NIIT       2014 A \n\n\n\n  \n\nOrganization 2:  Xoriant Solutions Pvt Ltd, Maple Labs \n\nDuration: Jan 2016 – Aug 2016 \n\nProject Name:  Real Time Hadoop Cluster Monitoring Solution. \n\nTechnology Used:  Python, Django, Hadoop, Collectd, Logstash, Elastic Search, Ansible, Splunk, JS \n\nRoles and Responsibilities:  \n\n Setting Up Multi Node Hadoop Clusters. \n\n Developed Python Collectd Plugins to monitor Hadoop, Server and network. \n\n Developed Python Application to start and manage the Monitoring setup with Hadoop job. \n\n Developed a User friendly Python CLI to Orchestrate the Cluster Nodes. \n\n Developed the DJango Rest API for orchestrator tasks using multiprocessing. \n\n Written Queries and created Tables and Charts in Splunk/Kibana to see the monitoring stats. \n\n Created HTML Home page of Monitoring app and Start the Hadoop Jobs with default inputs \n\nusing splunk’s inbuilt JS code. \n\nOrganization 3: \n\nTAS Information Intelligence \n\nRole: Python Developer \n\nClient: Thomson Reuters (Multiple Projects) \n\nDuration: Jul 2014 – Jan 2016 \n\nRoles and Responsibilities:   \n\nTechnology Used: Python, MySQL, XML, JavaScript, HTML \n\nBuilding Software application for below mentioned process. (Server – Side \n\nProgramming)  \n\n Working on Large sets of Structured and Semi-structured data from Web Pages and PDFs. \n\n Developed web application for Automated Information Processing of large data using \n\nmultiprocessing. \n\n Creation of output in form of XML and XL formats with Validation. \n\n Complete database management using SQL and LMDB. \n\n \n\nOrganization 4:    \n\nAccenture Services Pvt Ltd on payroll of Pyramid IT Solutions Pvt Ltd \n\nRole: Associate Software Engineer \n\nDuration: July 2013 – Feb 2014 \n\nProjects:  CTSD \n\nRoles and Responsibilities: \n\n       Worked with Development team for internal project ‘Roaster System’. \n\n       Took complete responsibility of UAT activity and final release. \n\n\n\n  \n\n                                             Personal Details \n\nDate of Birth  :        28 Oct 1989 \n\nSex   :        Male \n\nMarital Status :        Single \n\nFather’s Name :        Venkoba Rao \n\nMother Tongue :        Marathi \n\nLanguages Known :        English, Hindi, Kannada, Marathi and Tamil \n\nAddress  :        16/3, 9 th Cross, 3rd E main \n\n                                            Kacharakana Halli \n\n                                                                              Bangalore - 560084 \n\n                                                  Declaration \n\nI hereby declare that, to the best of my knowledge, the above information is true. \n\nBangalore         RAGHAVENDRA RAO V","annotation":[{"label":["Location"],"points":[{"start":5711,"end":5720,"text":"Bangalore "}]},{"label":["Location"],"points":[{"start":5541,"end":5550,"text":"Bangalore "}]},{"label":["Skills"],"points":[{"start":5379,"end":5379,"text":"C"}]},{"label":["Skills"],"points":[{"start":4858,"end":4858,"text":"C"}]},{"label":["Skills"],"points":[{"start":4631,"end":4631,"text":"C"}]},{"label":["Skills"],"points":[{"start":4561,"end":4561,"text":"C"}]},{"label":["Skills"],"points":[{"start":4252,"end":4255,"text":"Java"}]},{"label":["Skills"],"points":[{"start":4239,"end":4244,"text":" MySQL"}]},{"label":["Skills"],"points":[{"start":4232,"end":4237,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4105,"end":4105,"text":"C"}]},{"label":["Skills"],"points":[{"start":4086,"end":4091,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3908,"end":3908,"text":"C"}]},{"label":["Skills"],"points":[{"start":3851,"end":3851,"text":"C"}]},{"label":["Skills"],"points":[{"start":3746,"end":3751,"text":"DJango"}]},{"label":["Skills"],"points":[{"start":3713,"end":3713,"text":"C"}]},{"label":["Skills"],"points":[{"start":3690,"end":3690,"text":"C"}]},{"label":["Skills"],"points":[{"start":3683,"end":3688,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3576,"end":3581,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3506,"end":3506,"text":"C"}]},{"label":["Skills"],"points":[{"start":3499,"end":3504,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3475,"end":3475,"text":"C"}]},{"label":["Skills"],"points":[{"start":3355,"end":3355,"text":"C"}]},{"label":["Skills"],"points":[{"start":3331,"end":3336,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3282,"end":3282,"text":"C"}]},{"label":["Skills"],"points":[{"start":3129,"end":3132,"text":"Java"}]},{"label":["Skills"],"points":[{"start":3124,"end":3124,"text":"C"}]},{"label":["Skills"],"points":[{"start":3106,"end":3106,"text":"C"}]},{"label":["Skills"],"points":[{"start":3056,"end":3056,"text":"C"}]},{"label":["Skills"],"points":[{"start":3015,"end":3015,"text":"C"}]},{"label":["Skills"],"points":[{"start":3010,"end":3010,"text":"C"}]},{"label":["Skills"],"points":[{"start":2948,"end":2948,"text":"C"}]},{"label":["Skills"],"points":[{"start":2749,"end":2749,"text":"C"}]},{"label":["Skills"],"points":[{"start":2734,"end":2734,"text":"C"}]},{"label":["Skills"],"points":[{"start":2711,"end":2711,"text":"C"}]},{"label":["Skills"],"points":[{"start":2657,"end":2657,"text":"C"}]},{"label":["Skills"],"points":[{"start":2560,"end":2560,"text":"C"}]},{"label":["Skills"],"points":[{"start":2424,"end":2431,"text":" MongoDB"}]},{"label":["Skills"],"points":[{"start":2419,"end":2422,"text":"Java"}]},{"label":["Skills"],"points":[{"start":2391,"end":2396,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2311,"end":2311,"text":"C"}]},{"label":["Skills"],"points":[{"start":2164,"end":2172,"text":"Influxdb "}]},{"label":["Skills"],"points":[{"start":2154,"end":2161,"text":"Postgres"}]},{"label":["Skills"],"points":[{"start":2143,"end":2150,"text":" MongoDB"}]},{"label":["Skills"],"points":[{"start":2136,"end":2141,"text":" MySQL"}]},{"label":["Skills"],"points":[{"start":2095,"end":2098,"text":"Java"}]},{"label":["Skills"],"points":[{"start":2011,"end":2013,"text":"C++"}]},{"label":["Skills"],"points":[{"start":2011,"end":2011,"text":"C"}]},{"label":["Skills"],"points":[{"start":2007,"end":2007,"text":"C"}]},{"label":["Skills"],"points":[{"start":2001,"end":2004,"text":"Java"}]},{"label":["Skills"],"points":[{"start":1993,"end":1998,"text":"DJango"}]},{"label":["Skills"],"points":[{"start":1985,"end":1990,"text":"Python"}]},{"label":["Location"],"points":[{"start":1904,"end":1913,"text":"Bangalore "}]},{"label":["Skills"],"points":[{"start":1887,"end":1887,"text":"C"}]},{"label":["Location"],"points":[{"start":1853,"end":1862,"text":"Bangalore "}]},{"label":["Skills"],"points":[{"start":1831,"end":1831,"text":"C"}]},{"label":["Location"],"points":[{"start":1802,"end":1811,"text":"Bangalore "}]},{"label":["Skills"],"points":[{"start":1777,"end":1777,"text":"C"}]},{"label":["Skills"],"points":[{"start":1768,"end":1768,"text":"C"}]},{"label":["Education"],"points":[{"start":1764,"end":1767,"text":" BE "}]},{"label":["Skills"],"points":[{"start":1730,"end":1730,"text":"C"}]},{"label":["Location"],"points":[{"start":1605,"end":1614,"text":"Bangalore "}]},{"label":["Skills"],"points":[{"start":1308,"end":1308,"text":"C"}]},{"label":["Skills"],"points":[{"start":1047,"end":1050,"text":"Java"}]},{"label":["Skills"],"points":[{"start":1042,"end":1042,"text":"C"}]},{"label":["Skills"],"points":[{"start":1013,"end":1013,"text":"C"}]},{"label":["Skills"],"points":[{"start":879,"end":884,"text":"Agile "}]},{"label":["Skills"],"points":[{"start":787,"end":792,"text":"Python"}]},{"label":["Skills"],"points":[{"start":494,"end":494,"text":"C"}]},{"label":["Skills"],"points":[{"start":112,"end":112,"text":"C"}]},{"label":["Location"],"points":[{"start":100,"end":109,"text":"Bangalore "}]},{"label":["Name"],"points":[{"start":0,"end":18,"text":"RAGHAVENDRA RAO V  "}]}],"extras":null,"metadata":{"first_done_at":1532695135000,"last_updated_at":1532695135000,"sec_taken":108,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "CURRICULUM VITAE\nRaghavendra KS\n\n​ Raghav.shivappa@Gmail.com\n\n\n\n\n\n\nContact no: +91 9742125462\nCAREER OBJECTIVE\n\n\n\n\nTo associate with an organisation which progress dynamically and gives me a chance to update my knowledge and enhance my skills, in the state of art technologies and be a part of the team, the growth of organisation and my satisfaction thereof.\n\nPROFESSIONAL SUMMARY\n\n\n\n\tGood Knowledge of Data​ extracting​ using Python​​Regular Expression. \n\tPython​DBI knowledge - MySQL and oracle. \n\tHaving Experience on Django​ REST Framework.​ \n\tWebcrawling​in python​​ using Selenium​ and BeautifulSoup.​ \n\tGood Knowledge​in​ Python​.​ \n\tHands on Experience on git​ repository. \n\tGood Knowledge in MongoDB, Elasticsearch and Data warehousing. \n\n\n\tHadoop​experience spanning over HDFS​, MapReduce . \n\n\n\tGood Knowledge of Handling AWS server,​ Azure Servers.​ \n\tGood Knowledge​of​ UNIX Commands. \n\n\nTotal years of work experience: 2 years and 5 months.\n\n\n\nSoftware Engineer at Onetech Ventures India Pvt Ltd, Bangalore from March 2016 to Till Date.\n\nProject: Jarviz\n\n●\nTeam Size\n: 20\n●\nDuration\n: March 2106 to till Date\n●\nEnvironment\n: Java, Python, Django, Javascript, HTMl, CSS, Javascript, Jquery, SpringBoot, MongoDB and Elasticsearch.\n\nProject Overview:\n\nJarviz is a search engine conceptualised to ensure right leadership is identified in each and every job mandate. The search scope covers all key roles from middle to senior management. This is the first of its kind in India where the executive search consulting competence has been automated across key industries to enable the search business to scale massively.\n\nThis company is in a stealth mode with a product launch planned in couple of months.\n\nRoles and Responsibilities:\n\n\tInvolved in developing crawl engine called GLNM​ using python and Django webframe work. \n\n\n\tAutomate crawl engine to extract Data from Prob42, fundoodata, linkedin, Naukri and Monster. \n\n\n\tMaking sure that the developed scripts are working properly and checking other developer’s script as well. \n\n\n\tProgramming in python as well as perl. \n\n\n\tMaintaining Huge data from linkedin. \n\n\n\tWorking with databases like MongoDB, Mysql and Elasticsearch. \n\n\n\tWorking with Elastisearch to autocomplete results for search field. \n\n\tWorking with git repository to maintain standard code flexibality. \n\n\n\tMaintaining necessary reports and reporting the manager regularly. \n\n\n\tTracking the bugs in the scripting language and fixing them. \n\n\n\tInvolved in Data extraction through Python Regular expression. \n\n\n\tInvolved in Backend process like Mysql and mongoDB. \n\n\n\nJr.Software Engineer at Infiniti Research India Pvt Ltd, Bangalore from Sept 2014 to March 2016.\n\nProject: BusinessVibes\n\n●\nTeam Size\n: 6\n●\nDuration\n: 1 Year and 6 months\n●\nEnvironment\n: Perl, Phyton, Struts, JSP, Javascript, HTML, CSS, Javascript, Spring, Json and Mysql\n\nProject Overview:\n\nBusinessVibes is a free B2B social media network built for global trade professionals. Our goal is to connect like-minded businesses with each other, offering a transnational network proven to help build quality leads for its members. As a bonus, we also share your business events, B2B deals, trade enquiries and more all for free. BusinessVibes is headquartered in Toronto, and has offices in London, Bangalore and Beijing.\n\nRoles and Responsibilities:\n\n\tInvolved in developing perl scripts and some other scripts like java script. \n\n\n\tMaking sure that the developed scripts are working properly and checking other developer’s script as well. \n\n\n\tProgramming in python as well as perl. \n\n\n\tMaintaining necessary reports and reporting the manager regularly. \n\n\n\tTracking the bugs in the scripting language and fixing them. \n\n\n\tInvolved in Data extraction through Perl regex. \n\n\n\tInvolved in Backend process like Mysql and mongoDB. \n\n\n\tUsed elastic search to access the data from mysql table. \n\n\nProject: Removal of Similar Company Titles Using Hadoop\n\n●\nTeam Size\n: 2\n●\nDuration\n: 2 Months\n●\nEnvironment\n: Java, MySql, Sqoop, Perl and ​Hadoop\n\nProject Overview:\n\nSince we crawl Data using PERL script from multiple Third party source finally we end up with companies having the similar company names but from different sources .So in order to get rid of this conflict and faster production of result we made use of hadoop to remove duplicates.\n\nRoles and Responsibilities:​\n\tAs a Team member Involved in developing Java Program for Removal Similar Compay titles. \n\tMaking sure that the developed scripts are working properly and checking other developer’s script as well. \n\tImporting and Exporting data from MySQL to HDFS Using Sqoop. \n\n\nEDUCATION HISTORY\n\n\n\n2012 – 2014   Master of Technology (MTech) from RV College of Engineering Bangalore,\nVisvesvaraya Technological University. (77%)\n\n2008 – 2012   Bachelor of Engineering (ISE) from Visvesvaraya Technological University.(63%)\n\n\nTECHNICAL KNOWLEDGE\n\n\n\n\tOperating System:​ \tWindows, UNIX systems Ubuntu, Fedora. \n\tProgramming Languages:​ Python, Perl and Basic JAVA. \n\tDatabase:​ \t\tMongoDB, MySQL and Elastic Search. \n\tOther programming skills:​ HTML . \n\tWeb Framework​:\t Django \n\tIDE :\t\t\t Pycharm​ and Eclipse. \n\n\nAchievements\n\n\n\n\tReceived Outstanding Performance award ​for​ the year 2014-2015. \n\n\nPERSONAL STRENGTH\n\n\n\n\tPositive attitude. \n\tAdaptable nature. \n\n\n\tHard Working. \n\n\nINTERESTS AND ACTIVITIES\n\n\n\n\n●  Playing Badminton, Carrom, Cricket and Listening songs.\n\nPERSONAL DETAILS\n\n\n\n\n:\nRaghavendra KS\nName\n\n\nResidential Address\n:\n#28,1st Main, 2nd Cross, Dwarakanagar, Hosakerehalli, BSK 3rd Stage,\n\n\nBangalore-560085.\nMobile\n:\n+91 9742125462.\nDate of Birth\n:\n14-Feb-90\nLanguages\n:\nEnglish, Kannada\nNationality\n:\nIndian\nDECLARATION\n\n\n\nI hereby declare that all the statements made above are true & correct to maximum possible extent.\n\n\n\nDATE:\nPLACE: Bangalore\tRaghavendra KS","annotation":[{"label":["Name"],"points":[{"start":5811,"end":5824,"text":"Raghavendra KS"}]},{"label":["Location"],"points":[{"start":5801,"end":5809,"text":"Bangalore"}]},{"label":["Location"],"points":[{"start":5552,"end":5560,"text":"Bangalore"}]},{"label":["Name"],"points":[{"start":5437,"end":5450,"text":"Raghavendra KS"}]},{"label":["Skills"],"points":[{"start":5034,"end":5038,"text":"MySQL"}]},{"label":["Skills"],"points":[{"start":5025,"end":5031,"text":"MongoDB"}]},{"label":["Location"],"points":[{"start":4721,"end":4729,"text":"Bangalore"}]},{"label":["Education"],"points":[{"start":4661,"end":4680,"text":"Master of Technology"}]},{"label":["Skills"],"points":[{"start":4596,"end":4600,"text":"MySQL"}]},{"label":["Location"],"points":[{"start":3290,"end":3298,"text":"Bangalore"}]},{"label":["Location"],"points":[{"start":2652,"end":2660,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":2278,"end":2280,"text":"git"}]},{"label":["Skills"],"points":[{"start":2175,"end":2187,"text":"Elasticsearch"}]},{"label":["Skills"],"points":[{"start":2156,"end":2162,"text":"MongoDB"}]},{"label":["Skills"],"points":[{"start":1228,"end":1240,"text":"Elasticsearch"}]},{"label":["Skills"],"points":[{"start":1216,"end":1222,"text":"MongoDB"}]},{"label":["Location"],"points":[{"start":1011,"end":1019,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":790,"end":798,"text":"MapReduce"}]},{"label":["Skills"],"points":[{"start":783,"end":787,"text":"HDFS​"}]},{"label":["Skills"],"points":[{"start":729,"end":744,"text":"Data warehousing"}]},{"label":["Skills"],"points":[{"start":711,"end":723,"text":"Elasticsearch"}]},{"label":["Skills"],"points":[{"start":702,"end":708,"text":"MongoDB"}]},{"label":["Skills"],"points":[{"start":665,"end":667,"text":"git"}]},{"label":["Skills"],"points":[{"start":579,"end":586,"text":"Selenium"}]},{"label":["Skills"],"points":[{"start":522,"end":533,"text":"Django​ REST"}]},{"label":["Skills"],"points":[{"start":491,"end":496,"text":"oracle"}]},{"label":["Skills"],"points":[{"start":481,"end":485,"text":"MySQL"}]},{"label":["Name"],"points":[{"start":17,"end":30,"text":"Raghavendra KS"}]}],"extras":null,"metadata":{"first_done_at":1532692718000,"last_updated_at":1532692718000,"sec_taken":132,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Raghvendra Pateriya\nCell: +91 9582310928/7013808098\n\nEmail: raghvendra.pateriya@gmail.com\nProfile \n\n\n· B.E. (Information Technology) with hands on experience in open source technology.\n\n· Proficient in managing ensuring high quality standards.\n\n· I have been extensively involved in various phases of project life cycle i.e. requirement gathering, technical design, effort estimation, development, solution review, testing, production support, project/ technical lead and various \n\n\n        roles as well.\n\n· Providing solutions aligned with Business & IT Strategies whilst providing tools to monitor and evaluating projects that provide real benefit to businesses. Focusing on  this objective, I have gained broad experience in implementation, support, managing team and mentoring.\n\n  Technical Skill & Specialties\n\n\tLanguages\n\tPython (open to work on new technology)\n\n\tDatabases\n\tMySQL, PostgreSQL,  Familiar with Mongo(NOSQL).\n\n\tWeb Deigns\n\tJava Script, CSS, HTML, AngularJS, BootStrap.\n\n\tApplication Tools\n\tKapow, Git\\GitHub, Mercurial, SVN, Buganizer.  \n\n\tFramework\n\tDjango.\n\n\tOperating\n\nSystem\\Development\n\nEnvironment\n\tUbuntu(Linux based)\n\n\tWeb API Technology\n\tDjango REST Framework.\n\n\tExposure\n\tMachine Learning.\n\n\tDevelopment Methodology\n\tAgile.\n\n\nEmployment Details \n\n\nCDK Global\n\nSr. Member Technical (Since June 2017)\n\n*Project: A unified web framework which automate manual configuration and test suites of different communication devises like routers and telephony devises.\n\n*Technology: Python, Flask, MySQL, HTML, CSS, JS\n* Role & Responsibility:\n\n· Implementing Web framework.\n\n· Responsible for implementing core functionality, updating core design documentation, creating design documentation for new features and reviewing all CLs for conformation to existing coding style and work flow.\n\n· Managed project development through feature requests and bug priorities and their assignment to team members based on their skill sets and knowledge of the code base.\n\nCognizant Technology Solutions\n\nAssociate (From Sept 2015 to June 2017)\n\n* Client: Google \n\n* Project:\n\n#1. A web application that allows users to enter work assignments and mark availability on a daily basis. Each Geo location has it’s own policies and processes for how exactly to use the tool, but in general, an assignment can be created by leads, or the operator, by specifying a task (combination of country, stage, process). The data stored by this tool gives management helps insight into headcount distribution by various dimensions,  headcount availability and assignment details, and is used by multiple dashboards for metrics such as productivity, project progress and project time allotments.\n\n#2. Dash Board maintenance: A web interface which are pulling the data from multiple resources for analytics and managerial purpose. My role is here to maintain multiple dash board and also on requests developed multiple features to enhance the utility of dashboard.\n\n* Technology:\n\nPython, Django, JavaScript, BootStrap, GIT, Ubuntu, Vim editor and other internal technology like Buganizer, Piper, Borg. \n\n* Role & Responsibility:\n\n· Managing Team as well as working as individual resources.\n\n·  Responsible for implementing core functionality, updating core design documentation, creating design documentation for new features and reviewing all CLs for conformation to existing coding style and work flow.\n\n· Managed project development through feature requests and bug priorities and their assignment to team members based on their skill sets and knowledge of the code base.\n\n· Designed new administration page which included moving static values in a single file to the database and adding new APIs to support all new and existing functions. These new APIs and interfaces reduced the 5+ daily change requests turnaround time from 1 day to 2 minutes.\n\n· Maintaining the customer code standard and ethics.\n\n· Conducting interviews for hiring new resources and mentoring.\n\nSpan Across IT Solution Pvt Ltd\n\nSoftware/Product Engineer (From Nov, 2013 to Sept, 2015)\n\n* Project:\n\nWeb Product (www.taxspanner.com), that offers online preparation and filing of individual Income Tax Returns (ITR), Form-16 generation and tax calculator along with analytics. My sole  work is to upgrade the system to REST-Full API using Django REST Framework.\n\n* Technology: Python, Django REST frame work, PostgreSQL, Ubuntu, JavaScript, HTML, CSS, Mercurial.\n* Role & Responsibility:\n\n· Worked as a Full Stack Module lead Developer.\n\n· Handing Client query and requirements.\n\n· Visited multiple client location for requirements gathering and provide on-site support.\n\n· Worked as a lead for technical and non-technical (mostly CA) resources. \n\n· Understand the Financial Terminology and problem and deliver the optimize technology solution to reduce man efforts.\n\n· Since it is a small size company(startup environment) using limited resources develop and supported end to end product.\n\n· Developed solution with tight deadline.\n\n· Mentored team members for module and technology.\n\n· Maintained code standard and ethics.\n\n· Also contribute to Automate test case and integration.\n\nJade Global Software Pvt Ltd\n\nSoftware Engineer (From Aug 2012 to Nov 2013)\n\n* Client: Simply Hired\n\n* Project:\n\nI worked for Job Search Engine company where I got opportunity to work on multiple assignment like below: \n\n#1.  Data Monitoring Tool: Developed a web application which help to monitoring the process running into production, Also produce the statistics of jobs, Also validating the data (output of jobs). Some Normalization also taking place to refine the data.\n\n#2. Web Crawler: Using Python and Selenium developed script to pull the data from web, also crated multiple mirror site.\n\n#3. Robot Creation: Worked on Kapow tool to create robot file which crawl the information form the web.\n\n * Technology: Python, Django, Selenium Web Driver, PHP, HTML, CSS, JavaScript, GIT, Ubuntu, MySQL.\n\n* Role & Responsibility:\n\n· Worked as a offshore developer with reputed US based client as a front face to handle client for requirements gathering and solutions delivery.\n\n· Within 6 months of joining owning 4 project with different client and technology and managed small team for each.\n\n· Upgrade the code base technology from PHP to Python-Django.\n\n· Wrote and maintained multiple technical document for product features.\n\n· Worked as a shadow resource for other projects as well.\n\n· Re factored the reporting implementation.\n\n· Mentored new resources.\n\nEducational Background\nBachelor in Engineering from Bhabha Engineering Research Institute, Bhopal affiliated from Rajiv Gandhi Prodyogiki Vishwavidyalaya, Bhopal (M.P.) with 70.38% in the July- 2011.","annotation":[{"label":["Education"],"points":[{"start":6531,"end":6554,"text":"Bachelor in Engineering "}]},{"label":["Skills"],"points":[{"start":6287,"end":6292,"text":"Python"}]},{"label":["Skills"],"points":[{"start":5912,"end":5914,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":5905,"end":5909,"text":" HTML"}]},{"label":["Skills"],"points":[{"start":5864,"end":5869,"text":"Python"}]},{"label":["Skills"],"points":[{"start":5645,"end":5650,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4409,"end":4411,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":4402,"end":4406,"text":" HTML"}]},{"label":["Skills"],"points":[{"start":4339,"end":4344,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2997,"end":3005,"text":"BootStrap"}]},{"label":["Skills"],"points":[{"start":2969,"end":2974,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1530,"end":1532,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":1523,"end":1527,"text":" HTML"}]},{"label":["Skills"],"points":[{"start":1502,"end":1507,"text":"Python"}]},{"label":["Skills"],"points":[{"start":979,"end":987,"text":"BootStrap"}]},{"label":["Skills"],"points":[{"start":968,"end":976,"text":"AngularJS"}]},{"label":["Skills"],"points":[{"start":961,"end":965,"text":" HTML"}]},{"label":["Skills"],"points":[{"start":957,"end":959,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":944,"end":954,"text":"Java Script"}]},{"label":["Skills"],"points":[{"start":829,"end":834,"text":"Python"}]},{"label":["Education"],"points":[{"start":102,"end":106,"text":" B.E."}]},{"label":["Name"],"points":[{"start":0,"end":18,"text":"Raghvendra Pateriya"}]}],"extras":null,"metadata":{"first_done_at":1532673837000,"last_updated_at":1532673837000,"sec_taken":181,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "+91 9916-158-432\nrah.agarwal@outlook.com\nBangalore, India \n\n     RAHUL\n     AGARWAL\n         Data Scientist\n\n\n\t\t\t             Analyst seeking challenging role in transforming large, unruly data sets into competitive advantage.\n           JOB EXPERIENCES\t******************************************************************************************IBM INDIA \nEnterprise Sales Analytics:\n· Responsible for the developing a real-time streaming application (20K Data points/sec) on Spark Streaming that connects to Kafka for input, processes JSON data, requests a ML model for predicting Win Probability and sends it to Kibana for a real-time Dashboard.\n· Responsible for developing the Machine Learning Model for calculating the Win Probability value.\n· Handled the entire lifecycle of the model from pre-processing to parameter tuning of the final mode.\n· Tried multiple algorithms including but not limited to Linear Regression, Ensemble based Random Forest, GBM and XGBoost.\n· In the process of preparing a dash-board for final consumption by the leaders.\nR&D on Auto-ML:\n· Researching the use of Auto-ML as an API that could be used by developers to implement ML.\n· In the process of creating a comprehensive report outlining the comparison between multiple Auto-ML libraries available in the market.\n· Comparison includes but not limited to data-prepossessing, missing value treatment, hyper-parameter tuning, ensemble of models used and overall time taken to find out the best model.\n· Testing AutoML Libraries like Auto-Sklearn, T-Pot, MLBox etc. on real world datasets and analyse the accuracy.\n\nAFFINE ANALYTICS\nRecommendation Engine for personalized email content for a large Online Travel Company:\n· Developed a personalized communication platform to increase customer engagement by recommending right content at the right time to right set of customers for a given Campaign.\n· Built an Adaptive learning framework which can propose mail features based on multiple attributes like customer segment, campaign type, supply feeds, templates, modules etc.\n· Built an ecosystem wherein AD is generated automatically using scheduled jobs, \n· Continuous improvement on ML models for merchandizing e-mails using automation by incorporating Test and Control framework in the engine.\n· Used Logistic Regression, Random Forest, XGBoost algorithms to predict the best email content for every individual customer.\n· Built the entire engine on PySpark on Amazon EC2 via Qubole. The code was optimized to run the entire engine for over 50M+ customers within an hour using various optimization techniques. \n \nMeta-Channel Traffic Optimization for a large Online Travel Company:\n· Developed a Machine Learning engine using Random Forest to optimize the traffic for a large Travel Website thereby improving the ROI/Efficiency.\n· Created statistical model on R and PySpark to predict conversion rate of a given search query based on its historical booking patterns.\n· Performed a Cost Benefit Analysis to maximize the gross profit while maintaining a targeted efficiency using Linear Programming Optimization equation.\n· Clustering using K-means to identify distinct buckets for multiple variables.\n· Engine implementing the algorithm was built on PySpark on Amazon EC2 cluster.\n· Lead a team of 5 to implement entire algorithm successfully. \nDATA\nSCIENTIST\nJune2017-Present\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSENIOR\nBUSINESS ANALYST\nMay2016-June2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSENIOR\nDATA ANALYST\nJan 2013 – May2016\n\n\n\n\n\n\n\n\n\n\n\n\nCONSULTANT\nPart-TIme \n\n\n    DELL INTERNATIONAL SERVICES· Responsible for maintaining records, prepare statistical models, verify information and resolve routine problems. Activities included evaluate, analyze, monitor and disseminate information applicable to a specific Business requirement.\n· Collect required documentation; verify conformance of documents with standards.\n· Track, maintain and produce regular and ad hoc reports and Assesses accuracy of detailed information.\n· Analyze the SOW of different business verticals and create templates of reports/dashboard for analysis of various SLA targets and model solutions around it.\n· Generate reports on weekly basis with WTD and MTD data to closely monitor the SLA values and devise techniques to forecast and improve the efficiency of the account.\n· Generate monthly checkpoint deck for Delivery Leaders with last six month trending values of key SLA metrics.\n· Analyze the month on month data for various Service Desk accounts to find key improvement areas.\n· the Delivery leaders and help with SLA Penalty mitigations.\n·  Create statistical model for forecasting customer satisfaction metrics and also predict volumes.\n\n\n\n\n\n\n\n\t\t\t\t\n\n\n\n\n\n\t\t\t\t\n\n\n\t\t\t\t\t    \n       \n     DUDEGENIE.COM (Worked Part-time in a Chat based Virtual Assistant Startup)· Responsible for creating and monitoring growth tracking KPIs. Built visual dashboards on Excel to project the KPIs in real-time.\n· Analyze study and interpret app usage data across millions of users to understand user behavior and suggest improvements to the product team.\n· Provided insights on ROI on every marketing offer rolled out by the company. \n\n\n\n\n\n\n\n\n\t          SKILLSET\t\t*************************************************************************************\nR, Python, PySpark, C/C++\nR Studio, Jupyter Notebook, Tableau\nMS SQL Server\nSpark, PySpark, Hdfs, MapReduce\nPredictive Modelling - Linear/Logistic Regression Models, CART \nMachine Learning     - GBM, XGBoost, Random Forest, KNN, Segmentation - K-Means\nPROGRAMMING \nTOOLS\nDBMS\nBIG DATA\nANALYTICS\n\n\n\n\n\n\n\n\n\n\n   EDUCATION                **************************************************************************************B.TECH\nCOMPUTER SCIENCE\n2008 – 2012\n\nCLASS XII\nI.S.C BOARD\n2005 - 2007\n\nCLASS X\nI.C.S.E. BOARD\n1995 - 2005\n\n\n\n\n\n\n\n\t\t\t\tWEST BENGAL UNIVERSITY OF TECHNOLOGY, KOLKATA\n\t\t\t\tBranch: Computer Science & Engineering, Secured: 7.18 CGPA\t\n\n\t\t\t\tNATIONAL GEMS HIGHER SECONDARY SCHOOL, KOLKATA\n\t\t\t\tSecured: 83.2%\n\n\n\t\t\t\tNATIONAL GEMS HIGHER SECONDARY SCHOOL, KOLKATA\n\t\t\t\tSecured: 81%\n\n\n\t CERTIFICATIONS\t*************************************************************************************\n JAVA\nHADOOP\nITIL V3\nFOUNDATION\nNIIT, KOLKATA.  DURATION: 1 ½ MONTHS\nEDUPRISTINE (http://www.edupristine.com/), BANGALORE :  DURATION: 1½ Month\nAXELOS, BANGALORE\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n ACHIEVEMENTS\t************************************************************************************\n  · On Spot Award for development of EUS Global Productivity solution successfully supporting new account ‘Go-Lives’ for APJ Region at Dell.\n· Runner-up in the event Code Crackers held in the Tech-Fest of NIT DGP Aarohan’10.\n· Member of organizing committee (finance department) of college fest TRANCE ’11. \n\n    \n\n\n\n\n\n\n PERSONAL INFO\t***********************************************************************************\n\t13th April, 1989\nINDIAN\nENGLISH, HINDI, BENGALI\nMUSIC, TRAVELLING, GADGETS\nDATE OF BIRTH\t\n  NATIONALITY\n    LANGUAGES\n  HOBBIES","annotation":[{"label":["Skills"],"points":[{"start":7024,"end":7024,"text":"R"}]},{"label":["Skills"],"points":[{"start":6995,"end":6995,"text":"R"}]},{"label":["Skills"],"points":[{"start":6842,"end":6842,"text":"R"}]},{"label":["Skills"],"points":[{"start":6815,"end":6815,"text":"R"}]},{"label":["Skills"],"points":[{"start":6662,"end":6662,"text":"R"}]},{"label":["Skills"],"points":[{"start":6644,"end":6644,"text":"R"}]},{"label":["Skills"],"points":[{"start":6403,"end":6403,"text":"R"}]},{"label":["Skills"],"points":[{"start":6371,"end":6371,"text":"R"}]},{"label":["Skills"],"points":[{"start":6363,"end":6363,"text":"R"}]},{"label":["Skills"],"points":[{"start":6317,"end":6317,"text":"R"}]},{"label":["Skills"],"points":[{"start":6294,"end":6294,"text":"R"}]},{"label":["Skills"],"points":[{"start":6145,"end":6145,"text":"R"}]},{"label":["Skills"],"points":[{"start":6103,"end":6103,"text":"R"}]},{"label":["Skills"],"points":[{"start":6094,"end":6094,"text":"R"}]},{"label":["Skills"],"points":[{"start":6031,"end":6031,"text":"R"}]},{"label":["Skills"],"points":[{"start":6022,"end":6022,"text":"R"}]},{"label":["Skills"],"points":[{"start":5905,"end":5905,"text":"R"}]},{"label":["Skills"],"points":[{"start":5862,"end":5862,"text":"R"}]},{"label":["Skills"],"points":[{"start":5826,"end":5826,"text":"R"}]},{"label":["Skills"],"points":[{"start":5784,"end":5784,"text":"R"}]},{"label":["Education"],"points":[{"start":5777,"end":5792,"text":"COMPUTER SCIENCE"}]},{"label":["Skills"],"points":[{"start":5607,"end":5607,"text":"R"}]},{"label":["Skills"],"points":[{"start":5604,"end":5604,"text":"R"}]},{"label":["Skills"],"points":[{"start":5560,"end":5560,"text":"R"}]},{"label":["Skills"],"points":[{"start":5523,"end":5538,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":5519,"end":5519,"text":"R"}]},{"label":["Skills"],"points":[{"start":5498,"end":5498,"text":"R"}]},{"label":["Skills"],"points":[{"start":5452,"end":5452,"text":"R"}]},{"label":["Skills"],"points":[{"start":5436,"end":5440,"text":"Spark"}]},{"label":["Skills"],"points":[{"start":5427,"end":5431,"text":"Spark"}]},{"label":["Skills"],"points":[{"start":5377,"end":5377,"text":"R"}]},{"label":["Skills"],"points":[{"start":5371,"end":5375,"text":"C/C++"}]},{"label":["Skills"],"points":[{"start":5364,"end":5368,"text":"Spark"}]},{"label":["Skills"],"points":[{"start":5354,"end":5359,"text":"Python"}]},{"label":["Skills"],"points":[{"start":5351,"end":5351,"text":"R"}]},{"label":["Skills"],"points":[{"start":5179,"end":5179,"text":"R"}]},{"label":["Skills"],"points":[{"start":4883,"end":4883,"text":"R"}]},{"label":["Skills"],"points":[{"start":3637,"end":3637,"text":"R"}]},{"label":["Skills"],"points":[{"start":3629,"end":3629,"text":"R"}]},{"label":["Skills"],"points":[{"start":3617,"end":3617,"text":"R"}]},{"label":["Skills"],"points":[{"start":3534,"end":3534,"text":"R"}]},{"label":["Skills"],"points":[{"start":3388,"end":3388,"text":"R"}]},{"label":["Skills"],"points":[{"start":3236,"end":3240,"text":"Spark"}]},{"label":["Skills"],"points":[{"start":2853,"end":2857,"text":"Spark"}]},{"label":["Skills"],"points":[{"start":2845,"end":2845,"text":"R"}]},{"label":["Skills"],"points":[{"start":2798,"end":2798,"text":"R"}]},{"label":["Skills"],"points":[{"start":2711,"end":2711,"text":"R"}]},{"label":["Skills"],"points":[{"start":2681,"end":2696,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":2437,"end":2441,"text":"Spark"}]},{"label":["Skills"],"points":[{"start":2307,"end":2307,"text":"R"}]},{"label":["Skills"],"points":[{"start":2295,"end":2295,"text":"R"}]},{"label":["Skills"],"points":[{"start":1615,"end":1615,"text":"R"}]},{"label":["Skills"],"points":[{"start":1071,"end":1071,"text":"R"}]},{"label":["Skills"],"points":[{"start":1053,"end":1053,"text":"R"}]},{"label":["Skills"],"points":[{"start":940,"end":940,"text":"R"}]},{"label":["Skills"],"points":[{"start":913,"end":913,"text":"R"}]},{"label":["Skills"],"points":[{"start":680,"end":695,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":649,"end":649,"text":"R"}]},{"label":["Skills"],"points":[{"start":475,"end":479,"text":"Spark"}]},{"label":["Skills"],"points":[{"start":385,"end":385,"text":"R"}]},{"label":["Skills"],"points":[{"start":246,"end":246,"text":"R"}]},{"label":["Skills"],"points":[{"start":79,"end":79,"text":"R"}]},{"label":["Name"],"points":[{"start":65,"end":82,"text":"RAHUL\n     AGARWAL"}]},{"label":["Skills"],"points":[{"start":65,"end":65,"text":"R"}]},{"label":["Location"],"points":[{"start":41,"end":49,"text":"Bangalore"}]}],"extras":null,"metadata":{"first_done_at":1532671486000,"last_updated_at":1532671486000,"sec_taken":130,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Udaya Laxmi Ch\n\nEmail : laxmi.udaya@gmail.com\n\n\t\n\n\tPhone: -9740606990\n\t\n\n\n\tSummary\n\n\t· 9.5 years of experience in Software Development.\n· 3.5 years of experience in Machine Learning\n· Primary Skills – Machine Learning, R programming, Lotus Notes.\n· Presently working for Wipro Technologies, Bangalore.\n· Experience in planning, estimation, design, development, and testing object oriented applications.\n· Experience in preparing various technical documents like Functional Specs, HLD, LLD, Flowcharts and Test cases.\n· Sound Knowledge in Object Oriented Design Principles\n· Have Team Handling experience.\n· Domain experience of Manufacturing and Finance.\n· Have Experience in Scrum Agile Model\n· Understand business requirements from clients\n\n\n\n\tTechnical Skills\n\n\tKey skills: \n\tMachine Learning,R Programming, MySQL, PostgreSQL, Microsoft Access, SQL Server, FileMaker, Oracle, RDBMS, dBASE, Clipper, FoxPro, Firebase, Mongodb, Python,  ava, J2EE, Oracle Fusion,Oracle Cloud, Salesforce, Devops Android, Business Analyst, UI Developer, DBAs, Embedded Systems, .NET, Hadoop, SQL Developer, Big Data, Tableau, Networking, Etl, Informatica, Ios, Quality Analyst, Project Manager, Python, Data Science, Python, Machine Learning, SAS, Java, Scala, Hadoop, Hive, Bigdata, Programming, SQL server reporting, Msbi Ssis, Ssrs, Msbi, Sql Reporting, Artificial Intelligence, Pandas, Pyspark, Sklearn, Flask, Django, Map Reduce, Parametric Design, Modeling, Regression, Patterns, Data Mining, Text Mining, Oops, Deep Learning, Web Analytics, Time Series, Regression, Tensorflow, Azure, Linear Regression, Logistic Regression, Decision Tree, Random Forest, Data Structure, Computer Vision, IHS, WAS, Java EE, SQL Server, .NET core, C#, ASP.NET, Rdlc, Linq, Sql, Web Api, Mvc, Javascript, Web Services, Oracle, MS SQL, PHP, Laravel, CodeIgniter, Symfony, Zend, Phalcon, CakePHP, Yii, FuelPHP, React, Vue, Angular, Ember, Backbone, Lotus Notes\n\n\tAlgorithms:\n\tNaïve Bayes, K means clustering,Word Cloud\n\n\tDatabases: \n\tMicrosoft SQL, Mongo DB\n\n\tWeb Technologies: \n\tXML, XSLT, HTML,  JavaScript,  AJAX, JQuery\n\n\tIDE:\n\tR studio,Pycharm\n\n\n\tProfessional Experience\n\n\tCurrent Employer :\n\tWipro Technologies., Bangalore  – (Oct  2010  to till date) – Technical Lead/Data Scientist\n\n\tPrevious Employers :\n\tHSBC Software development , Hyderabad (June  2008  to Sep 2010)  - SE\n\n\n\tQualification\n\n\tDegree\n\tCollege\n\tUniversity/Board\n\tYear\n\tPercentage (%)\n\n\tMCA\n\tNizam College, Basheerbagh,Hyderabad\n\tOsmania University\n\t2008\n\t75\n\n\n\tProject Experience \n\n\tProject 1 : Exploratory Data Analysis:\n\nProject Description:   Performed EDA analysis to analyze the Purchase frequency of vehicles which occurred over past 3 years and try to predict the frequency occurring in the future.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Performed EDA analysis to find the insights of the data. Observed the summary of each and every variable to understand the variables.\n\n· Performed the feature selection using hypothesis testing.\n\n· Identified the outliers using box plot.\n\n· Identified the trend in the purchases using histogram.\n\n\n\n\tProject 2: Word Cloud Analysis:\n\nProject Description:   Performed Word cloud and Sentimental Analysis of the customer feedbacks. Graphically represented the most frequently occurred words through Word cloud. Through sentimental analysis we identified whether a user-generated text expresses positive, negative or neutral opinion.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Created a Corpus using TM package and performed pre-processing of data.\n\n· Removed the punctuations, stemming and stop words which are of no analytical value.\n\n· Built a Document term matrix and identified the most frequently occurring words\n\n· Graphically represented it using  RColorbrewer Package\n\n\n\tProject 3: Sentimental Analysis:\n\nProject Description: Performed Sentimental Analysis of customer feedbacks through Naïve Bayes. Used “e1071” Package for implementing naïve Bayes method.\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· The DTM created using TM package was an input to the Naive Bayes Model.\n\n· As Naive Bayes classifier is typically trained on data with categorical features. We have converted the count of the words into a factor variable that indicates Yes or No whether the word is present or not.\n\n\tProject 4: Clustering Analysis:\n\nProject Description: Classified the customers on the basis of their purchases whether they have purchased low variant or high variant trucks. It in turn helped in building the right customer strategies.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Performed data preparation and Normalization of data using min-max method.\n\n· As K-means algorithm groups a dataset into a user-specified number (k) of clusters. Identified the initial cluster centroids as 3.\n\n· K clusters are creating by associating every observation with the nearest mean.\n\n· Used elbow method to validate the number of clusters such that within-cluster sum of square(wss) is minimized.\n\n\n\n\tProject 5 : Inter Connection Management Tool\nProject Description: Inter-connection Management (IMT) is prototype being developed for Engineering and Sales department to handle customizations of an existing product based on the customer's requirement. Users from engineering department will identify the items, which need to be customized out of the entire product design.\nRole\n\n       : Module Lead\n\nEnvironment\n       : Python, Mongo DB, jQuery\n\nTasks handled:\n\n· Gathering Requirements and providing Project Plan and Effort Estimation details.\n\n· Understanding business requirements and preparing SoU (Statement of Understanding) and Functional/Technical Specification documents.\n\n· Providing Effort & Resource estimations\n\n· Planning for application development and deployment\n\n· Writing and executing Test Cases and Test scenarios\n\n· Creating design elements using Technical Specification.\n\n· Performing Unit testing & Peer Reviews\n\n· Work Allocation and mentoring the team\n\n· Providing Technical guidance to the team. \n\n\tProject 6\n: cvdAEI Application\n\nProject Description\n     : CVDAEI is a web based multilingual application developed for handling the Change Management process in Truck division of Daimler. The change request flows through different phases mainly Initialization, Evaluation, Decision and Conclusion. This application has a configurable workflow where the request flow and the responsible persons can be configured easily at any point of time. \n\nRole\n\n    : Developer/Tester\n\nEnvironment\n     : Lotus Notes, Java, HTML, XML, Java Script, JQuery\n\nTasks handled:\n\n· Gathering Requirements and providing Project Plan and Effort Estimation details.\n\n· Understanding business requirements and preparing SoU (Statement of Understanding) and Functional/Technical Specification documents.\n\n· Providing Effort & Resource estimations\n\n· Planning for application development and deployment\n\n· Writing and executing Test Cases and Test scenarios\n\n· Creating design elements using Technical Specification.\n\n· Performing Unit testing & Peer Reviews\n\n· Work Allocation and mentoring the team\n\n· Providing Technical guidance to the team. \n\n\n\n\tProject Title: Project Management Office \nProject Description: The purpose of this system is to enable the Project Management Office to manage and execute the IT Applications and Operations driven project tasks in  more systematic manner. It will also enable them to efficiently perform a role as a facilitator to coordinate various IT Operations teams and to ensure that project activity enters the department through one common interface. The project tasks will subsequently be dealt with in a common format and in a consistent and appropriate manner, ensuring open and regular communication between all involved parties.\n\nRole\n\n    : Developer/Tester\n\nEnvironment\n     : Lotus Notes, Java, HTML, XML, Java Script, JQuery\n\nTasks Handled :\n\n· Writing and Executing Test cases in client server based environment\n· Individually provided application support","annotation":[{"label":["Skills"],"points":[{"start":7951,"end":7956,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":7938,"end":7948,"text":"Java Script"}]},{"label":["Skills"],"points":[{"start":7933,"end":7935,"text":"XML"}]},{"label":["Skills"],"points":[{"start":7927,"end":7930,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":7921,"end":7924,"text":"Java"}]},{"label":["Skills"],"points":[{"start":7908,"end":7918,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":6645,"end":6650,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":6632,"end":6642,"text":"Java Script"}]},{"label":["Skills"],"points":[{"start":6627,"end":6629,"text":"XML"}]},{"label":["Skills"],"points":[{"start":6621,"end":6624,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":6615,"end":6618,"text":"Java"}]},{"label":["Skills"],"points":[{"start":6602,"end":6612,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":5522,"end":5527,"text":"jQuery"}]},{"label":["Skills"],"points":[{"start":5512,"end":5519,"text":"Mongo DB"}]},{"label":["Skills"],"points":[{"start":5504,"end":5509,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4645,"end":4652,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":4054,"end":4061,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":3941,"end":3951,"text":"Naïve Bayes"}]},{"label":["Skills"],"points":[{"start":3494,"end":3501,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":3132,"end":3141,"text":"Word Cloud"}]},{"label":["Skills"],"points":[{"start":2793,"end":2800,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":2110,"end":2116,"text":"Pycharm"}]},{"label":["Skills"],"points":[{"start":2101,"end":2108,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":2086,"end":2091,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":2080,"end":2083,"text":"AJAX"}]},{"label":["Skills"],"points":[{"start":2067,"end":2076,"text":"JavaScript"}]},{"label":["Skills"],"points":[{"start":2060,"end":2063,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":2054,"end":2057,"text":"XSLT"}]},{"label":["Skills"],"points":[{"start":2049,"end":2051,"text":"XML"}]},{"label":["Skills"],"points":[{"start":2018,"end":2025,"text":"Mongo DB"}]},{"label":["Skills"],"points":[{"start":2003,"end":2015,"text":"Microsoft SQL"}]},{"label":["Skills"],"points":[{"start":1977,"end":1986,"text":"Word Cloud"}]},{"label":["Skills"],"points":[{"start":1958,"end":1975,"text":"K means clustering"}]},{"label":["Skills"],"points":[{"start":1945,"end":1955,"text":"Naïve Bayes"}]},{"label":["Skills"],"points":[{"start":1918,"end":1928,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":1908,"end":1915,"text":"Backbone"}]},{"label":["Skills"],"points":[{"start":1901,"end":1905,"text":"Ember"}]},{"label":["Skills"],"points":[{"start":1892,"end":1898,"text":"Angular"}]},{"label":["Skills"],"points":[{"start":1887,"end":1889,"text":"Vue"}]},{"label":["Skills"],"points":[{"start":1880,"end":1884,"text":"React"}]},{"label":["Skills"],"points":[{"start":1871,"end":1877,"text":"FuelPHP"}]},{"label":["Skills"],"points":[{"start":1866,"end":1868,"text":"Yii"}]},{"label":["Skills"],"points":[{"start":1857,"end":1863,"text":"CakePHP"}]},{"label":["Skills"],"points":[{"start":1848,"end":1854,"text":"Phalcon"}]},{"label":["Skills"],"points":[{"start":1842,"end":1845,"text":"Zend"}]},{"label":["Skills"],"points":[{"start":1833,"end":1839,"text":"Symfony"}]},{"label":["Skills"],"points":[{"start":1820,"end":1830,"text":"CodeIgniter"}]},{"label":["Skills"],"points":[{"start":1811,"end":1817,"text":"Laravel"}]},{"label":["Skills"],"points":[{"start":1806,"end":1808,"text":"PHP"}]},{"label":["Skills"],"points":[{"start":1798,"end":1803,"text":"MS SQL"}]},{"label":["Skills"],"points":[{"start":1790,"end":1795,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":1776,"end":1787,"text":"Web Services"}]},{"label":["Skills"],"points":[{"start":1764,"end":1773,"text":"Javascript"}]},{"label":["Skills"],"points":[{"start":1759,"end":1761,"text":"Mvc"}]},{"label":["Skills"],"points":[{"start":1750,"end":1756,"text":"Web Api"}]},{"label":["Skills"],"points":[{"start":1745,"end":1747,"text":"Sql"}]},{"label":["Skills"],"points":[{"start":1739,"end":1742,"text":"Linq"}]},{"label":["Skills"],"points":[{"start":1733,"end":1736,"text":"Rdlc"}]},{"label":["Skills"],"points":[{"start":1724,"end":1730,"text":"ASP.NET"}]},{"label":["Skills"],"points":[{"start":1720,"end":1721,"text":"C#"}]},{"label":["Skills"],"points":[{"start":1709,"end":1717,"text":".NET core"}]},{"label":["Skills"],"points":[{"start":1697,"end":1706,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":1688,"end":1694,"text":"Java EE"}]},{"label":["Skills"],"points":[{"start":1683,"end":1685,"text":"WAS"}]},{"label":["Skills"],"points":[{"start":1678,"end":1680,"text":"IHS"}]},{"label":["Skills"],"points":[{"start":1661,"end":1675,"text":"Computer Vision"}]},{"label":["Skills"],"points":[{"start":1645,"end":1658,"text":"Data Structure"}]},{"label":["Skills"],"points":[{"start":1630,"end":1642,"text":"Random Forest"}]},{"label":["Skills"],"points":[{"start":1615,"end":1627,"text":"Decision Tree"}]},{"label":["Skills"],"points":[{"start":1594,"end":1612,"text":"Logistic Regression"}]},{"label":["Skills"],"points":[{"start":1575,"end":1591,"text":"Linear Regression"}]},{"label":["Skills"],"points":[{"start":1568,"end":1572,"text":"Azure"}]},{"label":["Skills"],"points":[{"start":1556,"end":1565,"text":"Tensorflow"}]},{"label":["Skills"],"points":[{"start":1544,"end":1553,"text":"Regression"}]},{"label":["Skills"],"points":[{"start":1531,"end":1541,"text":"Time Series"}]},{"label":["Skills"],"points":[{"start":1516,"end":1528,"text":"Web Analytics"}]},{"label":["Skills"],"points":[{"start":1501,"end":1513,"text":"Deep Learning"}]},{"label":["Skills"],"points":[{"start":1495,"end":1498,"text":"Oops"}]},{"label":["Skills"],"points":[{"start":1482,"end":1492,"text":"Text Mining"}]},{"label":["Skills"],"points":[{"start":1469,"end":1479,"text":"Data Mining"}]},{"label":["Skills"],"points":[{"start":1459,"end":1466,"text":"Patterns"}]},{"label":["Skills"],"points":[{"start":1447,"end":1456,"text":"Regression"}]},{"label":["Skills"],"points":[{"start":1437,"end":1444,"text":"Modeling"}]},{"label":["Skills"],"points":[{"start":1418,"end":1434,"text":"Parametric Design"}]},{"label":["Skills"],"points":[{"start":1406,"end":1415,"text":"Map Reduce"}]},{"label":["Skills"],"points":[{"start":1398,"end":1403,"text":"Django"}]},{"label":["Skills"],"points":[{"start":1391,"end":1395,"text":"Flask"}]},{"label":["Skills"],"points":[{"start":1382,"end":1388,"text":"Sklearn"}]},{"label":["Skills"],"points":[{"start":1373,"end":1379,"text":"Pyspark"}]},{"label":["Skills"],"points":[{"start":1365,"end":1370,"text":"Pandas"}]},{"label":["Skills"],"points":[{"start":1340,"end":1362,"text":"Artificial Intelligence"}]},{"label":["Skills"],"points":[{"start":1325,"end":1337,"text":"Sql Reporting"}]},{"label":["Skills"],"points":[{"start":1325,"end":1327,"text":"Sql"}]},{"label":["Skills"],"points":[{"start":1319,"end":1322,"text":"Msbi"}]},{"label":["Skills"],"points":[{"start":1313,"end":1316,"text":"Ssrs"}]},{"label":["Skills"],"points":[{"start":1302,"end":1310,"text":"Msbi Ssis"}]},{"label":["Skills"],"points":[{"start":1302,"end":1305,"text":"Msbi"}]},{"label":["Skills"],"points":[{"start":1280,"end":1299,"text":"SQL server reporting"}]},{"label":["Skills"],"points":[{"start":1267,"end":1277,"text":"Programming"}]},{"label":["Skills"],"points":[{"start":1258,"end":1264,"text":"Bigdata"}]},{"label":["Skills"],"points":[{"start":1252,"end":1255,"text":"Hive"}]},{"label":["Skills"],"points":[{"start":1244,"end":1249,"text":"Hadoop"}]},{"label":["Skills"],"points":[{"start":1237,"end":1241,"text":"Scala"}]},{"label":["Skills"],"points":[{"start":1231,"end":1234,"text":"Java"}]},{"label":["Skills"],"points":[{"start":1226,"end":1228,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1208,"end":1223,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1200,"end":1205,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1186,"end":1197,"text":"Data Science"}]},{"label":["Skills"],"points":[{"start":1178,"end":1183,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1161,"end":1175,"text":"Project Manager"}]},{"label":["Skills"],"points":[{"start":1144,"end":1158,"text":"Quality Analyst"}]},{"label":["Skills"],"points":[{"start":1139,"end":1141,"text":"Ios"}]},{"label":["Skills"],"points":[{"start":1126,"end":1136,"text":"Informatica"}]},{"label":["Skills"],"points":[{"start":1121,"end":1123,"text":"Etl"}]},{"label":["Skills"],"points":[{"start":1109,"end":1118,"text":"Networking"}]},{"label":["Skills"],"points":[{"start":1100,"end":1106,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":1090,"end":1097,"text":"Big Data"}]},{"label":["Skills"],"points":[{"start":1075,"end":1087,"text":"SQL Developer"}]},{"label":["Skills"],"points":[{"start":1067,"end":1072,"text":"Hadoop"}]},{"label":["Skills"],"points":[{"start":1061,"end":1064,"text":".NET"}]},{"label":["Skills"],"points":[{"start":1043,"end":1058,"text":"Embedded Systems"}]},{"label":["Skills"],"points":[{"start":1037,"end":1040,"text":"DBAs"}]},{"label":["Skills"],"points":[{"start":1023,"end":1034,"text":"UI Developer"}]},{"label":["Skills"],"points":[{"start":1005,"end":1020,"text":"Business Analyst"}]},{"label":["Skills"],"points":[{"start":989,"end":1002,"text":"Devops Android"}]},{"label":["Skills"],"points":[{"start":977,"end":986,"text":"Salesforce"}]},{"label":["Skills"],"points":[{"start":963,"end":974,"text":"Oracle Cloud"}]},{"label":["Skills"],"points":[{"start":949,"end":961,"text":"Oracle Fusion"}]},{"label":["Skills"],"points":[{"start":943,"end":946,"text":"J2EE"}]},{"label":["Skills"],"points":[{"start":929,"end":934,"text":"Python"}]},{"label":["Skills"],"points":[{"start":920,"end":926,"text":"Mongodb"}]},{"label":["Skills"],"points":[{"start":910,"end":917,"text":"Firebase"}]},{"label":["Skills"],"points":[{"start":902,"end":907,"text":"FoxPro"}]},{"label":["Skills"],"points":[{"start":893,"end":899,"text":"Clipper"}]},{"label":["Skills"],"points":[{"start":886,"end":890,"text":"dBASE"}]},{"label":["Skills"],"points":[{"start":879,"end":883,"text":"RDBMS"}]},{"label":["Skills"],"points":[{"start":871,"end":876,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":860,"end":868,"text":"FileMaker"}]},{"label":["Skills"],"points":[{"start":848,"end":857,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":830,"end":845,"text":"Microsoft Access"}]},{"label":["Skills"],"points":[{"start":818,"end":827,"text":"PostgreSQL"}]},{"label":["Skills"],"points":[{"start":811,"end":815,"text":"MySQL"}]},{"label":["Skills"],"points":[{"start":798,"end":808,"text":"Programming"}]},{"label":["Skills"],"points":[{"start":796,"end":808,"text":"R Programming"}]},{"label":["Skills"],"points":[{"start":779,"end":794,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":234,"end":244,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":219,"end":231,"text":"R programming"}]},{"label":["Skills"],"points":[{"start":201,"end":216,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":165,"end":180,"text":"Machine Learning"}]},{"label":["Name"],"points":[{"start":0,"end":13,"text":"Udaya Laxmi Ch"}]}],"extras":null,"metadata":{"first_done_at":1579625576000,"last_updated_at":1579626369000,"sec_taken":0,"last_updated_by":"aJOmJy1lvpOYFetVNuqLvFo9Vx42","status":"done","evaluation":"NONE"}}
{"content": "RAJ KUMAR ROY \n\nSandal Garden Apartments Thoripakkam, Chennai 600096 \n\n +91-9655636248 | Email: rareraj@outlook.com| \n\n \nProfessional Summary \n\n  \n\n Over 3+ years of extensive IT experience in Retail and FMCG domain to develop business \n\nsolutions that enable better decision making. \n\n Experienced in systems of insights, data science & advanced analytics, big data, cloud and \n\ndata management. \n\n Won Bronze Pillar award in Mindtree for the year 2016-17. \n\n Outstanding Performer for the year 2015-16 and 2016-17. \n\n Good Leadership, mentoring and interpersonal skills, believe in leading by doing. \n\n \n\n \n\nOrganizational Experience: \n\n \n\nOrganization Role Experience \n\nMINDTREE LTD Senior Engineer  OCTOBER 2014 - Till Date \n\n \n\n \n\nTools & Technologies \n\n \nCloud AWS S3 , EMR , EC2  \n\nData Storage SQL-Server, AWS Redshift  \n\nData Processing Spark, PL/SQL  \n\nAnalytics \nTechniques/Algorithm  \n\nCollaborative Filtering, Predictive Modeling (Linear \n\nRegression, Logistic Regression), Segmentation/Clustering \n\nProgramming \nLanguages  \n\nR, Python, Scala , PL/SQL, Shell Scripting  \n\n \n\nZxcsdlvmsdlmvlsdvlds,v,sd mnksd sdm, md cm \n\nsdcdcklmdklviowifkcsdlclwekmoiwemocmsmkdcl \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\nProject Details    \n\n \nSenior Engineer     : Feb15- Till date  \n\nClient            : Decision Support Group for a CPG Major \n\nProblem Statement :The Client is a CPG major and wanted to improve their sales planning for      \n\ntheir General Trade in terms of ensuring right products move to right outlet in \n\nright time, increasing the On-self Availability of their products, increasing the \n\nreach in customer and not losing any. \n\nResponsibilities / Contributions: \n\n To churn out the various recommendations like Out Of stock, Suggested Order Quantity and \n\nWidth pack for the client on monthly and quarterly basis. \n\n Helped client to launch the new Products in the market in different Geographic’s and \n\ndemography.    \n\n Implemented the Machine-learning algorithm Collaborative Filtering that increased the sales \n\nrecommendations and improved cross selling.  \n\n Migrated the on premise project ecosystem to a Cloud and Big Data Platform. \n\n Analyze the sales/transactional data on monthly biases and represent the analysis in \n\nwaterfall format. \n\n To take the client’s adhoc requirements. \n\n Optimized the performance of business-critical queries. \n\n Automations of many manual tasks with the help of niche technology like SPARK. \n\n To maintain the on premise database like releasing space, compression, removing the \n\ntemporary files etc. \n\n \n\n\n\n \n\n \n\nCertifications \n\n \n\n Certified Python Big Data Expert from Edureka  \n\n Certified Data Science R-Programming from Simplilearn \n\n \n\n \n\nEducational Qualification’s\n\n \n\n B.Tech in Electronics and Communication (2010-14) from NITMAS with 7.7/10 CGPA \n\n 12th (2009) From Army Public School Delhi Cantt, New Delhi with 79%. \n\n 10th (2007) From Army Public School Danapur, Patna Bihar with 77%. \n\n \n\n |Date Of Birth: 4 March 1992 | Language Proficiency: English and Hindi |","annotation":[{"label":["Education"],"points":[{"start":2802,"end":2807,"text":"B.Tech"}]},{"label":["Skills"],"points":[{"start":869,"end":877,"text":"Analytics"}]},{"label":["Skills"],"points":[{"start":788,"end":790,"text":"EC2"}]},{"label":["Skills"],"points":[{"start":782,"end":784,"text":"EMR"}]},{"label":["Skills"],"points":[{"start":767,"end":778,"text":"Cloud AWS S3"}]},{"label":["Name"],"points":[{"start":0,"end":13,"text":"RAJ KUMAR ROY "}]}],"extras":null,"metadata":{"first_done_at":1532672190000,"last_updated_at":1532672190000,"sec_taken":77,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Rajat Sarker \nBangalore, Jayanagar\nEmail: rajat9sarkar@gmail.com\nPhone: +91- 9717820265\nMasters of Statistics from Amity University with 3 years of experience in TATA CONSULTANCY SERVICES as a Business Analyst, 1 years as Data Analyst in R and Python with MMPL and presently working with iNurture as Senior trainer in Business Analytics in R and Python.\nOBJECTIVE:  \n· To take a challenging post for understanding business changes needs, assessing the impact of those changes, capturing, analyzing through tools like Python-Pandas and Numpy, Tensorflow, R-Software, Hadoop, SAS, advanced Excel and documenting requirements and then supporting the communication and delivery of those requirements with relevant parties.\nPROFESSIONAL EXPERIENCE (2010-2013) – (2015-2016):\n· Worked in the project to create consumer choice model using Random Forest machine learning algorithm.\n· Worked in creating various matrix of monthly turnover.\n\n· Creating an API in python to generate all the analytics using Django web frame work and Jinja Templating.\n· Conducted process analysis in accordance with Television Audience Measurement by quantifying (size) and qualifying (characteristics) this detailed television audience information by performing statistical analysis on television viewing data for NIELSEN.\n· Modeling on Logistic Regression, Ordinal regression and multinomial regression and monitoring the performance of the model.\n· Data Mining.\n· Worked in the platform of SAS and Proc(SQL), R-Software, Advanced Excel and Unix VBA Scripting, Macros in generating Client’s reports.\n· Proficient in R-Software, SAS and advanced excel to make statistical model.\n· Creating several matrix of telecom operator for 16 different states in India. Analyzing the performance state wise, district wise, Technicians. \n· Have been successful in delivering complete report with 100% accuracy and on time.\n· Generating various analytical reports using R-Software and Excel and reporting to our client.\n· Certified as an associate Catalyst: acting as bridge between the associates and HR.\nEMPLOYER:\n·  TATA CONSULTANCY SERVICES (3 years of Experience)\n·  MMPL ( 1 year)\n·  iNurture ( Currently working)\nPROJECT DETAILS in (TCS):\n\n· PROJECT NAME :- MEASUREMENT SCIENCE\n· CLIENT NAME:- NIELSEN\n· DURATION:- 28/06/2010    TO    8/05/2013\nPROJECT DESCRIPTION:\n\nThe field is television audience measurement for North America. TAM (Television Audience Measurement) is the specialized branch of media research, dedicated to quantifying (size) and qualifying (characteristics) this detailed television audience information by performing statistical analysis on television viewing data. Making Logistic Regression model and monitoring the performance of the model. Using the platform of R-Software, SAS and Advanced Excel. \nPROJECT DETAILS in (MMPL):\nProject Name: Data Analyst \nSoftware :- R-Software and Python- Pandas and numpy\nDuration:- 1 year ( 5th Feb 2016 – 12 Jan 17)\nPROJECT DESCRIPTION: \n\n· Worked in the project to create consumer choice model. Consumers are given loan based on many criteria’s. To filter those criteria and create a model that best represent the data using R-software and python machine learning algorithm.\n· Worked in creating various matrix of monthly turnover. Going to roots sources of turnovers. Highlighting the cross section of various parameters.\n· Creating an API in python to generate all the analytics and using Django Web-frame work to automate and make all the analytics real-time.\n\nPROJECT DETAILS in (I-nurture):\nProject Name: Senior Trainer in Business Analytics\n\nSoftware :- R-Software and Python- Pandas and numpy\nDuration:- Currently Working  ( 13 Jan 2017 to present)\nPROJECT DESCRIPTION: \n\n· Imparting Statistical knowledge like to faculties and aspiring students.\n\n· Giving Practical training in R and python.\n\nSKILL SET:\n\n· Python- Pandas and Numpy for building models \n· Machine learning Algorithm\n\n· Tensorflow\n\n· Python web-scraping \n\n· R-Software for Statistical Analysis\n· Hadoop (Hive)\n· SAS \n· Proc (SQL)\n· Advanced Excel\n· UNIX\n· MICROSOFT OFFICE WORD ,POWER POINT AND EXCEL\n· VBA, MACROS. \n· LOGISTIC REGRESSION\n· ORDINAL REGRESSION\n· MULTINOMIAL REGRESSION\n· MULTIPLE REGRESSION\n· TIME SERIES ANALYSIS \n· ARIMA MODELLING\n· STATISTICAL ANALYSIS\n· DATA MINING \n· TESTING OF HYPOTHESIS\n· MANAGING SKILL (ASSOCIATE CATALYST IN TCS, CLASS REPRESENTATIVE)\nEDUCATION:\n\n    SCHOOL/COLLEGE                   \nSTREAM\n\n  PASSING YEAR        PERCENTAGE\n· HIGH SCHOOL                            SCIENCE                                        2007                    63\n· GRADUATION            BSC (Computer Sci., Math’s, Stats)                   2010                    68\n· POST GRAD                           MSC  STATISTICS                               2015    \n 7.3 (CGPA)\nINTERNSHIPS/PROJECTS:\nSummer Internship (2014) \n\n· Name of the organization: - Indian Council of Medical Research at National institute of medical Science.\nPlace: - Delhi\n\nDuration: - from 01/05/13 to 31/06/13\n\nDescription: - Analyzing growth rate of disabilities within each states. Studying different categories of disabilities, which prevail in each states and their social life.\nProject (2015):\n\n· Name of the Organization:- Amity University\n\nPlace:-Noida\n\nDuration:- from  01/01/2015 to 02/03/2015\n\nDescription:- Statistical Analysis for five students of Master of Physiotherapy Department. I have done hypothesis testing for their relevant medical data.\n\nDissertation(2015):\n\n· Name of the organization:- Amity University\nPlace:- Noida\n\nDuration:- from 01/02/2015 to 01/05/2015\n\nDescription:- Univariate Distribution and its application.  \n\nFinding maximum likelihood method, Hazard Rate, Survival Function and Probability density function. The properties and application is analyzed using R-software. Graphs are plotted using different parametric combinations.  It helped in analyzing the behavior of the distributions.\nEXTRA-CURRICULAR ACTIVITIES: \n\n· Sports- Football (Part of football team for my Department).\n· Organizing activities for department.\n\n· Anchoring.  \nHOBBIES AND LEASURE:\n\n· ENTHUSIAST IN SPORT (CRICKET, FOOTBALL, BADMINTON, BASKETBALL).\n· ENHANCING PROGRAMMING SKILLS \n· READING BOOKS, NOVELS, CURRENT AFFAIRS, ECONOMMIC DEVELOPEMENTS.\n· PLAYING GUITAR \n· WATCHING TELEVISION\n· PARTICIPATING IN DEBATES \n· LEARNING LANGUAGES\nLANGUAGE:\n· ENGLISH\n· BENGALI\n· HINDI\nPERSONAL INFORMATION:\n\n· NAME:- RAJAT SARKER\n· AGE :- 30 YEARS\n· EMAIL :-rajat9sarkar@gmail.com\n· PHONE NO. :-9717820265\n· COUNTRY :- INDIA","annotation":[{"label":["Education"],"points":[{"start":4729,"end":4732,"text":"MSC "}]},{"label":["Skills"],"points":[{"start":2833,"end":2844,"text":"Data Analyst"}]},{"label":["Skills"],"points":[{"start":222,"end":233,"text":"Data Analyst"}]},{"label":["Skills"],"points":[{"start":193,"end":208,"text":"Business Analyst"}]},{"label":["Location"],"points":[{"start":14,"end":22,"text":"Bangalore"}]},{"label":["Name"],"points":[{"start":0,"end":11,"text":"Rajat Sarker"}]}],"extras":null,"metadata":{"first_done_at":1532668243000,"last_updated_at":1532668243000,"sec_taken":105,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Rajesh Das \n\nMobile no: +91-7890571071\n\n\nE-mail: rajeshdas.up@gmail.com\n\nSeeking a challenging position as a Software Developer with a growth-oriented     organization where my skills and experience will be utilized their full potential.\n\n· Proficient in conceptualizing, designing and coding technical solutions using PYTHON technology stacks.\n· Having 2.5 years of experience in PYTHON/DJANGO/POSTGRES technologies and previously 3.5 years of experience in PHP/MYSQL.\n\n· Strong Programming Skills in designing and implementation of complex applications using DJANGO.\n· Experience in working with Docker .\n\n· Hands on experience of application development and enhancement using Client/ Server concepts.\n\n· Extensive Object Oriented Development experience.\n\n· Experience in Version controls like GIT.\n\n· Good communication and interpersonal skills. Excellent problem solving skills with a strong technical background and enthusiastic, with a high degree of commitment.\n\n· \n\tPython Technologies\n\tPython, Django\n\n\tScripting Languages\n\tJavaScript,Jqury\n\n\tRDBMS\n\tMySQL/Postgres\n\n\tSoftware Development Methodology\n\tAgile Methodology\n\n\tIDE’s\n\tPycharm\n\n\tVersion Controller\n\tGIT\n\n\n\n\tQUALIFICATION\n\tUNIVERSITY/BOARD\n\tYEAR\n\tMARKS (%)\n\n\t10th\n\tBoard of secondary Education, Odisha\n\t2004\n\t70\n\n\t+2\n\tCouncil of higher secondary,  Education, Odisha\n\t2006\n\t61\n\n\tBCA\n\tFakir Mohan University\n\t2009\n\t72\n\n\n\n· From Jan 2012 to till date as “Software Engineer “with Remote Programmer India Pvt. Ltd.\n\n\nProject#1: Fobs Betting Software\nEnvironment: Python,  Django,  AJAX,  Jquery,  JavaScript,  HTML,  CSS, Postgres\nTeam Size: 6\nDescription: Fobs is a betting software. There are different games(Lottery Games, Sports etc..) in which player can place bet and can win attractive prizes. This software is running different country in Africa(South Africa, Kenya etc.). It has also some marketing tools to increase customer base  Ex.SMS campaign, Email campaign, Affiliate tracking, Vendor, Bonus system etc.\n\nResponsibilities:\n· Requirement analysis for building new feature.\n· Involved on backend development on different stuff with writing optimized postgres query.\n\n· Involved on frontend to develop new rich customer friendly features.\n\n· Wrote Optimized db query and implemented cache system to increase the db performance.\n\n· Worked on REST API and SOUP API to handle 3rd party APIs like SMS, USSD, Game Results etc.\n\nProject#2: Osier Fleet Management(ERP Software)\n\nEnvironment: Python, Django, AJAX, Jquery, Javascript, HTML, CSS, Postgres\nTeam Size: 2\nDescription: Osier is the partner of uber cab service in South Africa. This application is used to manage the business and automate many back office functions related to technology, services and human resources. It tracks all the details like vehicles, drivers(Online status, Login hour etc.), trips with location details and also employees details etc. System calculates correct figure of calculation like profit, investment, liability etc for different periods (Monthly, Weekly, Yearly) and also send remuneration to employees.\n\nResponsibilities:\n\n· Worked on Django/Postgres according to Requirement.\n\n· Made analysis for building the required new feature.\n\n· Developed both frontend and backend.\n\n· Worked on REST APIs.\n\nProject#4: School Management System\n\nEnvironment: PHP , AJAX, Jquery, Javascript, HTML, CSS, MySql\nTeam Size: 2\nDescription: This application is used to track student, teacher, management people details like attendance, salary, leave application details. It also figure out expenses, income, profits etc..\nResponsibilities:\n\n· Worked on YII(php framework).\n\n· Working some section of backend and frontend work.\n\nProject#3: Remote programmer official site\n\nEnvironment: PHP , AJAX, Jquery, Javascript, HTML, CSS, MySql\nTeam Size: 1\nDescription: This is the official site of remote programmer PVT LTD. It describes all the details information of company like hiring pattern, services etc.\nResponsibilities:\n\n· Working on YII(php framework) according to Requirement.\n\n· Working all backend and frontend work.\n\nOther Projects:\n\nI also have done PHP/MySql projects, YII/Custom framework is used to build this projects.\n\n\n\tDate Of Birth\n\t13th Feb 1989\n\n\tGender/Marital Status\n\tMale/Single\n\n\tBlood Group\n\tA+ve\n\n\tFather’s Name\n\tRama Chandra Das\n\n\tMother’s Name\n\tBula Lata Das\n\n\n\nPROFESSIONAL SNAPSHOT\n\n\n\nTECHNICAL EXPERTISE\n\n\n\nPROFESSIONAL QUALIFICATION\n\n\n\nPROFESSIONAL EXPERIENCE\n\n\n\nORGANISATIONAL EXPERIENCE\n\n\n\nPERSONAL DOSSIER\n\n\n\n\n\n\n\nrajeshdas.rm@gmail.com | +91-7685842183","annotation":[{"label":["Education"],"points":[{"start":1345,"end":1347,"text":"BCA"}]},{"label":["Skills"],"points":[{"start":459,"end":467,"text":"PHP/MYSQL"}]},{"label":["Skills"],"points":[{"start":381,"end":402,"text":"PYTHON/DJANGO/POSTGRES"}]},{"label":["Name"],"points":[{"start":0,"end":9,"text":"Rajesh Das"}]}],"extras":null,"metadata":{"first_done_at":1532684518000,"last_updated_at":1532684518000,"sec_taken":201,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "RAJESH KUMAR PRASAD\nContacts: +91 93794 20787\nE-Mail: rajeshprasad_19@yahoo.com, rajeshprasad5@gmail.com\nSeeking consulting/managerial/Leadership assignments as “Knowledge Specialist” with a growth oriented organization into area of Analytics, Decision Science, Strategic management and Consulting in BFSI, Retail (CPG/Ecommerce), Telecom, and Automotive & logistic industries\nAN OVERVIEW\n· A result oriented professional with 11 years (8+ years into marketing analytics) of experience into Research & Analytics consulting, Sales & operations planning and strategy. Strong experience into Marketing analytics (MMM) - Customer Targeting program analytics, Product & Pricing analytics, Sales & Revenue analystics, Channel/Spend attribution (Media Mix Analytics), Category analytics, Inventory planning & Markdown optimization, Statistical modeling techniques & Data mining, strategic decision making, Client Relationship Management and Team Management in Banking, Financial Services (Retail Banking), CPG, Retail/Ecommerce, Telecom, and Automotive & logistic industries. \n· Currently working into “Data Science” team associated with Cognizant Data Sciences team, Bangalore as Manager Analytics – Data Science – reporting to Senior Manager Analytics – Data Science and Associate Director – Data Science.\n· Experience in carrying out Senior Data Scientist role at CTS Data Sciences team for various statistical modeling & analytics, machine learning techniques and implementing analytical solutions/tracking improvement or modification in model improvement as a strategy to the business.\n· Proficient in using statistical analytical tools like SAS (advanced SAS programming – Proc, SQL, Marcos, STAT, Graph, ETS, Enterprise Miner), R (e1071, rpart, nnet, randomforest, gbm, mboost, arules,etc.), python (scikit-learn, Pandas, Pattern, Pylearn2, etc.) and SPSS, big data technologies Spark, Scala for result driven analysis by using different methods like predictive modeling, Product & Pricing analytics, Customer Analytics, time series, regression analysis, Market basket analysis, Market Mix Modeling, segmentation analysis (Cluster & Factor, Discriminant analysis), churn analysis, campaign analytics and response modeling, structural equation modeling, survival analysis, etc. \n· Used SAS/R for machine learning & pattern recognition techniques like K-means clustering, Logistic regression, Association rule, Decision Trees, Expectation Maximization (EM), SVMs, NN, etc. to transform data into decision making models. \n· Rich experience in dealing with unstructured data/large volumes of data by using Hadoop, Hive, Datameer, Spark, Scala, H2O and Mapreduce. Used visualization tools like Qlikview, data-fetching from MS SQL / Oracle DBs, etc.  \nEDUCATION\n2008\n\nChartered Financial Analyst from ICFAI University, Hyderabad. Secured CGPA 7.50/10. \n2004\n\nM.A. in Economics from Sambalpur University, Orissa. Secured 79%.\n2001\n\nB.Com. with Honours in Accountancy from Sambalpur University, Orissa. Secured 74%.\n\n2012    \nAdvanced Certificate Programme in Business Analytics (ACPBA), IIT, Bombay.\n\nOther Course Completed:\n\n2010 \nPost Advanced Analytics Certification (SAS, SPSS statistical tools) from Analytics Training Institute (ATI), Bangalore \nAREAS OF EXPOSURE\nResearch Analysis: Developing subject matter expertise (SME) and gathering industry-specific market and business information, using internal and external research sources. \n\nBusiness Analysis & strategic management: Interacting with the clients for requirement gathering. Deploying suitable business research tools to gauge business analytics model, market trends & competitor activities, etc. to gain the competitive edge. Providing recommendations for business strategies and best practices in the industry.\nClient Relationship Management & Decision Making: Managing customer centric operations, interfacing with clients for understanding their requirements & suggesting the most viable solutions / products and cultivating relations with them for customer retention & securing repeat business. Developing & maintaining relationships with the customers in target markets for business development and decision making.\n\nTeam Management: Leading, mentoring & monitoring the performance of the team members to ensure efficiency in process operations and meeting of individual & group targets. Creating and sustaining a dynamic environment that fosters development opportunities and motivates high performance amongst team members.\n\nPROFESSIONAL EXPERIENCE\n\nSince August 2016\n                 Cognizant, EBA-Ventures-Data Science, Bangalore \n\nManager Analytics – Data Science - (Grade M) \n\nReporting to: Associate Director – Data Science\nKEY ACCOUNTABILITIES:\n· Worked and supported Microsoft IDC team: Working for Bing Ads – Search Engine to support Live Market Place (LMP) services and RnR Analysis. Leading a team of 15 data scientists for identifying strategic decisions and business innovation for analytics and insight generation. Major deliverables: \n- Data mining and big data analytics for identifying revenue upside/downside or product features for the benefits of disparate stakeholders (users/advertisers, etc.)\n\n- Network protection, fraud detection, traffic quality management. \n\n- Advertising metrics and management, including relevance and user experience for various product ads \n\n- Liaison with demand stakeholders for Ads campaign planning and optimization. \n\n- Livesite / Bug tracking and root cause analysis for systematic issues which have impact on business revenue.  \n\n- Using variety of logs like monetization, query, slappy, C2C, etc. For enhancing the auction process optimization and model building.\n- Improving ROI for advertisers for better monetizing revenue / conversion ratios and creating better relevance scores for users.    \n\n· Working with extended teams on identifying industry and/or cross industry analytics approaches toward solution development, focused on repeatable, \"embedded analytics within Business Process Services (BPS) clients.\n· Conceptualize, build, implement and improve solutions using a variety of Machine Learning. Deep Learning and Optimization techniques, on data set spanning tens of billions of observations.\n\n· Project management understanding and experience in building and tracking project plans in the analytics domain. Present advanced concepts and techniques to senior executives and develop trusted and highly respected relationships with customers and colleagues.\n\n· Leverage event-driven architectures to deliver recommendations in near real-time and develop flexible APIs so results can be used by a variety of applications.\n\n· Collaborate with Data Scientist and Software Developer colleagues to research, debate, experiment and devise highly effective solutions based on Original Thinking. Implement automated processes for comprehensive model validation and quality checks.\n\n· Drive client engagements focused on Big Data and Advanced Business Analytics, in diverse domains such as product development, marketing research, public policy, optimization, and risk management.\n\n· Leading and mentor a team of data scientists to build algorithmic models for IoT/ M2M Analytics, Service Intelligence, Social Analytics, Product Intelligence, Machine log analytics, Runtime monitoring of deployed models\n\n· Leverage technology to enhance the competitive position of clients by identifying appropriate solutions and/or products and designs.\nSince Nov 2013\n                 Premier Farnell Element14, Bangalore \n\nGlobal Price Modelling (Leader) - (Grade 5 on a scale of 8) – Product & Pricing Team COE\nReporting to: Global Head of Product & Pricing (Mike Buffam)\nJob Role Summary: To work closely with “Head of Global Product & Pricing” to initiate series of advanced analytics projects into multiple business domains (like sales and marketing, supply chain, finance, Product) which will enhance pricing and revenue generation and will design process changes, thereby initiating strategic changes for business leaders or groups. Handling team and project management responsibilities to deliver projects successfully.\nFunctionalities: \n\n· Consulting: Creating Business Strategy by designing analytical Solutions, Problem Statement & Customer/Stakeholder Feedback Analysis, Competitor Product & pricing Benchmarking, Defining Target State Model.\n· Business Analysis: Gap Assessment, Requirement Gathering, proposing and setting Industry Benchmark and KPI Assessment, Business Case (for new projects) and Modelling\n· Biz Transformation: Business Process Study & Reengineering, Defining Product/Process/Application\n· Client servicing: Client interaction, feedback process and assisting team members in client communication\n\n· Project Management: Project planning, managing multiple stakeholders, propose alternate solutions\nKEY ACCOUNTABILITIES:\n· Design, develop and implement the Global pricing strategy across multiple, multi-currency Business Units to maximise sales and margin across all product segments and market channels to optimise customer price perception.\n· Leading the Analytics team for data management into marketing / Media mix modelling and insights generation. Monitoring and developing new models for Global Media drivers for traditional / digital channels (media mix / channel attribution modelling with Markov chains with customer targeting programs) ROI measurements with better monetizing ratios. \n· Responsible to handle and co-ordinate of 21 member team into modelling, reporting and analytics through 2 team leads. Provide meaningful analysis from large volumes of complex data to support strategic pricing decisions\n\n· Deployment of competitor price benchmarking capabilities and implementation into data visualisation tools.\n· Study, plan and execute the overall analytics strategy for the identified service line. Drive actionable insights, solutions and POC with stakeholders. Responsible for analytical model building, validation & implementing on the global business.\n· Designing and managing user interface (UI), tracking performance (by using industry benchmarks, KPIs, etc.) and recommending about the strategy changes to business leaders for improving or optimizing revenue. \n· Developed inventory planning / forecasting solution using SAS Merchandise Intelligence 5.4 \n· Above SAS product helped in price / promotion and markdown optimization thereby by using revenue optimization.\n· Developing price optimization and revenue management models utilizing company, secondary, and market data sources to guide list price setting and forecast associated revenue impacts.\n· Develop product & customer segmentation models to evaluate and test proposed discounting & list price regimes.\n· Develop experimental designs for price testing of proposed changes utilizing transactional and ecommerce data.\n· Used Spark, Scala to develop pricing engine.\n· Initiating promotional / marketing campaigns through A/B testing, forecasting revenue & margins through demand modelling, cost optimization, risk evaluation strategies. \n· Extend framework to create a true individualized (B-B or B-C) shopping (price and promotional) pricing for consumers based upon individual behaviours, preferences and brand loyalty.\nPosition Dimensions:\n\n· Opportunity analysis and process improvement through statistical modelling to define the strategic goal achievement for top management.\n· Multifunctional role of interacting with finance, supply chain, product management, marketing team and ecommerce functions in team settings.\n· Work impacts companywide profitability based pricing strategy. \n· Modelling on Supervised and unsupervised analytical techniques to solve problems of segmentation, classification and prediction like market basket analysis, collaborative filtering, channel attribution, campaign design, dynamic pricing, etc.\n· Shared responsibility for group sales and margin performance (£15m) for Period FY14. \n· Interact with vendors in price optimization and web data mining space.\n· Experience in dealing with large data sets and developing analytic software using SQL and data mining tools like QlikView, Tableau (use based), MS SQL Server and e-commerce analytics.\nAttainments: \n\n· Spot Award winner for Streamlining Pricing processes and systems, discount policies, pricing algorithm, tool creation for sales executives and managers which help in negotiating with customers\n\n· Revenue and margin optimization of 13 million pounds through Discrete choice modeling, Global Price Corridor, expectation maximization and promotional strategies on customers / customer analytics which got implemented into systems globally\n\nSince Dec 2010\n                Keystone Automotive Operations, Bangalore                                   \n\nBusiness Analytics (Assistant Manager) - (Reporting to Manager: Business Analytics) \nKey Deliverables:\nStrategy Development/Execution with help of Marketing Analytics using SAS, R & Python: \n\n· Leading a 5 member team (3 Business Analysts & 2 Data Modeller) and leading & delivering analytical projects as per requirement to different teams within the organization.\n· To Work in coordination with top strategic management team like sales & marketing team, product category team, merchandising team, finance and pricing team.\n· Building & developing analytical models and supporting strategies and execution plans based upon data (statistical analysis). Drive execution of those plans (e.g. Ability to formulate strategic decisions in various areas like SKU based discount pricing, financial forecasts, sales & marketing strategy models including product pricing, promotion, and positioning and supply chain issues).\n\n· Building revenue enhancement models such as cross-sell and up-sell approach for the SKUs in different categories for B-B and B-C (retail-side & wholesale customers).   \n· Work directly with senior leadership and cross-functionally across the company to establish and maintain functional specific operating and business metrics, generation and maintenance of KPIs, dashboards and balance scorecards by utilizing juniors in the team. \n\n· Support and challenge US region business cases and decisions / pre-sales analysis by managing the timely delivery of quality forecasts by using different analytical models like regression, time series, segmentation, machine learning techniques, etc.\n\n· Developing customer analytics, pricing optimization, demand & supply operations planning, marketing analytics models, profitability analysis, category performance, vendor scorecard and promotional effectiveness analysis, opportunity and insights analytics & forecasting, etc. \n· Making recommendations for SKU based or promotional prices & campaign management & evaluation for North American countries.\n\n· Working on ad-hoc requests Review requests for price modifications (price matches, invoice adjustments, discount requests) and approve /deny request based upon pricing models, market and business understanding.\nProject Management for Assigned Project: \n\n· Analysing large databases 150k+ and data mining and use of statistics, regression analysis, forecasting, etc using SAS, SPSS, SQL, advanced MS Excel & MS Access.\n\nJul’08 - Nov’10\n\n\n           Beroe Consulting India, Chennai                           Domain Specialist\nKey Deliverables:\nBusiness Analytics KRA’s -\n· Built Analytical Models: Predictive Modeling like Linear & Logistic regressions, Marketing Models, Response, Revenue, Attrition, Segmentation (Factor, cluster, etc.) and Product design models for Product launch for BFSI, Retail and Telecom Domain using SAS, SPSS, R.\n· Worked and supported for CPG clients like Unilever, Coca-Cola, Tyson Foods, Inc.etc; Retail giants like Target, Tesco, Costco and H&M.   \n\n· Projects undertaken include revenue maximization modeling, marketing analytics, customer acquisitions models, customers scorecards, loyalty modeling, segmentation of customer base and profiling, forecasting models, SKU based pricing analytics, product development & attrition management.\n\n· Developing insights from data analysis and prediction and providing strategies to help make Business decisions to meet their objectives.\n· Leading team of 7-8 members and supporting to get the job done.\n\n· Provide expertise and assistance in integrating machine learning & statistical approaches and work with business leadership teams to find best in class solutions\nSome projects in Retail, Telecom & BFSI Domain -   \n\n· Developed Churn analysis, CLV, Market Basket analysis, Market mix modeling, time series forecasting, etc.: identify bundles and bridge products, using company’s latest technology offering (Pair wise co-occurrence consistency measure), for cross-sell and other opportunities for growth for leading Retail clients.\n· Churn Analysis for a telecom giant: Recommended a new customer retention strategy through multi-variate analysis of customer attrition leading to 20% reduction is churn rate.\n· Developed package & pricing analytical model along with up-selling and cross-selling strategies resulting in revenue enhancement for telecom clients.   \n· Built Attrition model for major US bank for their business consumer portfolio.\n· Built customer behavioral segmentation model, (using Genetic Algorithm tools and techniques), to help client in their customer centric business initiative. Identified key and profitable customers (segments) for growth strategy, identified segment for cross sell opportunities, created excel based reports for their weekly and monthly sales promotion strategy and various other similar strategic initiatives for growth. \n· Was involved with various aspects related to project implementation like conducting impact analysis, coordinating with various departments in clients’ organization and formulating several optimization strategies.\nBusiness Research & Competitive Analytics KRA’s –\n\n· Worked on Key Performance Indicators (KPIs), balanced score cards, etc. creation of dashboards required by the clients by using SAS, MS Access & MS Excel.  \n\n· Using various statistical tools (SAS) for price forecasting techniques, demand/supply planning, sales and operations planning, Inventory management and optimization techniques, trends & forecasting, etc.\nAttainments:\n· High Appreciation of the customer behavioral segmentation & Fraud Analytics model built and this project has been has been showcased as a case study within and outside the company.\n\n· Proactively provided assistant in building strategies, improving analytics decision making by revenue analytics, category management, cost optimization, etc. for fortune 100 MNCs clients.\n\n· Instrumental in making recommendations about the analytical strategies & practices followed in the BFSI, Telecom, Pharmaceutical, Automotive and Retail industries.\n\n· Recipient of:\n\n· Special Recognition Award in Beroe Inc. during 2009 and 2010. \n· Best Mentor Award for year 2009. \n\nOct’04-May’07 \n                           RocSearch India Pvt. Ltd., NOIDA       Senior Equity Research Analyst\nKey Deliverables:\n\n· Leading a team of Jr. Analysts (2-3 analysts or more) depending on the project requirement. Handling Client management, coordinating the workflow & ensuring the delivery of the jobs to the client before the deadlines.\n\n· Investment research (fundamental, comparative and quantitative) across Banking, Oil & Gas and Auto industries, primarily equity research and financial modeling. \n· Using SAS statistical software for financial forecasting of the various macro-economic indicators, indexes and financial valuations.\n· Portfolio Selection/Evaluation: Used SAS system in calculation of multi-period risk-return measures, DCF, clustering of stocks, evaluating portfolios.\n\n· Statistical methods used like regression, time series (ARMA, ARIMA, etc.) and principal component analysis & cluster analysis.\n· Accountable for:\n\n· Forecasting the financial statements; building, developing and maintaining financial models and solving problems of Junior Analysts in the team. \n\n· Analyzing financial information and writing 5-6 page quarterly report/ 25-30 page full-fledged yearly report/ investment recommendation on company and industry segment.\nAttainments: \n\n· Recipient of:\n\n· Best Employee Award in the quarter of June’05, Dec’06 and Sep’07.\n\n· Best Stock Recommendation Award for Jul-Aug’05 quarter and Oct-Dec’06 quarter.  \nBEYOND CURRICULUM\n· Actively participated in the annual cultural fest as a Cultural-in-charge in class-X.\n\n· Led a team as a Captain in the Cricket Tournament at School and College level.\n\n· Won second prize in the Science Olympiad in Junior Level in School Competition.\n\nPERSONAL DOSSIER\n\nDate of Birth\n\n:\n19th May 1979\nLinguistics Abilities\n:      \nEnglish, Hindi and Oriya\n\nPresent Address\n\n:\nHouse No. 4, 5th Cross, Shivganga Layout, Mahadevpura, Outer Ring Road, \n\n                                                Bangalore – 560076, Karnataka, India\nPermanent Address\n:     \nHouse No. A-64, Sector–3, Rourkela – 769003, Orissa","annotation":[{"label":["Location"],"points":[{"start":20917,"end":20925,"text":"Bangalore"}]},{"label":["Location"],"points":[{"start":12732,"end":12740,"text":"Bangalore"}]},{"label":["Location"],"points":[{"start":7526,"end":7534,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":4685,"end":4696,"text":"Data Science"}]},{"label":["Skills"],"points":[{"start":4623,"end":4634,"text":"Data Science"}]},{"label":["Location"],"points":[{"start":4591,"end":4599,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":4577,"end":4588,"text":"Data Science"}]},{"label":["Location"],"points":[{"start":3234,"end":3242,"text":"Bangalore"}]},{"label":["Education"],"points":[{"start":2762,"end":2788,"text":"Chartered Financial Analyst"}]},{"label":["Skills"],"points":[{"start":1972,"end":1998,"text":"Product & Pricing analytics"}]},{"label":["Skills"],"points":[{"start":1364,"end":1375,"text":"Data Science"}]},{"label":["Skills"],"points":[{"start":1287,"end":1298,"text":"Data Science"}]},{"label":["Skills"],"points":[{"start":1249,"end":1260,"text":"Data Science"}]},{"label":["Skills"],"points":[{"start":1194,"end":1205,"text":"Data Science"}]},{"label":["Location"],"points":[{"start":1161,"end":1169,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":1141,"end":1152,"text":"Data Science"}]},{"label":["Skills"],"points":[{"start":1096,"end":1107,"text":"Data Science"}]},{"label":["Skills"],"points":[{"start":655,"end":681,"text":"Product & Pricing analytics"}]},{"label":["Skills"],"points":[{"start":589,"end":652,"text":"Marketing analytics (MMM) - Customer Targeting program analytics"}]},{"label":["Skills"],"points":[{"start":524,"end":563,"text":"Sales & operations planning and strategy"}]},{"label":["Skills"],"points":[{"start":491,"end":521,"text":"Research & Analytics consulting"}]},{"label":["Skills"],"points":[{"start":491,"end":521,"text":"Research & Analytics consulting"}]},{"label":["Name"],"points":[{"start":0,"end":18,"text":"RAJESH KUMAR PRASAD"}]}],"extras":null,"metadata":{"first_done_at":1532671354000,"last_updated_at":1532671354000,"sec_taken":262,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Rajesh Kumar Ranjan\n\nContact: +91 7676885165 \nE-Mail: rajesh.eclipse@gmail.com\nAddress: #172/A, P.R. Building,\n Near Thavarekere Bus Stop, B.T.M. \n16th Main, Bangalore-560029.\n\nJOB OBJECTIVE\nA results-driven, customer-focused, Software professional who can think “out of the box” looking forward for a career in Enterprise Application Integration.\nPROFILE\n\n· 2+ Years of relevant experience in Text Mining, Machine Learning(ML), Natural Language Processing(NLP).\n\n· Experience in Python and R Programming Language.\n\n· Experience of  working NLP Toolkits such as NLTK, SciKit-learn.\n\n· Holding good understanding on Deep Learning algorithm  such as Neural Network, CNN,RNN .\n\n· Understanding of ML/NLP Tools NLTK.\n\n· 5+  Years of relevant experience in Java, Object Oriented (OO) Concepts Oops, Web-based Technology, J2EE Edition.\n\n· Expertise in designing and development object-oriented multi-tier web applications, client/server applications.\n\n· Good Experience in Java, Struts Framework, JSF, Web Services REST(Spring MVC), Hibernate, Spring, Design         \n\n       Pattern, Servlets, JSP, JDBC, Node.js, JavaScript’s, Object Oriented JavaScript’s, Json, XML, JQuery, SQL,    \n\n       SearchAPI (Solr, Elastic Search, twig-kit), Web server (Tomcat), App Server (Web sphere).\n\n· Hands on experience using Eclipse and My-eclipse.\n\n· Extensive knowledge in developing front end components using HTML5, Ajax, JavaScript and CSS3.\n· Used Source control SVN, GitHub and IBM RTC.\n\n· Understanding of MVC framework.\n\n· Experience of working in Restful Web Services.\n\n· Experience of working in Linux OS.\n\n· Used Project Management Tool Assembla, Time task, IBM Jazz.\n· Expertise in Software Development Life Cycle Agile and Waterfall Methodologies.\nEMPLOYMENT HISTROY\n\n Company Name: Currently associated with IBM.\n Tenure:                 05/01/2015-till date\n Designation:        Senior Software Engineer.\n Company Name: Sakhatech Information System Pvt. Ltd.\n Tenure:                 26/07/2012 – 26/12/2014\n Designation:        Senior Software Engineer\n Company Name: Teembinsys Systems Private Limited(formally known as PrudentTel Technologies)\n Tenure:                 02/08/2010 – 24/07/2012\n Designation:        Software Engineer.\nEDUCATIONAL BACKGROUND\n· B.Tech with 70% Aggregate from VIT University Vellore  in 2010.\n· Passed 10+2 (PCM),(BSEB) with 62% in 2003 from Purnea College, Purnea \n· Passed  Matriculation,(Bihar Board) with 63% in 2001 from BBM High School Purnea.\n\nCERTIFICATIONS\n· Data Science 101(https://cognitiveclass.ai).\n· Machine Learning with Python(https://cognitiveclass.ai).\n· Machine Learning with R(https://cognitiveclass.ai).\n· R 101(https://cognitiveclass.ai).\nPROJECT UNDERTAKEN     \n\nPROJECT-1: HPT\n\nRole\n\n           : Senior Software Engineer\nTechnologies             : NLP, Machine Learning, Data Mining.\nEnvironment             : Ubantu 16.10.\n\nPeriod   \n           : Sep 2017 to till date.\nTeam Size\n           :  2\nDescription:\nApplication is dedicated for the social cause for Improving Hospital Services based on Patient Feedback.\nResponsibilities:\n· Exploratory Data Analysis and feature extraction.\n\n· Train set preparation, Model building and applying predictive modeling on existing data.\n\n· Created architecture design for real time data analysis using Rest API..\n\n· Client Interaction.\nPROJECT-2: AUTOBAHN , SPIM, SOT, and  SPEED\nRole\n\n           :Senior Software Engineer\nTechnologies             : Java, JSP, Spring, Hibernate, JQuery, JavaScript’s, CSS, Html.\nEnvironment             : Windows.\n\nDevelopment Tools   : IBM RSA, RTC, Jazz\nDatabase                    : DB2.\nPeriod   \n           : Jan 2016 to till date.\nTeam Size\n           :  8\nDescription:\nAutobahn used for product review and analysis app for sales person and distributors of IBM product before launching\n\nin market.\nResponsibilities:\n· Involved in enhancement.\n\n· Implemented slick grid API.\n\n· Work extensively on Java, Spring Rest Web services and Hibernate.\n\n· Implemented quartz scheduler.\n\n· Involved in Bug Fixing.\n\n· Involved in client side design using html5, JavaScript’s, jQuery.\nPROJECT-3: Kaarya (Document, Task, Meeting Management System)\nRole\n\n           :Senior Software Engineer\n\nClient                         : Continuum Wind Energy. (www.continuumenergy.in).\nTechnologies              : Java, JSP, Spring, Hibernate, JQuery, JavaScript’s, CSS, Html.\nEnvironment              : Ubuntu 12.4\nDatabase                    : MySQL.\nPeriod   \n           : June 2014 to Dec 2015.\nTeam Size\n           :  5\nDescription:\n\nDocument Management System web-based service offering a wide range of document management,\n\nMeeting management, Task management, Reports, Approvals work-flow applications at fraction of cost of on\n\nPremise solutions. Easy to use.\nResponsibilities:\n· Implemented Spring Restful API.\n\n· Work extensively on Java and Hibernate.\n\n· Involved in server side logic.\n\n· Responsible for implementing persistence layer.\n\n· Involved in client side design using html5, JavaScript’s, jQuery.\n· Involved in implementing design pattern.\nPROJECT-4: KITENGA\nRole\n\n          :Senior Software Engineer\n\nClient                          :TNT (www.tnt.com).\nTechnologies              : Java, JSP, Spring, Hibernate, JQuery, JavaScript, CSS, HTML.\nEnvironment               : Ubuntu 12.4\nDatabase                     : MySQL.\nPeriod   \n          : July 2014 to Aug 2014.\nTeam Size\n          :  7\nDescription:\n\nKitenga  is a courier tracking application for web, android, iPhone, window application.\nResponsibilities:\n· Implemented Spring Restful API.\n\n· Involved in implementing API to provide service to web, android, iPhone and window based apps.\n\n· Involved in client side design using html5, JavaScript’s, jQuery.\n· Involved in server side logic.\n\n· Involved in implementing design pattern.\nPROJECT-5: IBI (India Business Insight)\nRole\n\n           :Senior Software Engineer\n\nClient                          : Informatics India Ltd. (www.infor.com).\nTechnologies              : Java, Jsp, Spring, Hibernate, JQuery, JavaScript’s, Css, Html, Solr, Twigkit.\nEnvironment               : Ubuntu 12.4\nDatabase                     : MySQL.\nPeriod   \n            : December  2013 to May 2014.\nTeam Size\n            :  4\nDescription:\n\nINDIA BUSINESS INSIGHT is the first and only compare desk-research tool to Indian Business and industry\n\ninformation. INDIA BUSINESS INSIGHT, a product of Informatics (India) Limited it provide well indexed Indian content \n\nto Global database. INDIA BUSINESS INSIGHT knowledge base is captured from more than 312 sources\n\nWhich encompasses daily newspapers, magazines and accesses information disseminated through Government\n\nSources. INDIA BUSINESS INSIGHT monitors information on listed and unlisted companies, government bodies,\n\nTopics, industries, and people that matter the most for an organization. INDIA BUSINESS INSIGHT delivers\n\nthe knowledge where it is needed the most. No wonder, when it comes to credibility.\nResponsibilities:\n· Implemented basic search and advance search functionality.\n\n· Design solr architecture.\n\n· Implemented Twig-Kit (Search API).\n\n· Implemented server side logic.\n\n· Implemented client side design using JSP, JavaScript, JQuery, CSS, html.\nPROJECT-6: JgateSearch and JgateSearchSMT (Admin Module)\n\nRole\n\n           : Senior Software Engineer\n\nClient                           : Informatics India Ltd. (www.infor.com).\nTechnologies                : Java, JSP, JSF, Hibernate, Spring, JQuery, JavaScript’s, CSS, Html, Solr, Twig kit.\nEnvironment                : Ubuntu 12.4\nDatabase                       : MySQL.\nPeriod   \n            : June  2013 to Nov 2013.\nTeam Size\n            :  5\nDescription:\nJgateSearch is the product of Informatics Company. Basically the product provide journal or article search. in this\n\nproduct they categorization in different fields and provide the search result based on selected field. They provide\n\nbasic search and advance search with full text and abstract result. The product provide facility to create on account so you can upload your article and managed your account by self.\nResponsibilities:\n· Implemented basic search and advance search functionality.\n\n· Filter search result based on requirement.\n· Implemented auto suggest search keyword.\n· Responsibility for small enhancement in existing application. \n· Responsibility for look at indexing part.\n· Responsible for small User interface changes.\n· Responsible for bug fixing.\n\n· Implemented new Product in this application called Indian Journal and Open Access Journal.\n\n· Added two product In JgateSearchSMT Indian Journal and Open Access Journal.\nPROJECT-7: Treetle for Enterprise\n\nRole\n\n           : Software Engineer\n\nClient                         : Treetle Software Pvt. Ltd. (www.treetle.com).\nTechnologies              : Java, Node.js, JavaScript, html5, CSS3, JQuery, JSON.\nEnvironment              : Ubuntu 12.4\nDatabase                    : MySQL.\nPeriod   \n           : November  2012 to June 2013.\nTeam Size\n           :  5\nDescription:\nTreetle Enterprise is a software solution by which people can Connect to other like-minded people at their workplace\n\nwith matching interests, activities and in-turn enable you engage and together plan and you like to do most Treetle provides various activities which pave way for people to come together on a single platform for common interest and share and each other ideas, rate each other etc.\nResponsibilities:\n· Involved in client side design using html5, JavaScript’s, JQuery.\n\n· Involved in server side logic using Node.js.\n\n· Implemented JSON formatted data using Core Java.\n\n· Implemented Elastic Search. \n\n· Wrote SQL queries.\nPROJECT-8: REDCORALMENU\n\nRole\n\n\n      : Software Engineer\n\nClient                                : Digicat Digital Marketing Pvt Ltd. (www.digicat.in).\nTechnologies                     : Java, Node.js, JavaScript, html5, CSS3, JSON, Elastic Search\nEnvironment      \n       : Ubuntu 12.4\nDatabase                           : MySQL\n\nTesting Techniques           : QTP\nPeriod   \n\n       : July  2012 to October 2012.\nTeam Size\n\n       :  4\nDescription:\nThe concept of CORALMENU given a dish name, the app should be able to figure out the cuisine, the eating habits of\n\n the user and the restaurant within the area that the user wishes to eat at, in the given time of day.\nResponsibilities:\n\n· Design database using Db-designer4.\n· Involved in server side logic using node.js.\n\n· Involved in client side logic using node.js and JavaScript.\n\n· Design User interface using html5, dom and css.\n· Implemented JSON formatted data using Core Java.\n\n· Implemented Elastic Search. \n\n· Wrote SQL queries.\nPROJECT-9: WEB ATS GARMENTS\nRole\n\n\n      : Software Engineer\nTechnologies                    : Java, Struts, EJB, JSP, JavaScript\n\nEnvironment      \n      : Windows OS\n\nDatabase                           : Oracle 10g\n\nTesting Techniques           : QTP\nPeriod   \n\n      : Aug 2010 to July 2012.\nTeam Size\n\n      :  8\nDescription:\n\nThe concept of WEBATS Garments is “let’s work easy”. It is a three tier architecture using the latest technology with\n\n a very intuitive interface. The software automates the business processes for the entire life cycle of a fabric from Development to production. The costing sheet is done for approval of the garments cost/price. Finally, to conclude there is no doubt that in this economic conscience society that originations of all types want to be able to reduce their manufacturing costs. By streamlining the data flow between departments the information and allowing employees to \n\nview all of requirements to do their jobs, they will be able to provide customers a quick response with less turnaround time thus allowing the employees to work more efficiently.\nResponsibilities:\n· Responsible for writing Struts Action classes and JSPs.\n\n· Used Struts Tiles and Validation Framework.\n\n· Responsible for making download and upload classes using struts.\n· Implemented JDBC components..","annotation":[{"label":["Skills"],"points":[{"start":10793,"end":10796,"text":"Java"}]},{"label":["Skills"],"points":[{"start":10769,"end":10772,"text":"Java"}]},{"label":["Skills"],"points":[{"start":10614,"end":10617,"text":"Java"}]},{"label":["Skills"],"points":[{"start":10506,"end":10509,"text":"Java"}]},{"label":["Skills"],"points":[{"start":9884,"end":9887,"text":"Java"}]},{"label":["Skills"],"points":[{"start":9869,"end":9872,"text":"Java"}]},{"label":["Skills"],"points":[{"start":9622,"end":9625,"text":"Java"}]},{"label":["Skills"],"points":[{"start":9506,"end":9509,"text":"Java"}]},{"label":["Skills"],"points":[{"start":8837,"end":8840,"text":"Java"}]},{"label":["Skills"],"points":[{"start":8822,"end":8825,"text":"Java"}]},{"label":["Skills"],"points":[{"start":7487,"end":7490,"text":"Java"}]},{"label":["Skills"],"points":[{"start":7444,"end":7447,"text":"Java"}]},{"label":["Skills"],"points":[{"start":7205,"end":7208,"text":"Java"}]},{"label":["Skills"],"points":[{"start":6046,"end":6049,"text":"Java"}]},{"label":["Skills"],"points":[{"start":6008,"end":6011,"text":"Java"}]},{"label":["Skills"],"points":[{"start":5723,"end":5726,"text":"Java"}]},{"label":["Skills"],"points":[{"start":5252,"end":5255,"text":"Java"}]},{"label":["Skills"],"points":[{"start":5214,"end":5217,"text":"Java"}]},{"label":["Skills"],"points":[{"start":5007,"end":5010,"text":"Java"}]},{"label":["Skills"],"points":[{"start":4855,"end":4858,"text":"Java"}]},{"label":["Skills"],"points":[{"start":4363,"end":4366,"text":"Java"}]},{"label":["Skills"],"points":[{"start":4325,"end":4328,"text":"Java"}]},{"label":["Skills"],"points":[{"start":4087,"end":4090,"text":"Java"}]},{"label":["Skills"],"points":[{"start":3934,"end":3937,"text":"Java"}]},{"label":["Skills"],"points":[{"start":3485,"end":3488,"text":"Java"}]},{"label":["Skills"],"points":[{"start":3447,"end":3450,"text":"Java"}]},{"label":["Skills"],"points":[{"start":1409,"end":1412,"text":"Java"}]},{"label":["Skills"],"points":[{"start":1139,"end":1142,"text":"Java"}]},{"label":["Skills"],"points":[{"start":1109,"end":1112,"text":"Java"}]},{"label":["Skills"],"points":[{"start":967,"end":970,"text":"Java"}]},{"label":["Skills"],"points":[{"start":816,"end":827,"text":"J2EE Edition"}]},{"label":["Skills"],"points":[{"start":793,"end":813,"text":" Web-based Technology"}]},{"label":["Skills"],"points":[{"start":758,"end":791,"text":"Object Oriented (OO) Concepts Oops"}]},{"label":["Skills"],"points":[{"start":752,"end":755,"text":"Java"}]},{"label":["Skills"],"points":[{"start":429,"end":460,"text":"Natural Language Processing(NLP)"}]},{"label":["Skills"],"points":[{"start":407,"end":426,"text":"Machine Learning(ML)"}]},{"label":["Skills"],"points":[{"start":394,"end":404,"text":"Text Mining"}]},{"label":["Location"],"points":[{"start":158,"end":166,"text":"Bangalore"}]},{"label":["Name"],"points":[{"start":0,"end":18,"text":"Rajesh Kumar Ranjan"}]}],"extras":null,"metadata":{"first_done_at":1532672316000,"last_updated_at":1532672316000,"sec_taken":125,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Rajib Kumar\nE-mail : rajib7494@gmail.com\nMobile : +91 - 7406608608\n\t\n\n\nCareer Objective:\nTo utilize the best of my skills, education and experience in an organization by expanding my horizon of knowledge and leadership qualities.\n\t\n\t9 Years and 10 months of experience in Data Analytics, Data Science, Data  Warehousing , Infrastructure Automation,  Reporting and Business Intelligence using IBM Data and Business Analytics Software (SPSS Statistics, SPSS Modeler, SPSS CADS), IBM Cognos Analytics, R, Hadoop Mapreduce, Hive, Impala, Zookeeper, Python.\nDevelop and execute strategies and Predictive models for fraud prevention, Acquisition, account management processes within credit risk area.\nExperience in building strategies and models using various statistical techniques (CHAID, CART, Regression, Neural Networks Etc…) using IBM SPSS, R, Sql and Python.\nExposure to Machine learning and Cloud Technologies like Microsoft Azure, IBM Soft-layer Cloud.\nHands-on experience in continuous integration and delivery process by using various Dev-Ops tools like Chef, Nagios, Docker Etc …\nAs Senior Architect and principal business Analytics with background in Data Mining, Mathematics and technology I am always making an effort to deliver high quality Cross Brand solutions to our customers. Besides focusing on the technological and operational integration of these solutions on site I appreciate working in a team. I have been working this environment for the past 10 years.\n\n\n Professional Experience:\n\n\tDate\n\tCompany\n\tDesignation\n\n\tMay,2015 – Till date\n\tIBM, Bangalore, India\n\tArchitect  Advanced  Analytics\n\n\tAug, 2013 – Apr,2015\n\tTech Mahindra, Bangalore, India\n\tAssociate Tech Specialist\n\n\tJul, 2012 – Aug, 2013\n\tIBM India Ltd, Pune, India\n\tSenior Consultant\n\n\tJan, 2009 – Jul, 2012\n\tEmptoris Technologies India Ltd, Pune, India\n\tEngineer-Technical Solutions\n\n\tApril, 2008 – Jan, 2009\n\tAustralia and New Zealand Banking Group Limited(ANZ), Bangalore, India\n\tTechnical Analyst\n\n\nKey Skills:\nI have worked with the following hardware/software products, tools and methods.\n\tHardware/OS\n\tSoftware Products\n\tTools\n\n\tUnix, LINUX, Windows\n\tIBM Data and Business Analytics Software, Hadoop Map-reduce, Data Science, Analytical Solutions, Advanced Analytics, Data Mining, Data Modeling, IBM Cognos Analytics, Data-Base,  Scripting (Shell & Perl), Cloud , DevOps, Machine Learning, ETL, Reporting and Business Intelligence. \n\tIBM SPSS, HDFS, Hbase, Hive, Impala, Sqoop, Pig, Zookeeper, Nosql, Apache Spark, Ambari, IBM GPFS, Mapreduce, MongoDB, Flume, , Chef, Nagios, Docker, Cognos, Clouds, WebSphere, DataStage, R, Python, Shell scripting.\n\n\nEducational Qualifications:\n\tDegree and Date\n\tCollege / University\n\tMajor and Specialisation\n\n\tBachelor in Engineering, 2006\n\tBiju Pattanaik University Of Technology (BPUT), Rourkela.\n\tComputer Science & Engineering – 75.14%\n\n\t12th, 2001\n\tCouncil of Higher Secondary Education, Bhubaneswar\n\tPhysics, Chemistry and Mathematics – 58.13%\n\n\t10th, 1999\n\tBoard Of Secondary education, Cuttack\n\tMathematics, Science, Social Science, Literature – 71.33%\n\n\n\nProject: 1\n\tProject details / Description\n\tRoles and Responsibilities\n\n\tProject Name : Media Network Analytics\nClient Name : Etihad Airways \nPeriod of project : May-2015 – Till Date\n Twitter is an online social networking and microblogging service that enables users to send and read \"tweets\", which are text messages limited to 140 characters. Registered users can read and post tweets, but unregistered users can only read them. Users access Twitter through the website interface, SMS, or mobile device app.Vertica pulse is used to connect twitter website and collect data and loading into database based on search keywords of mobile devices.\n\t1. Designing and customizing data models for Data warehouse supporting data from multiple sources. \n1. Load data into twitter analytical base tables.\n1. Load dictionaries,mappings,whitle list,pos_words,Neg_words,stop_words and negation_words.\n1. Load data into non_neg_verbs,non_neg_adjectives,\nneg_neg_nouns,neg_neg_adverbs,pos_verbs,neg_verbs,\npos_nouns,neg_nouns,pos_adjectives and neg_adjectives tables.\n1. Designing and customizing data models for Data warehouse supporting data from multiple sources. \n1. Loading data into normalization and irregular verbs tables\nCreated twitter star schema data model \n1. Loading data into respective tables\n1. Scoring the sentiment of each tweet and loading into sentiment scoring table.\n1. Designing and customizing data models for Data warehouse supporting data from multiple sources. \n1. Extracted data from different flat files, MS Excel, MS Access and transformed the data based on user requirement\n\n\t\n\t\n\n\n\nProject: 2\n\tProject details / Description\n\tRoles and Responsibilities\n\n\tProject Name : MBRDI - Big Data Analytics\nClient Name : MBRDI( Mercedes-Benz Research and Development India), A Daimler Company\nPeriod of project : Aug-2013 – May-2015\nThe goal of the project is to assist with the implementation of Analytics and Big Data Platform for data mining. Provide a single Capital project tracking system which will combine data from proprietary software known as Q&A, various MS Excel spreadsheets, MS Access database and DB2. Secondly integrate it with information systems from other divisions, agencies, and outside organizations. Implementing a complex ETL, Analytics solution in the challenging Daimler IT landscape.\n\t1. Working knowledge on quantitative analysis, linear/multiple regression, logistic regression, CHAID modeling, and analysis and historical behavioral analysis.\n1. Hands on with data management, including database and spreadsheet applications, with the ability to use moderately complex models.\n1. Working with business users and business analyst for requirements gathering and business analysis. \n1. Converted business requirement into high level and low level design. \n1. Designing and customizing data models for Data warehouse supporting data from multiple sources. \n1. Extracted data from different flat files, MS Excel, MS Access and transformed the data based on user requirement using Datastage and loaded data into target, by scheduling the sessions. \n1. Worked on IBM Infospher Datastage 9.1 tool - Source Analyzer, Data Warehousing designer, Mapping and Transformation Designer. Developed Datastage mappings and also in tuning of mappings for better performance.\n1. Stored ETL data from relational, flat file, XML files using Datastage.\n1. Done automation of file provisioning process using UNIX-Shell scripting, Data mappings and Oracle utilities.\n\n\t\n\t\n\n\nProject: 3\n\tProject details / Description\n\tRoles and Responsibilities\n\n\tProject Name      : New BU Dimension\nPeriod of project : July-2012 – Aug-2013\n To implement a new dimension for the Business Unit. Currently the Business Unit is based on Ledger Unit and Cost Center. The new structure will be based on Ledger Unit, Cost Center and General Ledger. The new structure will help Amex with better spend visibility across their Business Units. Most of the economies in the region didn’t efficiently mobilize their domestic financial resources either. Subsequently Amex arrived for establishment of capital markets in least development countries (LDCs) in this region particularly.In order to implement the new dimension, IBM will be to sharing a report from the current cube which will contain a combination of Ledger Unit, Cost Center and General Ledger ids. Amex will be reviewing the same and share the business unit hierarchy for the combinations listed in the report. Based on this IBM will be implementing the new Business Unit Dimension.\n\t1. Created reusable mapplets and Transformations starting concurrent batch process in server and did backup, recovery and tuning of sessions. \n1. Created sequential batches and concurrent batches for sessions. \n1. Developed PL/SQL procedures/packages to kickoff the SQL Loader control files/procedures to load the data into Oracle. \n1. Worked with Memory cache for static and dynamic cache for the better throughput of sessions containing Rank, Lookup, Joiner, Sorter and Aggregator transformations.\n1. Written SQL Scripts and PL/SQL Scripts to extract data from Database and for Testing Purposes.\n1. Supporting daily loads and work with business users to handle rejected data. \n1. Developed Interfaces using UNIX Shell Scripts to automate the bulk load & update Processes. \n1. Executing test scripts to verify actual results against expected results by using Power Connect for source (DB2) validation and Oracle for target validations.\n\n\t\n\t\n\n\n\n\nProject: 4\n\tProject details / Description\n\tRoles and Responsibilities\n\n\tProject Name       : Claim Data warehouse Automation\nClient                      : Shell, Netherlands\nPeriod of project  : Jan-2009 – Jun-2012\n This application decays the times of execution of the complete project life cycle. As a result it reconciles multiple reports and sends it to the concerned users as an e-mail. It helps to reduce data corruptions and production issues.\n\t1. As a Production Support Engineer the primary responsibility is code level investigation of the jobs (UNIX, Shell Scripting, Oracle 9i, SQL, PL/SQL, Packages, Procedures and Functions, Shell and Perl Scripts).\n1. Data fixing involves writing PL/SQL Scripts and SQL, which would cater the needs of the businesses.\n1. Takes an active part in Database related developments (Oracle Architecture, SQL, PL/SQL Scripts, SQL and PL/SQLTuning).\n1. The major part of my team included Constant Analysis, system monitoring, responding to customer queries and responding to critical/severe business problems and doing appropriate escalation based on criticality and feasibility.\n\n\t\n\t\n\n\n\nKey Courses / Certifications:\n\tProgram or Course\n\tCoverage\n\tDates\n\n\tIBM Certified Specialist for IBM SPSS Modeler Professional \n\tIBM SPSS Modeler and Statistics\n\tMay-2016\n\n\tIBM SPSS C&DS Administration training\n\tDeployment Life cycle for SPSS, Elementary operation techniques, Data Platform Operations\n\tJul-2014\n\n\tWAS training \n\tInstallation, Configuration, Integration, Clustering, Deployment\n\tFeb-2013\n\n\tTraining on Cognos Analytics \n\t IBM Cognos Analytics\n\tDec-2017\n\n\tTraining on Problem management\n\t Mostly areas related to Incident and change order management\n\tMar-2012\n\n\n\n\t\n\n\n\nPlace:\n\t\n\t\n\tName:\n\t\n\n\tDate:","annotation":[{"label":["Skills"],"points":[{"start":10133,"end":10152,"text":"IBM Cognos Analytics"}]},{"label":["Education"],"points":[{"start":2735,"end":2757,"text":"Bachelor in Engineering"}]},{"label":["Skills"],"points":[{"start":2432,"end":2435,"text":"HDFS"}]},{"label":["Skills"],"points":[{"start":2360,"end":2375,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":2284,"end":2303,"text":"IBM Cognos Analytics"}]},{"label":["Skills"],"points":[{"start":2181,"end":2197,"text":"Hadoop Map-reduce"}]},{"label":["Skills"],"points":[{"start":2139,"end":2178,"text":"IBM Data and Business Analytics Software"}]},{"label":["Location"],"points":[{"start":1946,"end":1954,"text":"Bangalore"}]},{"label":["Location"],"points":[{"start":1650,"end":1658,"text":"Bangalore"}]},{"label":["Location"],"points":[{"start":1562,"end":1570,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":477,"end":496,"text":"IBM Cognos Analytics"}]},{"label":["Skills"],"points":[{"start":392,"end":431,"text":"IBM Data and Business Analytics Software"}]},{"label":["Name"],"points":[{"start":0,"end":10,"text":"Rajib Kumar"}]}],"extras":null,"metadata":{"first_done_at":1532692337000,"last_updated_at":1532692337000,"sec_taken":152,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "RAJIV SHANBHAG\nSENIOR SOFTWARE ENGINEER\n\nMobile: +91 9886831921 Email: rajiv.shanbhag@gmail.com\t\nPython 2.7, Mongo DB, Data Science, Data Mining, Text Mining, Sentiment Analysis, OCR –tesseract, Image Processing\nEXECUTIVE SUMMARY\nWIPRO TECHNOLOGIES, Bangalore, India\nSenior Project Engineer, November 2015 – till present. \n· I have overall 6.4 years of experience in various software development technologies including 3 Years 6 months in Text Analytics and Text Mining.\n· I have been involved in development of data mining solution for entity extraction from financial PDFs and using OCR technologies to extract data from scanned images like driving license, passport and invoice.\n· I have been trained in using NoSQL Databases such as MongoDB and having well hands-on experience in CRUD operations.\n· Responsible for developing POCs for new projects.\n· I’m responsible for designing and developing modules for the desired task.\n· I’m responsible for day to day interaction with client and gathering new requirements or enhancements.\n\nWIPRO TECHNOLOGIES, Bangalore, India\n\nProject Engineer, April 2011 – October 2015.\n· Worked as a core developer responsible to build, unit test and deliver functionalities related to algorithms like classification using Naïve Bayes, Data Mining using K-means algorithm.\n· Worked in Data crawling from social media using NLP.\n· Took lead in the testing phase before deployment of the application.\n· Worked as support engineer in application stability phase, using ticketing tool HP SM7.-\n· Well known about ITIL processes-Incident, Interaction & change management. \n· Analyzing the report by writing the MS SQL query and generating the report.\n\nPROFESSIONAL EXPERIENCE \n\nCurrent POC :  SQL to MongoDB migration\nClient\t:  Cisco(Apr 2017- Till)\nIt is a migration project in which existing sql data can be migrated to mongoDB and will integrated with Tableau for reporting purpose.\n\nResponsibilities and Technologies\n· Took complete ownership to extract and migrate the data.\n· Used python 3 to develop migration procedure from sql to MongoDB.\n·  Installation and administration task done in server for Tableau 10.3.\n\nProject :  Sensis - Marketing Services for Australian businesses\nClient\t:  Sensis Australia(May 2016- Dec 2016)\n\nIt’s a Data mining from the text pdf, which is a classified image from some of the news papers. As per category vise need to segregate the advertisement from the page and display it to end user.\n\nResponsibilities and Technologies\n\n· Using OpenCV 3.0 preprocessing the image, which is a classified page.\n· Segregate the image using contouring, dilation, noise reduction algorithms.\n·  Configure the OCR as per needs.\n· Using Python Scripting to extract data from row text generated by tesseract.\n· Followed   Agile model.\n· Daily updating status to BA’s and getting updates on specific requirement.\n· Delivering the same with documentation and flow chart.\n\nProject : CVS Document Processing \nClient\t: Apple US(Oct 2015-Apr 2016)\nIt is a document classification with data mining project which involves extraction of data from different type of Medical documents which is Scanned pdf/Images, using OCR technology.\nResponsibilities and Technologies\n· Using Python Scripting to extract data from document .\n· Using OCR technologies to read data from images like scanned Medical Invoices, Medical Reports.\n· Followed SDLC, Agile model.\n· Taking new requirements from the client, preparing modules for development and responding to client on a weekly basis about the status.\n\nProject:Digital Customer Experience Management (DCxM)\nClient\t:Wipro Technologies (In-house solution building and pre-sales)\nDCxM is Wipro’s In-house solution catering to the digital needs of today. It caters to different domains like banking, retail, automobile etc to provide customized digital solution using its data science and natural language processing capabilities.\nResponsibilities and Technologies\n    Email Routing:\n· Developed a POC for E-Mail routing which involved extracting email, classifying it according to department using Naïve Bayes algorithm, running natural language processing on the text of the mail and forwarding it to the concerned person depending on the outcome of the classifier and sentiment analyzer.\n\n\nProject 1: Barclays User Insights \nClient\t: Barclays Bank UK\nIt is a data mining project which involves extraction of data from different kind of documents like financial statements, UK driving licenses, Passports, Bank Cover letters, Scanned Tax Invoices using OCR technology.\nResponsibilities and Technologies\n· Using Python Scripting to extract data from documents like financial statements and bank cover letters.\n· Using OCR technologies to read data from images like scanned driving license, passports, tax Invoices.\n· Followed SDLC, Agile model.\n· Taking new requirements from the client, preparing modules for development and responding to client on a weekly basis about the status.\n\n\nProject 2: KYC Automation and Verification\nClient\t: Standard Bank Of South Africa\nThis assignment is completely deal with getting the text information from different kind of inputs like pdf, text, image or excel  and verifying the Extracted data with the existing data. As part of KYC, changes can be updated in actual DB periodically.\nResponsibilities and Technologies\n· Using Python Scripting to extract data from POI documents and POR documents.\n· Applying image processing algorithms with the help of Open CV 3.0.\n· Using OCR technologies to read data from images like scanned driving license, passports and Residential agreements.\n· Followed SDLC, Agile model.\n· Taking new requirements from the client, preparing modules for development and responding to client on a weekly basis about the status.\n\n\n\nProject 3: Campaign Management\nClient\t: Honda, Toyota, Kohl’s\nHonda, Toyota Camry and Kohl’s are retail firm which needed recommendations to enhance their digital marketing capabilities and improve their social media presence.\nResponsibilities and Technologies: \n· Finding the best strategy to resolve the dynamic web-page visibility in search engines.\n· Providing on page and off page recommendations to the client for a better visibility for their site in Google’s SERP results\n· Providing social media optimization for better social visibility.\n· Interacting with US, Italy and Australia clients.\n\nTrainings and Internships:\n· Python 2.7\n· MongoDB \n· MySql, MS sql\n· Oracle Database \n· Tesseract-OCR\n· Model View Control Architecture\n· SAP-ABAP\n· Informatica Power Center\n· IBM-Watson\n\n\n\nEDUCATION\n\n\tSTANDARD\n\tBOARD/UNIVERSITY\n\tPERCENTAGE\n\t                           INSTITUTE\n\n\tPG(MCA)\n\tVTU Belgaum\n\t71.4\n\tMalnad College of Engineering, Hassan\n\n\tUG\n\tKarnataka University Dharwad\n\t64\n\tDr. A.V Baliga College of Arts & Science.\n\n\tSSLC\n\tKarnataka State Board\n\t86\n\tJVMK\n\n\n\n\nACHIEVEMENTS\n· I got promoted to Sr. Project Engineer from Project Engineer in Wipro Technologies .\n· I got the Feather to My Cap award from ENU Sales Delivery Head .\n· I got the Connected Enterprise Services Roll of Honor Award in October 2014.\n\n\nRajiv Shanbhag\t\t\t\t\t\t\t\t\t\tDate:\n\t\t\t\t\t\t\t\t\t\t\tPlace:","annotation":[{"label":["Education"],"points":[{"start":6650,"end":6656,"text":"PG(MCA)"}]},{"label":["Skills"],"points":[{"start":6545,"end":6554,"text":"IBM-Watson"}]},{"label":["Skills"],"points":[{"start":6518,"end":6541,"text":"Informatica Power Center"}]},{"label":["Skills"],"points":[{"start":6507,"end":6514,"text":"SAP-ABAP"}]},{"label":["Skills"],"points":[{"start":6457,"end":6469,"text":"Tesseract-OCR"}]},{"label":["Skills"],"points":[{"start":6422,"end":6426,"text":"MySql"}]},{"label":["Skills"],"points":[{"start":6411,"end":6418,"text":"MongoDB "}]},{"label":["Skills"],"points":[{"start":6397,"end":6407,"text":" Python 2.7"}]},{"label":["Skills"],"points":[{"start":1728,"end":1735,"text":"MongoDB "}]},{"label":["Location"],"points":[{"start":1056,"end":1064,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":737,"end":744,"text":"MongoDB "}]},{"label":["Location"],"points":[{"start":250,"end":258,"text":"Bangalore"}]},{"label":["Name"],"points":[{"start":0,"end":13,"text":"RAJIV SHANBHAG"}]}],"extras":null,"metadata":{"first_done_at":1532686927000,"last_updated_at":1532686927000,"sec_taken":214,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "RESUME           \n\n\n\n\n\n\n\n\nRAJKUMAR.N                                                                                \n\n             \nMail ID: rajimpc@gmail.com\n\nC8, NAGARKOIL STREET,                                                              \n\n\n\nBLOCK 11, NEYVELI\n\nPIN 607803\n\nMobile: 8807185223\n\n                \n\n       \n                                                 \n\n\tSummary:\n\n\t                    Seeking data scientist/Analytics position with Six year and six month experience in Machine Learning, NLP, Image Processing, Cognitive modeling, developing statistical models, Prediction and statistical analysis, Advanced Analytics with proven records in developing state-of-art model along with Ph.D.\n\n\n\n\tEducational Qualification:\n\n\n\n\tDegree\n\tCollege\n\tUniversity/ State Board\n\tYear\n\t%\n\n\tPh.D Computer Science\n\nDomain: Machine Learning & Statistical Analysis \n\tAnnamalai University\n Under guidance of                                      Dr V. RAMALINGAM (IIT- Delhi)\n\tAnnamalai University\n\t2012-2016\n\t           Completed\n\n\n\tM.E  Mobile and pervasive computing\n\n\n\tVelammal Engineering college, Chennai\n\tAnna University\n\t2009-2011\n\t7 CGPA\n\n\tB.E. Information & technology\n\n\n\tAnnai Theresa  College of Engineering, Tamil Nadu\n\tAnna University\n\t2009\n\t  75 %\n\n\n\n\tH.S.L.C\n\n\n\tSt pauls Matriculation  higher secondary school,Tamil Nadu\n\tTamil Nadu\n\n State Board\n\t2005\n\t72%\n\n\tS.S.L.C\n\tJawahar Matriculation higher secondary school, Tamil Nadu\n\tTamil Nadu\n\nstate board\n\t2003\n\t  67%\n\n\n\n\n\tExperience:\n\n\t(2010 -2011)\n\n\n\tWorked as developer in TIFAC CORE Pervasive Computing Technologies under Department of Science and Technology (DST), Central Govt. of India, New Delhi. \n\n\t2015 June – Till Date\n\tIBM – LABS (ISL)\n\n\n\n\tPublished State of Art Real-time Machine Learning and Natural language processing (NLP) project output videos on following website https://sites.google.com/site/rajaucse1 \n\n\n\n\n\tExperience Summary:\n\n\t                     TIFAC- CORE Pervasive Computing Technologies (2010 -2011)\n                        (Department of Science and Technology, Govt. of INDIA, New Delhi)\n\nTITLE: Data Scientist \n\nOne year as developer in TIFIC CORE – Using challenging Indian Central Government Biometric data set (UID – Aadhar Approx. 200 million records) preliminary analysis was conducted to choose best machine learning algorithm for recognizing identities based on query data along with ApacheTM hadoop.\nImplemented various machine learning algorithms such as support vector machine, Auto Associative Neural Network, Genetic algorithm, HMM, EMM, etc., and clustering algorithms like fuzzy, k means, c means, PCA, ICA, etc. \nConducted statistical analysis using z -test, t – test, Cross fold validation, Confusion matrix and ROC to measure performance. \n\nFinally founded, a probabilistic modeling approach using Bayesian classifier with PCA based clustering yield high accuracy ratio.\n\n\n                 Doctoral Research in Machine Learning and Statistical Analysis  (2012 - 2015)\nUnder guidance of Dr. V. RAMALINGAM (IIT- Delhi)\nTitle: Researcher\n\nProject 1: Embodied Conversational Agent based on Natural Language Processing (2012 - 2014)\n\nTwo year involved implementing virtual agent with information management, Machine learning and engaged with dialogues based on user queries. \n\nUnlike traditional models of machine learning such as spending enormous effort to train huge corpus of data set each and every time a novel Life Long continuous SVM learning is implemented for continuous instant learning written in Matlab. Included substantial text mining and extraction using a variety of existing tools such as Matlab Machine learning tools, Python: Scrapy, ScikitLearn, Deep Learning, pybrain to compare performance and R for statistical analysis.\n\n[Developed similar application as Windows 10 CORTANA utilizing Natural Language Processing and Artificial Intelligence.\n(Note: CORTANA and our Applications are similar but not in algorithms, methods and visual we used our own NLP and machine learning methods with Virtual Agents)]\n[Received best Machine Learning Application Award in 2014 Annamalai University ]\nProject 2: Artificially Intelligent Model for reporting physical therapy statistics (2014 - 2015)\n\nOne year and nine months using statistical methods and fault database analysis to identify the workout causing physical therapy to fail and also evaluated the statistical value of solutions and make a recommendation. Included development of a .NET application (LV Merge) to assist simulation practices using Python, Matlab and R programming.\n\nImplemented deep learning methods such as random forest tree using real time series analysis\n\nVerus solutions (August 2015)  Two months freelancing in Predicting football winning team NWT group, UK \nInvolved in predicting winning probability for football team using Matlab machine learning technique\nI) (Jan 2015- June 2015) six months involved in predicting future stock market using Python- ScikitLearn and improved prediction rate by adding cascading technique (strength of multiple neural network) \nII) August 2015 one month involved in mining suspicious IP from available data set using machine learning in crypteianetworks using regression, Arima modeling\nI implemented many machine learning algorithms in various applications such as Future Stock Market Prediction,  Artificially Intelligent Self Reporting models, Cloud usage analysis, etc., and I published some of my project output videos in following website: https://sites.google.com/site/rajaucse1 \nAccenture – Data Scientist\nI. Developed model for prioritizing Resume using python and R\nII. RESUME parsing using NLP and prioritizing based on education and  skill sets using Python\nIII. Medical Document classification through Cognitive Modeling - extracting drug details, symptoms, reaction of drug, patient age, sex,etc using Python, R & SQL\nIV. Email classification (Microsoft) – Extracting data from, to, subject, noun phrase and exploring meaning using python\n\n\n\n\tIBM – Data Scientist\n\nI) Website Crawling and Indexing in Mongo DB\n\nII) Graph QL for analytics\n\nIII) Using NLP Document parsing and tagging – Topic extraction\nIV) Customized Document (Learning recommendation) recommendation for various student styles by calibrating cognitive capability and readability score\nV) Image processing – Facial Expression Recognition and calibrating customer’s engagement\n\nVI) Web analytics – Creating Session ID, Crawling content and web documents for analytics, Elastic search for content retrieval\n\nVII) Video Analytics – Searching meta data inside video\n\n\n\tComputer Skills:\n\n\t                Operating Systems:\n\n\n\tWindows- 7, 8 .1 \n\n Linux- Ubuntu, Cent OS\n\n\n\n\tProgramming Languages & Packages :                             \n\n\n\tProgramming in c#, Hadoop, Pig, Tableau, Java, Python, R programming, SAS, Matlab, Octave, MySQL, NOSQL, MongoDB, IBM DB2, Shell scripting, Ruby, Open CV Open ML, CUDA C/C++, Weka-3, NLTK, Open NLP,  Scrapy, ScikitLearn, Deep Learning, pybrain  (Open source Machine Learning S/W), HTML, XML, SQL, OOPS concept, UML, JSON, Image Processing, Data Mining, Text Mining, Amazon web service, Solr search, Elastic search, Word2vec. \n\n\tDomain Knowledge:\n\tMachine Learning Algorithms (Neural network, Genetic, Fuzzy, SVM – support vector machine),  Natural language processing (NLP), Prediction modeling, Regression, Deep Learning, Data Mining – (Complete, Incomplete, Structured and Un structured data set), Time series analysis, Data warehousing, Data Management, Text mining – GENSIM, Semantic Similarity, Segmentation, Feature Extraction, Processing Structured and un Structured Database, Testing (ANNOVA, FRIEDMAN) Data Structures, PCA, Clustering, Statistical analysis and modeling – ARIMA model, etc., Cloud computing, Big Data, Graphical visualization (Graphs, Tables and charts) \n\n\n\tAcademic Projects :\n\n\tProject in M.E\n\n\t  Project Name:\n\tAssociation rule mining with hashing and pipelining for statically analyzing unstructured data base\n\n\tTechnology:\n\tMachine learning \n\n\t                                This project involves face recognition using Neural Network classifier and compared performance of various machine learning algorithms against FERET face database.\n\n\n\tProject in B. E \n\n\t  Project Name:\n\tA comparative performance study of a fine-grain multi-threading model on distributed memory machines\n\n\tTechnology:\n\tMulti-Threading\n\n\t           This project presents a comparative study in implementation of threads in distributed system using java\n\n\n\tcertification courses:\n\n\t· Completed Java and C# with .net in NIIT Pondicherry during year 2009.\n\n· Azure Machine Learning from Microsoft during year 2012.\n· Completed IBM DB2 course  Dallas Technologies during year 2013.\n\n\n\n\n\tWorkshop and publications:\n\n\tWorkshop attended\n\t· UGC SAP DRS-1 Annamalai University sponsored inter disciplinary research methodology workshop.\n\n· National Research Methodology workshop on speech and image processing.\n\n· National workshop in pervasing computing technologies.\n\n\n\n\tConference / Journal\n\t· International conference on Soft Computing, Optimized face recognition using 2D wavelet decomposition principle component analysis with singular value decomposition using bayesian classifier.\n\n· IEEE conference, Intelectually combined face recognition using curvelet based principle component analysis for feature extraction and bayesian classifier.\n\n· International conference on signal processing, Intelligent face recognition using 2d wavelet transformation using SVD.\n\n· IEEE  pattern analysis and machine intelligence Realtime human detection from cascaded SVM classifier using raster scanning approach (Accepted Waiting for publication).\n\n· International Journal of Applied Engineering Research “Novel random forest tree based human action recognition using rgb-d sensor”\n\n· International Journal of Applied Engineering Research ”A Novel Fuzzy Rule Based Occluded Facial Expression Recognition System Using Expression Overlapping Technique”\n\n\n\n\tExtracurricular Activity\n\n\t· Worked as system administrator in Annamalai University.\n\n· Given lecturers in various Machine learning algorithms (Supervised, Unsupervised, Regression classifier, Clustering, SVM, EM, GMM, HMM, SOM, Neural networks, Genetic algorithm, fuzzy etc.,)  and estimation of classifier performance (bagging, bootstrap, cross validation, etc.,) in Annamalai University.\n\n· Student member in IEEE.\n\n· Blood donor.\n\n\n\tIn plant training\n\n\t· Undergone implant training in BSNL Chennai during year 2009.\n\n\n\n\n\tRoles in college\n\n\t· Organized industrial visits and functions in department.\n\n· Active member in cultural events in college. \n\n· Taken several seminars in school and university\n\n\n\n\tPersonal Information:\n\n\tName:\n\tRAJKUMAR.N\n\n\t       Permanent Address:\n\tC8, NAGAR KOIL STREET,BLOCK-11,NEYVELI    PIN: 607803\n\n\tNationality:\n\tIndian\n\n\tLanguages known:\n\tEnglish, Tamil\n\n\tMobile number:\n\t8807185223\n\n\nDeclaration:-\n\n                 I hereby declare that the information is true to the best of my knowledge.\nPlace:  NEYVELI \n\n\n                                              \n    \n  \n   yours faithfully,\n\n\n\n\n\n\n\n\n\n\n\n\n   RAJKUMAR.N","annotation":[{"label":["Location"],"points":[{"start":11029,"end":11035,"text":"NEYVELI"}]},{"label":["Location"],"points":[{"start":10802,"end":10808,"text":"NEYVELI"}]},{"label":["Skills"],"points":[{"start":8616,"end":8631,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":7318,"end":7320,"text":"NLP"}]},{"label":["Skills"],"points":[{"start":7196,"end":7211,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":7071,"end":7086,"text":"Image Processing"}]},{"label":["Skills"],"points":[{"start":7007,"end":7022,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":6943,"end":6945,"text":"NLP"}]},{"label":["Skills"],"points":[{"start":6097,"end":6099,"text":"NLP"}]},{"label":["Skills"],"points":[{"start":5634,"end":5636,"text":"NLP"}]},{"label":["Skills"],"points":[{"start":4050,"end":4065,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":3980,"end":3982,"text":"NLP"}]},{"label":["Skills"],"points":[{"start":2924,"end":2939,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1798,"end":1800,"text":"NLP"}]},{"label":["Skills"],"points":[{"start":1748,"end":1763,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":827,"end":842,"text":"Machine Learning"}]},{"label":["Education"],"points":[{"start":796,"end":816,"text":"Ph.D Computer Science"}]},{"label":["Skills"],"points":[{"start":563,"end":580,"text":"statistical models"}]},{"label":["Skills"],"points":[{"start":532,"end":549,"text":"Cognitive modeling"}]},{"label":["Skills"],"points":[{"start":514,"end":529,"text":"Image Processing"}]},{"label":["Skills"],"points":[{"start":509,"end":511,"text":"NLP"}]},{"label":["Skills"],"points":[{"start":491,"end":506,"text":"Machine Learning"}]},{"label":["Location"],"points":[{"start":257,"end":263,"text":"NEYVELI"}]},{"label":["Name"],"points":[{"start":26,"end":36,"text":"RAJKUMAR.N "}]}],"extras":null,"metadata":{"first_done_at":1532691406000,"last_updated_at":1532691406000,"sec_taken":277,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Udaya Laxmi Ch\n\nEmail : laxmi.udaya@gmail.com\n\n\t\n\n\tPhone: -9740606990\n\t\n\n\n\tSummary\n\n\t· 9.5 years of experience in Software Development.\n· 3.5 years of experience in Machine Learning\n· Primary Skills – Machine Learning, R programming, Lotus Notes.\n· Presently working for Wipro Technologies, Bangalore.\n· Experience in planning, estimation, design, development, and testing object oriented applications.\n· Experience in preparing various technical documents like Functional Specs, HLD, LLD, Flowcharts and Test cases.\n· Sound Knowledge in Object Oriented Design Principles\n· Have Team Handling experience.\n· Domain experience of Manufacturing and Finance.\n· Have Experience in Scrum Agile Model\n· Understand business requirements from clients\n\n\n\n\tTechnical Skills\n\n\tKey skills: \n\tMachine Learning,R Programming, MySQL, PostgreSQL, Microsoft Access, SQL Server, FileMaker, Oracle, RDBMS, dBASE, Clipper, FoxPro, Firebase, Mongodb, Python,  ava, J2EE, Oracle Fusion,Oracle Cloud, Salesforce, Devops Android, Business Analyst, UI Developer, DBAs, Embedded Systems, .NET, Hadoop, SQL Developer, Big Data, Tableau, Networking, Etl, Informatica, Ios, Quality Analyst, Project Manager, Python, Data Science, Python, Machine Learning, SAS, Java, Scala, Hadoop, Hive, Bigdata, Programming, SQL server reporting, Msbi Ssis, Ssrs, Msbi, Sql Reporting, Artificial Intelligence, Pandas, Pyspark, Sklearn, Flask, Django, Map Reduce, Parametric Design, Modeling, Regression, Patterns, Data Mining, Text Mining, Oops, Deep Learning, Web Analytics, Time Series, Regression, Tensorflow, Azure, Linear Regression, Logistic Regression, Decision Tree, Random Forest, Data Structure, Computer Vision, IHS, WAS, Java EE, SQL Server, .NET core, C#, ASP.NET, Rdlc, Linq, Sql, Web Api, Mvc, Javascript, Web Services, Oracle, MS SQL, PHP, Laravel, CodeIgniter, Symfony, Zend, Phalcon, CakePHP, Yii, FuelPHP, React, Vue, Angular, Ember, Backbone, Lotus Notes\n\n\tAlgorithms:\n\tNaïve Bayes, K means clustering,Word Cloud\n\n\tDatabases: \n\tMicrosoft SQL, Mongo DB\n\n\tWeb Technologies: \n\tXML, XSLT, HTML,  JavaScript,  AJAX, JQuery\n\n\tIDE:\n\tR studio,Pycharm\n\n\n\tProfessional Experience\n\n\tCurrent Employer :\n\tWipro Technologies., Bangalore  – (Oct  2010  to till date) – Technical Lead/Data Scientist\n\n\tPrevious Employers :\n\tHSBC Software development , Hyderabad (June  2008  to Sep 2010)  - SE\n\n\n\tQualification\n\n\tDegree\n\tCollege\n\tUniversity/Board\n\tYear\n\tPercentage (%)\n\n\tMCA\n\tNizam College, Basheerbagh,Hyderabad\n\tOsmania University\n\t2008\n\t75\n\n\n\tProject Experience \n\n\tProject 1 : Exploratory Data Analysis:\n\nProject Description:   Performed EDA analysis to analyze the Purchase frequency of vehicles which occurred over past 3 years and try to predict the frequency occurring in the future.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Performed EDA analysis to find the insights of the data. Observed the summary of each and every variable to understand the variables.\n\n· Performed the feature selection using hypothesis testing.\n\n· Identified the outliers using box plot.\n\n· Identified the trend in the purchases using histogram.\n\n\n\n\tProject 2: Word Cloud Analysis:\n\nProject Description:   Performed Word cloud and Sentimental Analysis of the customer feedbacks. Graphically represented the most frequently occurred words through Word cloud. Through sentimental analysis we identified whether a user-generated text expresses positive, negative or neutral opinion.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Created a Corpus using TM package and performed pre-processing of data.\n\n· Removed the punctuations, stemming and stop words which are of no analytical value.\n\n· Built a Document term matrix and identified the most frequently occurring words\n\n· Graphically represented it using  RColorbrewer Package\n\n\n\tProject 3: Sentimental Analysis:\n\nProject Description: Performed Sentimental Analysis of customer feedbacks through Naïve Bayes. Used “e1071” Package for implementing naïve Bayes method.\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· The DTM created using TM package was an input to the Naive Bayes Model.\n\n· As Naive Bayes classifier is typically trained on data with categorical features. We have converted the count of the words into a factor variable that indicates Yes or No whether the word is present or not.\n\n\tProject 4: Clustering Analysis:\n\nProject Description: Classified the customers on the basis of their purchases whether they have purchased low variant or high variant trucks. It in turn helped in building the right customer strategies.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Performed data preparation and Normalization of data using min-max method.\n\n· As K-means algorithm groups a dataset into a user-specified number (k) of clusters. Identified the initial cluster centroids as 3.\n\n· K clusters are creating by associating every observation with the nearest mean.\n\n· Used elbow method to validate the number of clusters such that within-cluster sum of square(wss) is minimized.\n\n\n\n\tProject 5 : Inter Connection Management Tool\nProject Description: Inter-connection Management (IMT) is prototype being developed for Engineering and Sales department to handle customizations of an existing product based on the customer's requirement. Users from engineering department will identify the items, which need to be customized out of the entire product design.\nRole\n\n       : Module Lead\n\nEnvironment\n       : Python, Mongo DB, jQuery\n\nTasks handled:\n\n· Gathering Requirements and providing Project Plan and Effort Estimation details.\n\n· Understanding business requirements and preparing SoU (Statement of Understanding) and Functional/Technical Specification documents.\n\n· Providing Effort & Resource estimations\n\n· Planning for application development and deployment\n\n· Writing and executing Test Cases and Test scenarios\n\n· Creating design elements using Technical Specification.\n\n· Performing Unit testing & Peer Reviews\n\n· Work Allocation and mentoring the team\n\n· Providing Technical guidance to the team. \n\n\tProject 6\n: cvdAEI Application\n\nProject Description\n     : CVDAEI is a web based multilingual application developed for handling the Change Management process in Truck division of Daimler. The change request flows through different phases mainly Initialization, Evaluation, Decision and Conclusion. This application has a configurable workflow where the request flow and the responsible persons can be configured easily at any point of time. \n\nRole\n\n    : Developer/Tester\n\nEnvironment\n     : Lotus Notes, Java, HTML, XML, Java Script, JQuery\n\nTasks handled:\n\n· Gathering Requirements and providing Project Plan and Effort Estimation details.\n\n· Understanding business requirements and preparing SoU (Statement of Understanding) and Functional/Technical Specification documents.\n\n· Providing Effort & Resource estimations\n\n· Planning for application development and deployment\n\n· Writing and executing Test Cases and Test scenarios\n\n· Creating design elements using Technical Specification.\n\n· Performing Unit testing & Peer Reviews\n\n· Work Allocation and mentoring the team\n\n· Providing Technical guidance to the team. \n\n\n\n\tProject Title: Project Management Office \nProject Description: The purpose of this system is to enable the Project Management Office to manage and execute the IT Applications and Operations driven project tasks in  more systematic manner. It will also enable them to efficiently perform a role as a facilitator to coordinate various IT Operations teams and to ensure that project activity enters the department through one common interface. The project tasks will subsequently be dealt with in a common format and in a consistent and appropriate manner, ensuring open and regular communication between all involved parties.\n\nRole\n\n    : Developer/Tester\n\nEnvironment\n     : Lotus Notes, Java, HTML, XML, Java Script, JQuery\n\nTasks Handled :\n\n· Writing and Executing Test cases in client server based environment\n· Individually provided application support","annotation":[{"label":["Skills"],"points":[{"start":7951,"end":7956,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":7938,"end":7948,"text":"Java Script"}]},{"label":["Skills"],"points":[{"start":7933,"end":7935,"text":"XML"}]},{"label":["Skills"],"points":[{"start":7927,"end":7930,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":7921,"end":7924,"text":"Java"}]},{"label":["Skills"],"points":[{"start":7908,"end":7918,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":6645,"end":6650,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":6632,"end":6642,"text":"Java Script"}]},{"label":["Skills"],"points":[{"start":6627,"end":6629,"text":"XML"}]},{"label":["Skills"],"points":[{"start":6621,"end":6624,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":6615,"end":6618,"text":"Java"}]},{"label":["Skills"],"points":[{"start":6602,"end":6612,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":5522,"end":5527,"text":"jQuery"}]},{"label":["Skills"],"points":[{"start":5512,"end":5519,"text":"Mongo DB"}]},{"label":["Skills"],"points":[{"start":5504,"end":5509,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4645,"end":4652,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":4054,"end":4061,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":3941,"end":3951,"text":"Naïve Bayes"}]},{"label":["Skills"],"points":[{"start":3494,"end":3501,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":3132,"end":3141,"text":"Word Cloud"}]},{"label":["Skills"],"points":[{"start":2793,"end":2800,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":2110,"end":2116,"text":"Pycharm"}]},{"label":["Skills"],"points":[{"start":2101,"end":2108,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":2086,"end":2091,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":2080,"end":2083,"text":"AJAX"}]},{"label":["Skills"],"points":[{"start":2067,"end":2076,"text":"JavaScript"}]},{"label":["Skills"],"points":[{"start":2060,"end":2063,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":2054,"end":2057,"text":"XSLT"}]},{"label":["Skills"],"points":[{"start":2049,"end":2051,"text":"XML"}]},{"label":["Skills"],"points":[{"start":2018,"end":2025,"text":"Mongo DB"}]},{"label":["Skills"],"points":[{"start":2003,"end":2015,"text":"Microsoft SQL"}]},{"label":["Skills"],"points":[{"start":1977,"end":1986,"text":"Word Cloud"}]},{"label":["Skills"],"points":[{"start":1958,"end":1975,"text":"K means clustering"}]},{"label":["Skills"],"points":[{"start":1945,"end":1955,"text":"Naïve Bayes"}]},{"label":["Skills"],"points":[{"start":1918,"end":1928,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":1908,"end":1915,"text":"Backbone"}]},{"label":["Skills"],"points":[{"start":1901,"end":1905,"text":"Ember"}]},{"label":["Skills"],"points":[{"start":1892,"end":1898,"text":"Angular"}]},{"label":["Skills"],"points":[{"start":1887,"end":1889,"text":"Vue"}]},{"label":["Skills"],"points":[{"start":1880,"end":1884,"text":"React"}]},{"label":["Skills"],"points":[{"start":1871,"end":1877,"text":"FuelPHP"}]},{"label":["Skills"],"points":[{"start":1866,"end":1868,"text":"Yii"}]},{"label":["Skills"],"points":[{"start":1857,"end":1863,"text":"CakePHP"}]},{"label":["Skills"],"points":[{"start":1848,"end":1854,"text":"Phalcon"}]},{"label":["Skills"],"points":[{"start":1842,"end":1845,"text":"Zend"}]},{"label":["Skills"],"points":[{"start":1833,"end":1839,"text":"Symfony"}]},{"label":["Skills"],"points":[{"start":1820,"end":1830,"text":"CodeIgniter"}]},{"label":["Skills"],"points":[{"start":1811,"end":1817,"text":"Laravel"}]},{"label":["Skills"],"points":[{"start":1806,"end":1808,"text":"PHP"}]},{"label":["Skills"],"points":[{"start":1798,"end":1803,"text":"MS SQL"}]},{"label":["Skills"],"points":[{"start":1790,"end":1795,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":1776,"end":1787,"text":"Web Services"}]},{"label":["Skills"],"points":[{"start":1764,"end":1773,"text":"Javascript"}]},{"label":["Skills"],"points":[{"start":1759,"end":1761,"text":"Mvc"}]},{"label":["Skills"],"points":[{"start":1750,"end":1756,"text":"Web Api"}]},{"label":["Skills"],"points":[{"start":1745,"end":1747,"text":"Sql"}]},{"label":["Skills"],"points":[{"start":1739,"end":1742,"text":"Linq"}]},{"label":["Skills"],"points":[{"start":1733,"end":1736,"text":"Rdlc"}]},{"label":["Skills"],"points":[{"start":1724,"end":1730,"text":"ASP.NET"}]},{"label":["Skills"],"points":[{"start":1720,"end":1721,"text":"C#"}]},{"label":["Skills"],"points":[{"start":1709,"end":1717,"text":".NET core"}]},{"label":["Skills"],"points":[{"start":1697,"end":1706,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":1688,"end":1694,"text":"Java EE"}]},{"label":["Skills"],"points":[{"start":1683,"end":1685,"text":"WAS"}]},{"label":["Skills"],"points":[{"start":1678,"end":1680,"text":"IHS"}]},{"label":["Skills"],"points":[{"start":1661,"end":1675,"text":"Computer Vision"}]},{"label":["Skills"],"points":[{"start":1645,"end":1658,"text":"Data Structure"}]},{"label":["Skills"],"points":[{"start":1630,"end":1642,"text":"Random Forest"}]},{"label":["Skills"],"points":[{"start":1615,"end":1627,"text":"Decision Tree"}]},{"label":["Skills"],"points":[{"start":1594,"end":1612,"text":"Logistic Regression"}]},{"label":["Skills"],"points":[{"start":1575,"end":1591,"text":"Linear Regression"}]},{"label":["Skills"],"points":[{"start":1568,"end":1572,"text":"Azure"}]},{"label":["Skills"],"points":[{"start":1556,"end":1565,"text":"Tensorflow"}]},{"label":["Skills"],"points":[{"start":1544,"end":1553,"text":"Regression"}]},{"label":["Skills"],"points":[{"start":1531,"end":1541,"text":"Time Series"}]},{"label":["Skills"],"points":[{"start":1516,"end":1528,"text":"Web Analytics"}]},{"label":["Skills"],"points":[{"start":1501,"end":1513,"text":"Deep Learning"}]},{"label":["Skills"],"points":[{"start":1495,"end":1498,"text":"Oops"}]},{"label":["Skills"],"points":[{"start":1482,"end":1492,"text":"Text Mining"}]},{"label":["Skills"],"points":[{"start":1469,"end":1479,"text":"Data Mining"}]},{"label":["Skills"],"points":[{"start":1459,"end":1466,"text":"Patterns"}]},{"label":["Skills"],"points":[{"start":1447,"end":1456,"text":"Regression"}]},{"label":["Skills"],"points":[{"start":1437,"end":1444,"text":"Modeling"}]},{"label":["Skills"],"points":[{"start":1418,"end":1434,"text":"Parametric Design"}]},{"label":["Skills"],"points":[{"start":1406,"end":1415,"text":"Map Reduce"}]},{"label":["Skills"],"points":[{"start":1398,"end":1403,"text":"Django"}]},{"label":["Skills"],"points":[{"start":1391,"end":1395,"text":"Flask"}]},{"label":["Skills"],"points":[{"start":1382,"end":1388,"text":"Sklearn"}]},{"label":["Skills"],"points":[{"start":1373,"end":1379,"text":"Pyspark"}]},{"label":["Skills"],"points":[{"start":1365,"end":1370,"text":"Pandas"}]},{"label":["Skills"],"points":[{"start":1340,"end":1362,"text":"Artificial Intelligence"}]},{"label":["Skills"],"points":[{"start":1325,"end":1337,"text":"Sql Reporting"}]},{"label":["Skills"],"points":[{"start":1325,"end":1327,"text":"Sql"}]},{"label":["Skills"],"points":[{"start":1319,"end":1322,"text":"Msbi"}]},{"label":["Skills"],"points":[{"start":1313,"end":1316,"text":"Ssrs"}]},{"label":["Skills"],"points":[{"start":1302,"end":1310,"text":"Msbi Ssis"}]},{"label":["Skills"],"points":[{"start":1302,"end":1305,"text":"Msbi"}]},{"label":["Skills"],"points":[{"start":1280,"end":1299,"text":"SQL server reporting"}]},{"label":["Skills"],"points":[{"start":1267,"end":1277,"text":"Programming"}]},{"label":["Skills"],"points":[{"start":1258,"end":1264,"text":"Bigdata"}]},{"label":["Skills"],"points":[{"start":1252,"end":1255,"text":"Hive"}]},{"label":["Skills"],"points":[{"start":1244,"end":1249,"text":"Hadoop"}]},{"label":["Skills"],"points":[{"start":1237,"end":1241,"text":"Scala"}]},{"label":["Skills"],"points":[{"start":1231,"end":1234,"text":"Java"}]},{"label":["Skills"],"points":[{"start":1226,"end":1228,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1208,"end":1223,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1200,"end":1205,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1186,"end":1197,"text":"Data Science"}]},{"label":["Skills"],"points":[{"start":1178,"end":1183,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1161,"end":1175,"text":"Project Manager"}]},{"label":["Skills"],"points":[{"start":1144,"end":1158,"text":"Quality Analyst"}]},{"label":["Skills"],"points":[{"start":1139,"end":1141,"text":"Ios"}]},{"label":["Skills"],"points":[{"start":1126,"end":1136,"text":"Informatica"}]},{"label":["Skills"],"points":[{"start":1121,"end":1123,"text":"Etl"}]},{"label":["Skills"],"points":[{"start":1109,"end":1118,"text":"Networking"}]},{"label":["Skills"],"points":[{"start":1100,"end":1106,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":1090,"end":1097,"text":"Big Data"}]},{"label":["Skills"],"points":[{"start":1075,"end":1087,"text":"SQL Developer"}]},{"label":["Skills"],"points":[{"start":1067,"end":1072,"text":"Hadoop"}]},{"label":["Skills"],"points":[{"start":1061,"end":1064,"text":".NET"}]},{"label":["Skills"],"points":[{"start":1043,"end":1058,"text":"Embedded Systems"}]},{"label":["Skills"],"points":[{"start":1037,"end":1040,"text":"DBAs"}]},{"label":["Skills"],"points":[{"start":1023,"end":1034,"text":"UI Developer"}]},{"label":["Skills"],"points":[{"start":1005,"end":1020,"text":"Business Analyst"}]},{"label":["Skills"],"points":[{"start":989,"end":1002,"text":"Devops Android"}]},{"label":["Skills"],"points":[{"start":977,"end":986,"text":"Salesforce"}]},{"label":["Skills"],"points":[{"start":963,"end":974,"text":"Oracle Cloud"}]},{"label":["Skills"],"points":[{"start":949,"end":961,"text":"Oracle Fusion"}]},{"label":["Skills"],"points":[{"start":943,"end":946,"text":"J2EE"}]},{"label":["Skills"],"points":[{"start":929,"end":934,"text":"Python"}]},{"label":["Skills"],"points":[{"start":920,"end":926,"text":"Mongodb"}]},{"label":["Skills"],"points":[{"start":910,"end":917,"text":"Firebase"}]},{"label":["Skills"],"points":[{"start":902,"end":907,"text":"FoxPro"}]},{"label":["Skills"],"points":[{"start":893,"end":899,"text":"Clipper"}]},{"label":["Skills"],"points":[{"start":886,"end":890,"text":"dBASE"}]},{"label":["Skills"],"points":[{"start":879,"end":883,"text":"RDBMS"}]},{"label":["Skills"],"points":[{"start":871,"end":876,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":860,"end":868,"text":"FileMaker"}]},{"label":["Skills"],"points":[{"start":848,"end":857,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":830,"end":845,"text":"Microsoft Access"}]},{"label":["Skills"],"points":[{"start":818,"end":827,"text":"PostgreSQL"}]},{"label":["Skills"],"points":[{"start":811,"end":815,"text":"MySQL"}]},{"label":["Skills"],"points":[{"start":798,"end":808,"text":"Programming"}]},{"label":["Skills"],"points":[{"start":796,"end":808,"text":"R Programming"}]},{"label":["Skills"],"points":[{"start":779,"end":794,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":234,"end":244,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":219,"end":231,"text":"R programming"}]},{"label":["Skills"],"points":[{"start":201,"end":216,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":165,"end":180,"text":"Machine Learning"}]},{"label":["Name"],"points":[{"start":0,"end":13,"text":"Udaya Laxmi Ch"}]}],"extras":null,"metadata":{"first_done_at":1579625576000,"last_updated_at":1579626369000,"sec_taken":0,"last_updated_by":"aJOmJy1lvpOYFetVNuqLvFo9Vx42","status":"done","evaluation":"NONE"}}
{"content": "Rakesh Kumar Pahwa\n\n\n+91-9986254160 | rikkypahwa@gmail.com | Coffee Board Layout, Bengaluru\nOverall Highlight:\nSolid Data Science experience with Machine/Deep Learning and BigData(Hadoop) technologies.\n\nTechnical Skills:\n· Data Science Skills: Machine Learning and Deep Learning, Neural Networks, Classification and Regression, Supervised, Unsupervised and Reinforcement Learning, Predictive analytics, Recommendation Systems, Statistics, Hypothesis Testing, Natural Language Processing, Object Detection, Computer Vision, EDA, Spark ML, Convolutional and Recurrent Neural Networks, \n· Data Science Tools: Tensorflow, Pandas, Numpy, Scipy, Scikit-Learn, iPython/Jupyter Notebook, Matplotlib, ggPlot, OpenCV, NLTK, Keras, Pillow\n· BigData Skills: HDFS, MapReduce, Spark (PySpark and Spark-Scala), Hive, Pig, Hbase, Kafka, Oozie, Phoenix, Sqoop, Flume, Solr, HortonWorks, Cloudera, MapR \n\n· Programming Skill: Python, Scala, Core Java, PL/SQL, Shell Scripting\n· Other technologies: MySql, Teradata, Oracle, Virtualization, Jenkins, Unix/Linux, Maven, SBT, Eclipse, IntelliJ, Netbeans, PyCharm\nProfessional Experience (9 years):\n\n\n· Working with Target Corporation India, Bangalore as a Senior Analyst.\n· Worked as a Project Lead with Syntel, Pune from Sept 2015 to March 2016.\n· Worked as a Senior Consultant with Capgemini, Bangalore from Feb 2015 to Sept 2015. \n· Worked as a Technical Consultant with Hewlett Packard India Software Operations, Bangalore from Feb 2009 to Feb 2015. \n\nPROJECT Participation:\n\n\nProject # 1\n\n\nTGTV Ad Recommendations:\n\tOrganization\n\tTarget Corporation\n\n\tTools & technologies\n\tMachine Learning, Deep Learning, Neural Networks, Tensorflow, Keras, Spark ML, Hive, Hadoop, \n\n\tTeam Size\n\t5\n\n\tCurrent Role\n\tSenior Analyst\n\n\nProject Description:\nThe objective of this project is to personalize the experience for identified web guests. Guests data was collected from various channels like iPad, iPhone, Android Devices, Cartwheel, Browser. TV clicks data was collected from the 3rd Party tools. Data was preprocessed through PCA algorithms and recommendations algorithms were developed to personalize the campaigns, guest web pages.\nRole & Responsibilities:\n\n· Developed Collaborative Filtering, Association Learning techniques using Python Machine/Deep Learning models. \n\n· Analyzed the TV feeds/ Guest Data to prepare Deep Learning model.\n\n· Decision Tree Algorithms were developed on Transactions data to find the targeted guests for product recommendations.\n\n· Developed the Neural Networks using Tensorflow.\n· Developed spark/Hive code to preprocess the data.\n· Worked with other teams to create the real-time processing of the data.\n\nProject # 2\n\nT-Stores sale forecasting:\n\tOrganization\n\tTarget Corporation\n\n\tTools & technologies\n\tMachine Learning, Deep Learning, Pandas, Numpy, Scipy, Hive, Spark, PySpark\n\n\tTeam Size\n\t3\n\n\tCurrent Role\n\tSenior Analyst\n\n\nProject Description:\n\nThe objective of this project is to do assortment planning. Time series models were developed using RNNs to predict the sales at store level. Guests Latitude/Longitude information was used to correct the Block Ids of the guests using Ray-Casting Algorithm. Haversine distance formula was used to decrease the number of iterations by finding the distance of the guests from the centroids of the Block Ids. \nRole & Responsibilities:\n\n· Developed Time Series Model using Historical Data to predict the sale at stores level.\n· Developed Haversine distance code to find the geographical distance between the Block Ids centroid to Guests Lat/Lon.\n\n· Prepared data with Guests Lat/Lon, Block Ids Lat/Lon and minimum and distance of 100 miles.   \n· Developed ray-casting algorithm using PySpark to correct the Block group ids.\n\nProject # 3\n\nvMM Health Prediction Project (Sept-2015 – March 2016)\n\n\tClient\n\tValence Health care\n\n\tOrganization\n\tSyntel India Pvt Ltd\n\n\tTools & technologies\n\tMachine Learning, Hive, Python, Elastic Search\n\n\tRole\n\tProject Lead\n\n\tTeam Size\n\t4\n\n\nProject Description:\n\nThe objective of this project is to do the member matching/linking using distance based algorithms and predict the Patients visits and duration of their stay in the hospital. Incremental data was compared with Hbase tables data using deterministic and probabilistic methods. Deterministic matching used to find the perfect match of the records on number of feature vectors. Probabilistic matching was implemented using Levenshtein distance algorithm. Regression algorithms was implemented predict the Patient visits and duration of their stay in the hospital.\nRole & Responsibilities:\n· Preprocessing of the data and feature engineering.\n\n· Written Python code for the distance algorithms.\n· Created model to predict the patient visits in the hospital.\n· Improvised the model using cross validation, Regularization techniques. \n· Curl queries to fetch the data from Hbase using Elasticsearch.\n· Hbase Data modelling.\n· Hive queries and UDFs to preprocess the data and store in structured form.\nProject # 4\n\nEBBS Sourcing Project (Feb-2015 – Sept-2015)\n\n\tClient\n\tScope International (Standard Chartered Bank), Malaysia\n\n\tOrganization\n\tCapgemini India Pvt Ltd\n\n\tTools & technologies\n\tHDFS, MapReduce, Shell Scripting, Hive, MySQL, Core Java, Falcon, Oozie, Spark, Sqoop, Flume, Zookeeper, Control-M, CDC\n\n\tRole\n\tTech Lead\n\n\tTeam Size\n\t12\n\n\nProject Description:\n\nThe objective of the EBBS Sourcing Project is to develop a Data Lake as part of Standard Chartered Bank’s strategy to create an Enterprise Data Management (EDM) platform. The Data Lake was part of the ‘Tier 1’ layer of the EDM and was developed using Hadoop based technologies. This Tier will be a source of data for other storage and processing layers within the broader EDM. This Project is divided into three layers – Landing Layer for the data, Storage Layer for the data and Processing Layer for the data.\nRole & Responsibilities: \n\n· Written shell scripts for preprocessing and storing of data with date/hour partitions in HDFS.\n· Extract the data using Hive Queries and UDFs.\n· Coordinate with the control-M, CDC team to schedule jobs.\n· Schedule the Jobs using Oozie.\n· Creating xml files for apache falcon.\n· Written MapReduce jobs for filtering and joining table’s data.\nProject # 5\n\nInsurance Claim Analysis (March-2014 – Jan-2015)\n\n\tClient\n\tPacific Life Insurance, USA\n\n\tOrganization\n\tHewlett Packard India Software Operations\n\n\tTools & technologies\n\tHDFS, MapReduce, Shell Scripting, Hive, MySQL, Core Java, Oozie, Sqoop, Flume, Zookeeper,\n\n\tRole\n\tHadoop Developer\n\n\tTeam Size\n\t10\n\n\nProject Description:\n\n· Execute advisory role for customers to help them with their Big data journey. Providing consultancy, develop proof of concept and creating a larger vision and roadmap\n\n· Lead technology exploration and innovation on Big data technologies\n\n· Facilitate competency building and solution designing capabilities in Big data technologies\n\n· Support pre-sales team to prepare RFI and RFPs for big data solutions\n· Create focus on NoSQL and other next generation big data analytics\nRole & Responsibilities: \n· Exporting data to HDFS cluster using Flume/Sqoop.\n· Analyzed the data using Hive Queries and UDFs.\n· Written multiple map reduce jobs in java for data cleaning and preprocessing.\n· Written Hive queries.\n· Work with the documentation team to update the design documents.\n· Provided multiple training sessions for new joiners.\n· Responsible for integrating Hive and Hbase.\n Project # 6\n\nBSM Event Management Analysis (Feb 2013 – Jan 2014)\n\tClient\n\tHewlett Packard\n\n\tOrganization\n\tHewlett Packard India Software Operations\n\n\tTools & technologies\n\tHDFS, MapReduce, Core Java, Oozie, Sqoop, Flume, Zookeeper,\n\n\tRole\n\tHadoop Developer\n\n\tTeam Size\n\t7\n\n\nProject Description:\n\nHP, uses Sitescope to monitor their environments. SiteScope is agentless monitoring software focused on monitoring the availability and performance of distributed IT infrastructures, including Servers, Network devices and services, Applications and application components, operating systems and various IT enterprise components.\nAll the events are stored in RDBMS. As part of Hadoop Analytics, the data is first moved from Oracle DB to HDFS and analyzed using Hive/Pig. \nRole & Responsibilities: \n· Responsible for building scalable distributed data solutions using Hadoop.\n·  Installed and configured Hadoop MapReduce, HDFS and developed multiple MapReduce jobs in Java for data cleansing and preprocessing.\n· Installed and configured Hive and also written Hive UDFs.\n· Analyzed the data by performing Hive queries and running Pig scripts to know user behavior. \n· Importing and exporting data into HDFS using Sqoop.\n· Schedule the Jobs using Oozie.\nProject # 7\n\nOMW/OMU (March 2009 – Nov 2012)\n\tOrganization\n\tHewlett Packard India Software Operations\n\n\tTools & technologies\n\tShell Scripting, SQL, Oracle, Core Java, Multithreading\n\n\tRole\n\tTechnical Solution consultant\n\n\tTeam Size\n\t5\n\n\nProject Description\nThis project aims at providing CPE (Current product engineering) for the product HP operations manager window/Unix and operations manager interface.\nHP Operations manager is a product used to manage IT infrastructure for any organization, this product provides flexibility to manage whole IT infrastructure from a single server irrespective of various operating system and architectures of various servers.\n\nThe product basically follows the client server model of communication with one of the server acting as Management server (server from which we can manage whole infrastructure) while on rest of the OM agent is installed which communicates with the management server, providing all the necessary information for the server where it is installed.\nRoles & Responsibilities:-\n· Serving and validating the Enhancements requests raised by global clients in the existing modules of the product.\n· Providing best solution for Issues/Bugs rose, in compliance with SLA\n· Acquiring full knowledge (Code/Business level) of all the systems under consideration.\n\n· Worked on Type 1 and Type 2 Hypervisors.\n· Interactions with other teams (PD) to resolve issues with minimal turnaround time.\n\n· Perform environment checkup for all Platforms (Our test infrastructure) and applications weekly.\n\n· Developing value-adds (designing/documenting/implementing) on monthly basis for upcoming patch releases.\n\n· Providing knowledge transfer, training to new resources.\nAchievement:\n\n\n· Awarded for serving business critical requests for clients by HP Software solution.   \n\n· Awarded for the star of the month in the team and champion award worldwide department.\n\n· Secured first prize in project display in Technshiya-festive at SKIET.\nAcademic Qualification:\n\n\n\tDegree\n\tUniversity/Board\n\tYear of Passing\n\tPercentage\n\n\tB.Tech. (Electronics and Comm.)\n\tKurukshetra University\n\t2008\n\t74.1%\n\n\t12th \n\tHaryana\n\t2004\n\t74.8%\n\n\t10th\n\tHaryana\n\t2002\n\t63%\n\n\n· Topped college in 2 semesters during B.Tech.\nExtra-Curricular Activities\n\n\n· Actively participate in Company sports meet.\n\n· Yoga and meditation secretary in College.\n\n· Acting as an organizer for various fun team events.\nStrengths\n\n\n· Proactive & Responsible \n\n· Good team skills\n\n· Good Communication & analytical skills\n\nPersonal Detail\n\n\nFather’s Name \n\nMr. Sudesh Kumar Pahwa\nMother’s Name\n\nMrs. Darshana Pahwa\nBirth Date \n\n18 Jun 1986\nGender\n\n\nMale\n\nMarital Status \n\nMarried\nCurrent Address\n#321, Green Apple Apartment, Coffee board layout, Bangalore - 560024\nPlace: Bangalore  \n\n\n\n\n\n\n\n\nDate: \n\nRakesh Kumar Pahwa","annotation":[{"label":["Name"],"points":[{"start":11487,"end":11504,"text":"Rakesh Kumar Pahwa"}]},{"label":["Education"],"points":[{"start":10756,"end":10786,"text":"B.Tech. (Electronics and Comm.)"}]},{"label":["Skills"],"points":[{"start":2264,"end":2284,"text":"Machine/Deep Learning"}]},{"label":["Skills"],"points":[{"start":172,"end":186,"text":"BigData(Hadoop)"}]},{"label":["Skills"],"points":[{"start":146,"end":166,"text":"Machine/Deep Learning"}]},{"label":["Location"],"points":[{"start":81,"end":90,"text":" Bengaluru"}]},{"label":["Name"],"points":[{"start":0,"end":17,"text":"Rakesh Kumar Pahwa"}]}],"extras":null,"metadata":{"first_done_at":1532671856000,"last_updated_at":1532671856000,"sec_taken":91,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Rama Subba Reddy  \n \n\nSUMMARY \n \nME in Chemical Engineering from IISc Bengaluru with 8 years of experience in data science and mathematical \n\nmodeling. \n\n \n\nSKILLS \n Statistics: Hands-on experience on Kriging (special/Geo statistics), Random Forest (Decision trees), Neural \n\nNetwork, Bagging, Boosting, Time series analysis, Clustering using distance, Spline interpolation, Nonlinear \n\nRegression, Function fitting, Hypothesis testing and Design of Experiments, parallel programming in r.\n Programming Languages:  R, C, C++, Fortran\n Scripting:  Hive, Iron Python in SpotFire\n Software:  MATLAB, Excel & SpotFire (Visualization Software), TFS (basics), GitHub(basics)\n Worked with Hadoop ecosystem, Basic knowledge of MapReduce\n Team management, Agile development methodology, Project planning through Lifecycle.\n\n\n\nProfessional Experience  \n Senior Technical Professional at Halliburton Technology Center since March 2014. \n\n Senior QA at Cd-Adapco from September 2013 to Feb 2014. \n\n Senior Project engineer at Tridiagonal Solutions from October 2012 to September 2013. \n\n Worked as system engineer at Tata Consultancy Services from August 2009 to October 2012.  \n \n\nData Science related experience: (5 years) \nData Science:  \n\n Demonstrated value of data analysis in evaluating fracturing services performance by executing proof of \n\nconcept (POC) for the first time in Permian basin. \n\n Developed statistical model using kriging and random forest technique to estimate oil production. \n\nFurthermore, evaluated linear regression, neural networks, decision tree and boosting. \n\n Built optimization algorithm around the machine learning algorithm to optimize the predictor space for \n\naccurate predictions. \n\n Built a process to extract, transform and load (ETL) US oil and gas production data using Apache Hive. \n\n Automated data validation by creating an r scripts for generating reports for data quality. \n\n Developed dynamic visualization tools based upon the customer requirement using TIBCO Spotfire tool. \n\nUtilized scripting in Iron Python to enhance performance and user experience of Spotfire visualizations. \n\n Dashboard for operational efficiency to track performance of crews working in North America region. \n\n \nMathematical Modeling & Data science:   \n\n Developed and implemented abstract mathematical models in C++ to allow release of new features and \n\nfluids calculations without the need of re-releasing the software every quarter.\n Developed Rheology, Friction, Fluid Loss, Fracturing and Acidizing mathematical models through non-\n\nlinear regression using Excel. \n\n Guided a team of seven software developers and testers to deliver end to end solution for material property \ncalculation software. \n\n \n \n \n \n \n \n \n \nEmail: rama826@gmail.com Tel: (+91)9960318674 \n\n\n\nRama Subba Reddy \n \nProject Management, Reporting & Documentation:  \n\n Executed project management through LifeCycle involving acquiring requirement from Strategic Business \n\nManager, budgeting and developing the project plan by executing cost and risk analysis, distributing work \n\namong resources, developing models, implementing in C++ and validating through field data within \n\ncommitted timeline, all the while following process and documentation in accordance with ISO. \n\n Marketed developed models and tools by presenting in business and internal conferences. Published \n\ntechnology bulletins and case studies for internal marketing. \n\n\n\nOther Industry Experience: (4 years)\n Modeling and experimental studies on Drug Release from Swelling Controlled Release Systems    \n\n Modeling and Experimental Studies on Ultra-fine Grinding in a Planetary Ball Mill \n\n CFD modelling of drug delivery through Stent \n\n Modelling of Stirred tank reactor using computational dynamics and process dynamic simulations \n\n DEM simulations of SAG Mill and Screw Augur using EDEM \n\n Design of coffee been dryer using EDEM. \n\n Design of conveyor belt for delicate food material transport. \n\n Coupled CFD+DEM simulation of shoe mold filling.\n \n\nEDUCATION \nYear Degree Institution CGPA/Percentage \n\n2009 M.E Indian Institute of science (IISC), Bengaluru 6.4/8 \n\n2007 B.Tech JNTU 77 \n\n \n\nCERTIFICATES & ACHIEVEMENTS \n\n Data science specialization from Johns Hopkins university/Course era (In progress) \n\n Commercialized 3 data driven products in 3 years \n\n Received several appreciation emails from SBM and top management \n\n Project management training and certification by Halliburton \n\n Intellectual Property training and certification by Halliburton  \n\n Crew Leadership training and certification by Halliburton \n\n Life Cycle Management training and certification by Halliburton \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\n1)  \n \n \n \n \n \n\n \n\n \n\n \nEmail: rama826@gmail.com Tel: (+91)9960318674","annotation":[{"label":["Skills"],"points":[{"start":4649,"end":4649,"text":"C"}]},{"label":["Skills"],"points":[{"start":4582,"end":4582,"text":"C"}]},{"label":["Skills"],"points":[{"start":4379,"end":4379,"text":"R"}]},{"label":["Skills"],"points":[{"start":4326,"end":4326,"text":"C"}]},{"label":["Skills"],"points":[{"start":4297,"end":4297,"text":"C"}]},{"label":["Education"],"points":[{"start":4229,"end":4230,"text":"ME"}]},{"label":["Skills"],"points":[{"start":4223,"end":4223,"text":"C"}]},{"label":["Skills"],"points":[{"start":4214,"end":4214,"text":"C"}]},{"label":["Skills"],"points":[{"start":4209,"end":4209,"text":"R"}]},{"label":["Skills"],"points":[{"start":4207,"end":4207,"text":"C"}]},{"label":["Skills"],"points":[{"start":4160,"end":4160,"text":"C"}]},{"label":["Skills"],"points":[{"start":4101,"end":4101,"text":"C"}]},{"label":["Skills"],"points":[{"start":4069,"end":4069,"text":"C"}]},{"label":["Skills"],"points":[{"start":4021,"end":4021,"text":"C"}]},{"label":["Skills"],"points":[{"start":4013,"end":4013,"text":"C"}]},{"label":["Skills"],"points":[{"start":3696,"end":3696,"text":"C"}]},{"label":["Skills"],"points":[{"start":3587,"end":3587,"text":"R"}]},{"label":["Skills"],"points":[{"start":3576,"end":3576,"text":"C"}]},{"label":["Skills"],"points":[{"start":3554,"end":3554,"text":"R"}]},{"label":["Skills"],"points":[{"start":3160,"end":3162,"text":"C++"}]},{"label":["Skills"],"points":[{"start":3160,"end":3160,"text":"C"}]},{"label":["Skills"],"points":[{"start":2936,"end":2936,"text":"C"}]},{"label":["Skills"],"points":[{"start":2864,"end":2864,"text":"R"}]},{"label":["Skills"],"points":[{"start":2835,"end":2835,"text":"R"}]},{"label":["Name"],"points":[{"start":2824,"end":2840,"text":"Rama Subba Reddy "}]},{"label":["Skills"],"points":[{"start":2824,"end":2824,"text":"R"}]},{"label":["Skills"],"points":[{"start":2497,"end":2497,"text":"R"}]},{"label":["Skills"],"points":[{"start":2359,"end":2361,"text":"C++"}]},{"label":["Skills"],"points":[{"start":2359,"end":2359,"text":"C"}]},{"label":["Skills"],"points":[{"start":2066,"end":2076,"text":"Iron Python"}]},{"label":["Skills"],"points":[{"start":2024,"end":2024,"text":"C"}]},{"label":["Skills"],"points":[{"start":1835,"end":1838,"text":"Hive"}]},{"label":["Skills"],"points":[{"start":1372,"end":1372,"text":"C"}]},{"label":["Skills"],"points":[{"start":1132,"end":1132,"text":"C"}]},{"label":["Skills"],"points":[{"start":961,"end":961,"text":"C"}]},{"label":["Skills"],"points":[{"start":919,"end":919,"text":"C"}]},{"label":["Skills"],"points":[{"start":763,"end":768,"text":"Agile "}]},{"label":["Skills"],"points":[{"start":735,"end":735,"text":"R"}]},{"label":["Skills"],"points":[{"start":560,"end":570,"text":"Iron Python"}]},{"label":["Skills"],"points":[{"start":554,"end":557,"text":"Hive"}]},{"label":["Skills"],"points":[{"start":530,"end":536,"text":"Fortran"}]},{"label":["Skills"],"points":[{"start":525,"end":527,"text":"C++"}]},{"label":["Skills"],"points":[{"start":525,"end":525,"text":"C"}]},{"label":["Skills"],"points":[{"start":522,"end":522,"text":"C"}]},{"label":["Skills"],"points":[{"start":519,"end":519,"text":"R"}]},{"label":["Skills"],"points":[{"start":388,"end":388,"text":"R"}]},{"label":["Skills"],"points":[{"start":327,"end":327,"text":"C"}]},{"label":["Skills"],"points":[{"start":236,"end":236,"text":"R"}]},{"label":["Skills"],"points":[{"start":202,"end":209,"text":"Kriging "}]},{"label":["Skills"],"points":[{"start":39,"end":39,"text":"C"}]},{"label":["Education"],"points":[{"start":33,"end":34,"text":"ME"}]},{"label":["Skills"],"points":[{"start":27,"end":27,"text":"R"}]},{"label":["Skills"],"points":[{"start":11,"end":11,"text":"R"}]},{"label":["Name"],"points":[{"start":0,"end":16,"text":"Rama Subba Reddy "}]},{"label":["Skills"],"points":[{"start":0,"end":0,"text":"R"}]}],"extras":null,"metadata":{"first_done_at":1532693259000,"last_updated_at":1532693259000,"sec_taken":111,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Ranvir Kumar\n  Phone: +91-8102521214\n      Ranvirk020@gmail.com\n\nRelevant Exp in Data scientist & ML : 2.5 Yrs \nWork Experience:\n· A dynamic professional with nearly 4.2 year of experience.\n· Having 2 year and 5 months experience as Data Scientist with R programming.\n· Currently working for NTT DATA Information Processing Services Private Limited from May 2016 to till now.\n· Previously worked for Radisis solution (india) Pvt. Ltd. from October 2013 to May 2016 Bangalore.\n· Experience Summary :\n· Having 4.2 years of IT Experience in Data scientists and Oracle SQL,PL/SQL Developer.\n· Having experience in R STUDIO, R Programming.\n\n· Having experience in Machine learning, Linear Regression, Logistic Regression, K-means\n· Responsible for creating and modifying the Data frames, sub setting the objects according to the business requirement. \n\n· Having good knowledge in Other Utilities TOAD, SQL LOADER, SQL*PLUS.\n\n· Worked on development of SQL Queries, procedures, functions and packages as per        business requirement.   \n\n· Main responsibilities include understanding of client requirements & develop solutions.\n\n· Ability to be an effective team player and work under time constraints.\n\n· Good interpersonal communication skills & Technical Documentation skills.\n\n \nSkill Sets\nOS - Windows XP /7/8, Unix, Linux\nLanguages - SQL, PL/SQL , Shell Scripting, R\nDatabases - Oracle 9i/10g/11g\nTools - Toad, SQL*Loader, SQL*Plus\n\nMachine Learning Techniques   : Linear Regression, Logistic Regression, K-means\nProfessional Experience\n· Project#1: CCA FMS\n\n· Client:   Connector Healthcare\n\n· Duration: May’2016 till Date\n\n· Skill     :  R, Machine Learning, SQL\n\n· Role    :  Software Developer Analyst\n\n· Technology used: PL SQL, R STUDIO, CLEAR QUEST, TOAD\n\n· Description:  The Commonwealth Health Insurance Connector Authority (Health Connector) is an independent public authority serving as the Affordable Care Act (ACA)-compliant marketplace for the Commonwealth.  The organization is charged with providing subsidized and unsubsidized health insurance to individuals and small employers. \n\n· Responsibilities: \n\n· An active team member to understand the business requirements given by client in SRS. \n· Involve in analyzing requirements and preparing SDS from SRS. \n· Importing data from different sources like ORACLE DATABASE, CSV, SAS,SPSS, EXCEL and manipulating the data as per the requirement.\n· As a Team member involved in coding and testing.\n\n· Proposing feasible solution to user requirements. \n\n· Responsible for PL/SQL development\n\n· Developing data frames, pie chart, bar chart as part of change request or new requirement.\n· Responsible for doing the analysis and providing the solution for the complex issues occurring with the application.\n\n· Handling daily incidents/issues for application.\n\n· Having daily status meeting within the team for the progress and issues occurring and affecting the application.\n\n· Preparing weekly & monthly report and presenting it to the management as a presentation on monthly basis.\n\n· Providing on-call support to the application as and when required.\n\n\nProject #2\nClient:- TeliaSonera Sverige\nDuration – Dec 2013 to Feb 2015\nEnvironment - Oracle 10g/PL/SQL/SQL*PLUS/SQL LOADER\nRole: PL/SQL Developer\n\nDescription: TeliaSonera is the dominant telephone company and mobile network operator in Sweden and Finland. The company has operations in other countries in Northern, Eastern Europe. To operate transaction for subscription /redemption, we need to maintain the various bonds details, customer details etc. There is a need for executing the standing instructions given by the customer for the proceedings of the same package used for maintaining customer details in the database. It also contains the information about current customer attributes, address details, billing information, recent interactions etc.\n\n     Responsibilities:\n· Wrote and modified Oracle PL and SQL, Sql statements procedures and function\n·  Loaded Data into Oracle Tables using SQL Loader\n· Created Packages and Procedures to automatically drop table indexes and create indexes for  the tables. \n· Worked extensively on Ref Cursor, External Tables and Collections. \n· Preparation of SQL Loader scripts Pl/Sql programs for inbound interface.\n\n· Developed outbound interface to transfer the data from base tables to external System.\n\n· Creating PL/SQL Packages, Procedures, Functions for data population and updation as per project requirements.\n· Created database objects like stored procedures, function, packages, Cursor, Ref Cursor and Triggers.\n\nProject #3\nProject: Telewings Wireless LTD\nEnvironment - Oracle 10g/PL/SQL/SQL*PLUS/SQL LOADER\nDuration – Apr 2015 to May 2016\nRole – PL/SQL Developer\nDescription:- Telenor India (formally known as Uninor),is a Indian mobile network operator based in gurgaon,haryana,India. The company is wholly owned subsidiary of Telenor Group, a telecommunications company headquartered in Oslo, Norway Telenor India communications Pvt ltd.\nResponsibilities:\n\n\n· Used SQL LOADER to upload the information into the database tables-Preparation of SQL Loader scripts Pl/Sql programs .\n· Creating PL/SQL Packages, Procedures, Functions for data population and updation as per project requirements. \n· Writing queries based on specifications.\n·  Developed materialized views  in distributed environments.\n· Creating PL/SQL Packages, Procedures, Functions for data population and updation as per project requirements.\n· Wrote complex SQL queries using joins, sub queries and inline views to retrieve data from the database.\nEducational Qualifications : \nGraduated From Lovely Professional university in Bachelor Of Technology in Computer Science engineering in 2013\n\nPersonal Details : \n\nDate Of Birth: 16/03/1990\nLanguages Known: English, Hindi, Punjabi\nAddress: BTM 2nd Stage, Bangalore","annotation":[{"label":["Location"],"points":[{"start":5849,"end":5857,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":5387,"end":5392,"text":"PL/SQL"}]},{"label":["Skills"],"points":[{"start":5169,"end":5174,"text":"PL/SQL"}]},{"label":["Skills"],"points":[{"start":4723,"end":4728,"text":"PL/SQL"}]},{"label":["Skills"],"points":[{"start":4657,"end":4662,"text":"PL/SQL"}]},{"label":["Skills"],"points":[{"start":4383,"end":4388,"text":"PL/SQL"}]},{"label":["Skills"],"points":[{"start":3246,"end":3251,"text":"PL/SQL"}]},{"label":["Skills"],"points":[{"start":3213,"end":3218,"text":"PL/SQL"}]},{"label":["Skills"],"points":[{"start":2535,"end":2540,"text":"PL/SQL"}]},{"label":["Skills"],"points":[{"start":1760,"end":1763,"text":"TOAD"}]},{"label":["Skills"],"points":[{"start":1351,"end":1365,"text":"Shell Scripting"}]},{"label":["Skills"],"points":[{"start":1342,"end":1347,"text":"PL/SQL"}]},{"label":["Skills"],"points":[{"start":891,"end":894,"text":"TOAD"}]},{"label":["Skills"],"points":[{"start":620,"end":632,"text":"R Programming"}]},{"label":["Skills"],"points":[{"start":569,"end":574,"text":"PL/SQL"}]},{"label":["Skills"],"points":[{"start":558,"end":567,"text":"Oracle SQL"}]},{"label":["Location"],"points":[{"start":465,"end":473,"text":"Bangalore"}]},{"label":["Name"],"points":[{"start":0,"end":11,"text":"Ranvir Kumar"}]}],"extras":null,"metadata":{"first_done_at":1532682967000,"last_updated_at":1532682967000,"sec_taken":103,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Rashmi​ ​R​ ​Bhat  \nWeb​ ​Developer \n \nEmail:​ ​rbhat03@gmail.com \nPhone:​ ​+91​ ​9535830019 \n \n \n\n \n\nObjective Seeking​ ​a​ ​position​ ​as​ ​a​ ​​Web​ ​Developer​ ​​with​ ​a \ntechnology-driven​ ​organization​ ​that​ ​encourages \ninnovative​ ​thinking​ ​and​ ​career​ ​development​ ​enabling \na​ ​better​ ​work–life​ ​balance. \n\nSummary • 5​ ​years​ ​of​ ​experience \n• Highly​ ​proficient​ ​in​ ​​ ​Python,​ ​Django,​ ​HTML,​ ​CSS, \n\nJavascript,​ ​jQuery,​ ​Celery,  \nComputer/Software \nProficiency \n\nProgramming​ ​Languages​:​ ​​Python,​ ​HTML/HTML5, \n\nCSS/CSS3,Javascript,XML,SQL \n\nTools​ ​and​ ​Systems​ ​​:Django​ ​(1.3,​ ​1.5,1.8),​ ​Git,​ ​Ajax, \n\nJSON,​ ​Google​ ​Openid​ ​OAuth,​ ​Aptana​ ​Studio,​ ​Atom, \n\nPyCharm,​ ​Microsoft​ ​Office,​ ​Apache,​ ​Vagrant, \n\nAnsible,ngnix,​ ​Python(2.7,3.4,3.5)​ ​MySQL,  \n\nAPIs​ ​and​ ​Libraries:​ ​​jQuery​ ​,​ ​Google​ ​Visualization \n\nAPI,​ ​Highcharts,​ ​Bootstrap,​ ​Django​ ​AllAuth,​ ​Firebased \n\nCloud​ ​Messaging,​ ​Pdfkit,  \n\nPlatforms​:​ ​MS​ ​Windows​ ​(XP,​ ​Vista,​ ​7,​ ​8,​ ​Server \n\n2008,Server​ ​2012),​ ​Linux​ ​Ubuntu \n\nDatabases​:​ ​MySQL,SQLite \n\nExperience Tarams​ ​Technologies​ ​Pvt​ ​Ltd \nDesignation:​ ​​Software​ ​Engineer​ ​(Oct​ ​2015​ ​-​ ​Current​ ​) \nProject:​ ​​MB​ ​Sales​ ​App \nRole:​ ​​​ ​Backend​ ​Developer \n\nTechnology:​ ​​Django​ ​REST-​ ​API,​ ​Python,​ ​Celery, \nDjango​ ​Unit​ ​Tests \nDescription:  \n\n• A​ ​Mobile​ ​app​ ​designed​ ​for​ ​recording​ ​sales​ ​and \n\ncollection​ ​targets​ ​and​ ​activities​ ​of​ ​sales \n\n\n\nrepresentatives​ ​such​ ​as​ ​meetings​ ​,​ ​tasks​ ​and \n\nclient​ ​data. \n\n• An​ ​interface​ ​for​ ​the​ ​managers​ ​to​ ​monitor​ ​the \n\nactivities​ ​and​ ​progress​ ​of​ ​the​ ​team. \n\n \n\nProject:​ ​​MB​ ​Dashboard \nRole:​ ​​​ ​Developer \n\nTechnology:​ ​​Django​ ​REST-​ ​,API,​ ​Python, \nJavascript,​ ​HTML​ ​Templating,​ ​CSS,​ ​Pdfkit \nDescription:  \n\n• An​ ​admin​ ​interface​ ​for​ ​user​ ​management \n\nalong​ ​with​ ​data​ ​management. \n\n• A​ ​web​ ​interface​ ​for​ ​the​ ​sales​ ​representatives \n\nto​ ​view​ ​their​ ​activities. \n\n \n\nTelenetix​ ​Pvt​ ​Ltd  \nDesignation​ ​:​​ ​​Senior​ ​Software​ ​Engineer​ ​(​ ​Nov​ ​2012​ ​– \nSep​ ​2015) \n\n \n\nProject:​ ​​TxMonitor \nRole:​ ​​​ ​Developer \n\nTechnology:​ ​​Django​ ​Framework​ ​,Python, \nJavascript,​ ​HTML​ ​Templating,​ ​CSS \nDescription:  \n\n• A​ ​website​ ​to​ ​monitor​ ​server​ ​performance​ ​and \n\nservices. \n\n• An​ ​interface​ ​to​ ​add,​ ​update​ ​&​ ​delete \nservers,​ ​eventhandlers​ ​and​ ​credentials​ ​to \nbe​ ​used​ ​for​ ​monitoring​ ​the​ ​components. \n\n \n\n \n\nProject:​ ​​SolarGMU \nRole:​ ​​Developer \n\nTechnology:​ ​​Django​ ​Framework​ ​,Python, \nJavascript,​ ​HTML​ ​Templating,​ ​CSS \n\n\n\nDescription:  \n\n• ​ ​A​ ​website​ ​to​ ​monitor​ ​various​ ​devices. \n\n• An​ ​interface​ ​to​ ​read​ ​and​ ​write​ ​various \ndevice​ ​registers. \n\n• Graphical​ ​representations​ ​to​ ​display​ ​the \nvariation​ ​in​ ​the​ ​device​ ​readings​ ​on​ ​a \ndaywise​ ​basis​ ​using​ ​Google​ ​charts. \n\n \n\n \n\nProject:​ ​​SolarSmoother \nRole:​ ​​Developer \n\nTechnology:​ ​Ladder​ ​Programming \n\nDescription:  \n\n• ​ ​Software​ ​to​ ​control​ ​the​ ​inverter​ ​output​ ​based \n\non​ ​the​ ​solar​ ​power​ ​being​ ​generated. \n\n• To​ ​smooth​ ​the​ ​inverter​ ​output​ ​power \nduring​ ​sudden​ ​spikes​ ​in​ ​the​ ​solar​ ​input,​ ​in \norder​ ​to​ ​avoid​ ​any​ ​damage​ ​to​ ​the​ ​electrical \ndevices​ ​connected. \n\n \n\nEducation Bachelor​ ​of​ ​Engineering​ ​(​ ​BE)​ ​in \nElectronics​ ​&​ ​Communication  \nGSSSIETW,​ ​MYSORE​ ​/​ ​2008​ ​– \n2012 \n \n\nPersonal​ ​Details ​​ ​​ ​​ ​​​ ​​ ​Date​ ​of​ ​Birth​​ ​​ ​​ ​​:​​ ​23​rd​​ ​Feb​ ​​1991  \n\n​​ ​​ ​​ ​​​ ​​ ​Marital​ ​Status​​ ​​:​​ ​Single \n\n​​ ​​ ​​ ​​ ​​ ​Religion​​ ​​ ​​ ​​ ​​ ​​ ​​:​​ ​Hindu  \n\n​​ ​​ ​​ ​​​ ​​ ​Nationality​​ ​​ ​​:​ ​ ​Indian \n\n​​ ​​ ​​ ​​ ​​​ ​Languages​ ​​:​ ​​ ​​English,​ ​Hindi,​ ​Kannada  \n\nTulu​ ​and​ ​Telugu.  \n\n\n\nInterests : ​Listening to Music, Pencil        \n\nSketching, Reading, travelling and Outdoor     \n\nsports. \n\n \n \n\n \nDeclaration \n\n \nI​ ​hereby​ ​solemnly​ ​affirm​ ​that​ ​all​ ​details​ ​provided​ ​above​ ​are​ ​true​ ​to​ ​the​ ​best​ ​of​ ​my \nknowledge​ ​and​ ​belief​ ​and​ ​at​ ​all​ ​times​ ​I​ ​shall​ ​carry​ ​myself​ ​in​ ​a​ ​manner​ ​that​ ​lends​ ​dignity​ ​to \nthe​ ​organization​ ​and​ ​worthy​ ​enough​ ​of​ ​the​ ​person.  \n\n \n  \n\n  \n(Rashmi​ ​R​ ​Bhat)","annotation":[{"label":["Name"],"points":[{"start":4324,"end":4340,"text":"Rashmi​ ​R​ ​Bhat"}]},{"label":["Education"],"points":[{"start":3402,"end":3428,"text":"Bachelor​ ​of​ ​Engineering"}]},{"label":["Skills"],"points":[{"start":2675,"end":2678,"text":"​CSS"}]},{"label":["Skills"],"points":[{"start":2654,"end":2658,"text":"​HTML"}]},{"label":["Skills"],"points":[{"start":2641,"end":2650,"text":"Javascript"}]},{"label":["Skills"],"points":[{"start":2632,"end":2637,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2609,"end":2615,"text":"​Django"}]},{"label":["Skills"],"points":[{"start":2298,"end":2301,"text":"​CSS"}]},{"label":["Skills"],"points":[{"start":2277,"end":2281,"text":"​HTML"}]},{"label":["Skills"],"points":[{"start":2264,"end":2273,"text":"Javascript"}]},{"label":["Skills"],"points":[{"start":2255,"end":2260,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2232,"end":2238,"text":"​Django"}]},{"label":["Skills"],"points":[{"start":1839,"end":1842,"text":"​CSS"}]},{"label":["Skills"],"points":[{"start":1818,"end":1822,"text":"​HTML"}]},{"label":["Skills"],"points":[{"start":1805,"end":1814,"text":"Javascript"}]},{"label":["Skills"],"points":[{"start":1796,"end":1801,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1770,"end":1776,"text":"​Django"}]},{"label":["Skills"],"points":[{"start":1343,"end":1349,"text":"​Celery"}]},{"label":["Skills"],"points":[{"start":1334,"end":1339,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1309,"end":1315,"text":"​Django"}]},{"label":["Skills"],"points":[{"start":918,"end":924,"text":"​Django"}]},{"label":["Skills"],"points":[{"start":846,"end":852,"text":"​jQuery"}]},{"label":["Skills"],"points":[{"start":788,"end":793,"text":"Python"}]},{"label":["Skills"],"points":[{"start":564,"end":573,"text":"Javascript"}]},{"label":["Skills"],"points":[{"start":540,"end":544,"text":"​HTML"}]},{"label":["Skills"],"points":[{"start":531,"end":536,"text":"Python"}]},{"label":["Skills"],"points":[{"start":458,"end":464,"text":"​Celery"}]},{"label":["Skills"],"points":[{"start":448,"end":454,"text":"​jQuery"}]},{"label":["Skills"],"points":[{"start":435,"end":444,"text":"Javascript"}]},{"label":["Skills"],"points":[{"start":427,"end":430,"text":"​CSS"}]},{"label":["Skills"],"points":[{"start":419,"end":423,"text":"​HTML"}]},{"label":["Skills"],"points":[{"start":409,"end":415,"text":"​Django"}]},{"label":["Skills"],"points":[{"start":400,"end":405,"text":"Python"}]},{"label":["Name"],"points":[{"start":0,"end":16,"text":"Rashmi​ ​R​ ​Bhat"}]}],"extras":null,"metadata":{"first_done_at":1532674055000,"last_updated_at":1532674055000,"sec_taken":217,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Ravi Bhusan Singh\nPassport –P0756369\nLocation: Gurgaon, India\nMobile: +91-9711306018\n\n\n\n\n\nE-mail: ravi.om90@gmail.com\n\nsirius.singh@yahoo.in\nSkype: sirius.singh\nLinkedIn: https://www.linkedin.com/in/hunterat/\n\tCAREER OBJECTIVE \n\t\n\t\n\t\n\n\nI am looking forward to take myself to next level. I have high level of personal morals and integrity. I am Goal    oriented, self-motivated and committed to the successful outcome of the project. I am willing to work hard and have a great desire to learn.\n\tSummary \n\t\n\t\n\t\n\n\n· Since January 2012, have 5 year and 10 months of extensive hands on experience of product development and automation scripting.\n\n· A team player with excellent communication and interpersonal skills who has the ability to work independently.\n\n· Currently working as IT Analyst at Tata Consultancy Services.\n\n· B.Tech in 2011 from KNGD Modi Engineering College, Modinagar, Ghaziabad (UPTU).\n\n\tTechnologies  \n\t\n\n\tLanguages\n\t Python, Perl, C, Shell Scripting\n\n\tFrameworks\n\t Mojolicious, Gearman, Django\n\n\tGUI\n\t HTML, CSS, JavaScript, Ajax,\n\n\tDatabase\n\tMySQL, Redis\n\n\tSource Control\n\tGit, Gerrit\n\n\tTools\n\tEclipse, Edit++, Postman, Rally, Remedy, Jmeter, Apache benchmark, Newman\n\n\tAPIs\n\tFacebook, Twitter, Wunderground\n\n\tOthers\n\tApache, AWS, Load Balancer, Auto-scaling, Celery, REST, Microservices, Jenkins, Nagios, MS Office\n\n\n\tEDUCATION \n\t\n\t\n\t\n\n\tDegree/Certificate\n\tInstitute/School \n\tCPI/Percentage \n\tYear \n\n\tB.Tech\n\t(KNGD Modi Engineering college) UPTU\n\t70.2%\n\t2011\n\n\tIntermediate\n\tPt.Deen Dayal Uppadhya Snatan Dharma Vidyalaya (UP Board)\n\t80.2%\n\t2006\n\n\tHigh School\n\tPt.Deen Dayal Uppadhya Snatan Dharma Vidyalaya (UP Board)\n\t76.5%\n\t2004\n\n\n\tCAREER CONTOUR\n\n\n\tTata Consultancy Services                  (October,2015)\n\t                IT Analyst\n\n\n    Roles & Responsibilities:\n\n· Interaction with client to understand the requirement\n\n· Preparation for functional specification and discussions for scoping, design and Implementation\n· Building prototype before implementation of features\n\n· Development for enhancements/features\n· Unit testing\n\n· Writing scripts for automating the manual tasks like monitoring tools/products and servers and running processes.\n\n· Providing support for product.\n· Conducting knowledge and team building sessions.\nProjects:\n\na) MCPRE (Cisco):  Build and Release tool          \nTechnologies:  Python, MySQL, Perl, Eclipse, Rally, Remedy, git, Linux, Nagios, Jenkins\nTeam Size: 5\n\nRoles & Responsibilities:\n· Interaction with client to understand the requirement\n\n· Development for enhancements/features\n\n· Bug Fixes\n\n· Unit Testing\n\n· Automation for monitoring tools, NFS space, running processes\n\n· Providing support for product\n\nb) CFlow (Cisco):  Code coverage tool          \nTechnologies:  Python, Celery, Microservices\nTeam Size: 1\n\nRoles & Responsibilities:\n\n· Interaction with client to understand the requirement\n\n· Development for enhancements/features\n\n· Bug Fixes\n\n· Unit Testing\n\n\tKenscio Digital    ( July 2012 - September 2015)\n\t                          Sr. Software Engineer\n\n\n    Roles & Responsibilities:\n\n· Interaction with client to understand the requirements\n· Preparation for functional specification and discussions for scoping, design and Implementation\n\n· Building prototypes before implementation of features\n\n· Development for enhancements/features\n\n· Unit testing\n\n· Deployment\n\n· Maintaining AWS\nProjects:\n\na) Real Time personalization (RTP):  Creates images (.png/.gif) to make dynamic promotional campaigns for companies like e-commerce, banking\nTechnologies:  Perl, MySQL, Python, Edit++, git, Linux, Redis, Gearman, ImageMagick, Ajax,\nTemplate Toolkit, Apache, AWS, Load balancer, Auto-scale \n\nTeam Size: 2\n\nURL: http://realtimepersonalisation.com/ \nRoles & Responsibilities:\n\n· Interaction with client to understand the requirement\n\n· Designing architecture\n\n· Development for enhancements/features\n\n· Bug Fixes\n\n· Unit Testing\n\n· Maintaining AWS\n\nb) Multi-Channel Multi Intelligence System (McMIS): Data analytics and email marketing tool       \nTechnologies:  Perl, MySQL, Python, Edit++, git, Linux, Redis, Gearman, Ajax, Template Toolkit, Apache\nTeam Size: 4\nURL: http://www.kenscio.com/mcmis.php\n\nRoles & Responsibilities:\n\n· Requirement Analysis \n\n· Development for enhancements/features\n\n· Bug Fixes\n\n· Unit Testing\n\n\tOctane                          ( January  2012 - June 2012)\n\t                          Email Campaign Executive\n\n\n    Roles & Responsibilities:\n\n· Creating HTML campaigns for promotional emails\n\n· Testing for NO-Spam delivery of emails.\n\n· Setting up DKIM, FBL for clients\n\nPERSONAL AND INTER-PERSONAL SKILLS/Achievements \n· Bagged 5th Digital award from IAMAI for RTP product.\n\nhttp://www.kenscio.com/blog/2015/01/20/best-email-marketing-campaign-award-for-kenscio/\n· Bagged DMAi award for RTP product.\n· Earned TCS-Gems for being chosen as employee of the month in 2016.\n\n· 2nd prize for tech-collage at college fest – “spandan-2010”\n· Organized Events like Jagaran-2010 and De-roads (Roadies)-2010.\n\n· Participated in workshop ‘Ethical Hacking and Information Security’ at IIT Roorkee.\n\n\tHobbies \n\t\n\t\n\t\n\n\nTravelling, listening to music, watching movies","annotation":[{"label":["Skills"],"points":[{"start":4453,"end":4454,"text":" C"}]},{"label":["Skills"],"points":[{"start":4399,"end":4400,"text":" C"}]},{"label":["Skills"],"points":[{"start":4124,"end":4129,"text":"Apache"}]},{"label":["Skills"],"points":[{"start":4055,"end":4061,"text":" Python"}]},{"label":["Skills"],"points":[{"start":4043,"end":4046,"text":"Perl"}]},{"label":["Skills"],"points":[{"start":3924,"end":3926,"text":"AWS"}]},{"label":["Skills"],"points":[{"start":3641,"end":3643,"text":"AWS"}]},{"label":["Skills"],"points":[{"start":3633,"end":3638,"text":"Apache"}]},{"label":["Skills"],"points":[{"start":3551,"end":3557,"text":" Python"}]},{"label":["Skills"],"points":[{"start":3539,"end":3542,"text":"Perl"}]},{"label":["Skills"],"points":[{"start":3419,"end":3420,"text":" C"}]},{"label":["Skills"],"points":[{"start":3368,"end":3370,"text":"AWS"}]},{"label":["Skills"],"points":[{"start":2747,"end":2748,"text":" C"}]},{"label":["Skills"],"points":[{"start":2739,"end":2745,"text":" Python"}]},{"label":["Skills"],"points":[{"start":2695,"end":2696,"text":" C"}]},{"label":["Skills"],"points":[{"start":2679,"end":2680,"text":" C"}]},{"label":["Skills"],"points":[{"start":2404,"end":2410,"text":"Jenkins"}]},{"label":["Skills"],"points":[{"start":2354,"end":2357,"text":"Perl"}]},{"label":["Skills"],"points":[{"start":2338,"end":2344,"text":" Python"}]},{"label":["Skills"],"points":[{"start":2211,"end":2212,"text":" C"}]},{"label":["Skills"],"points":[{"start":1678,"end":1679,"text":" C"}]},{"label":["Skills"],"points":[{"start":1662,"end":1663,"text":" C"}]},{"label":["Education"],"points":[{"start":1422,"end":1427,"text":"B.Tech"}]},{"label":["Skills"],"points":[{"start":1309,"end":1315,"text":"Jenkins"}]},{"label":["Skills"],"points":[{"start":1279,"end":1280,"text":" C"}]},{"label":["Skills"],"points":[{"start":1246,"end":1248,"text":"AWS"}]},{"label":["Skills"],"points":[{"start":1238,"end":1243,"text":"Apache"}]},{"label":["Skills"],"points":[{"start":1163,"end":1168,"text":"Apache"}]},{"label":["Skills"],"points":[{"start":1083,"end":1084,"text":" C"}]},{"label":["Skills"],"points":[{"start":1026,"end":1027,"text":" C"}]},{"label":["Skills"],"points":[{"start":953,"end":967,"text":"Shell Scripting"}]},{"label":["Skills"],"points":[{"start":949,"end":950,"text":" C"}]},{"label":["Skills"],"points":[{"start":944,"end":947,"text":"Perl"}]},{"label":["Skills"],"points":[{"start":935,"end":941,"text":" Python"}]},{"label":["Skills"],"points":[{"start":864,"end":865,"text":" C"}]},{"label":["Education"],"points":[{"start":823,"end":828,"text":"B.Tech"}]},{"label":["Skills"],"points":[{"start":797,"end":798,"text":" C"}]},{"label":["Skills"],"points":[{"start":757,"end":758,"text":" C"}]},{"label":["Location"],"points":[{"start":47,"end":53,"text":"Gurgaon"}]},{"label":["Name"],"points":[{"start":1,"end":16,"text":"avi Bhusan Singh"}]}],"extras":null,"metadata":{"first_done_at":1532682447000,"last_updated_at":1532682447000,"sec_taken":137,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Reddi Mohan\t\t\t\t\t\t          ☎ +91 8494 900 966\t\n\t\t\t          \t ✉ reddimohanclass@gmail.com\n\n\n\nPython developer with 8 years of experience in total along with PHP, HTML, CSS, Javascript, jQuery. Well experienced in end to end development and delivering the project. A full stack developer, REST API, Python, AWS services and Agile/Scrum experience. Technology selection based on project by analyzing requirements. I follow Agile/scrum where we estimate tasks and follow the sprint model development.\nKey Skills\nPython, AWS service, EC2, EBS, LAMP stack, PHP, MySql, HTML, CSS, Bootstrap, Javascript, jQuery, Perl, CakePHP, Linux, Git, Bitbucket, Jira.\nCertifications: AWS certified solution architect\nEmployment Details\n1. Senior Developer, Whyable Technologies - Bangalore\n\tDec 2014 to till date\n\tClients\t\t: Doorda, FireText, MyLocalpitch\nExpertise\t: Python, AWS, Ionic3, LAMP, HTML, CSS, Bootstrap, Javascript\n\n2. Software Engineer II, Paxterra Software Solutions - Bangalore\n\tJan 2011\n to Dec 2014 - 4 Years\n\tClient\t\t: Ericsson\nExpertise\t: CakePHP framework, LAMP, HTML, CSS, Javascript, jQuery, Perl\n\n3. Web Developer, R2 International - Bangalore\n\tJul 2008 to Dec 2010 - 2.6 Years\n\tClient\t\t: Internal project, Gamucci\nExpertise\t: LAMP, HTML, CSS, PHP, Wordpress\n\n\t\nProject Details\n\n\tOrganization: Whyable Technologies                               Dec 2014 – Till date\n\n\tPosition: Senior Developer\n\n\n\nProject\t\t: Doorda\nEnvironment\t: Python, AWS, EBS, S3, API development, Bitbucket, Jira, Agile\nTem size\t\t: 2\nRole & Responsibilities : \n· Requirement gathering\n· Requirement analysis and getting the clarification from client\n· Having daily scrum call with client to update the progress on tasks\n· Responsible for the project delivery in time and deliver the beautiful piece of code\n· Responsible for code commit and code quality \n· Managing servers (AWS EC2) and data (S3 bucket and EBS)\nDescription\t\t: Open data solutions, more can be read here\n\n· Extensive knowledge in Python.\n· Extensive knowledge on EC2 server management and EBS.\n·  I have scraped millions and millions of data from more than 100 data sources and more than 100 datasets using python.\n· Scraped millions of data using APIs\n· Processed XML, HTML, JSON, txt file data and saved into MySql database\n· Finding out the better ways to download large data in less time.\n· Finding out the better and fastest way to import this huge data into MySql tables.\n· Written cron files using python to automate the most of the downloads by scraping and though APIs.\n· Scraped 80% of doorda.com data using my scripts.\n· This is my one of interested project I worked with\n\n\nProject\t\t: MyLocalpitch\nEnvironment\t: LAMP, Symfony framework, PHP, HTML, CSS, Stripe, BookingBug, Bitbucket, Jira\nTem size\t\t: 2\nDescription\t\t: Online Sports booking software\nResponsibilities:\n· Requirement gathering and planning and executing.\n· Integrated Stripe payment system with Symfony framework\n· Integrated BookingBug online booking system with MyLocalpitch project where users can select their favourite sport and book it online.\n· I have done BookingBug API flow designs and architecture on how to implement them based on our needs.\n\n\nProject\t\t: FireText\nEnvironment\t: LAMP, PHP, APIs, HTML, CSS, Bitbucket, Jira.\nTem size\t\t: 1\nDescription\t\t: SMS marketing system, worked on Integrating the third party APIs\n\n· Developed APIs and integrated FireText APIs with different third party apps\n· This whole project is abou\n· Extensive knowledge in understanding the third party APIs and integrate them with another.\n· All this project is about webhooks, API calls, on SMS sent create ticket or on ticket create send SMS. It was very interesting project.\n· Integrates Zendesk, Freshdesk, Zapier... etc with FireText SMS API by creating FireText app in Zapier and created a Firetext app for Zendesk.\n· Have written PHP based APIs for Firetext to do some automated tasks. ex: when sms sent do something, when sms received do something.\n\n\n\n\n\n\n\tOrganization: Paxterra Software Solutions                            Jan 2011 to Dec 2014\n\n\tPosition: Senior Developer\n\n\n\nProject\t\t: Ericsson Internal tools\nEnvironment\t: LAMP, PHP, CakePHP, HTML, CSS, Perl\nTem size\t\t: 4\nDescription\t\t: Ericsson Internal tools development\n\n· Developed LSV (Latest stable release) Tool and maintained the code and server (LAMP).\n· I have Involved in end to end development and deployment of the tool.\n· LSV is a tool where team will see the latest release regression test results in high and detail level.\n· I am responsible for the code commits and deployment of the tool.\n· I have mainly used CakePHP, HTML, CSS, MySql, Perl, Javascript and jQuery in the project\n\n\n\n\tOrganization: R2 International                                                     Jul 2008 – Dec 2010\n\n\tPosition: Team Member\n\n\n\nProject\t\t: Internal tools, Gamucci\nEnvironment\t: LAMP, PHP, MySql, Wordpress\nTem size\t\t: 2\nDescription\t\t: Internal tools and Wordpress customization\n\n· Developed Internal tools using PHP, MySql and maintained them\n· Worked on First Gamucci Wordpress site and customized the UI based on the designs\n\nI here by declare that all the information furnished above are right to the best of my knowledge.\n\n\t\t    A.Reddi Mohan","annotation":[{"label":["Name"],"points":[{"start":5211,"end":5221,"text":"Reddi Mohan"}]},{"label":["Skills"],"points":[{"start":4993,"end":4997,"text":"MySql"}]},{"label":["Skills"],"points":[{"start":4988,"end":4990,"text":"PHP"}]},{"label":["Skills"],"points":[{"start":4865,"end":4869,"text":"MySql"}]},{"label":["Skills"],"points":[{"start":4860,"end":4862,"text":"PHP"}]},{"label":["Skills"],"points":[{"start":4649,"end":4654,"text":"jQuery"}]},{"label":["Skills"],"points":[{"start":4634,"end":4643,"text":"Javascript"}]},{"label":["Skills"],"points":[{"start":4621,"end":4625,"text":"MySql"}]},{"label":["Skills"],"points":[{"start":4616,"end":4618,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":4610,"end":4613,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":4605,"end":4607,"text":"PHP"}]},{"label":["Skills"],"points":[{"start":4171,"end":4173,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":4165,"end":4168,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":4160,"end":4162,"text":"PHP"}]},{"label":["Skills"],"points":[{"start":4151,"end":4153,"text":"PHP"}]},{"label":["Skills"],"points":[{"start":3847,"end":3849,"text":"PHP"}]},{"label":["Skills"],"points":[{"start":3233,"end":3235,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":3227,"end":3230,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":3216,"end":3218,"text":"PHP"}]},{"label":["Skills"],"points":[{"start":2704,"end":2706,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":2698,"end":2701,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":2693,"end":2695,"text":"PHP"}]},{"label":["Skills"],"points":[{"start":2409,"end":2413,"text":"MySql"}]},{"label":["Skills"],"points":[{"start":2256,"end":2260,"text":"MySql"}]},{"label":["Skills"],"points":[{"start":2215,"end":2218,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":2034,"end":2036,"text":"EBS"}]},{"label":["Skills"],"points":[{"start":2008,"end":2010,"text":"EC2"}]},{"label":["Skills"],"points":[{"start":1975,"end":1980,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1886,"end":1888,"text":"EBS"}]},{"label":["Skills"],"points":[{"start":1857,"end":1859,"text":"EC2"}]},{"label":["Skills"],"points":[{"start":1449,"end":1451,"text":"EBS"}]},{"label":["Skills"],"points":[{"start":1436,"end":1441,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1250,"end":1252,"text":"PHP"}]},{"label":["Skills"],"points":[{"start":1245,"end":1247,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":1239,"end":1242,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":1089,"end":1094,"text":"jQuery"}]},{"label":["Skills"],"points":[{"start":1077,"end":1086,"text":"Javascript"}]},{"label":["Skills"],"points":[{"start":1072,"end":1074,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":1066,"end":1069,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":1045,"end":1047,"text":"PHP"}]},{"label":["Skills"],"points":[{"start":899,"end":908,"text":"Javascript"}]},{"label":["Skills"],"points":[{"start":883,"end":885,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":877,"end":880,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":850,"end":855,"text":"Python"}]},{"label":["Skills"],"points":[{"start":616,"end":618,"text":"PHP"}]},{"label":["Skills"],"points":[{"start":598,"end":603,"text":"jQuery"}]},{"label":["Skills"],"points":[{"start":586,"end":595,"text":"Javascript"}]},{"label":["Skills"],"points":[{"start":570,"end":572,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":564,"end":567,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":557,"end":561,"text":"MySql"}]},{"label":["Skills"],"points":[{"start":552,"end":554,"text":"PHP"}]},{"label":["Skills"],"points":[{"start":535,"end":537,"text":"EBS"}]},{"label":["Skills"],"points":[{"start":530,"end":532,"text":"EC2"}]},{"label":["Skills"],"points":[{"start":517,"end":527,"text":"AWS service"}]},{"label":["Skills"],"points":[{"start":509,"end":514,"text":"Python"}]},{"label":["Skills"],"points":[{"start":306,"end":316,"text":"AWS service"}]},{"label":["Skills"],"points":[{"start":298,"end":303,"text":"Python"}]},{"label":["Skills"],"points":[{"start":185,"end":190,"text":"jQuery"}]},{"label":["Skills"],"points":[{"start":173,"end":182,"text":"Javascript"}]},{"label":["Skills"],"points":[{"start":168,"end":170,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":162,"end":165,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":157,"end":159,"text":"PHP"}]},{"label":["Skills"],"points":[{"start":93,"end":98,"text":"Python"}]},{"label":["Name"],"points":[{"start":0,"end":10,"text":"Reddi Mohan"}]}],"extras":null,"metadata":{"first_done_at":1532683999000,"last_updated_at":1532683999000,"sec_taken":102,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "RISHAB ASTHANA\nData Scientist\n91-9911393341 | r.asthana5144@gmail.com\n\n\nProfessional Summary:\n\nHighly analytical and process-oriented data science professional with experience in CPG retail and insurance which involved in-depth knowledgeof statistics, databases, curation, manipulation and visualization. Furnish insights, analytics and business intelligence used to advance opportunity identification, process reengineering and corporate growth.\n\nHighlights:\n\n· Data mining, cleaning and imputation.\n· Regression algorithms include Linear and Logistics Regression, Classification algorithms include Decision Trees, Random Forest, K Nearest Neighbors.\n· Dimensionality reduction using Principal Components Analysis.\n· Cluster Analysis using k means clustering and other statistical data modeling.\n· Data Table in R for efficient handling of high dimensional datasets. \nTechnical Skills:\n\n· Strong background in R programming for statistical modeling and data aggregation.\n· Data visualization using Shiny, ggplot, a web application framework for R.\n· Good hold on key machine learning algorithms.\n· Statistical test like t-test, F-test, Chi-square for business evaluation and validation of business objectives.\n· Efficient in using K-Cross-validation and Ensemble while building predictive models.\n· Efficient in Base and Advanced SAS.\n· Exposure to Hadoop framework.\n· Intermediate knowledge of SQL.\n· Proficient in MS Office.\nExperience:\n\n· GrayMatter Software Services:\t\t\t\t\t 10-Apr-16 to till date\n\nProjects:\nData Governance \nDuration: Feb’17 to till Dec’17\nTechnology/Tool: R programming, Hive, RDBMS,SQL, Processmaker, Pentaho (ETL Tool)\nDescription:Develop an automated product for leading alcohol beverage company which involved the flow and processing of Respondent Survey Data stored in highly complex raw SPSS file from Source to Business Dashboards for the end users along with data governance for Data Management.\n\nRole/Objectives:\n· Perform scalable analytics and develop country-wise production ready ETL Scripts using R Language which handles the large-scale datasets in SPSS file and brings meaningful insights from them.\n· Provide technical leadership as SME to the team for domain knowledge, design and developing system. \n· Interact with Business/Clients as a POC, Requirement Gathering and roll out of project to customer.\n· Create and present project related presentations in Business Meetings with the customer. \n· Develop the Data Governance module using R, procesmaker Tool for ensuring the data quality and management of intermediary data by the end users. \n· Handshaking of Multiple systems and Modules like Linux, Windows, R, SQL, Processmaker for the data flow.\n· Use Algorithmsin R such as lapply, sapply, data table, parallel processing, etc for efficient handling of high dimensional survey files.\n· Use of Pentaho Data Integration tool (ETL) to insert, update MY SQL Server tables.\n\n\nPredictive Analytics in CPG/Retail  \nDuration: Aug’16 to Dec’16\nTechnology/Tool: R programming, Hive, SparkR, Shiny\nDescription: Analyse the beverage brand health based on survey data from the customers and predict the most important factors that is involved in increasing the sales trajectory. \n\nRole/Objectives:\n· Regression Analysis for a leading alcoholic beverage company, analysing country-wise beer consumption data to find out the correlation between sales, consumption volumes and brand recall and derive the predictors for sales thereof.\n· Develop and deploy the reusable Shiny application for the business users.\n· Application is developed using R, Shiny, SparkR, Hive for faster evaluation, modelling and visualization of end results.\n· Work with various matrices of survey data of beverages in bringing out the meaning full insights for the client.\n· Machine Learning Algorithms used such as Decision Tree, Correlation, Principal Component Analysis etc. \n\nInsurance Predictive Models Using R and shiny\nDuration:  May’16-July’16 \nTechnology/Tool: R programming and shiny\n      Description: Develop a model that helps business users to cross sell products and understand the factors responsible \n      for policies to lapse, surrender and predict likelihood of a customer/policy to lapse in next 3months. \n\n\nRole/Objectives:\n· Collect and understand various customer and policies related data like customer demographics, customer interaction mode, policy details, events of the policies like lapse, surrender, mature etc.\n· Develop an algorithm using logistics regression, decision trees, random forest that predicts the likelihood of the policy’s event to happen before hand.\n· Understand the past purchase pattern of a customer and build a cross sell model using Apriori algorithm that predicts the next product to the customer with the high probability of acceptance.\n· Forecasting of Annual Net Premium.\n· Bundle the algorithms and approach with reusable Shiny Application for the end users to generate the \nresults and the reports. \n\n\n\n· AnalytixLabs – 6 months Corporate Training of Business Analytics\t\tOct-15 to Mar-16\n\nProject: Customer Churn Model\nDuration: Oct’15 – Mar’16\nTechnology/Tool: SAS/Excel\nDescription: Deep Understanding of the Telecom Customer Data leading to driven insights of profitable customer or non-profitable customer in their life span with the network provider.\nRole/Objectives:\n· Develop customer churn model and classify existing customers into groups of profitable and non-profitable customers so as to target accordingly using various statistical and modelling techniques such as logistic regression, decision trees etc.\n\n· Convergys                      \t\t\t\t\t\t\t23-Jan-15 to 2-Mar-16\n\nProject: Customer Data Insights\nTechnology/Tool: MSExcel\nDescription: Thorough Analysis of data and reporting with the objective of finding the root cause of the problems and the solution in a timely driven manner.\n    Role/Objectives:\n· As part of the self-driven analysis team of 5 members, we worked on agents data based on their Net Promoter Sore, Customer Satisfaction Scores to prepare the weekly reports and sharing with the team members and generating reports using EXCEL based on deficiency of sales percentages to make the agents aware of other number of sales required till date to meet the company’s business objective.\n\n\n\n\nAchievements\n\nSuccessfully completed Data Science competition hosted by Analytics Vidhya, community for data science and machine learning professional.\n\nCompetition Source:https://datahack.analyticsvidhya.com/contest/practice-problem-big-mart-sales-iii/\nObjective:Build predictive models and find out the sales for each product at a particular grocery store.\nDescription/Approach:\n· Involved cleaning, manipulation and imputation of data.\n· Exploratory Data Analysis for feel of attributes.\n· Principal Components Analysis to deal with the curse of dimensionality and highly correlated variables.\n· 10-Fold Cross Validation for validation of model’s performance.\n· Ensemble of models to boost the prediction accuracy on the unseen data.\n\nACADEMIC AND CERTIFICATION\n\n· B.SC (Honors). in Statistics, Ramjas College, University of Delhi. [2011-2014]\n· Certified in Business Analyst with SAS and R from Analytixslabs, the renowned analytics institutelocated in Gurgaon.\n· Certified in Financial Mathematics by the Institute of Faculty of Actuaries, UK\nPersonal Information:\n\n· Date of Birth: 3rd Oct 1992\n· Gender: Male\n· Nationality: Indian\n· Marital Status: Bachelor","annotation":[{"label":["Education"],"points":[{"start":7052,"end":7064,"text":"B.SC (Honors)"}]},{"label":["Skills"],"points":[{"start":6405,"end":6420,"text":"machine learning"}]},{"label":["Skills"],"points":[{"start":3975,"end":3987,"text":"R programming"}]},{"label":["Skills"],"points":[{"start":2997,"end":3009,"text":"R programming"}]},{"label":["Skills"],"points":[{"start":2895,"end":2897,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":2653,"end":2655,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1605,"end":1607,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1578,"end":1590,"text":"R programming"}]},{"label":["Skills"],"points":[{"start":1396,"end":1398,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1350,"end":1355,"text":"Hadoop"}]},{"label":["Skills"],"points":[{"start":1322,"end":1333,"text":"Advanced SAS"}]},{"label":["Skills"],"points":[{"start":1068,"end":1083,"text":"machine learning"}]},{"label":["Skills"],"points":[{"start":911,"end":923,"text":"R programming"}]},{"label":["Name"],"points":[{"start":0,"end":13,"text":"RISHAB ASTHANA"}]}],"extras":null,"metadata":{"first_done_at":1532692184000,"last_updated_at":1532692184000,"sec_taken":0,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "SADAT HUSSAIN\nE-Mail:  sadat201966@gmail.com\nMobile: +91 8867679412 / 8250911089\n\nCareer Objective:\n      To be associated with a progressive organization that gives me scope to gain knowledge and skills in accordance with the latest technologies and to be part of a team that dynamically works towards the growth of the organization.\nSummary of Skills:\n· Having 9 years of experience in IT industry.\n· Working Experience of Python programming language.\n· Good experience in Finance domain and security risk analysis.\n· Good experience of Virtualbox, AWS etc.\n· Good experience in Jira.\n· Good experience of Data Parsing and Analysis  \n· Good experience in development of Models in Finance domains using Python/ANN/TF etc\n· Good knowledge of Supervised and Un-Supervised learning.\n· Good knowledge of learning algorithms like Linear, Logistics, ANN, SVM & Deep Learning.\n· Good knowledge of Tensor flow, Sklearn libs, numpy, Pandas, Requests.\n· Active participant in HackerEarth and Kaggle challegens.\n· Good experience in Working with Ubuntu and Windows OS.\n· Good experience in providing work estimation, task assignments and billing approvals.\n· Machine Learning by Stanford University on Coursera mentored by Prof. Andrew Ng. \nProfessional Experience:\n· Working in Dexcel Electronics Designs Pvt. Ltd , Bangalore as Lead Software Engineer from February 2014 to till date. \n· Worked with Safe Net Info Tech Pvt. Limited, Noida as Sr. Software Engineer from August 2013 to Jan 2014.\n· Worked with PT Pure Testing Pvt. Limited, Noida as Sr. Software Engineer from Jul 2012 to Jul. 2013\n· Worked with Sasken Communications Technologies, Bangalore as Sr. Software Engineer from Sept 2008 to Jul. 2012.\n\nEducation Profile:\n· Bachelor of Engineering in Information Technology From The University of Burdwan\nWest Bengal, with 71%.\nTechnical Skills:\n· Operating System\n          :   Linux, Windows.\n· Machine Learning                :   Linear, Logistics, ANN, SVM & Deep Learning,Tensorflow, \n    Numpy, SkLearn.\n· Scripting Languages            :   Python, Perl, Shell script.\n· Domains                            :    Finance, Automation, Telecom, Cloud Computing.\nProject # 1: Development of a hybrid stock trading framework  with machine     \nlearning techniques \nDescription:This project is about the development of a hybrid stock trading framework \nintegrating technical analysis with machine learning techniques. Investors in the stock Market can maximize profits by buying or selling their investment at\nproper time. The key to realize high profits in stock trading is to find out the suitable trading time with the minimum risk of trading. Successful classification of up and down movements in stock price index values can helpful for the investors to make effective trading strategies.\n     OS Used              :  Ubuntu\n     Models Used       :   ANN,SVM, KNN\n     Libs Used          :    Tensorflow, SkLearn, Pandas, TA-lib, Numpy.\n     Language Used  :  Python.\n\n     Tools\n\n: Jira\nDuration             :  May  -16 to Till date.\nProject # 2: Development of Web Based Tool Automation Framework\nDescription: This project is about the development of web bsed automation framework      for the functionality of various proprietary tools using Rest arch. The tool includes thermal analyzer, battery analyzer, system scope etc. We have used python with Requests  library. The automation framework runs on Windows as well as on Chrome book.\nResponsibility:\n· Design of the tool’s framework.\n· Implementation of framework using Python and Requests.\n· Task estimation and assignment of the same to subordinate. \n· Bug fixing and error reporting.\nOS Used              :  Windows, Chromebook\nTools Used          :  Selenium web driver.\nLanguage Used  :  Python.\nDuration             :  Feb  -14 to Apr-16\n     Project # 3: Development of Sentinel Cloud Run-Timeless Automation framework\nDescription: This project is about the development of test automation framework for testing the functionality Sentinel Cloud Run-Timeless web services.  Sentinel Cloud Services is a license and entitlement management solution by SafeNet for SaaS and on-premise applications. Sentinel Cloud Services provides list of product features that can be used to license SaaS and on-premise applications. (1) Feature Based Authorization (2) Innovative License Models (3) Entitlement management and Provisioning etc.\nResponsibility:\n· Implementation of framework using REST  services.\n· Creating and deployment of infrastructure on Amazon WS as well as on local VM.\n· Test case execution and error logging.\n· Divide the User Stories among peers.\n· Development of test cases.\n· Bug reporting and tracking.\n· Organizing Sprint planing and backlog meetings. \nOS Used              :  Ubuntu and RHEL.\nTools Used          :  VMWare VMs, JIRA, Query Browser.\nLanguage Used  :  Python.\nDuration             :  August -13 to Till date.\n      Project # 4: Development of LTE-Small Cell Test Automation framework.\nDescription: Automated Test Framework (ATF) is a software component to validate the functionality and performance of eNodeB board. eNodeB is the high speed data switch with Radio Frequency (RF) interface to subscriber equipment end and Ethernet interface towards \nnetwork end. Subscriber equipment in this case is User Equipment (UE) which is USB dongle capable of connecting to Internet. \nThe data communication flow between UE and eNodeB is over RF channel. The eNodeB acts as data switch which transfers packet data to and from multiple UE to the IP network over Ethernet network. \nThe ATF system simulates the subscriber actions to create connection to public data network (PDN) and generate data traffic according to various performance parameters. It monitors the system and collects the actual observed performance data parameters.\nResponsibility:\n· Implement the different functionalities of test  automation framework.\n· Writing the design documents related to the modules begin owned. \n· Execute performance and system testing of Lte small eNodeB board.\n· Development of test cases.\n· Bug reporting and tracking.\n· Maintenance of test report.\nOS Used              :  Fedora(Linux).\nTools Used          :  iPerf, Wireshark,SVN.\nLanguage Used  :  Python.\nDuration             :  Jul -12 to Jul-13.\nProject # 5: Development of Mobile Automation framework.\nDescription: This project is about the development of test automation framework for testing the functionality of mobile phone. The telephony emulator is exact replica of MS in functionality. Using the test automation framework, a tester can able to initiate a call, forward call, wait a call. A tester can also send bulk sms, add names to the phone contact book. Tester can also check call logs. The emulator was designed using the Perl-/Tk as GUI, Perl as backend script. The main intention is to run automate test cases using this tool. \nResponsibility:\n· Developed the GUI using Perl/TK.\n· Implemented the voice call, call wait and call forward functionality.\n· Test case execution and error logging.\n· Development of test cases.\n· Maintenance of test report.\n· Monitored and reported progress and issues to the immediate supervisor.\nOS Used             :  ubuntu.\nTools Used         :  Bugzilla, SVN.\nLanguage Used:    Per/Tk.\nDuration             :  Apr -12 to Jun 2012.\nProject # 6: UMTS Field Testing\n Description: This project involves field testing on UMTS Technology and provided the infrastructure to execute the Field Testing to test the protocol stack of 3G(R99 and above) in live network.\nPerformed testing of protocol stack of UE for validating the proper functioning of the device with different 3G releases and perform preliminary analysis. Tested various scenarios like 3G handover to 2G and vice versa, initial call setup, upload and download data packets. Field testing performed both on data calls as well as voice calls.\nResponsibility:\n· Performed testing live on 3G deployed networks.\n· Throughput validation on both UL and DL in high, medium and low RSCP.\n· Tested the scenarios by executing AT commands.\n· Collecting and performing preliminary analysis of logs.\n· Involved in static and dynamic testing.\n· Involved in test case environment setup.\nOS Used             :  Windows.\nTools Used         :  Mobile analyzer, Network monitor.\nDuration             :  Apr -11 to Mar.12\nLanguage Used :   Python\nProject # 7: Development of Build Automation Framework.\nDescription: This project involves the development of build automation framework.\nDeveloper engineers release a build in every three months or any regression happens. Earlier they used to do all the steps of build process manually. Now using this build automation framework, a developer automates the whole build process.\nResponsibility:\n· Constructed test scripts from the Test Plan and Functional Design documents.\n· Organized demo and code reviews before the team.\n· Development of test cases.\n· Monitored and reported progress and issues to the immediate supervisor.\n· Test case execution and error logging.\n· Maintenance of test report.\nOS Used             :  Windows xp.\nTools Used         :  MKS, QC ,Eclipse.\nLanguage Used  :  Perl/Python\nDuration             :  Jan-11 to Mar-11.\nPROJECT # 8: Mobile Application Testing (Flashlite):\nDescription:This project involves the application testing of Flashlite player on Nokia smartphone. Flashlite is a lightweight version of Adobe Flash Player. This version is intended for mobile phones and allows users of these devices to view multimedia content. There are various types of Flashlite testing. Some of them are (a) Audio and video testing (b) Feature interaction testing (c) out of memory testing.  \nResponsibilities:\n· Involved in Basic Acceptance testing, Functional testing, Live Website testing and certification testing, Regression testing .\n· Bug reporting and verification.\n· Development of test cases.\n· Involved in the conducting daily scrum meeting.\n· Maintenance of test report.\n· Maintenance of test report and sharing with client.\n\nOS Used                     :     Windows\n\nTools Used                 :     Quality Center (QC), iSource, Mobile device\n\nLanguage used          :     Python, Perl\n\nDuration of Project   :     Jan-2010 to  Dec-2010\nPROJECT # 9: Development of Automated Performance Testing Framework (Billing)\nDescription: This project is about the development of test automation framework which tests the performance of MMSC (a network element that enables cellular phones to send and receive pictures and sound clips as well as text messages). \nWhenever, sms or mms are sent or received, it gets logged. Using this framework, a tester can figure out, how many sms or mms are logged in a given amount of time. Tester can also set a range for a particular type of sms or mms and based on the output, he can pass or fail a test case. \nResponsibility:\n· Constructed test scripts from the Test Plan and Functional Design documents.\n· Participated in test execution for partly and nightly runs on MMSGEN.\n· Organized demo and code reviews before client as well as team.\n· Weekly status reporting through emails and telecons.\n· Integrated other tools and run them in cronjobs.\nOS Used             :  RHEL\nTools Used         :  Eclipse, SVN.\nLanguage Used:  Perl.\nDuration             :  Oct. 2008 to Dec 2009.\n\nAchievements:\n· Recipient of the Spot award for completing the task well before deadline.\n· Recipient of the 'Titan' of the quarter award.\nTrainings:\n· ML course of Coursera.\n· C, C++.\nPersonal Details:\n       Languages known:  English, Hindi & Bengali.\n       Marital Status     :  Single\n      \n       Hobbies\n\n :  Listening to music, watching movies and reading newspaper.\n.","annotation":[{"label":["Skills"],"points":[{"start":11261,"end":11264,"text":"Perl"}]},{"label":["Skills"],"points":[{"start":10185,"end":10188,"text":"Perl"}]},{"label":["Skills"],"points":[{"start":10177,"end":10182,"text":"Python"}]},{"label":["Skills"],"points":[{"start":9166,"end":9171,"text":"Python"}]},{"label":["Skills"],"points":[{"start":9161,"end":9164,"text":"Perl"}]},{"label":["Skills"],"points":[{"start":8363,"end":8368,"text":"Python"}]},{"label":["Skills"],"points":[{"start":6924,"end":6927,"text":"Perl"}]},{"label":["Skills"],"points":[{"start":6791,"end":6794,"text":"Perl"}]},{"label":["Skills"],"points":[{"start":6774,"end":6777,"text":"Perl"}]},{"label":["Skills"],"points":[{"start":6234,"end":6239,"text":"Python"}]},{"label":["Skills"],"points":[{"start":6163,"end":6167,"text":"Linux"}]},{"label":["Skills"],"points":[{"start":4846,"end":4851,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4507,"end":4515,"text":"Amazon WS"}]},{"label":["Skills"],"points":[{"start":3753,"end":3758,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3530,"end":3535,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2964,"end":2969,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2060,"end":2065,"text":"Shell "}]},{"label":["Skills"],"points":[{"start":2054,"end":2057,"text":"Perl"}]},{"label":["Skills"],"points":[{"start":2046,"end":2051,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1896,"end":1911,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1878,"end":1882,"text":"Linux"}]},{"label":["Education"],"points":[{"start":1723,"end":1745,"text":"Bachelor of Engineering"}]},{"label":["Location"],"points":[{"start":1637,"end":1645,"text":"Bangalore"}]},{"label":["Location"],"points":[{"start":1307,"end":1315,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":1149,"end":1164,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":704,"end":709,"text":"Python"}]},{"label":["Skills"],"points":[{"start":425,"end":430,"text":"Python"}]},{"label":["Name"],"points":[{"start":0,"end":12,"text":"SADAT HUSSAIN"}]}],"extras":null,"metadata":{"first_done_at":1532694530000,"last_updated_at":1532694530000,"sec_taken":134,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "SAIF KHAN\n\nCredentials\n\nResult-oriented Data scientist offering 8 years of proven success in the areas of advance statistical analysis, research and development in both domestic and international market.  Possess in depth knowledge in Business Statistics , Predictive and  Prescriptive modeling, machine learning, Social network analysis and Text analytics.\n\nExperienced in building best-in-class predictive models and decision tools to address business needs by leveraging state-of-the-art machine learning and statistical algorithms. Highly accomplished in providing data driven business insights to fortune 500 companies so far.\n\nWorked for various domains i.e. Banking, Retail, Energy and utility, Oil & Gas, Consumer Survey, Casino and Gaming focused on Analytics , machine learning and deep learning , Consulting, Solutioning, Architecture, Implementation with Pre – Sales expertise.\n\n\n\tBusiness Analytics, Business Intelligence & Big Data Exposure\n\n\tBusiness \nAnalytics\n\tBusiness Statistics\n\tDescriptive Statistics, Distribution theory, Business Hypothesis, Statistical inferences , Sampling,  ANOVA, Design of Experiment, Multivariate analysis\n\n\t\n\tPredictive\n\tRegression analysis, Regression diagnostics, Residual analysis and collinearity issues, Logistic Regression, Odds Ratio, ROC curves, Time series and Forecasting, ARIMA & GARCH models\n\n\t\n\tPrescriptive\n\tLinear Programming, Dynamic programming, Mixed integer programming, Multi criteria decision making  techniques( AHP, DEA), Monte Carlo simulation\n\n\t\n\tMachine Learning\n\tNeural Networks( ANN), Nearest neighbor, Decision tree,  Naive bayes, Support Vector, Apriori, Random forest, Bagging and boosting, Stochastic gradient descent\n\n\t\n\tDeep Learning\n\tDeep networks and regularization, Convolutional networks, Auto encoders, Deep generative models, Sequence modeling, Reinforcement learning, \n\n\t\n\tData Mining\n\tClustering and segmentation, Classification and discriminant analysis, Principal component analysis\n\n\t\n\tMarketing Analytics\n\tPrice bundling, Non linear pricing, Market basket analysis, RFM analysis, Bass diffusion models, Customer lifetime model (CLV), Markdown optimization, Market mix modeling, Conjoint analysis, Structural Equation modeling\n\n\t\n\tStochastic\n\tMarkov Models\n\n\tBusiness Intelligence\n\tMetadata Modeling\n\tMetadata Design & Development\n\n\t\n\tCube\n\tProcess, Strategies, Design & Development\n\n\t\n\tReporting\n\tTemplate Designing & Development\n\n\t\n\tKPI Modeling\n\tMetric, Calculation, Formulas, Design & Development\n\n\t\n\tScorecard & Dashboard\n\tMetric Template Designing & Development\n\n\t\n\tPortal Management\n\tUser,  Roles & Privileges, Webpage Designing & Development\n\n\tBig Data\n\tStrategy\n\tCompose current business strategies in order to link Big Data and Analytics\n\n\t\n\tUnderstanding & Processing\n\n\tIdentification of a suitable storage for Big Data, Data ingestion, Data cleaning and processing (Exploratory data analysis), Visualization of the data, Apply the machine learning algorithms (If required)\n\n\n\n\n\n\nProfessional Experience\n\n\n\tCompany\n\tPlace\n\tDesignation\n\tFrom\n\tTo\n\n\tHarman International\n\tLondon\n\tSr. Data Scientist\n\tMar 2016\n\tJuly 2017\n\n\tEsyasoft Technologies \n\tBangalore\n\tData Scientist\n\tMar 2015 \n\tMar  2016\n\n\tARIMA Research LLC\n\tBangalore\n\tAnalytics Consultant\n\tJun 2014 \n\tNov  2015\n\n\tIIM Bangalore      \n\tBangalore\n\tResearch Associate\n\tAug 2010\n\tMar  2014\n\n\tMERIT\n\tNew Delhi\n\tIT Administration\n\tMay 2008\n\tJun  2009\n\n\n\n\nAcademic Qualification\n\n\n\tQualification\n\tSubject\n\tUniversity\n\tSession\n\tPercentage\n\tRemarks\n\n\tMasters\n\tStatistics\n\tPatna University \n\t 2006-2008\n\tApprox 65 %\n\tTop 5 in class\n\n\tBachelors\n\tStatistics \n\t\n\t2003-2006\n\tApprox 75 %\n\tRanked 1st in class\n\n\n\n\nTechnical Summary:\n\nStatistical Packages: \tSPSS, R,  Python, Matlab\nSpreadsheet/Visualization: MS excel 2010, @Risk, Tableau\n\n            Organization:       Harman International ( A Samsung company)\n\tClient\n\tDodge Data and Analytics, USA\n\n\tProduct/Tools(s)\n\tPython, AWS , NLP \n\n\tDuration\n\tMay 2017 – July 017\n\n\tRole\n\tData Scientist\n\n\t\nJob Responsibilities\n\n\t\n\nWorked with the Dodge Data & Analytics team, for construction document ingestion system. Analyzed billions of construction documents using Natural language processing. Extensively used NLTK python libraries processing for building document classification algorithm.\n\n\n\n\n\n\t    Client\n\tLadbrokes, UK\n\n\tProduct/Tool(s)\n\tGoogle Analytics, Google Big Query, R, Machine learning\n\n\tDuration\n\tOctober 2016 - May 2017\n\n\tRole\n\tData Scientist\n\n\t\nJob Responsibilities\n\n\t\nWorked as a data scientist at a client location in London for Ladbrokes, UK. Helped business with statistical algorithm for building recommendation engine.\nAnalyzed click stream data to predict user behavior at Ladbrokes gaming site. Identified user journey across the sites using path analysis. Worked extensively on Google Analytics and Google Big query to extract hit level data.\n\n\n\n\n\n\t    Client\n\tBritish Telecom, UK\n\n\n\tProduct/\nTool(s)\n\tR, Python, Predictive Modeling\n\n\tDuration\n\tMar 2016 to Sep 2017\n\n\n\tRole\n\tData Scientist\n\n\n\t\nJob Responsibilities\n\n\t\nWorked with the client British Telecom, UK for the project titled BT Fault analytics.\nPlayed a key role as a lead statistician to nurture models related to fault prediction of DSLAM devices for the entire UK network from the exploratory data analysis to the final model delivery stage. \nPerformed Root cause analysis for identification of specific causes generating a problem. Used correlation and statistical analysis on information’s gathered from faulty devices and their associated infrastructure. Was responsible for fault detection, location and recovery.\nGenerated association rules for DSLAM devices in the network to understand whose confidence is greater than or equal to predefined minimum confidence value and detected anomalies\n\n\n\n\n\nOrganization:       Esyasoft Technologies Private Limited, Bangalore, India\n\n\t    Client\n\tCESC Smart Grid Project, ACAD Division\n\n\n\tProduct/\nTool(s)\n\tR , Tableau, SQL, Forecasting, Load prediction\n\n\tDuration\n\tMarch  2015 - March 2016\n\n\n\tRole\n\tData Scientist\n\n\n\t\nJob Responsibilities\n\n\t\nPlayed a key roles as a lead data scientist in the analytics department, managing a team size of 4 members\nWas involved in various Center of Excellence (COE) driven  initiatives in areas of smart metering, Outage management, Meter data management, Smart grid solutions, Automated metering infrastructure,  Peak load estimation, Energy loss analysis and theft prediction, Reliability modeling\nForecasted and monitored energy consumption patterns at feeder, transformer and meter level data   \nProvided statistical insights through visualization and analytics for utility offerings/operations dashboards in a real time environment to identify key areas with substantial potential of savings.\nCreated sales opportunities in the electrical utility industry by writing white papers, case studies and research publications\n\n\n\n\n\n\n\n\t  Organization\n\t    ARIMA Research, Bangalore, India\n\n\n\t\nJob Responsibilities\n\n\t· Worked as a functional consultant with retail, banking, healthcare and telecom customers.\n· Identified key business processes like Account Profiling, Cross-sell/ up-sell opportunities looking at customer’s historic data.\n· Worked at Customer’s churns analysis and retention using Linear Regressions, Multinomial Logistic Regression and classification algorithms.\n· Performed Employee attrition, survey analysis and survival analysis for a leading Human Resource firm.\n· Performed forecasting techniques for a major Telecom player based out of EMEA.\n\n\n\n\t  Organization\n\t    Indian Institute of Management, Bangalore, India \n\n\n\t\nJob Responsibilities\n\n\t· Assisted in establishing datacenter lab (DCAL), a warehouse of Indian-centric data to support academic researches.\n· Collaborated with faculties to design teaching curriculum on business analytics to improve the pedagogy.\n· Co-authored a report titled “Life time sustenance for weapon systems and equipment being procured ex import”, Army school management boards, Ministry of defense. (MOD) India. \n· Conducted research on existing provisions of defense procurement policies, 2013 for ToT & MToTs\n· Developed a methodology to evolve processes and procedures for smooth life time sustenance and up gradation of weapon systems. \n· Estimated the total cost of ownership (TCOs) for materials and product support for the defense equipments \n· Used the analytic hierarchy process technique for structured decision making and priorities\n· Co-authored a report titled “Diversification into non-shipping areas” for shipping corporations of India\n· Lead successful identification of areas to diversify funds to increase profitability and implementation of a successful transition plans\n· Conducted preliminary research on Open standards policy for the Govt. of Karnataka. Research is now being synthesized for the introduction to information technology policy, 2015\n· Analyzed effectiveness of Free and Open Source Software (FOSS) in e-Governance projects in India, for a joint project sponsored by ICFOSS & IIMB.\n· Worked with faculty on a consulting project from Casino and gaming industry to strategize seasonal promotions across casinos. Was responsible for building predictive model to understand patron behavior on more than hundreds of attributes. Revealed factors that contributes to Casino loyalty\n· Worked as a teaching assistant for the following courses: Business Analytics,   Data mining, Spreadsheet modeling, Econometrics, Management science & Business statistics.\n\n\n\nOrganization:    Mohyal Educational & Research Technology\nRole/Contribution: Performed routine server monitoring and performance benchmarking, Maintain network system, Written SQL scripts to manipulate data for loading & extracts, monitor and maintain the database system\n\nRESEARCH\n· Research paper titled “The development of hierarchical forecasting model for predicting electrical load in the Indian utility industry” (Paper presentation at International conference on Big data & Analytics for business, Delhi,  India, March 17-18, 2016)\n· Presented a research paper titled “Knowledge extraction in Hospitality industry: A text analytic approach” at ICRAMSCS, Central University of Bihar, May 29-31, 2015\n\nkhan.iimb@gmail.com, saif.stats@gmail.com\nLinked In - https://www.linkedin.com/in/saif-khan-a539a976/\nH.No # 84, 5th Main, BTM Layout, Stage-1, Bangalore,560029, India,  Mobile: +91 8105820438\n [1]\n \n \nSAIF KHAN\n \n \nkhan.iimb@gmail.com\n, saif.stats@gmail.com\n \nLinked In \n-\n \nhttps://www.linkedin.com/in/saif\n-\nkhan\n-\na539a976/\n \nH.No # 84, 5th Main, BTM Layout, Stage\n-\n1, Bangalore,560029, India\n,\n \n \nMobile\nÈ\n: +91 8105820438\n \n \n[\n1\n]\n \n \nCredentials\n \n \nResult\n-\noriented Data scientist offering \n8\n \nyears of proven success in the areas of advance statistical analysis, \nresearch and development in both domestic and international market. \n \nPossess in depth knowledge in \nBusiness Statistics , Predictive and  Prescriptive modeling, machine learning, Social \nnetwork analysis and \nText analytics.\n \n \nExperienced in building best\n-\nin\n-\nclass predictive models and decision tools to address business needs by \nleveraging state\n-\nof\n-\nthe\n-\nart machine learning and statistical algorithms\n.\n \nHighly accomplished in providing \ndata \ndriven business insights to fortune 500 companies so far.\n \n \nWorked for various domains i.e. Banking, Retail, Energy and utility, Oil & Gas, Consumer Survey, Casino and \nGaming focused on Analytics , machine learning and deep learning \n, \nConsulting, Solutionin\ng, \nArchitecture\n, \nImplementation with Pre \n–\n \nSales expertise.\n \n \n \nBusiness Analytics, \nBusiness Intelligence\n \n& Big Data Exposure\n \nBusiness \n \nAnalytics\n \nBusiness Statistics\n \nDescriptive Statistics, Distribution theory, Business \nHypothesis, Statistical inferences , \nSampling,  ANOVA, \nDesign of Experiment, Multivariate analysis\n \nPredictive\n \nRegression analysis, Regression diagnostics, Residual \nanalysis and collinearity issues, Logistic Regression, Odds \nRatio, ROC curves, Time series and Forecasting, ARIMA & \nGARCH \nmodels\n \nPrescriptive\n \nLinear Programming, Dynamic programming, Mixed \ninteger programming, Multi criteria decision making  \ntechniques( AHP, DEA), \nMonte Carlo simulation\n \nMachine Learning\n \nNeural Networks( ANN), Nearest \nneighbor, Decision tree, \n \nNaive bayes, Support Vector, Apriori, Random forest, \nBagging and boosting, \nStochastic gradient descent\n \nDeep Learning\n \nDeep networks and regularization, Convolutional networks, \nAuto encoders, Deep generative \nmodels, Sequence \nmodeling,\n \nReinforcement learning, \n \nData Mining\n \nClustering and segmentation, Classification and \ndiscriminant analysis, Principal component analysis\n \nMarketing Analytics\n \nPrice bundling, Non linear pricing, Market basket analysis, \nRFM analysis, Bass diffusion \nmodels, Customer lifetime model \n(CLV), Markdown optimization\n, Market mix \nmodeling, \nConjoint analysis, Structural Equation modeling\n \nStochastic\n \nMarkov Models\n \nBusiness \nIntelligence\n \nMetadata Modeling\n \nMetadata Design & Development\n \nCube\n \nProcess, Strategies\n,\n \nDesign & Development\n \nReporting\n \nTemplate Designing & Development\n \nKPI Modeling\n \nMetric, Calculation, Formulas, Design & Development\n \nScorecard & \nDashboard\n \nMetric Template Designing & Development\n \nPortal Management\n \nUser,  Roles & Privileges, Webpage \nDesigning & \nDevelopment\n \nBig Data\n \nStrategy\n \nC\nompose current business strat\negies in order to link Big \nData\n \nand Analytics\n \nUnderstanding\n \n& \nProcessing\n \n \nIdentification of \na suitable storage for Big Data, Data \ningestion, \nData cleaning and processing \n(Exploratory data \nanalysi\ns),\n \nVisualization of the data, \nApply the machine \nlearning algorithms (If required)","annotation":[{"label":["Skills"],"points":[{"start":13546,"end":13553,"text":"Big Data"}]},{"label":["Skills"],"points":[{"start":13365,"end":13372,"text":"Big Data"}]},{"label":["Skills"],"points":[{"start":13309,"end":13309,"text":"R"}]},{"label":["Skills"],"points":[{"start":13099,"end":13099,"text":"R"}]},{"label":["Skills"],"points":[{"start":12772,"end":12772,"text":"R"}]},{"label":["Skills"],"points":[{"start":12545,"end":12545,"text":"R"}]},{"label":["Skills"],"points":[{"start":12339,"end":12339,"text":"R"}]},{"label":["Skills"],"points":[{"start":12042,"end":12042,"text":"R"}]},{"label":["Skills"],"points":[{"start":12032,"end":12032,"text":"R"}]},{"label":["Skills"],"points":[{"start":11990,"end":11990,"text":"R"}]},{"label":["Skills"],"points":[{"start":11983,"end":11983,"text":"R"}]},{"label":["Skills"],"points":[{"start":11965,"end":11965,"text":"R"}]},{"label":["Skills"],"points":[{"start":11912,"end":11912,"text":"R"}]},{"label":["Skills"],"points":[{"start":11888,"end":11888,"text":"R"}]},{"label":["Skills"],"points":[{"start":11867,"end":11867,"text":"R"}]},{"label":["Skills"],"points":[{"start":11630,"end":11637,"text":"Big Data"}]},{"label":["Skills"],"points":[{"start":11351,"end":11351,"text":"R"}]},{"label":["Skills"],"points":[{"start":10668,"end":10668,"text":"R"}]},{"label":["Location"],"points":[{"start":10582,"end":10590,"text":"Bangalore"}]},{"label":["Name"],"points":[{"start":10410,"end":10418,"text":"SAIF KHAN"}]},{"label":["Location"],"points":[{"start":10351,"end":10359,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":10153,"end":10153,"text":"R"}]},{"label":["Skills"],"points":[{"start":9783,"end":9783,"text":"R"}]},{"label":["Skills"],"points":[{"start":9777,"end":9777,"text":"R"}]},{"label":["Skills"],"points":[{"start":9772,"end":9772,"text":"R"}]},{"label":["Skills"],"points":[{"start":9557,"end":9557,"text":"R"}]},{"label":["Skills"],"points":[{"start":9537,"end":9537,"text":"R"}]},{"label":["Skills"],"points":[{"start":9271,"end":9271,"text":"R"}]},{"label":["Skills"],"points":[{"start":8788,"end":8788,"text":"R"}]},{"label":["Skills"],"points":[{"start":7604,"end":7604,"text":"R"}]},{"label":["Location"],"points":[{"start":7578,"end":7586,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":7426,"end":7426,"text":"R"}]},{"label":["Skills"],"points":[{"start":7294,"end":7294,"text":"R"}]},{"label":["Skills"],"points":[{"start":7260,"end":7260,"text":"R"}]},{"label":["Skills"],"points":[{"start":6952,"end":6952,"text":"R"}]},{"label":["Location"],"points":[{"start":6927,"end":6935,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":6917,"end":6917,"text":"R"}]},{"label":["Skills"],"points":[{"start":6912,"end":6912,"text":"R"}]},{"label":["Skills"],"points":[{"start":6437,"end":6437,"text":"R"}]},{"label":["Skills"],"points":[{"start":6046,"end":6046,"text":"R"}]},{"label":["Skills"],"points":[{"start":6017,"end":6017,"text":"R"}]},{"label":["Skills"],"points":[{"start":5930,"end":5930,"text":"R"}]},{"label":["Location"],"points":[{"start":5839,"end":5847,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":5331,"end":5331,"text":"R"}]},{"label":["Skills"],"points":[{"start":5014,"end":5014,"text":"R"}]},{"label":["Skills"],"points":[{"start":4985,"end":4985,"text":"R"}]},{"label":["Skills"],"points":[{"start":4921,"end":4926,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4918,"end":4918,"text":"R"}]},{"label":["Skills"],"points":[{"start":4456,"end":4456,"text":"R"}]},{"label":["Skills"],"points":[{"start":4428,"end":4428,"text":"R"}]},{"label":["Skills"],"points":[{"start":4370,"end":4370,"text":"R"}]},{"label":["Skills"],"points":[{"start":3996,"end":3996,"text":"R"}]},{"label":["Skills"],"points":[{"start":3968,"end":3968,"text":"R"}]},{"label":["Skills"],"points":[{"start":3915,"end":3920,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3767,"end":3767,"text":"R"}]},{"label":["Skills"],"points":[{"start":3717,"end":3722,"text":"Matlab"}]},{"label":["Skills"],"points":[{"start":3709,"end":3714,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3705,"end":3705,"text":"R"}]},{"label":["Skills"],"points":[{"start":3699,"end":3702,"text":"SPSS"}]},{"label":["Skills"],"points":[{"start":3632,"end":3632,"text":"R"}]},{"label":["Education"],"points":[{"start":3500,"end":3518,"text":"Masters\n\tStatistics"}]},{"label":["Skills"],"points":[{"start":3490,"end":3490,"text":"R"}]},{"label":["Skills"],"points":[{"start":3348,"end":3348,"text":"R"}]},{"label":["Skills"],"points":[{"start":3304,"end":3304,"text":"R"}]},{"label":["Location"],"points":[{"start":3293,"end":3301,"text":"Bangalore"}]},{"label":["Location"],"points":[{"start":3276,"end":3284,"text":"Bangalore"}]},{"label":["Location"],"points":[{"start":3216,"end":3224,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":3202,"end":3202,"text":"R"}]},{"label":["Skills"],"points":[{"start":3197,"end":3197,"text":"R"}]},{"label":["Location"],"points":[{"start":3146,"end":3154,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":2814,"end":2821,"text":"Big Data"}]},{"label":["Skills"],"points":[{"start":2717,"end":2724,"text":"Big Data"}]},{"label":["Skills"],"points":[{"start":2644,"end":2651,"text":"Big Data"}]},{"label":["Skills"],"points":[{"start":2590,"end":2590,"text":"R"}]},{"label":["Skills"],"points":[{"start":2379,"end":2379,"text":"R"}]},{"label":["Skills"],"points":[{"start":2059,"end":2059,"text":"R"}]},{"label":["Skills"],"points":[{"start":1832,"end":1832,"text":"R"}]},{"label":["Skills"],"points":[{"start":1632,"end":1632,"text":"R"}]},{"label":["Skills"],"points":[{"start":1340,"end":1340,"text":"R"}]},{"label":["Skills"],"points":[{"start":1331,"end":1331,"text":"R"}]},{"label":["Skills"],"points":[{"start":1289,"end":1289,"text":"R"}]},{"label":["Skills"],"points":[{"start":1282,"end":1282,"text":"R"}]},{"label":["Skills"],"points":[{"start":1265,"end":1265,"text":"R"}]},{"label":["Skills"],"points":[{"start":1213,"end":1213,"text":"R"}]},{"label":["Skills"],"points":[{"start":1189,"end":1189,"text":"R"}]},{"label":["Skills"],"points":[{"start":1168,"end":1168,"text":"R"}]},{"label":["Skills"],"points":[{"start":937,"end":944,"text":"Big Data"}]},{"label":["Skills"],"points":[{"start":674,"end":674,"text":"R"}]},{"label":["Skills"],"points":[{"start":24,"end":24,"text":"R"}]},{"label":["Name"],"points":[{"start":0,"end":8,"text":"SAIF KHAN"}]}],"extras":null,"metadata":{"first_done_at":1532675795000,"last_updated_at":1532675795000,"sec_taken":149,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Samyuktha S S\nmobile: 91 - 9538201403\nharisamyuktha9@gmail.com\nProfile\n\n· Having an overall of 6.5 years of IT experience\n· Having 4 years of experience as a developer in Python and in java\n· Having 2 years experience in Genetic algorithms ,Machine learning and\nDeep learning using python and Tensor Flow\n· Having experience in Apache Hadoop ,Spark, spark SQL,Spark streaming, Solr ,Kafka ,Influx ,Hive , Pig, R and Scala\n· Ph.D ( Deep Learning in BigData ) at VIT University Vellore,India in progress.\n· Given corporate training in deep learning and machine learning techniques\n· Experience with SQL and NoSQL databases\n· Experience in HTML,CSS, XML and UML.\n· Strong in development and design of commercial and business applications.\n· Ability to learn in work environment, fluent in communication, Productive interpersonal skills with ability to understand and co-operate group requirements efficiently.\nPrimary Skills\n\n\tML and DL Technologies\n\tR,SparkML,Tensor Flow\n\n\tProgramming Languages\n\tPython and java 8\n\n\tBig data Frameworks\n\tApache Hadoop ,Spark, sparkSQL, Spark Streaming,Kafka,Influx,Solr,Apache Pig\n\n\nEmployment Summary\n\n\tSno\n\tCompany\n\tPosition\n\tDate Hired\n\n\t1\n\tDatamatics Global Services Limited,Bangalore\n\tConsultant (Machine learning ,deep leaning architect and developer)\n\tSep 2015 to May 2017\n\n\t2\n\tTHE OXFORD COLLEGE OF\nENGINEERING, BANGALORE\n\tAssistant Professor(Department of Information Science and\n\tJuly/2013 to June/2014\n\n\n\t\n\t\n\tEngineering)\n\t\n\n\t3\n\tINFOSYS TECHNOLOGIES , BANGALORE\n\tSenior Software Engineer\n\tJuly/2008 – September/2009\n\n\t4\n\tIBM INDIA ,BANGALORE\n\tApplication Developer\n\tMarch/2007 - July/ 2008\n\n\t5\n\tGTEC SOFTWARE SOLUTIONS ,ERODE\n\tDeveloper\n\tMay/2005 to Feb/\n2007\n\n\nEducation\n\n\tEducation\n\tYear\nof Passing\n\tAggregate marks\nin percentage\n\tInstitute\n\n\tPh.D(Deep Learning)\nPart Time\n\tIn progress\n\t90%\n\tVIT University,Vellore,India\n\n\tM.E(computer Science)\n\t2013\n\t84%\n\tVelalar College Of Engineering and Technology, Erode,India\n\n\tB.E(computer science)\n\t2004\n\t79%\n\tBannari\nAmman\nInstitute\nof Technology,Sathamangalam,India\n\n\tHIGHER\nSECONDARY\n\t1999\n\t94.58%\n\tBharathi Vidhya Bhavan M.H.S.C, Erode,India\n\n\tSSLC\n\t1997\n\t87.72%\n\tBharathi Vidhya Bhavan M.H.S.C, Erode,India\n\n\nWorkshops attended\n\n\tSno\n\tName\n\tDate\n\tPlace\n\n\t1\n\tBigData Applications Development on HPC platforms\n\tDec 14,15\n2017\n\tCDAC Bangalore\n\n\t2\n\tReal time Analytics in Big data using Spark,Kafka and Influx\n\t27\nto\n28 october 2017\n\tCDAC Bangalore\n\n\t3\n\tHadoop for Big Data analytics and\n\tJune 27 to\n\tCDAC Bangalore\n\n\n\t\n\tanalytics using spark\n\t30 2016\n\t\n\n\t4\n\tData sciences and big data\n\tAug 5 to 7\n2015\n\tCDAC Bangalore\n\n\t5\n\tNS-2 and Qualnet\n\tFeb\n27,28\n2013\n\tKongu Engineering College,Erode\n\n\t6\n\tOpen Source RTOS for Real time embedded applications using Blackfin UCLinux\n\tMay 6 to\n19 2013\n\tKongu Engineering College,Erode\n\n\n\n\tName\n\tNLP using open NLP in java\n\n\tClient\n\tResearch and Development,Strategic Solutions Group,Datamatics\n\n\tDuration\n\tFeb 2016 to April 2016\n\n\tTechnology\n\tPython,Java\n\n\tDescription\n\tTo classify text data according to Named-entity recognition (NER) (also known as entity identification, entity chunking and entity extraction) is a subtask of information extraction that seeks to locate and classify named entities in text into pre-defined categories such as the names of persons, organizations, locations, expressions of times, quantities, monetary values, percentages, etc.\n\n\tContribution\n\tDesign,development,training and testing\n\n\nProject 2\n\n\tName\n\tProduct Recommendation Engine - The Genetic Algorithm Approach\n\n\tClient\n\tResearch and Development,Strategic Solutions Group,Datamatics\n\n\tDuration\n\tSep/2015 to feb 2016\n\n\tTechnology\n\tApache spark, solr,java,python and Pig\n\n\tDescription\n\tTo recommend Products to the customer by exploring the customer's unsaid preferences  through  evolutionary  unsupervised  learning  techniques.  The\nProduct  Recommendation  uses  Genetic  algorithm  and  pattern  mining\n\n\n\t\n\ttechniques to derive customer's buying pattern. The recommendations are of 2 types :\n1. Similar recommendation:The recommendation based on the study of customer's preferences using clustering algorithms.\n2. Suggested\nrecommendation:\nThe\nrecommendation\nbased\non\nthe probability of customer buying the product based on market basket analysis.\n\n\tContribution\n\tDesign,development,training and testing\n\n\nProject 3\n\n\tName\n\tLatent factor using ALS algorithm\n\n\tClient\n\tResearch and Development,Strategic Solutions Group,Datamatics\n\n\tDuration\n\tApril 2016 to June 2016\n\n\tTechnology\n\tApache Spark Machine learning\n\n\tDescription\n\tIdentify the product attribute and the latent factors of the customer towards the product compute the matrix of dimensionality reduction on the latent factors for each product attribute.\nGet an equivalent matrix on the customer's liking of the product\n\n\tContribution\n\tDesign,development,training and testing\n\n\nProject 4\n\n\tName\n\tOnline Bidding\n\n\tClient\n\tReusable component for Other Business Units in Infosys\n\n\tDuration\n\tJuly 2009 to sep 2009\n\n\tServer\n\tIBM Web sphere\n\n\tTechnology\n\tCore Java, servlets, JSP,JSTL, Java script, HTML, XML and Hibernate\n\n\tData Base\n\tOracle9i\n\n\tFramework\n\tStruts 1.3\n\n\tDescription\n\tOnline bidding is a process of bidding items online. It has two main\nfunctionalities: bidder and admin. The admin takes care of placing the items for bid and bidder is the person who takes part in the bid.\n\n\n\t\n\tThe winner of the bid is decided by the algorithm There are 5 main algorithms:\n1. Straight biding\n2. Automatic bidding\n3. Bid many\n4. closest bidding\n5. Buy now bidding\nThe online bidding system also takes care of user registration, password and username validation, sending emails to the bidders on the password and winning status.\nThe component has complex GUI features for the admin and the bidder.\n\n\tContribution\n\t1.Requirement analysis and enhancement 2.Design\n3. Coding and self testing.\n\n\nProject 5\n\n\tName\n\tAJAX JSF Table Filler\n\n\tClient\n\tReusable component for Other Business Units in Infosys\n\n\tDuration\n\tApril 2009 to June 2009\n\n\tServer\n\tSun Glass Fish\n\n\tTechnology\n\tJAVA, AJAX, Servlets, Java Script, HTML and JSF custom Tag\n\n\tData Base\n\tOracle\n\n\tFramework\n\tJSF\n\n\tDescription\n\tThe AJAX JSF Table Filler is a component for the client side AJAX refresh of the user’s preferences. Consider an example of the user being a college student and he wants to select his college option from a given source table\n,the options that he will select should dynamically get reflected in the preference table and removed from source table using AJAX. The options in the preference table can be arranged based on preference ranking or user selection, vertically, horizontally, with number of rows and columns all set as a JSF custom tag.\nEvery click of the source item will lead to a DB refresh with the items\n\n\n\t\n\tdeleted from preference table coming back to source table.\n\n\tContribution\n\t1.Requirement analysis and enhancement 2.Design\n3. Coding and self testing.\n\n\nProject 6\n\n\tName\n\tProduct Key Generator\n\n\tClient\n\tReusable component for Other Business Units in Infosys\n\n\tDuration\n\tFeb 2009 to March 2009\n\n\tTechnology\n\tCore Java, Swings, AWT.\n\n\tDescription\n\tProduct Key Generator (PDK) is a desktop application. It is used to generate a Unique Product key for every newly created product. The generated product key can be changed by the user. The system will accept or reject the modified product key based on the algorithm used. There are 3 algorithms used for the product key generation:\nUsing Patterns:\nThis algorithm used has 3 combinations for product key generation: Caps only-product key with only CAP\nNumbers only-product key with only number Mixed-product key with mixed caps and numbers. Hash Algorithm\nThe hash algorithm uses java’s inbuilt hash algorithm techniques to generate the product key. This uses the customer information to prepare the seed to generate the hash algorithm based product key. If the customer information has changed it gives a new seed for the hash algorithm. When the user tried to change the product key generated, the PDK will check if the new product key is backtracked to the original seed, if it does, the new product code is accepted. If not the user is given an error message.\nUUID Algorithm\nUUID stands for Universal Unique ID. It generates a unique the product key based on java’s inbuilt UUID. The generated product key is tested based on the Regular expression. If the user tries to change the product key, PDK checks for the regular expression and accepts or rejects the new product key.\n\n\tContribution\n\t1.Requirement analysis and enhancement\n\n\n\t\n\t2. Design\n3. Coding and self testing.\n\n\n\nProject 7\n\n\tName\n\tFile Cache\n\n\tClient\n\tReusable component for Other Business Units in Infosys\n\n\tDuration\n\tDec 2008 to Jan 2009\n\n\tServer\n\tMicrosoft FTP server.\n\n\tTechnology\n\tPython\n\n\tDescription\n\tFile Cache is a desktop application; it uses FTP protocol and connects to a remote machine.\nThe file cache is supplied with an XML file; this file contains the details of the remote IP address and the remote file name, trigger type and last updated timestamp.\nThe file cache reads the remote details and compares the remote file time stamp to the last updated time stamp, if the remote file time stamp has changed after the last updated time stamp a trigger such as an email or an popup alert specified by user is sent.\n\n\tContribution\n\t1.Requirement analysis and enhancement 2.Design\n3. Coding and self testing.\n\n\n\n\tName\n\tRegression Testing Framework\n\n\tClient\n\tReusable component for Other Business Units in Infosys\n\n\tDuration\n\tJuly 2008 to Aug 2008\n\n\tTechnology\n\tPython\n\n\tData Base\n\tSQL\n\n\tDescription\n\tRegression Testing Framework (RTF) is used to checks if the bulk data send in the date base is send in properly. RTF is used during regression testing bulk data inserted into the data base.The RTF does regression testing by reading the inserted data from an excel sheet and check whether the exact\nreplica  is  available  in  the  data  base.  It  generates  a  report  based  on the\n\n\n\t\n\tcomparison between the DB and the excel sheet. The report has a status pass or fail. If all the comparison between the DB and excel sheet is the same, the report is a pass. Else the report is a fail. The failed report contains the mismatched record, total number of records passed and records failed.\n\n\tContribution\n\t1.Requirement analysis and enhancement 2.Design\n3. Coding and self testing.\n\n\nProject 9\n\n\tName\n\tICORE\n\n\tClient\n\tAT&T\n\n\tDuration\n\tAug 2007 to June 2008\n\n\tTechnology\n\tPython\n\n\tData Base\n\tSQL\n\n\tDescription\n\tICORE is AT&T OSS that supports AT&T’s high-speed services, which include Frame Relay, ATM and IP FR services for both domestic and global. It is basically a provisioning system for Ports, PVCs for FR, ATM and IP over FR networks and also maintains the inventory of the same.\nModules:\n· ICORE services variety of ATT OSS like\n· BMP (Trouble Ticketing System),\n· AISE (Ordering System),\n· Netscope (Maintenance troubleshooting and information system)\n· Alarm view (alarm reporting and correlation),\n· CNMS (customer network management),\n· CMT (capacity management tool for network design), and others.\n\n\tContribution\n\t1.Requirement analysis 2.Design\n3.Coding and self testing for data base migration between AT&T and SBC\n\n\nProject 11\n\n\tName\n\tBancalombarda Teller\n\n\tClient\n\tItalian Bank Bancalombarda\n\n\tDuration\n\tMar 2007 to Aug 2007\n\n\n\tTechnologyP ython\n\tPython\n\n\tData Base\n\tsql\n\n\tDescription\n\tBancalombarda is an Italian Bank which needs a teller application which is the interface between the teller services and customer, the Teller consists of the following roles and responsibilities:\n· Cash operations\n· Static Financial transactions\n· Receiving cash from customer\n· Sorting cash according to denominations\n· Applicable limits\n· Authorization steps\n· Cheque transactions\n\n\tContribution\n\tCode design and testing for plug-in\n· Sorting cash according to denominations\n· Cheque transactions(Infra group cheques)\n\n\nDeclaration\n\nThe information given above is true to the best of my knowledge.\nS .S. Samyuktha\nProject 1\n\n\n\nProject 8","annotation":[{"label":["Skills"],"points":[{"start":11360,"end":11365,"text":"Python"}]},{"label":["Skills"],"points":[{"start":10467,"end":10472,"text":"Python"}]},{"label":["Skills"],"points":[{"start":9557,"end":9562,"text":"Python"}]},{"label":["Skills"],"points":[{"start":8771,"end":8776,"text":"Python"}]},{"label":["Skills"],"points":[{"start":8280,"end":8283,"text":"java"}]},{"label":["Skills"],"points":[{"start":7697,"end":7700,"text":"java"}]},{"label":["Skills"],"points":[{"start":4512,"end":4527,"text":"Machine learning"}]},{"label":["Skills"],"points":[{"start":4506,"end":4510,"text":"Spark"}]},{"label":["Skills"],"points":[{"start":3664,"end":3667,"text":"java"}]},{"label":["Skills"],"points":[{"start":2968,"end":2973,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2842,"end":2845,"text":"java"}]},{"label":["Skills"],"points":[{"start":2375,"end":2379,"text":"Spark"}]},{"label":["Skills"],"points":[{"start":1234,"end":1249,"text":"Machine learning"}]},{"label":["Skills"],"points":[{"start":1068,"end":1072,"text":"Spark"}]},{"label":["Skills"],"points":[{"start":1051,"end":1055,"text":"Spark"}]},{"label":["Skills"],"points":[{"start":1006,"end":1009,"text":"java"}]},{"label":["Skills"],"points":[{"start":995,"end":1000,"text":"Python"}]},{"label":["Skills"],"points":[{"start":950,"end":954,"text":"Spark"}]},{"label":["Education"],"points":[{"start":424,"end":428,"text":"Ph.D "}]},{"label":["Skills"],"points":[{"start":360,"end":364,"text":"Spark"}]},{"label":["Skills"],"points":[{"start":343,"end":347,"text":"Spark"}]},{"label":["Skills"],"points":[{"start":327,"end":340,"text":" Apache Hadoop"}]},{"label":["Skills"],"points":[{"start":262,"end":274,"text":"Deep learning"}]},{"label":["Skills"],"points":[{"start":241,"end":256,"text":"Machine learning"}]},{"label":["Skills"],"points":[{"start":221,"end":238,"text":"Genetic algorithms"}]},{"label":["Skills"],"points":[{"start":185,"end":188,"text":"java"}]},{"label":["Skills"],"points":[{"start":171,"end":176,"text":"Python"}]},{"label":["Name"],"points":[{"start":0,"end":12,"text":"Samyuktha S S"}]}],"extras":null,"metadata":{"first_done_at":1532690788000,"last_updated_at":1532690788000,"sec_taken":135,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Sandeep K P\n\n\n\n\n\nEmail\nsandeeprao6289@gmail.com\n\nPresent Address\n#216, Lalbagh​ Road 4th cross, Opp. Archana Complex, Bangalore-560027\n\nMobile: +91 9035006194\n\n\nPersonal Data\n\nDate of Birth: 06-02-1989\n\nLanguages Known: English, Hindi, Kannada.\nPassport No: J9324620\n \n\nObjective\n\nTo be successful in the field that I get in and to provide valuable service to the organization.\n\n\nWeb Developer\n\nHaving 5.4 years experience as a web developer.\nGood in using quality standards, having good interpersonal and communication skills.\nSkilled in understanding Client Requirements.\n\n\nEducation\n\nBachelor of Engineering (B.E Information Science) from S.E.A College of Engineering & Technology Bangalore. (Visvesvaraya Technological University)\n\nTechnical Qualification\n\nGood knowledge in Python/Django framework, Django REST, JavaScript, Jquery, Ajax, HTML5, CSS, GIT and JSON.\n\nBasic knowledge on web scraping using BeautifulSoup, numpy and pandas.\n\nWorking Experience\n\n\tWorking as Web Developer from 15th​​ Nov 2017 to till date with Experis IT Pvt. Ltd.\n\n\n\tWorked as Web Developer from 7th​​ Nov 2016 to 14th Nov 2017 with Aveto Consulting, Bangalore.\n\n\n\tWorked as Web Developer from 5th​​ July 2013 to 29th​​ Oct 2016 with Double Spring Media Pvt Ltd, Bangalore.\n\n\n\t​Worked as IMAC Project Co-ordinator from 25th​​ Jan 2012 to\n\n\n28th​​ Jan 2013 with IBM INDIA Pvt Ltd, Bangalore.\nProject: GolfConnectX\n\n\tDirect interaction with the client from project design to delivery(Beta version).\n\nPerformed complete backend programming using Python/Django REST framework.\n\nPerformed DB design in Postgres SQL.\n\nPerformed server side configuration for the software in AWS.\n\nUsed GIT for version control.\n\nProject duration - 6 months.\n\n\n\nProject: DivorceMasters\n\n\tDirect interaction with the client from project design to delivery(Beta version).\n\nPerformed major backend programming using Python/Django framework.\n\nPerformed front end programming using HTML5, CSS, Javascript and Jquery.\n\nPerformed DB design in Postgres SQL.\n\nPerformed server side configuration for the software in AWS.\n\nUsed GIT for version control.\n\nIntegrated payment gateway like Stripe.\n\nProject duration - 6 months.\n\n\n\nProject: Blackmonk (blackmonk.com)\n\n\tPerformed major backend programming using Python/Django.\n\nPerformed front end programming using HTML5, CSS, Javascriopt and Jquery.\n\nDeveloped saas version of the project.\n\nPerformed server side configuration for the software.\n\nUsed SVN for version control.\n\nIntegrated third party APIs.\n\nIntegrated payment gateway like Stripe, Paypal, Authorise.net etc.\n\nDirect interaction with multiple clients.\n\nProject duration - 2.5 years.\n\n\n\nProject: Team Wave (teamwave.com)\n\n\tPerforming backend development using Django REST framework.\n\nIntegrated google drive API and other third party APIs.\n\nUsed numpy and pandas for data management.\n\nProject duration - 6 months.\n\n\n\nProject: Tiro (tiro.com.au and tiro.ie)\n\nClient: Tiro Systems PVT LTD(AU)\n\n\tPerforming major backend programming using Python/Django.\nPerformed front end programming using HTML5, CSS, JS and Jquery.\nPerformed server side configuration for the software.\nUsed GIT (Atlassian bitbucket) for version control.\nDirect interaction with the client.\nProject duration - 2 months.\n\nStrengths:\n\n\n\tSelf motive.\n\nGood team worker.\n\nHonesty and Hard working.\n\nQuick Learner.\n\nSincere and Disciplined\n\n\n\n\nI hereby certify that all the above information furnished is true to the best of my knowledge and belief.\n\n\n\n\nThanking you,\nSincerely\n\n(Sandeep K P)","annotation":[{"label":["Name"],"points":[{"start":3501,"end":3511,"text":"Sandeep K P"}]},{"label":["Skills"],"points":[{"start":3134,"end":3136,"text":"GIT"}]},{"label":["Skills"],"points":[{"start":3067,"end":3072,"text":"Jquery"}]},{"label":["Skills"],"points":[{"start":3055,"end":3057,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":3048,"end":3052,"text":"HTML5"}]},{"label":["Skills"],"points":[{"start":2995,"end":3007,"text":"Python/Django"}]},{"label":["Skills"],"points":[{"start":2337,"end":2342,"text":"Jquery"}]},{"label":["Skills"],"points":[{"start":2316,"end":2318,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":2309,"end":2313,"text":"HTML5"}]},{"label":["Skills"],"points":[{"start":2255,"end":2267,"text":"Python/Django"}]},{"label":["Skills"],"points":[{"start":2077,"end":2079,"text":"GIT"}]},{"label":["Skills"],"points":[{"start":1995,"end":2006,"text":"Postgres SQL"}]},{"label":["Skills"],"points":[{"start":1963,"end":1968,"text":"Jquery"}]},{"label":["Skills"],"points":[{"start":1943,"end":1945,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":1936,"end":1940,"text":"HTML5"}]},{"label":["Skills"],"points":[{"start":1872,"end":1884,"text":"Python/Django"}]},{"label":["Skills"],"points":[{"start":1663,"end":1665,"text":"GIT"}]},{"label":["Skills"],"points":[{"start":1581,"end":1592,"text":"Postgres SQL"}]},{"label":["Skills"],"points":[{"start":1527,"end":1539,"text":"Python/Django"}]},{"label":["Location"],"points":[{"start":1364,"end":1372,"text":"Bangalore"}]},{"label":["Location"],"points":[{"start":1247,"end":1255,"text":"Bangalore"}]},{"label":["Location"],"points":[{"start":1135,"end":1143,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":863,"end":866,"text":"JSON"}]},{"label":["Skills"],"points":[{"start":855,"end":857,"text":"GIT"}]},{"label":["Skills"],"points":[{"start":850,"end":852,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":843,"end":847,"text":"HTML5"}]},{"label":["Skills"],"points":[{"start":837,"end":840,"text":"Ajax"}]},{"label":["Skills"],"points":[{"start":829,"end":834,"text":"Jquery"}]},{"label":["Skills"],"points":[{"start":817,"end":826,"text":"JavaScript"}]},{"label":["Skills"],"points":[{"start":779,"end":791,"text":"Python/Django"}]},{"label":["Location"],"points":[{"start":684,"end":692,"text":"Bangalore"}]},{"label":["Location"],"points":[{"start":118,"end":126,"text":"Bangalore"}]},{"label":["Name"],"points":[{"start":0,"end":10,"text":"Sandeep K P"}]}],"extras":null,"metadata":{"first_done_at":1532690971000,"last_updated_at":1532690971000,"sec_taken":182,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Saranya Govindaraj\n\nPhone: +91 9597268158\nEmail: gsaranya18@gmail.com\n\nOBJECTIVE \n\nTo work in an environment that would enable me to provide an exceptional contribution with right responsibilities and opportunities for me and the organization to grow in unison. Always aspiring towards value addition and self-development.\nSUMMARY\n· 7.5 years of working experience in Pharma domain - IT industry with 5 years in SQL, PL/SQL, Service Management and 2.5 years in R Programming, Python, Data Analysis, Machine Learning.\n· Joined Infosys Ltd. on 21th June 2010 as a fresher after completing B.E Computer Science from Karpagam College, TN, India in 2010.\n· Currently, designated as Technology Analyst and working for a leading Pharma Client as Data Analyst.\n· Travelled to Sweden for onsite assignment from Infosys for 2.5 years. \n· Excellent written and verbal communication skills. Excellent team player with unique individuality.\nSKILL SET            \n· Working as Data Analyst - R programming, Python(Numpy, Scipy, Scikit-learn, Matplotlib), Machine Learning for a Pharma client.\n\n· Aware of Regression, Classification, Clustering, Time Series Analysis, Text Mining, Dimensionality Reduction and Boosting Algorithms. \n\n· Worked on Tableau Desktop Application. \n\n· Aware of Hadoop, HDFS, Spark (PySpark). \n\n· Worked as PL/SQL Developer for Quality Control systems (Global QC LIMS, SmartLab and Global Empower) by providing solutions to Clients proactively on complex issues with my technical abilities.\n· Good at gathering client requirements and implementing the requirements as per business needs.\n· Have expertise on troubleshooting problem tickets through active participation in code red calls.\n\n· Aware of Nugenesis LMS SDMS technology for archiving lab applications data. \n· Worked as Global Release, Incident, Problem and Change manager for QC applications. \n\n· Good exposure to all phases of Software Development Life Cycle (SDLC), ITIL Standards and IS PDM and ADF process.\n· Very strong written and verbal communication, coordination and Business handling skills and capable of managing issues easily.\n\n· Strong and proven ability in Project planning, Reporting and Resource Management especially good at handling work pressure.\n\nPROJECT EXPERIENCE\nProject: Data Analysis Project                                                                                      (Aug’ 15 – Present)                                    \n\nLocation: India                                                                                                       \n\nClient Name: US headquartered leading Pharma client.\n       \n\nRole: Technology Analyst – Data Analyst/Scientist             \n\nResponsibilities:\n\n1. Statistical model (Predictive) development on R Studio using various statistical & Machine Learning       techniques/Algorithms.\n\n2. Test/train the model, Improve Model accuracy.\n\n3. Worked on Regression techniques such as Simple Linear, Multiple, Polynomial, SVR, DT, Random Forests, Survival Analysis, Non-Linear Least Square, CART(Regression Trees)\n\n4. Worked on Classification techniques such as Logistic, KNN, SVM, Naive Bayes, Decision Trees, Random Forest, CART(Classification Trees)\n5. Aware of K Means and Hierarchical Clustering techniques.\n\n6. Time Series Analysis models - AR, MA, ARMA, ARIMA, forecasting\n7. Text Mining in R – Sentiment Analysis, Topic Modeling.\n\n8. Worked on PCA - Dimensionality Reduction techniques\n\n9. Worked on Cross validation(k fold) and Gradient Boosting. \n\n10. Hands-on experience in Tableau Desktop Application.\nProject: Nugenesis Archival Project                                                                                      (Jan’ 15 – Jul’ 15)                                    \n\nLocation: Sweden (Jan’ 15 – Jul’15)                                                                                                      \n\nClient Name: UK headquartered leading Pharma client.\n       \n\nRole: Technology Analyst - PL/SQL Developer             \n\nResponsibilities:\n\n1. Managing Business requirements gathering and work with the team on implementing the same.\n\n2. Coordinating with different business stakeholders in driving the changes as per plan.\n\n3. Working on Packages, procedures, functions and triggers creation.\n\n4. Liaising with Vendor on discussing issues and fixing them.\n\nProject: SmartLab and Empower upgrade Project                                                            (Jul’ 14 – Dec’ 14)                                    \n\nLocation: Sweden (Jul’14 – Dec’ 14)                                                                                                      \n\nClient Name: UK headquartered leading Pharma client.\n       \n\nRole: Technology Analyst - Onsite Application SME and Onsite Project Co-coordinator             \n\nResponsibilities:\n\n1. Involved in SmartLab and Empower upgrade project architecture audit with Architects \n2. Worked on Application upgrade planning and implementation with all eco-partners.\n3. Worked on IPAD and BTD phases of the project and driven the project completely from onshore.\n4. Driven daily project status calls and managed status reporting, escalations.\nProject: Business As Usual\nLocation: India (Nov’10 – Jul’13), Sweden (Jul’13 – Jun’14)                                             (Nov’ 10 – Jun’ 14)                                    \n\nClient: UK headquartered leading Pharma client.\n\nRole: Systems Engineer – PL/SQL Developer\nResponsibilities:\n1. Worked on creating Procedure, Functions, Packages, Triggers as per the requirement.\n\n2. Have experience in table, Index, Views, Synonyms, Sequence, Constraints creation.\n\n3. Worked on many Bug Fixes and Service Enhancement Requests related those modules.\n\n4. Basic application related errors troubleshooting as part of BAU with stringent SLAs.\n\n5. Been at onsite (Sweden) as QC Application SME since July, 2013 till Aug 2014 as primary customer POC.\nCERTIFICATIONS\n\n· Data Science and Machine Learning Bootcamp with R - Udemy\n\n· ITIL v3 foundation.\n· Infosys Internal Oracle Administrator Certification.\n\n· Infosys Internal Oracle PL/SQL Certification.\n· Infosys Internal Certification in Project Management.\n\n· Completed Infosys Internal Business Communication Enablement Program. \n\n· Unix basics.\n\nTRAININGS UNDERGONE\n\n· R programming Training at Infosys.\n\n· Tableau Desktop Application Training at Infosys.\n· Trained on Oracle 9i by Oracle Corporation.\n\n· Trained in Generic C, C++, UNIX, Java, and Oracle at Infosys.\n· Taken a day tour at Pharma manufacturing site and have understanding on Pharma Manufacturing and Quality Control and Assurance process. \nSOFTWARE SKILLS\n\nOperating Systems:\nMS Windows 2000/XP Professional/Vista, Win 7, MS Windows Server 2000/2003/2008 R2\n  Programming Languages:     R programming, Python, Oracle SQL and PL/SQL\n  Database:\n\nOracle 9i, 10g, 11g, 12c\nTools worked on:                   R-Studio, Tableau, BMC Remedy, Remedy on Demand (RoD), Service Now, Clearcase, Microsoft Visio 2010, Microsoft Office Project 2007, MS Package (Word, Excel, Power point), Oracle Enterprise Manager (OEM).\nEDUCATION\n\tDegree &Branch\n\tInstitute / University\n\tPercentage\n\n\tB.E Computer Science\n\tKarpagan College, Coimbatore.\n\t89%\n\n\tHigher secondary\n\tP.S.G.R. Krishnammal Hr. Sec. School, Coimbatore.\n\t90%\n\n\t10th \n\tP.S.G.R. Krishnammal Hr. Sec. School, Coimbatore.\n\t95%\n\n\nPERSONAL DETAILS\n\n\tName\n\tSaranya Govindaraj\n\n\tDate of Birth\n\t18-09-1989\n\n\tMarital Status\n\tMarried\n\n\tHobbies \n\tBrowsing, Watching Movies\n\n\nACHIEVEMENTS\n\n· Received ‘YUVA KALA BHARATHI’ award for academic and sports excellence.\n\n· Received Anna University 3rd rank in Computer Science department out of 234 colleges in Tamil Nadu State, India.\n· Won ‘BEST ROOKIE’ award in Infosys – 2010-2011, ‘BRAVO’ award in Infosys – 2012, ‘HIFLYER’ award in Infosys – 2015, ‘STAR’ award in Infosys - 2017.\n· District level Runner up in Kho-Kho Game.\n\n· Completed lower and higher examinations in typewriting.\n\n· Athlete and secured several prizes in short and long distance running.\n\n· Received many appreciations from Pharma Business Clients for work excellence.\n\nREFERENCES: \n\nAvailable upon request.","annotation":[{"label":["Name"],"points":[{"start":7368,"end":7385,"text":"Saranya Govindaraj"}]},{"label":["Education"],"points":[{"start":7145,"end":7147,"text":"B.E"}]},{"label":["Skills"],"points":[{"start":6800,"end":6802,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":6797,"end":6802,"text":"PL/SQL"}]},{"label":["Skills"],"points":[{"start":6789,"end":6791,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":6774,"end":6779,"text":"Python"}]},{"label":["Skills"],"points":[{"start":6086,"end":6088,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":6083,"end":6088,"text":"PL/SQL"}]},{"label":["Skills"],"points":[{"start":5937,"end":5952,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":5417,"end":5419,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":5414,"end":5419,"text":"PL/SQL"}]},{"label":["Skills"],"points":[{"start":3960,"end":3962,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":3957,"end":3962,"text":"PL/SQL"}]},{"label":["Skills"],"points":[{"start":2782,"end":2797,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":2267,"end":2279,"text":"Data Analysis"}]},{"label":["Skills"],"points":[{"start":1320,"end":1322,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1317,"end":1322,"text":"PL/SQL"}]},{"label":["Skills"],"points":[{"start":1295,"end":1299,"text":"Spark"}]},{"label":["Skills"],"points":[{"start":1286,"end":1290,"text":"Spark"}]},{"label":["Skills"],"points":[{"start":1271,"end":1277,"text":" Hadoop"}]},{"label":["Skills"],"points":[{"start":1041,"end":1056,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":993,"end":998,"text":"Python"}]},{"label":["Education"],"points":[{"start":587,"end":589,"text":"B.E"}]},{"label":["Skills"],"points":[{"start":499,"end":514,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":484,"end":496,"text":"Data Analysis"}]},{"label":["Skills"],"points":[{"start":476,"end":481,"text":"Python"}]},{"label":["Skills"],"points":[{"start":461,"end":473,"text":"R Programming"}]},{"label":["Skills"],"points":[{"start":420,"end":422,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":417,"end":422,"text":"PL/SQL"}]},{"label":["Skills"],"points":[{"start":412,"end":414,"text":"SQL"}]},{"label":["Name"],"points":[{"start":0,"end":17,"text":"Saranya Govindaraj"}]}],"extras":null,"metadata":{"first_done_at":1532691970000,"last_updated_at":1532691970000,"sec_taken":146,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Satish Chappa chappasatish@yahoo.com     \nData Scientist               Contact No: +91 -9543544236\n\nExperience Profile\n\n• Satish has 6.7 years of experience in Software Application, Data Management, Predictive \nModelling and Quantitative Data Analysis.  \n\n• Intensive hands-on experience on Data analytics. Technical skills spanning from statistics to \nprogramming including data engineering, data visualization, machine learning and \nProgramming in R and python.\n\n• Leads and conducts analytics projects, providing detailed analysis, both written and verbal, \nof marketing initiatives.\n\n• Uses client ticket dump to analyze the frequency of tickets, Seasonality, SLA impact, \nApplication criticality for RFP proposal.\n\n• Evaluates new business tools, techniques and processes for incorporation into company and \ndepartment best practices.\n\n• Developed and deployed Analytic solutions that would highlight potential cost saving areas\nfor various accounts in the organization. \n\n• Collaborated closely with different business teams on deal winning RFPs. Efficiently worked \nwith Text mining techniques which would identify the areas of improvement.\n\nTechnical Exposures\n\n Machine Learning : Regression, Classification, Decision tress, Random forest,\n       NLP (Text mining), PCA, MCA, KNN, SVM, k-means clustering, \n       Time series, Market Basket Analysis, Web scraping. \n\n Statistical Package : R Programming, Python and SAS Basics\n Database : DB2,Oracle\n Visualization : ggplot2\n Languages : COBOL, JCL, Java\n\nProfessional Experience\n\nSep 2010– Apr 2014\nSoftware Engineer, Steria India Ltd, Chennai\n\nApr 2014– Till date\nAssociate, Cognizant Technology Ltd, Coimbatore\n\nTechnical Experience Summary in Data Science\n\nCognizant Technology Solutions (Apr 2014 – Till Date)\nModel: left Shift Solution\n\n• Left Shift model performs extensive text processing on a list of patterns in the data dump \nproviding a wide spectrum of left shift opportunities in various output views.\n\n• The analytical solution can be leveraged to improve the Mean Time To Resolve (MTTR) \nparticular pattern of tickets and also to reduce the variation in effort to resolve particular \npattern of tickets.\n\n• The solution also provides the user to point to the “Effort” field in the input data extract \nwhich will be used by the solution to arrive at a Box-plot. \n\n• Box-plot output against the “Resolution Time” in the input data extract, providing the “Mean-\nTime-To-Resolve” analysis output for the top-k patterns identified.\n\n1\n\n\n\nSatish Chappa chappasatish@yahoo.com     \nData Scientist               Contact No: +91 -9543544236\n\nModel: Debt Classification\n\n• The Debt Classification solution is a machine learning technique which aims at classifying the \nDebt category of a ticket dump based on manual classification. It also projects whether a \nticket is avoidable or not.\n\n• The solution works by studying the rules of the manual classification done and then \nincorporating the rules to classify the Debt category of the prediction dataset.\n\nModel: Volumetric Analysis\n\n• Volumetric Analysis to analyze client data dumps and identifying the best and worst \nperforming areas.\n\n• Volumetric Analysis model performs analysis and provides graphical representation of \nvarious parameters that defines a ticket like Monthly ticket count, Application wise split up of \ntickets.\n\nModel: Influx Reduction and Automation\n\n• Influx Reduction Opportunity” identifying solution provides a perspective to any user by \nanalyzing their data dumps using a text mining algorithm, N-gram. \n\n• The model performs extensive text processing on a list of identified patterns in the data \ndump providing a wide spectrum of influx reduction opportunities in 2 output views.\n\n• The solution also provides the user to point to a “Classifier” field against which the top-k \npatterns can be associated to project a heat-map view based on a co-relation ratio.\n\n• Automation model performs extensive text processing on the highly occurring list of patterns \nin the data dump providing a wide spectrum of automation opportunities in 3 output views \n(Uni, Bi and Tri gram).\n\n• Technical Experience Summary in Mainframe\n\nSteria India Ltd (Sep 2010 – Apr 2014)\nProject      :  TESCO   -  Tesco is  a supermarket chain. It started in the United Kingdom, and are \ncurrently based there.  Tesco Operations in UK are the largest within the Group, with over \n3500 stores and over 310,000 colleagues it now has supermarkets in other countries around \nthe world. Tesco sells thousands of products. Tesco originally only sold food, but it now sells \nother things like mobile phones, DVDs and videos, clothing, and books. It is also an Internet \nService Provider in the United Kingdom.  Tesco is  the biggest supermarket in the UK and \nIreland and also is the third largest retailer in the world. Tesco is also a PLC, a public limited \ncompany. Tesco is the biggest supermarket in the UK and Ireland and also is the third largest retailer in \nthe world. \nRoles and Responsibility:\n• Analysis and implementation of the project involving design, unit test case preparation \nand code development.\n\n• Prepare the UTP and UTR documents for client reference and review.\n• Develop and enhance the JCL jobs and PROCs as per the design requirements.\n\n2\n\n\n\nSatish Chappa chappasatish@yahoo.com     \nData Scientist               Contact No: +91 -9543544236\n\n• Worked on most of the scenarios and issues, if any persists, during the testing phase in \norder to avoid any glitches during the Optest and Live releases.\n\n• Provide the system testing support during the product release.                                                \nAcademic Profile\n\n• Master’s Degree in Computers in Andhra University, Visakhapatnam\n\n3\n\n\n\tExperience Profile\n\tTechnical Exposures\n\tProfessional Experience\n\tTechnical Experience Summary in Data Science\n\tTechnical Experience Summary in Mainframe\n\tAcademic Profile","annotation":[{"label":["Education"],"points":[{"start":5680,"end":5694,"text":"Master’s Degree"}]},{"label":["Name"],"points":[{"start":5289,"end":5301,"text":"Satish Chappa"}]},{"label":["Skills"],"points":[{"start":5246,"end":5246,"text":"R"}]},{"label":["Skills"],"points":[{"start":5232,"end":5234,"text":"JCL"}]},{"label":["Skills"],"points":[{"start":5161,"end":5161,"text":"R"}]},{"label":["Skills"],"points":[{"start":5007,"end":5007,"text":"R"}]},{"label":["Skills"],"points":[{"start":4997,"end":4997,"text":"R"}]},{"label":["Skills"],"points":[{"start":3407,"end":3407,"text":"R"}]},{"label":["Skills"],"points":[{"start":3372,"end":3372,"text":"R"}]},{"label":["Name"],"points":[{"start":2513,"end":2525,"text":"Satish Chappa"}]},{"label":["Skills"],"points":[{"start":2447,"end":2447,"text":"R"}]},{"label":["Skills"],"points":[{"start":2374,"end":2374,"text":"R"}]},{"label":["Skills"],"points":[{"start":2064,"end":2064,"text":"R"}]},{"label":["Skills"],"points":[{"start":2052,"end":2052,"text":"R"}]},{"label":["Skills"],"points":[{"start":1514,"end":1517,"text":"Java"}]},{"label":["Skills"],"points":[{"start":1509,"end":1511,"text":"JCL"}]},{"label":["Skills"],"points":[{"start":1502,"end":1506,"text":"COBOL"}]},{"label":["Skills"],"points":[{"start":1401,"end":1401,"text":"R"}]},{"label":["Skills"],"points":[{"start":1235,"end":1235,"text":"R"}]},{"label":["Skills"],"points":[{"start":1191,"end":1191,"text":"R"}]},{"label":["Skills"],"points":[{"start":1047,"end":1047,"text":"R"}]},{"label":["Skills"],"points":[{"start":705,"end":705,"text":"R"}]},{"label":["Skills"],"points":[{"start":456,"end":461,"text":"python"}]},{"label":["Skills"],"points":[{"start":450,"end":450,"text":"R"}]},{"label":["Name"],"points":[{"start":0,"end":12,"text":"Satish Chappa"}]}],"extras":null,"metadata":{"first_done_at":1532683115000,"last_updated_at":1532683115000,"sec_taken":147,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Mr Satyasarathi Behera, \nTechnical Lead \nE-mail: Satyasarathi1985@gmail.com\nMob # 8553998817\nSummary of Qualifications (Knowledge & Skill Areas)\n· Working with HARMAN Connected Services since October 2010.\n· Over 9+ years of experience in IT industry as Python and Perl Developer in System Analysis, Design, Development & Implementation of various Client/Server, Web-based applications. \n· Developing python scripts for automation tests on the core API's as per the user stories provided by the client. \n· Good working knowledge of Python, Django, Pl/SQL, Perl, Catalyst, UNIX, Shell scripting.\n· Thorough knowledge of Object Oriented Analysis and Design.\n· Developing python and Perl scripts for Automation tests on the core API's as per user stories provided by the client. \n· Extensive work experience in MVC frame work like Django ,GI::Application, Catalyst.\n· Good exposure to Object Oriented Python and Perl (Moose).\n· Experienced in writing Unit test and code coverage using Python and perl.\n· Experienced in effective usage of standard Perl libraries and writing different Python modules.\n· Well versed in generating Scripts for Data Driven tests using Perl testing modules.\n· Strong development skill on T-SQL-Function, Procedures, Packages, Triggers.\n· Experienced in developing Client-server & Enterprise Applications.\n· Developed automated UNIX Shell scripts and Perl scripts for production support.\n· Well versed in writing Unit test cases and performing Integration testing of developed modules.\n· Sound knowledge of Installing, Configuring and Maintaining Linux, Apache server, MySQL and Perl modules.\n· Knowledge of different flavors of UNIX & Linux Like– HP-UX and Red hat Linux.\n· Good exposure to all phases of a Software development life cycle.\n· Quick learner & have an ability to apply new tools & technologies accurately.\n\n\nProject Experience & Customer Information:\n\n\t\n\nProject name: CAS School pages\n\tHarman Connected Services\n\n\tRole \n\tTechnical Lead - (Python Developer)\n\n\tProject Summary\n\tLiaison International’s (School Pages) provides below facilities   to Program directors  for publishing program details in CAS school pages.\n·  Log-in using the admin login\n· Click on the Manage Surveys tab to access the scaffold which will be used to create your new survey.\n· Click on new survey link.\n· Enter the name of your survey, some instructions if any then click create. You'll see your survey listed along with the others.\nWe now need to add all relevant data to your survey, beginning with the sections. Each section consists of a name, some attributes and questions. Each question consists of question text, some attributes as well as fields. Each field in turn has a label while others may also have constraints. Input all this data which should be clearly stipulated in the specification document the BA responsible for your survey has provided you.\nOnce the data entry part is complete, you now have a skeleton of your survey up. Go back to the survey listing page by clicking the Manage Surveys tab, or by appending your URL as such, 'prefix:port/manager/surveys', then clicking on your newly created survey. You should now be able to access your survey. You will notice though that aside from the 'School Directory' label at top of the page, the page is empty. We need to add a listing of schools and programs that will participate in your survey. And they are two ways of doing this; manually, directly to the database or by using the management tools of the survey.\n\n\tClient\n\tLiaison International, Boston, USA\n\n\tSkills\n\tPython, Django, Unix, PostgreSQL, Shell Scripting\n\n\tTools\n\tJira, GIT(Version control)\n\n\tResponsibilities  \n\n\t· Responsible for gathering requirements, system analysis, design, development and deployment.\n· Developed Views and Templates with Python and using Django's view controller and template language, Website interface is created. \n· Developed a Python/Django based web application using Python scripting for data processing,\n· Implemented RESTful Web Services for the data transportation between multiple systems\n· Followed PEP-8 Standards & used SONAR for writing quality code. \n· Write python script for APIs to dump the  data structures to process detect the   failure point for debugging. \n· Developed API modularizing existing python module with the help of pyyaml libraries which is an YAML parser and emitter for Python\n\n\n\n\n\n\n\t\n\nProject name: Centralized Application Services\n\tHarman Connected Services\n\n\tRole \n\tTechnical Lead - (Perl Developer)\n\n\tProject Summary\n\tLiaison Internationl’s CAS application is a web-based application system that allows students to apply to multiple participating Medical higher Educational programs with a single online application. This application also facilitates a streamlined admissions process for programs.\nThe business model also provides a new, state of the art application platform with enhanced design and user experience.\nIt also provides an efficient process to apply to programs using any device. \n\n\tClient\n\tLiaison International, Boston, USA\n\n\tSkills\n\tPerl, Unix, T-SQL, Shell Scripting\n\n\tTools\n\tJira, GIT(Version control)\n\n\tResponsibilities  \n\n\t· Responsible for gathering requirements, system analysis, design, development and deployment.\n· Developing web applications using Perl/CGI::Application \n· Coding and bug fixing of the application.\n· Preparing Design document for any major Enhancements.\n· Writing unit test cases and code coverage for the Application.\n· Performing code reviews.\n· Writing different Perl scripts for various kinds of reports for the application.\n· Design different database models for the applications.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\t\n\nProject name: TheBizmo \n\tWortal Technologies\n\n\tRole \n\tSoftware engineer  - (Perl development)\n\n\tProject Summary\n\tThebizmo music business gives us a great cross section of music genres for a great music experience.\nthebizmo was built by musicians for musicians. It is a shot at leveling the playing field for everyone both big and small.\nthebizmo is an Instant free opportunity to get your wares to market. No need to pay anyone anything. Just set up your store and start selling  The software team that conceptualized and built one of the world’s first digital download services and then moved on to build the world’s largest mobile music service Groove-mobile. This experience made the client realize what the next generation of the music business needed was a 360 degree micro store to sell and market everything music — so they built thebizmo.\n\n\tClient\n\tThebizmo\n\n\tSkills\n\tPerl, Catalyst, MySQL, Unix shell scripting \n\n\tTools\n\tSVN, Trac.\t\n\n\tResponsibilities  \n\n\t· Developing web applications of Thebizmo using Perl, Perl catalyst.\n· Coding and bug fixing of the application.\n· Design different database models for the applications.\n· Debugging & resolving problems reported by customer.\n· Design Admin interface for the application for user management.\n· Writing Perl automation script for automation testing.\n· Writing different Perl scripts for various kinds of reports for the application. \n· Installing, Configuring and Maintaining Linux, Apache, MySQL and Perl modules.\n· Gathering the functional requirements and understand the low-level design.\n· Writing JavaScript to validate different html form.\n· Using standard   Perl libraries and writing different Perl modules.\n· Creating the data base tables and manipulating them using SQL queries.\n· Monitoring the error log file.\n\n\n\t\n\nProject name: BIMS\n\tWortal Technologies\n\n\tRole \n\tSoftware engineer  \n\n\tProject Summary\n\tTexas Instruments – BIMS (Bonded Item Management system) supports the potential of a customs inspection. All bonded items should be tracked to an owner and location. This requires that there is a system available to provide owner and location information for all bonded items. The current system, addresses the customs reporting components of bonded items. This project covers the development of an application that supports the following aspects of bonded items:\n· Provides a register of all bonded items & capture information associated with them.\n· A System to track bonded items.\n· Management reporting, audit reporting, location reporting, End-user reporting.\n· Provides a tool for the end user to request transfer of a bonded item from one individual to another.\n· Push-reports to cost center mangers.\n\n\n\tClient\n\tTexas Instruments \n\n\tSkills\n\tPerl ,CGI, Java script\n\n\tTools\n\tSVN, Trac\n\n\tResponsibilities  \n\n\t· Developing client-server applications of BIMS using Perl, CGI Java script.\n· Coding and bug fixing of the applications.\n· Executing Admin DB lock script for database access management.\n· Helping Admin for writing various shell and Perl scripts.\n· Debugging & resolving problems reported by Customer.\n· Installing, Configuring and Maintaining Linux, Apache, MySQL and Perl modules.\n· Gathering the functional requirements and understand the low-level design.\n· Writing JavaScript to validate different html forms.\n· Generate Automation test script using Perl-testing modules\n\n\n\n\n\nProfessional Experience\n· Harman Connected Services\t\t\t\t\tOct 2010 to Current date\nA leading IT company specializing in the areas of Cloud, Mobile, and Analytics Capabilities amongst other latest trending technologies.\nPosition: Technical Lead\nRole: Perl developer, Code review, preparing Design document.\n\n· Wortal Technologies  \t\t\t\t\t\t   Feb 2009 to OCT-2010\nServices based Company headquartered in Bangalore India\nPosition: Software Engineer.\nRole: Perl Developer. \n\nEducation\nCompleted B.SC. (IT major elective) from Fakir Mohan university  \t\t\t\t\t             \nAdvanced Training/Certification Details\nPython/Django @Harman\nAwards and Recognitions\n· Received Harman – “Hall of fame” award from the Project Manager for efficient contribution towards Liaison’s Metrics.\n· Received Harman “Going Extra Mile” award four times for my contribution to the Liaison account.\n· Received ‘Best Delivery Team’ award at Wortal Technology for Thebizmo account.","annotation":[{"label":["Skills"],"points":[{"start":9644,"end":9649,"text":"Django"}]},{"label":["Primary skill"],"points":[{"start":9637,"end":9642,"text":"Python"}]},{"label":["Primary skill"],"points":[{"start":9485,"end":9488,"text":"Perl"}]},{"label":["Primary skill"],"points":[{"start":9284,"end":9287,"text":"Perl"}]},{"label":["Primary skill"],"points":[{"start":9010,"end":9013,"text":"Perl"}]},{"label":["Primary skill"],"points":[{"start":8824,"end":8827,"text":"Perl"}]},{"label":["Skills"],"points":[{"start":8814,"end":8818,"text":"MySQL"}]},{"label":["Primary skill"],"points":[{"start":8688,"end":8691,"text":"Perl"}]},{"label":["Primary skill"],"points":[{"start":8509,"end":8512,"text":"Perl"}]},{"label":["Primary skill"],"points":[{"start":8390,"end":8393,"text":"Perl"}]},{"label":["Primary skill"],"points":[{"start":7329,"end":7332,"text":"Perl"}]},{"label":["Primary skill"],"points":[{"start":7292,"end":7295,"text":"Perl"}]},{"label":["Primary skill"],"points":[{"start":7128,"end":7131,"text":"Perl"}]},{"label":["Skills"],"points":[{"start":7118,"end":7122,"text":"MySQL"}]},{"label":["Primary skill"],"points":[{"start":6997,"end":7000,"text":"Perl"}]},{"label":["Primary skill"],"points":[{"start":6930,"end":6933,"text":"Perl"}]},{"label":["Primary skill"],"points":[{"start":6683,"end":6686,"text":"Perl"}]},{"label":["Primary skill"],"points":[{"start":6677,"end":6680,"text":"Perl"}]},{"label":["Skills"],"points":[{"start":6556,"end":6560,"text":"MySQL"}]},{"label":["Skills"],"points":[{"start":6546,"end":6553,"text":"Catalyst"}]},{"label":["Primary skill"],"points":[{"start":6540,"end":6543,"text":"Perl"}]},{"label":["Primary skill"],"points":[{"start":5740,"end":5743,"text":"Perl"}]},{"label":["Primary skill"],"points":[{"start":5528,"end":5531,"text":"Perl"}]},{"label":["Primary skill"],"points":[{"start":5293,"end":5296,"text":"Perl"}]},{"label":["Primary skill"],"points":[{"start":5068,"end":5071,"text":"Perl"}]},{"label":["Primary skill"],"points":[{"start":4500,"end":4503,"text":"Perl"}]},{"label":["Primary skill"],"points":[{"start":4383,"end":4388,"text":"Python"}]},{"label":["Primary skill"],"points":[{"start":3950,"end":3955,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3915,"end":3920,"text":"Django"}]},{"label":["Primary skill"],"points":[{"start":3908,"end":3913,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3815,"end":3820,"text":"Django"}]},{"label":["Primary skill"],"points":[{"start":3798,"end":3803,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3565,"end":3570,"text":"Django"}]},{"label":["Primary skill"],"points":[{"start":3557,"end":3562,"text":"Python"}]},{"label":["Primary skill"],"points":[{"start":1979,"end":1984,"text":"Python"}]},{"label":["Name"],"points":[{"start":1653,"end":1656,"text":"UNIX"}]},{"label":["Primary skill"],"points":[{"start":1603,"end":1606,"text":"Perl"}]},{"label":["Skills"],"points":[{"start":1593,"end":1597,"text":"MySQL"}]},{"label":["Primary skill"],"points":[{"start":1375,"end":1378,"text":"Perl"}]},{"label":["Name"],"points":[{"start":1352,"end":1355,"text":"UNIX"}]},{"label":["Primary skill"],"points":[{"start":1161,"end":1164,"text":"Perl"}]},{"label":["Primary skill"],"points":[{"start":1081,"end":1086,"text":"Python"}]},{"label":["Primary skill"],"points":[{"start":1044,"end":1047,"text":"Perl"}]},{"label":["Primary skill"],"points":[{"start":982,"end":987,"text":"Python"}]},{"label":["Primary skill"],"points":[{"start":909,"end":912,"text":"Perl"}]},{"label":["Primary skill"],"points":[{"start":898,"end":903,"text":"Python"}]},{"label":["Skills"],"points":[{"start":853,"end":860,"text":"Catalyst"}]},{"label":["Skills"],"points":[{"start":828,"end":833,"text":"Django"}]},{"label":["Primary skill"],"points":[{"start":680,"end":683,"text":"Perl"}]},{"label":["Skills"],"points":[{"start":578,"end":592,"text":"Shell scripting"}]},{"label":["Skills"],"points":[{"start":572,"end":575,"text":"UNIX"}]},{"label":["Skills"],"points":[{"start":562,"end":569,"text":"Catalyst"}]},{"label":["Primary skill"],"points":[{"start":556,"end":559,"text":"Perl"}]},{"label":["Skills"],"points":[{"start":548,"end":553,"text":"Pl/SQL"}]},{"label":["Skills"],"points":[{"start":540,"end":545,"text":"Django"}]},{"label":["Primary skill"],"points":[{"start":532,"end":537,"text":"Python"}]},{"label":["Primary skill"],"points":[{"start":265,"end":268,"text":"Perl"}]},{"label":["Primary skill"],"points":[{"start":254,"end":259,"text":"Python"}]},{"label":["Name"],"points":[{"start":3,"end":21,"text":"Satyasarathi Behera"}]}],"extras":null,"metadata":{"first_done_at":1532627988000,"last_updated_at":1532627988000,"sec_taken":0,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Udaya Laxmi Ch\n\nEmail : laxmi.udaya@gmail.com\n\n\t\n\n\tPhone: -9740606990\n\t\n\n\n\tSummary\n\n\t· 9.5 years of experience in Software Development.\n· 3.5 years of experience in Machine Learning\n· Primary Skills – Machine Learning, R programming, Lotus Notes.\n· Presently working for Wipro Technologies, Bangalore.\n· Experience in planning, estimation, design, development, and testing object oriented applications.\n· Experience in preparing various technical documents like Functional Specs, HLD, LLD, Flowcharts and Test cases.\n· Sound Knowledge in Object Oriented Design Principles\n· Have Team Handling experience.\n· Domain experience of Manufacturing and Finance.\n· Have Experience in Scrum Agile Model\n· Understand business requirements from clients\n\n\n\n\tTechnical Skills\n\n\tKey skills: \n\tMachine Learning,R Programming, MySQL, PostgreSQL, Microsoft Access, SQL Server, FileMaker, Oracle, RDBMS, dBASE, Clipper, FoxPro, Firebase, Mongodb, Python,  ava, J2EE, Oracle Fusion,Oracle Cloud, Salesforce, Devops Android, Business Analyst, UI Developer, DBAs, Embedded Systems, .NET, Hadoop, SQL Developer, Big Data, Tableau, Networking, Etl, Informatica, Ios, Quality Analyst, Project Manager, Python, Data Science, Python, Machine Learning, SAS, Java, Scala, Hadoop, Hive, Bigdata, Programming, SQL server reporting, Msbi Ssis, Ssrs, Msbi, Sql Reporting, Artificial Intelligence, Pandas, Pyspark, Sklearn, Flask, Django, Map Reduce, Parametric Design, Modeling, Regression, Patterns, Data Mining, Text Mining, Oops, Deep Learning, Web Analytics, Time Series, Regression, Tensorflow, Azure, Linear Regression, Logistic Regression, Decision Tree, Random Forest, Data Structure, Computer Vision, IHS, WAS, Java EE, SQL Server, .NET core, C#, ASP.NET, Rdlc, Linq, Sql, Web Api, Mvc, Javascript, Web Services, Oracle, MS SQL, PHP, Laravel, CodeIgniter, Symfony, Zend, Phalcon, CakePHP, Yii, FuelPHP, React, Vue, Angular, Ember, Backbone, Lotus Notes\n\n\tAlgorithms:\n\tNaïve Bayes, K means clustering,Word Cloud\n\n\tDatabases: \n\tMicrosoft SQL, Mongo DB\n\n\tWeb Technologies: \n\tXML, XSLT, HTML,  JavaScript,  AJAX, JQuery\n\n\tIDE:\n\tR studio,Pycharm\n\n\n\tProfessional Experience\n\n\tCurrent Employer :\n\tWipro Technologies., Bangalore  – (Oct  2010  to till date) – Technical Lead/Data Scientist\n\n\tPrevious Employers :\n\tHSBC Software development , Hyderabad (June  2008  to Sep 2010)  - SE\n\n\n\tQualification\n\n\tDegree\n\tCollege\n\tUniversity/Board\n\tYear\n\tPercentage (%)\n\n\tMCA\n\tNizam College, Basheerbagh,Hyderabad\n\tOsmania University\n\t2008\n\t75\n\n\n\tProject Experience \n\n\tProject 1 : Exploratory Data Analysis:\n\nProject Description:   Performed EDA analysis to analyze the Purchase frequency of vehicles which occurred over past 3 years and try to predict the frequency occurring in the future.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Performed EDA analysis to find the insights of the data. Observed the summary of each and every variable to understand the variables.\n\n· Performed the feature selection using hypothesis testing.\n\n· Identified the outliers using box plot.\n\n· Identified the trend in the purchases using histogram.\n\n\n\n\tProject 2: Word Cloud Analysis:\n\nProject Description:   Performed Word cloud and Sentimental Analysis of the customer feedbacks. Graphically represented the most frequently occurred words through Word cloud. Through sentimental analysis we identified whether a user-generated text expresses positive, negative or neutral opinion.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Created a Corpus using TM package and performed pre-processing of data.\n\n· Removed the punctuations, stemming and stop words which are of no analytical value.\n\n· Built a Document term matrix and identified the most frequently occurring words\n\n· Graphically represented it using  RColorbrewer Package\n\n\n\tProject 3: Sentimental Analysis:\n\nProject Description: Performed Sentimental Analysis of customer feedbacks through Naïve Bayes. Used “e1071” Package for implementing naïve Bayes method.\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· The DTM created using TM package was an input to the Naive Bayes Model.\n\n· As Naive Bayes classifier is typically trained on data with categorical features. We have converted the count of the words into a factor variable that indicates Yes or No whether the word is present or not.\n\n\tProject 4: Clustering Analysis:\n\nProject Description: Classified the customers on the basis of their purchases whether they have purchased low variant or high variant trucks. It in turn helped in building the right customer strategies.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Performed data preparation and Normalization of data using min-max method.\n\n· As K-means algorithm groups a dataset into a user-specified number (k) of clusters. Identified the initial cluster centroids as 3.\n\n· K clusters are creating by associating every observation with the nearest mean.\n\n· Used elbow method to validate the number of clusters such that within-cluster sum of square(wss) is minimized.\n\n\n\n\tProject 5 : Inter Connection Management Tool\nProject Description: Inter-connection Management (IMT) is prototype being developed for Engineering and Sales department to handle customizations of an existing product based on the customer's requirement. Users from engineering department will identify the items, which need to be customized out of the entire product design.\nRole\n\n       : Module Lead\n\nEnvironment\n       : Python, Mongo DB, jQuery\n\nTasks handled:\n\n· Gathering Requirements and providing Project Plan and Effort Estimation details.\n\n· Understanding business requirements and preparing SoU (Statement of Understanding) and Functional/Technical Specification documents.\n\n· Providing Effort & Resource estimations\n\n· Planning for application development and deployment\n\n· Writing and executing Test Cases and Test scenarios\n\n· Creating design elements using Technical Specification.\n\n· Performing Unit testing & Peer Reviews\n\n· Work Allocation and mentoring the team\n\n· Providing Technical guidance to the team. \n\n\tProject 6\n: cvdAEI Application\n\nProject Description\n     : CVDAEI is a web based multilingual application developed for handling the Change Management process in Truck division of Daimler. The change request flows through different phases mainly Initialization, Evaluation, Decision and Conclusion. This application has a configurable workflow where the request flow and the responsible persons can be configured easily at any point of time. \n\nRole\n\n    : Developer/Tester\n\nEnvironment\n     : Lotus Notes, Java, HTML, XML, Java Script, JQuery\n\nTasks handled:\n\n· Gathering Requirements and providing Project Plan and Effort Estimation details.\n\n· Understanding business requirements and preparing SoU (Statement of Understanding) and Functional/Technical Specification documents.\n\n· Providing Effort & Resource estimations\n\n· Planning for application development and deployment\n\n· Writing and executing Test Cases and Test scenarios\n\n· Creating design elements using Technical Specification.\n\n· Performing Unit testing & Peer Reviews\n\n· Work Allocation and mentoring the team\n\n· Providing Technical guidance to the team. \n\n\n\n\tProject Title: Project Management Office \nProject Description: The purpose of this system is to enable the Project Management Office to manage and execute the IT Applications and Operations driven project tasks in  more systematic manner. It will also enable them to efficiently perform a role as a facilitator to coordinate various IT Operations teams and to ensure that project activity enters the department through one common interface. The project tasks will subsequently be dealt with in a common format and in a consistent and appropriate manner, ensuring open and regular communication between all involved parties.\n\nRole\n\n    : Developer/Tester\n\nEnvironment\n     : Lotus Notes, Java, HTML, XML, Java Script, JQuery\n\nTasks Handled :\n\n· Writing and Executing Test cases in client server based environment\n· Individually provided application support","annotation":[{"label":["Skills"],"points":[{"start":7951,"end":7956,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":7938,"end":7948,"text":"Java Script"}]},{"label":["Skills"],"points":[{"start":7933,"end":7935,"text":"XML"}]},{"label":["Skills"],"points":[{"start":7927,"end":7930,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":7921,"end":7924,"text":"Java"}]},{"label":["Skills"],"points":[{"start":7908,"end":7918,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":6645,"end":6650,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":6632,"end":6642,"text":"Java Script"}]},{"label":["Skills"],"points":[{"start":6627,"end":6629,"text":"XML"}]},{"label":["Skills"],"points":[{"start":6621,"end":6624,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":6615,"end":6618,"text":"Java"}]},{"label":["Skills"],"points":[{"start":6602,"end":6612,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":5522,"end":5527,"text":"jQuery"}]},{"label":["Skills"],"points":[{"start":5512,"end":5519,"text":"Mongo DB"}]},{"label":["Skills"],"points":[{"start":5504,"end":5509,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4645,"end":4652,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":4054,"end":4061,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":3941,"end":3951,"text":"Naïve Bayes"}]},{"label":["Skills"],"points":[{"start":3494,"end":3501,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":3132,"end":3141,"text":"Word Cloud"}]},{"label":["Skills"],"points":[{"start":2793,"end":2800,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":2110,"end":2116,"text":"Pycharm"}]},{"label":["Skills"],"points":[{"start":2101,"end":2108,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":2086,"end":2091,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":2080,"end":2083,"text":"AJAX"}]},{"label":["Skills"],"points":[{"start":2067,"end":2076,"text":"JavaScript"}]},{"label":["Skills"],"points":[{"start":2060,"end":2063,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":2054,"end":2057,"text":"XSLT"}]},{"label":["Skills"],"points":[{"start":2049,"end":2051,"text":"XML"}]},{"label":["Skills"],"points":[{"start":2018,"end":2025,"text":"Mongo DB"}]},{"label":["Skills"],"points":[{"start":2003,"end":2015,"text":"Microsoft SQL"}]},{"label":["Skills"],"points":[{"start":1977,"end":1986,"text":"Word Cloud"}]},{"label":["Skills"],"points":[{"start":1958,"end":1975,"text":"K means clustering"}]},{"label":["Skills"],"points":[{"start":1945,"end":1955,"text":"Naïve Bayes"}]},{"label":["Skills"],"points":[{"start":1918,"end":1928,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":1908,"end":1915,"text":"Backbone"}]},{"label":["Skills"],"points":[{"start":1901,"end":1905,"text":"Ember"}]},{"label":["Skills"],"points":[{"start":1892,"end":1898,"text":"Angular"}]},{"label":["Skills"],"points":[{"start":1887,"end":1889,"text":"Vue"}]},{"label":["Skills"],"points":[{"start":1880,"end":1884,"text":"React"}]},{"label":["Skills"],"points":[{"start":1871,"end":1877,"text":"FuelPHP"}]},{"label":["Skills"],"points":[{"start":1866,"end":1868,"text":"Yii"}]},{"label":["Skills"],"points":[{"start":1857,"end":1863,"text":"CakePHP"}]},{"label":["Skills"],"points":[{"start":1848,"end":1854,"text":"Phalcon"}]},{"label":["Skills"],"points":[{"start":1842,"end":1845,"text":"Zend"}]},{"label":["Skills"],"points":[{"start":1833,"end":1839,"text":"Symfony"}]},{"label":["Skills"],"points":[{"start":1820,"end":1830,"text":"CodeIgniter"}]},{"label":["Skills"],"points":[{"start":1811,"end":1817,"text":"Laravel"}]},{"label":["Skills"],"points":[{"start":1806,"end":1808,"text":"PHP"}]},{"label":["Skills"],"points":[{"start":1798,"end":1803,"text":"MS SQL"}]},{"label":["Skills"],"points":[{"start":1790,"end":1795,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":1776,"end":1787,"text":"Web Services"}]},{"label":["Skills"],"points":[{"start":1764,"end":1773,"text":"Javascript"}]},{"label":["Skills"],"points":[{"start":1759,"end":1761,"text":"Mvc"}]},{"label":["Skills"],"points":[{"start":1750,"end":1756,"text":"Web Api"}]},{"label":["Skills"],"points":[{"start":1745,"end":1747,"text":"Sql"}]},{"label":["Skills"],"points":[{"start":1739,"end":1742,"text":"Linq"}]},{"label":["Skills"],"points":[{"start":1733,"end":1736,"text":"Rdlc"}]},{"label":["Skills"],"points":[{"start":1724,"end":1730,"text":"ASP.NET"}]},{"label":["Skills"],"points":[{"start":1720,"end":1721,"text":"C#"}]},{"label":["Skills"],"points":[{"start":1709,"end":1717,"text":".NET core"}]},{"label":["Skills"],"points":[{"start":1697,"end":1706,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":1688,"end":1694,"text":"Java EE"}]},{"label":["Skills"],"points":[{"start":1683,"end":1685,"text":"WAS"}]},{"label":["Skills"],"points":[{"start":1678,"end":1680,"text":"IHS"}]},{"label":["Skills"],"points":[{"start":1661,"end":1675,"text":"Computer Vision"}]},{"label":["Skills"],"points":[{"start":1645,"end":1658,"text":"Data Structure"}]},{"label":["Skills"],"points":[{"start":1630,"end":1642,"text":"Random Forest"}]},{"label":["Skills"],"points":[{"start":1615,"end":1627,"text":"Decision Tree"}]},{"label":["Skills"],"points":[{"start":1594,"end":1612,"text":"Logistic Regression"}]},{"label":["Skills"],"points":[{"start":1575,"end":1591,"text":"Linear Regression"}]},{"label":["Skills"],"points":[{"start":1568,"end":1572,"text":"Azure"}]},{"label":["Skills"],"points":[{"start":1556,"end":1565,"text":"Tensorflow"}]},{"label":["Skills"],"points":[{"start":1544,"end":1553,"text":"Regression"}]},{"label":["Skills"],"points":[{"start":1531,"end":1541,"text":"Time Series"}]},{"label":["Skills"],"points":[{"start":1516,"end":1528,"text":"Web Analytics"}]},{"label":["Skills"],"points":[{"start":1501,"end":1513,"text":"Deep Learning"}]},{"label":["Skills"],"points":[{"start":1495,"end":1498,"text":"Oops"}]},{"label":["Skills"],"points":[{"start":1482,"end":1492,"text":"Text Mining"}]},{"label":["Skills"],"points":[{"start":1469,"end":1479,"text":"Data Mining"}]},{"label":["Skills"],"points":[{"start":1459,"end":1466,"text":"Patterns"}]},{"label":["Skills"],"points":[{"start":1447,"end":1456,"text":"Regression"}]},{"label":["Skills"],"points":[{"start":1437,"end":1444,"text":"Modeling"}]},{"label":["Skills"],"points":[{"start":1418,"end":1434,"text":"Parametric Design"}]},{"label":["Skills"],"points":[{"start":1406,"end":1415,"text":"Map Reduce"}]},{"label":["Skills"],"points":[{"start":1398,"end":1403,"text":"Django"}]},{"label":["Skills"],"points":[{"start":1391,"end":1395,"text":"Flask"}]},{"label":["Skills"],"points":[{"start":1382,"end":1388,"text":"Sklearn"}]},{"label":["Skills"],"points":[{"start":1373,"end":1379,"text":"Pyspark"}]},{"label":["Skills"],"points":[{"start":1365,"end":1370,"text":"Pandas"}]},{"label":["Skills"],"points":[{"start":1340,"end":1362,"text":"Artificial Intelligence"}]},{"label":["Skills"],"points":[{"start":1325,"end":1337,"text":"Sql Reporting"}]},{"label":["Skills"],"points":[{"start":1325,"end":1327,"text":"Sql"}]},{"label":["Skills"],"points":[{"start":1319,"end":1322,"text":"Msbi"}]},{"label":["Skills"],"points":[{"start":1313,"end":1316,"text":"Ssrs"}]},{"label":["Skills"],"points":[{"start":1302,"end":1310,"text":"Msbi Ssis"}]},{"label":["Skills"],"points":[{"start":1302,"end":1305,"text":"Msbi"}]},{"label":["Skills"],"points":[{"start":1280,"end":1299,"text":"SQL server reporting"}]},{"label":["Skills"],"points":[{"start":1267,"end":1277,"text":"Programming"}]},{"label":["Skills"],"points":[{"start":1258,"end":1264,"text":"Bigdata"}]},{"label":["Skills"],"points":[{"start":1252,"end":1255,"text":"Hive"}]},{"label":["Skills"],"points":[{"start":1244,"end":1249,"text":"Hadoop"}]},{"label":["Skills"],"points":[{"start":1237,"end":1241,"text":"Scala"}]},{"label":["Skills"],"points":[{"start":1231,"end":1234,"text":"Java"}]},{"label":["Skills"],"points":[{"start":1226,"end":1228,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1208,"end":1223,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1200,"end":1205,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1186,"end":1197,"text":"Data Science"}]},{"label":["Skills"],"points":[{"start":1178,"end":1183,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1161,"end":1175,"text":"Project Manager"}]},{"label":["Skills"],"points":[{"start":1144,"end":1158,"text":"Quality Analyst"}]},{"label":["Skills"],"points":[{"start":1139,"end":1141,"text":"Ios"}]},{"label":["Skills"],"points":[{"start":1126,"end":1136,"text":"Informatica"}]},{"label":["Skills"],"points":[{"start":1121,"end":1123,"text":"Etl"}]},{"label":["Skills"],"points":[{"start":1109,"end":1118,"text":"Networking"}]},{"label":["Skills"],"points":[{"start":1100,"end":1106,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":1090,"end":1097,"text":"Big Data"}]},{"label":["Skills"],"points":[{"start":1075,"end":1087,"text":"SQL Developer"}]},{"label":["Skills"],"points":[{"start":1067,"end":1072,"text":"Hadoop"}]},{"label":["Skills"],"points":[{"start":1061,"end":1064,"text":".NET"}]},{"label":["Skills"],"points":[{"start":1043,"end":1058,"text":"Embedded Systems"}]},{"label":["Skills"],"points":[{"start":1037,"end":1040,"text":"DBAs"}]},{"label":["Skills"],"points":[{"start":1023,"end":1034,"text":"UI Developer"}]},{"label":["Skills"],"points":[{"start":1005,"end":1020,"text":"Business Analyst"}]},{"label":["Skills"],"points":[{"start":989,"end":1002,"text":"Devops Android"}]},{"label":["Skills"],"points":[{"start":977,"end":986,"text":"Salesforce"}]},{"label":["Skills"],"points":[{"start":963,"end":974,"text":"Oracle Cloud"}]},{"label":["Skills"],"points":[{"start":949,"end":961,"text":"Oracle Fusion"}]},{"label":["Skills"],"points":[{"start":943,"end":946,"text":"J2EE"}]},{"label":["Skills"],"points":[{"start":929,"end":934,"text":"Python"}]},{"label":["Skills"],"points":[{"start":920,"end":926,"text":"Mongodb"}]},{"label":["Skills"],"points":[{"start":910,"end":917,"text":"Firebase"}]},{"label":["Skills"],"points":[{"start":902,"end":907,"text":"FoxPro"}]},{"label":["Skills"],"points":[{"start":893,"end":899,"text":"Clipper"}]},{"label":["Skills"],"points":[{"start":886,"end":890,"text":"dBASE"}]},{"label":["Skills"],"points":[{"start":879,"end":883,"text":"RDBMS"}]},{"label":["Skills"],"points":[{"start":871,"end":876,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":860,"end":868,"text":"FileMaker"}]},{"label":["Skills"],"points":[{"start":848,"end":857,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":830,"end":845,"text":"Microsoft Access"}]},{"label":["Skills"],"points":[{"start":818,"end":827,"text":"PostgreSQL"}]},{"label":["Skills"],"points":[{"start":811,"end":815,"text":"MySQL"}]},{"label":["Skills"],"points":[{"start":798,"end":808,"text":"Programming"}]},{"label":["Skills"],"points":[{"start":796,"end":808,"text":"R Programming"}]},{"label":["Skills"],"points":[{"start":779,"end":794,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":234,"end":244,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":219,"end":231,"text":"R programming"}]},{"label":["Skills"],"points":[{"start":201,"end":216,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":165,"end":180,"text":"Machine Learning"}]},{"label":["Name"],"points":[{"start":0,"end":13,"text":"Udaya Laxmi Ch"}]}],"extras":null,"metadata":{"first_done_at":1579625576000,"last_updated_at":1579626369000,"sec_taken":0,"last_updated_by":"aJOmJy1lvpOYFetVNuqLvFo9Vx42","status":"done","evaluation":"NONE"}}
{"content": "Saubhik Kundu \nLinkedIn Link: https://www.linkedin.com/in/saubhik-kundu-22304a58/  \nAccalim Badges: https://www.youracclaim.com/users/saubhik-kundu \n \n\nAddress Email Cell No. \n\n135 R.N. Tagore Road, Dumdum Kolkata, 700077 kundusaubhik007@gmail.com  (+91)9073384251 \n(+91)9475933687 \n\n \n\n \n➢ 4.4 years of experience in JAVA/J2EE development, Test tools and framework development and \n\nAutomation testing. I am experienced in RESTful API, microservice development on cloud and cognitive \nplatform. I am also IBM certified cloud application developer. \n \n\n➢ Given below is brief highlight of my work– \n \n\n✓ Worked extensively with Java from both development and test automation perspective \n✓ Developing RESTful microservices, Openwhisk serverless actions on cloud and cognitive platform \n✓ Developed JAVA based web applications with microservices implementation \n✓ Worked with Bluemix cloud foundry, kuburnetes, Travis CI and Docker \n✓ Responsive web application automation testing with Selenium & Appium in both Desktop and mobile \n✓ Mobile native and web application automation testing with Seetest Automation \n✓ POS (Point of Sale) application automation testing with Eggplant and Sikuli \n✓ Test Automation on cloud platform with Seetest cloud and Saucelabs \n✓ Developed Hybrid Test Automation framework in java  \n✓ Junit, TestNG test script writing using Mockito \n✓ Implemented Continuous Integration with Jenkins, Travis \n✓ Developed many utilities with Macro Programming  \n✓ Performance testing with Jmeter and Blazemeter \n\n \n➢ Given below is brief highlight of overall responsibilities I had– \n\n \n✓ RESTful API, microservices development on cloud and cognitive platform \n✓ Implementation of continuous delivery toolchain for cloud build, deploy and test in Bluemix \n✓ Module level development \n✓ Test automation framework and tools development in JAVA \n✓ Automation test script development and execution \n✓ Test plan and Test strategy preparation \n✓ Team mentoring, status reporting, onsite and client coordination and Documentation \n✓ Giving training on selenium, seetest and core java at BU level at cognizant academy \n✓ Conducting inter project audit for the accounts within same BU (Business unit) \n✓ Performing Technical POCs (Proof of concept) to identify the best suited automation tool for testing \n\nand application security \n✓ Innovation champion of the account and implemented and driven many innovations \n\n \n\n \n➢ Technologies: JAVA/J2EE, Test Automation, Microservice and Restful API development, cloud, cognitive  \n➢ Cloud and cognitive skills: IBM Bluemix cloud, Clouding NoSQL DB, NLP techniques, IBM Watson APIs, IBM \n\nCloud function - Openwhisk, Kuburnetes, Docker, Cloud object storage \n➢ Test tools: Selenium, Appium, Seetest Automation, Eggplant, Sikuli, Saucelabs, SOAP-UI, Jmeter, Blazemeter \n➢ Languages: Java, JAX-RS, swagger, jersey framework, JDBC, servlet, REST, JSON, HTML, CSS, XML, XSLT, SQL \n➢ Scripting Languages: VB Script, Macro programming, Shell scripting, curl, JavaScript, Sensetalk \n➢ Unit test frameworks: Junit, TestNG, Mockito, Jacoco \n➢ Test Management tool: HP Quality Center, Mingle, Bugzilla, Zenhub \n➢ Build Tool: Maven, Ant \n\nProfile Summary \n\nSkill Set \n\nhttps://www.linkedin.com/in/saubhik-kundu-22304a58/\nhttps://www.youracclaim.com/users/saubhik-kundu\nmailto:kundusaubhik007@gmail.com\n\n\n➢ Build Management Tool: Jenkins, Travis \n➢ Source Code version control tool: Git, SVN \n➢ Certifications:  \n\n✓ IBM certified app developer in cloud platform V2 \n✓ ISTQB Foundation level certification in Testing \n✓ Seetest External Certification \n✓ Cognizant Certification in Java, Selenium, Software testing, Agile, T&H L0 and Restaurant L1 \n\n \n\n \n\nCompany Name Job Role Name Tenure Service Line \n\nIBM India Pvt. Ltd. Senior Technical Services \nSpecialist \n\n30th January, 2017 - \nPresent \n\nCloud Business Innovation \nCenter \n\nCognizant Technology \nSolutions \n\nSenior Test Analyst 06th August, 2013 – 27th \nJanuary,2017 \n\nQuality Engineering and \nAssurance \n\n \nExperience Details: \nProject 1: \n\nProject Title  Pearson Cardinal + Revel + Watson (8th February, 2017 to Present) \n\nTools and Languages Java, Microservices, IBM Bluemix cloud, Cloudant NoSQL DB, NLP techniques, \nIBM Watson APIs, JAX-RS, REST, Json, Git, TestNG, JUnit, Mockito, Maven, Travis, \nCloud object storage, Curl, HTML, Javascript, Docker, Kuburbnetes, Openwhisk  \n\n \nPROJECT DESCRIPTION: IBM is developing a Virtual Tutor for college students in partnership with the world’s \nleading online education and publishing company. The tutor uses Watson APIs extensively and we are building the \nproduct as realistic as possible and will assist students with their learning by explaining concepts through natural \nlanguage dialogue  \nROLES AND RESPONSIBILITIES:  \n\n• Development of the entire microservice architecture based test automation framework for end to end \ntesting of Watson cognitive tutor \n\n• Develop tools in java to validate the content package and training – all developed in RESTful microservices \nas Bluemix cloud foundry application or as Openwhisk action \n\n• Microservice development for a key feature of the application, RESTful wrapper APIs for cloudant DB and \nS3 cloud object storage \n\n• Development of customized Integration testing tools in java to test different REST API end points \n\n• Development of automated content ingestion and training pipeline for Watson cognitive tutor using java, \nOpenwhisk and Node-RED flow \n \n\nProject 2: \n\nProject Title  PJI RWD and App Refresh QA (24th November, 2014 to 27th January 2017) \n\nTools and Languages Core Java, Selenium, Eclipse, SEETEST, Appium, VBScript, Oracle SQL developer, \nJenkins, Ant build tool, Saucelabs cloud platform \n\n \nPROJECT DESCRIPTION: Customer wanted to migrate their online Application to Responsive Web Design which \nshould support various resolutions on desktops and other devices like tablets and Mobiles. And customer wanted \nto launch new mobile Apps for iOS. \nROLES AND RESPONSIBILITIES:  \n\n• Develop and customize Test Automation framework for responsive web and Native Application in java \nSelenium and seetest) with support for both desktop and mobile device along with capability of multi-\nthreading, multi-browser execution in any cloud platform \n\n• Integrate the test automation suite with Build management tool Jenkins to achieve CI \n\n• Automation Feasibility analysis, develop test Automation Scripts, Test Automation Execution, Co-\nOrdination with customer and Onshore counterpart, Status Reporting, Module Level Planning, Conducting \nAudits, Preparation of Test Strategy, Test Planning, Test Metrics and Estimations, Managing Team, \npreparing decks and case studies. I was also the idea champion of the account implemented many \ninnovations with macro programming and building tools in java. \n\n \n\nWork Experience \n\n\n\n \n \n \nProject 3: \n\nProject Title  JIB POS Automation POC (1st Sept, 2014 to 24th Nov, 2014) \n\nTools and Languages Sensetalk, Eggplant, SQL server 2008 \n\nPROJECT DESCRIPTION: Customer wanted a robust automation solution for their Xpient POS system and RISC \nsystem. For that they wanted cognizant to suggest an automation tool and prepare a framework with that tool and \nautomate few of their functionalities and deliver the developed framework along with the prepared script. \nROLES AND RESPONSIBILITIES: Responsibilities include identifying the best automation tool for their Xpient POS \nand developing the Automation framework with that tool and deliver Automation Suite to Customer which does \nnot require any manual intervention, setting up the initial project environment, Preparing the Automation POC \nreport and deliver and demonstrate that to the customer, Develop and Peer Review Automation Scripts, Co-\nOrdination with customer, Status Reporting. \n \nProject 4: \n\nProject Title  Sodexo SMART Migration (1st May, 2014 to 31st Aug, 2014) \n\nTools and Languages SQL server 2008, Core Java, Selenium, Sikuli, Eggplant \n\nPROJECT DESCRIPTION: Customer wanted to migrate their SMART web application (survey based application) to \n.net platform and the functional QA was done by cognizant in agile mode with development team \nROLES AND RESPONSIBILITIES: Responsibilities include requirement analysis, test scenario and test case design, \ntest case execution, co-ordination with onsite, implement automation through innovation to reduce the execution \neffort, conducting the automation POC for the application with all possible automation tool and share the outcome \nin form of report with customer. I was also the idea and innovation champion of the account. \n \nProject 5: \n\nProject Title  PJI Functional & Automation QA (19th November, 2013 to 30th April, 2014) \n\nTools and Languages Core Java, Selenium, Eclipse, Sikuli, PostGreSQL, VBScript \n\nPROJECT DESCRIPTION: Customer wanted to implement NextGen POS system by replacing their legacy POS. QA \nstarted with POS application testing and went into Regression and Automation testing phase. \nROLES AND RESPONSIBILITIES:  \n\n• Develop test automation framework for NextGenPOS in selenium and integrate that with sikuli to support \nautomation of back end legacy application. \n\n• Deliver Automation Suite to Customer which does not require any manual intervention \n \n\n \n\nEducational Qualification \n\n   \n\nInstitute Degree University/Board Year Percentage \n\nJalpaiguri Government \nEngineering College \n\nB-Tech in Computer Science \nand Engineering \n\nWest Bengal University of \nTechnology \n\n \n2013 \n\n \n88.00% \n\nAsansol Cheliadanga High \nSchool \n\nHigher Secondary \nExamination \n\n \nWBCHSE \n\n \n2009 \n\n \n90.20% \n\nAsansol Ramakrishna \nMission High School \n\nSecondary Examination   \nWBBSE \n\n \n2007 \n\n \n88.75% \n\n \n\n \n➢ Got two quarterly awards in IBM and several awards and accolades in Cognizant \n➢ IBM Intellectual Capital/ Intellectual Property Creator  \n➢ Won first prize in internal competition for test innovation platform (IGNITE) for the framework I \n\ndeveloped for Watson cognitive tutor \n➢ Rated best in the all the appraisal cycle, i.e.  for calendar year 2014-15 and 2015-16 \n➢ Topper of CSE department in college  \n➢ Ranked 5th in Burdwan District and 3rd in Asansol in Higher Secondary examination \n\nAchievements","annotation":[{"label":["Education"],"points":[{"start":9378,"end":9383,"text":"B-Tech"}]},{"label":["Skills"],"points":[{"start":8946,"end":8963,"text":"Automation testing"}]},{"label":["Skills"],"points":[{"start":3454,"end":3467,"text":"IBM certified "}]},{"label":["Skills"],"points":[{"start":2443,"end":2451,"text":"JAVA/J2EE"}]},{"label":["Skills"],"points":[{"start":1604,"end":1614,"text":"RESTful API"}]},{"label":["Skills"],"points":[{"start":506,"end":519,"text":"IBM certified "}]},{"label":["Skills"],"points":[{"start":436,"end":460,"text":" microservice development"}]},{"label":["Skills"],"points":[{"start":424,"end":434,"text":"RESTful API"}]},{"label":["Skills"],"points":[{"start":384,"end":401,"text":"Automation testing"}]},{"label":["Skills"],"points":[{"start":318,"end":326,"text":"JAVA/J2EE"}]},{"label":["Location"],"points":[{"start":205,"end":212,"text":" Kolkata"}]},{"label":["Name"],"points":[{"start":0,"end":12,"text":"Saubhik Kundu"}]}],"extras":null,"metadata":{"first_done_at":1532684990000,"last_updated_at":1532684990000,"sec_taken":108,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Mobile\t\n+919051067359\n\nEmail\nsenguptasaunak@gmail.com\n\n\n                                                          \n\nSenior Node Js Developer\nBITCANNY TECHNOLOGIES\nPRIVATE LIMITED\n\nFrom: 18/10/2016 to Present\nSALARY: 4.20 l/p\n\nAssistant Programmer\nFARSCOPE CLIENT SYS\nSOLUTIONS PRIVATE LIMITED,\nKOLKATA\nFROM: 02-01-2015 to 07/10/2016\n\nPHP Developer\nIkf technologies Pvt Ltd,\nKoLKATA\nFROM : 1/4/2014 to 30/12/2015\n\nAssociate Developer\nCodebox, MUMBAI\nFROM : 1/12/2013 to 1/4/2014\n\n\n\nDATABASES\nMonGoDB, MySQL\n\nSERVER SIDE \nNOde.JS, PHP\n\n\nFRONTEND\nReact JS, JSX,\nHTML , CSS\n\n\nREVISION CONTROl \nSVN\n\nOTHERS\nEXPRESS JS, MONGOOSE.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n             \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                                               \n\n\n\n\n                     \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlace : Kolkata \n\nDate : 14/7/2017                                                                               \n\tSaunak Sen Gupta\n\nLooking for a responsible position in a respectable firm for an\nopportunity to grow my skills. \n\n\n\nEXPERIENCE\n\n· Have worked to develop React Native apps both in IOS and Android. \n· Have worked extensively in javascript platforms, to build website, apps and databases. \n· Worked as a lead in setting up platform(Node JS, React JS and MongoDB) in start ups. \n· Have also worked on implementing unit testing with mocha and chai. \n· Worked on setting up Amazon Alexa voice service with a home automation system.\n· Have gained experience in domains such as Ground Transport, Home Automation.\n· Involved in end to end project development, including requirement analysis, task estimation, handling of clients, database design, UI development and server side Api development.\n· Received appreciation for commendable and dedicated job done in all the organizations I have worked in \n\n\n\n\nPROJECTS  AND TECHOLOGIES                                                                                                                                        \n\nPROJECT TITLE: Rently Manager\n\nPROJECT MODULE : Mobile App\n\nPROJECT DESCRIPTION: It is an app meant for the property managers to add and manage their properties.\n\nTECHOLOGIES: React Native and  Node JS\n\nItunes Link : https://itunes.apple.com/in/app/rently-manager/id965126783?mt=8\n\nGoogle Playstore Link : https://play.google.com/store/apps/details?id=com.rently.app&hl=en\n\n\n\n\nPROJECT TITLE: Rently Keyless\n\nPROJECT MODULE : Alexa\n\nPROJECT DESCRIPTION: A smart home appliance driven by Alexa Voice Control.\n\nTECHOLOGIES: Node JS\n\nAlexa Skill link : http://alexa.amazon.com/spa/index.html#skills/dp/B01NAM3JQJ/?ref=skill_dsk_skb_sr_0\n\nhttp://alexa.amazon.com/spa/index.html#skills/dp/B01N5J6CYT/?ref=skill_dsk_skb_sr_1\n\n\n\nPROJECT TITLE: LIMOKIT\n\nPROJECT DESCRIPTION: A booking management service provider. Meant to be used by car operators to manage their bookings, invoice clients and also manage their accounts. \n\nTECHOLOGIES: MongoDB,  Angular JS and Node JS (with Mongoose) \n\nWebsite Link : http://www.limokit.com/\n\n\n\nPROJECT TITLE: RIDEBOOM\n\nPROJECT DESCRIPTION: An app meant for booking a cab (taxi, luxury or van), in any city across the world.\n\nTECHOLOGIES: MongoDB, Angular JS and PHP.\n\nWebsite Link : http://rideboom.com/\n\n\n\nPROJECT TITLE: ONE STOP NATION \n\nPROJECT DESCRIPTION: A website to search any place in Mumbai, starting from groceries and medical shops to restaurants and hangout places.\n\nTECHOLOGIES: PHP and MySQL.\n\nWebsite Link : http://www.onestopnation.com/\n\n\n\n\n\n\nPROJECT TITLE: LOST IN LONDON\n\nPROJECT DESCRIPTION: A mobile app developed for the city of London, to browse parties, tours, attractions etc. and in some cases purchase tickets as well.\n\nTECHOLOGIES: CodeIgniter(PHP), MySQL.\n\nWebsite Link : http://www.lostinlondon.com/\n\n\n\nEDUCATION \n\nUNIVERSITY: West Bengal university of technology, Kolkata\nCOURSE: Master in Computer Application, (MCA) 8/2013\nDGPA: 8.23\n\nUNIVERSITY: West Bengal university of technology, Kolkata\nCOURSE: Bachelor in Computer Application, (BCA) 8/2010\nDGPA: 7.77\n\n\n\nPERSONAL INFORMATION\n\nName: Saunak Sen Gupta\n\nFather’s Name: Salil Sen Gupta\n\nAge: 28\n\nDate of Birth : 27/01/1989\n\nNationality: Indian\n\nCurrent City: Kolkata\n\nPermanent Address: R/4 Cluster 8 Purbachal Housing Estate Salt Lake City\nKolkata : 700097\n\n\nHOBBIES \n· Reading, internet surfing, chess, solving riddles and puzzles.\n· Interested in sports like cricket and football. \n\n\n\n\n\nDECLARATION  \n\nI hereby declare that the above written particulars are true to the best of my\nknowledge and belief.\n\n\n\n\n\n\n\n                                                                         --------------------------\n                                                                           (Saunak Sen Gupta)","annotation":[{"label":["Name"],"points":[{"start":4698,"end":4713,"text":"Saunak Sen Gupta"}]},{"label":["Location"],"points":[{"start":4250,"end":4257,"text":"Kolkata "}]},{"label":["Name"],"points":[{"start":4046,"end":4061,"text":"Saunak Sen Gupta"}]},{"label":["Education"],"points":[{"start":3833,"end":3863,"text":" Master in Computer Application"}]},{"label":["Skills"],"points":[{"start":3701,"end":3705,"text":"MySQL"}]},{"label":["Skills"],"points":[{"start":3424,"end":3428,"text":"MySQL"}]},{"label":["Skills"],"points":[{"start":3415,"end":3418,"text":" PHP"}]},{"label":["Skills"],"points":[{"start":3184,"end":3187,"text":" PHP"}]},{"label":["Skills"],"points":[{"start":3170,"end":3179,"text":"Angular JS"}]},{"label":["Skills"],"points":[{"start":3160,"end":3167,"text":" MongoDB"}]},{"label":["Skills"],"points":[{"start":2949,"end":2955,"text":"Node JS"}]},{"label":["Skills"],"points":[{"start":2934,"end":2943,"text":"Angular JS"}]},{"label":["Skills"],"points":[{"start":2923,"end":2930,"text":" MongoDB"}]},{"label":["Skills"],"points":[{"start":2517,"end":2523,"text":"Node JS"}]},{"label":["Skills"],"points":[{"start":2190,"end":2196,"text":"Node JS"}]},{"label":["Skills"],"points":[{"start":1287,"end":1294,"text":" MongoDB"}]},{"label":["Skills"],"points":[{"start":1266,"end":1272,"text":"Node JS"}]},{"label":["Name"],"points":[{"start":936,"end":951,"text":"Saunak Sen Gupta"}]},{"label":["Location"],"points":[{"start":829,"end":836,"text":"Kolkata "}]},{"label":["Skills"],"points":[{"start":614,"end":621,"text":"MONGOOSE"}]},{"label":["Skills"],"points":[{"start":602,"end":611,"text":"EXPRESS JS"}]},{"label":["Skills"],"points":[{"start":528,"end":531,"text":" PHP"}]},{"label":["Skills"],"points":[{"start":500,"end":504,"text":"MySQL"}]}],"extras":null,"metadata":{"first_done_at":1532679698000,"last_updated_at":1532679698000,"sec_taken":350,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "He is having 12 months exp. in IBM Watson \nIBM Watson Certified – Have worked on Create chat board text to speech integration.\n\nHas done Alexa framework only training part…\n\nPython Programming: 1 Year Rating: 3/5\n\tSaurabh gupta\n\n\tMahaveer Palm Apartment,\n#421, Vijaya Bank Layout ,\nB.G. Road, Bangalore\n\n\tMobile:8310448823\n\n\tsaurabhggupta07@gmail.com\n\n\n\nOBJECTIVE:\nTo work as a key player in a creative and challenging environment using cutting edge technologies where I could constantly learn and improve my technical and analytical abilities and utilize my potentials by successfully delivering solutions.\nPROFESSIONAL SKILLS:\nI am IBM Watson V3 certified application developer. Watson is IBM’s AI platform for business. Among the various cognitive services it offers, the Conversation Agent is used to build, deploy and optimize Chabot’s quickly and efficiently using its advanced capabilities and easy to use interface. He has experience working on Watson BOT Service to develop the Chabot for technical support assistance to enable the different channels. He has experience in solution design using Watson cognitive services.\nI worked on RPA and machine learning project for one of the reputed Banking client to provide the zero human interaction automation. I also developed the solution for automation of different kind of Desktop, Web based and COBOL based tools using the HOLMES Mimictron developed using OCR and end to end Email automation by using NLP service.\nI have workingexperience on Machine learning projects, which involved integration of OCR and NLP components for information extraction from structured and semi-structured data.\nHe has also worked on document digitization project to reduce human effort to extract the information and create the JAXML.\nI worked on multiple projects solution design using different cognitive service. I also have experience in requirements gathering, solution consultation and development of code in programming languages like Python, Java along with integration of cognitive services.\nPROFESSIONAL EXPERIENCE:\n· Currently working with Wipro Digital as a Technical Lead from Feb’16 to current.\n· I worked with Hewlett Packard Global soft, Bangalore as a SVC info Developer fromOct’14 to Feb’16. \n· I worked with Cap Gemini India, Bangalore as a Consultant from Aug’14 to Sep’15. \n· I worked with Wipro Technologies as a Software Engineer from Feb’11 to Aug ‘14.\nPERSONAL STRENGTHS:\n· Have the motivation to take independent responsibility as well as ability to contribute.\n· Good interpersonal and communicative skills.\nEDUCATIONAL QUALIFICATION: \n· B.TECH from UPTU University, Ghaziabad.\n· 12th from SPIC, Kanpur.\nSKILLS:\n· IBM Watson, Amazon Alexa, Wipro HOLMES services\n· Java & Python coding\n· Technical design & development\n· Requirement gathering & use case design\n· Databases experience in Gemfire, Oracle, MySQL\n· Spring boot, Micro services ,  Maven, REST Web services\n· Leadership and communication skills\nPROJECTS:\n1. UBS : CAIP\n\tClient\n\t: UBS\n\n\tTechnologies\n\t: Core Java, Web services, NLP, RPA\n\n\n\tDuration\n\t: March’16  to July’16\n\n\nResponsibilities:\n· Involved in requirement gathering from client side.\n· System design, high / low-level architecture design.\n· Work with HOLMES team to build the solution to automate the UBS BPS process.\n· High/Low level Design of the technical architecture.\n· Involved in Code development\n2. SCHLUMBERGER\n\tClient\n\t: Schlumberger\n\n\tTechnologies\n\t:Java, Spring, Web services and python, NLP\n\n\n\tDuration\n\t: July’16  to Sep’16\n\n\nResponsibilities:\n· Involved in requirement gathering from client side.\n· Work with HOLMES team to build tool to extract entity and provide the csvfile.\n· High/Low level Design of the technical architecture.\n· Involved in Code development\n3. THOMSON REUTERS\n\tClient\n\t: Thomson Reuters\n\n\tTechnologies\n\t: Core Java, Spring, Web services.\n\n\n\tDuration\n\t: March’16 to July’16\n\n\nResponsibilities:\n· Involved in requirement gathering from client side.\n· Project architecture design.\n· Work with HOLMES platform team to build tool to convert PDF to JXML.\n· High/Low level Design of the technical architecture.\n· Involved in Code development\n4. AMERICAN AIRLINES\n\tClient\n\t: American Airlines\n\n\tTechnologies\n\t: Core Java, Spring MVC, Web services.\n\n\n\tDuration\n\t: Oct’15 to Feb’16\n\n\nResponsibilities:\n· Involved in requirement gathering from client side.\n· High/Low level Design of the technical architecture.\n· Involved in Code development\n· Involved in developing modules, which include work on different layers of application.\n5. SWA- SOUTHWEST CARGO  AIRLINES\n\tClient\n\t: SWA (Southwest Airlines Cargo)\n\n\tTechnologies\n\t: Core Java, Spring MVC, Angular JS, HTML, CSS,GemFire .\n\n\n\tDuration\n\t: Aug’14  to Sep’15\n\n\tDescription:\n\t\n\n\nSouthwest Airlines Cargoprovides expedited Air Cargo services for Customers who need fast, friendly and reliable service. The project is based on the Manage Cargo System. \nResponsibilities:\n· Design of the technical architecture.\n· Involved in Code development\n· Involved in requirement gathering.\n· Involved in POC’s on Angular JS and Gemfire, Spring MVC, Integration, Fisheyetool, Sonar Violation fixes.\n· Working as a Java developer.\n· Involved in developing modules, which include work on different layers of application.\n6. UBS- PRDB\n\tClient\n\t: UBS (Union Bank of Switzerland)\n\n\tTechnologies\n\t: Core Java, Struts , Java script, HTML,CSS\n\n\n\tDuration\n\t: Oct’12 to July’14\n\n\tDescription:\n\t\n\n\nPRDB contain indicative data about the products sold or traded by Wealth Management. PRDB also provides pricing features like enquiry, history and variance data of securities. PRDB application is the main portal to add, maintain and view security related information in Project Reference Database. \nResponsibilities:\n· Involved in Code development\n· Involved in bug fixing and enhancement in the application.\n· Worked on documenting functional Specification, Design, UTC and other documents before the actual development.\n· Responsible for analyzing use cases and creating development task for them.\n· Involved in developing modules, which include work on different layers of application.\n7. UBS - CEFS\n\tClient\n\t: UBS (Union Bank of Switzerland)\n\n\tTechnologies\n\t: Core Java, Struts \n\n\n\tDatabase                                                                              \n\t: Sybase \n\n\tWeb Technologies                                                   \n\t: Java-Script , XML, HTML\n\n\n\t Tools\n\t: HP Quality Center\n\n\n\tDuration\n\t: Aug’11 to Oct ’12\n\n\tDescription:\n\t\n\n\nCorporate Employee Financial Services (CEFS) is a business unit within UBS Financial Services Inc. that delivers leading-edge equity compensation plan services and support for stock options, restricted grant awards, performance grant awards, stock appreciation rights and employee stock purchase plans. CEFS has more than a decade of experience delivering service to Fortune 1000 companies and their participants across the globe. With more than 230 employees and over 265 CEFS network Financial Advisors in 55 cities, CEFS services nearly 100 corporate clients and 650,000 plan participants.\nResponsibilities:\n· Understanding the Business requirements and Functionality.\n· Involved in developing modules, which include work on different layers of application.\n· Worked on documenting functional Specification, Design, UTC, Traceability and other documents\nBefore the actual development.\n· Worked on POC using DOJO framework to demo the same for analyzing the technical limitations if any before actual integration in to the project. \n· Defect tracking and fixing bugs.\n\n\n4. UBS CEFS - PORTFOLIO\n\tClient\n\t: UBS (Union Bank of Switzerland)\n\n\tTechnology \n\t: Core Java, JSP-Struts\n\n\n\tWeb Technologies                                                     \n\t: Java-Script ,HTML\n\n\tDatabase                                                                       \n\t: Oracle10g\n\n\tDuration\n\t: Jun’12 to Sep’12\n\n\nOne Source WM-CEFS is a core website development project. This module is basically for future prediction of the stock prices by Charts and graphical view. \nResponsibilities:\n· Understanding the Business requirements and Functionality.\n· Involved in developing modules, which include work on different layers of application.\n· Worked on documenting functional Specification, Design, UTC, Traceability and other documents\n before the actual development.\n· Worked on POC using DOJO framework to demo the same for analyzing the technical limitations if any before actual integration in to the project. \n· Defect tracking and fixing bugs.\nPERSONAL DETAILS:\n\tName of the Candidate \n\n\t: Saurabh Gupta\n\n\tFather’s Name\n\t: Mr.  Sunil Gupta\n\n\tMother’s Name\n\n\t: Mrs. Poonam Gupta\n\n\tDate of Birth\n\t: 07-08-1989\n\n\tLanguages known\nPassport No.\n\t: English, Hindi.\n:K8819933\n\n\n\nDECLARATION:\nI hereby declare that all the information furnished above is true to the best of my knowledge and belief.\nPlace: Bangalore                                                                                               \n\n\n\nDate: \n\n\nSaurabh Gupta","annotation":[{"label":["Location"],"points":[{"start":8892,"end":8900,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":7661,"end":7669,"text":"Core Java"}]},{"label":["Skills"],"points":[{"start":6205,"end":6213,"text":"Core Java"}]},{"label":["Skills"],"points":[{"start":5347,"end":5355,"text":"Core Java"}]},{"label":["Skills"],"points":[{"start":4640,"end":4648,"text":"Core Java"}]},{"label":["Skills"],"points":[{"start":4250,"end":4262,"text":" Web services"}]},{"label":["Skills"],"points":[{"start":4228,"end":4236,"text":"Core Java"}]},{"label":["Skills"],"points":[{"start":3848,"end":3860,"text":" Web services"}]},{"label":["Skills"],"points":[{"start":3830,"end":3838,"text":"Core Java"}]},{"label":["Skills"],"points":[{"start":3487,"end":3489,"text":"NLP"}]},{"label":["Skills"],"points":[{"start":3461,"end":3473,"text":" Web services"}]},{"label":["Skills"],"points":[{"start":3057,"end":3059,"text":"RPA"}]},{"label":["Skills"],"points":[{"start":3052,"end":3054,"text":"NLP"}]},{"label":["Skills"],"points":[{"start":3037,"end":3049,"text":" Web services"}]},{"label":["Skills"],"points":[{"start":3027,"end":3035,"text":"Core Java"}]},{"label":["Skills"],"points":[{"start":2918,"end":2930,"text":" Web services"}]},{"label":["Location"],"points":[{"start":2283,"end":2291,"text":"Bangalore"}]},{"label":["Location"],"points":[{"start":2192,"end":2200,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":1565,"end":1567,"text":"NLP"}]},{"label":["Skills"],"points":[{"start":1459,"end":1461,"text":"NLP"}]},{"label":["Skills"],"points":[{"start":1143,"end":1145,"text":"RPA"}]},{"label":["Location"],"points":[{"start":293,"end":301,"text":"Bangalore"}]},{"label":["Name"],"points":[{"start":214,"end":226,"text":"Saurabh gupta"}]},{"label":["Skills"],"points":[{"start":174,"end":191,"text":"Python Programming"}]},{"label":["Skills"],"points":[{"start":137,"end":151,"text":"Alexa framework"}]},{"label":["Skills"],"points":[{"start":43,"end":62,"text":"IBM Watson Certified"}]}],"extras":null,"metadata":{"first_done_at":1532691745000,"last_updated_at":1532691745000,"sec_taken":134,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "▪ Data Science, Analytics & Insights: \n\n Expertise in finding solutions of business problems by using Analytics, Machine \n\nlearning techniques.  \n\n Rich experience in predictive analytics, forecasting techniques, customer behavior, \n\nKey driver analysis, Fault Prediction, Feature Engineering. \n\n Hands on experienced in using Machine learning techniques; Deep Learning, Naïve \n\nBays Classifier, SVM, Random Forest, Association Rule, ANN, Text Mining& \n\nCollaborative Filtering for recommendation. \n\n Experience with multivariate linear and logistic regression, time-series, Discriminant \n\nanalysis, principle component and cluster analysis. Also skilled with project \n\nmanagement, professional mentorship, and communication of technical information to \n\na non-technical audience. Majorly used R, Python, SPSS, SQL, Hive and Impala. \n\n Develop innovative and effective approaches to solve client's analytics problems and \n\ncommunicates results and methodologies. \n\n \n\n▪ Client Interaction and Project Management: Work in collaboration with clients and maintain \n\nproject management presentations of weekly updates and timeline as per the project schedule. \n\n▪ Working in a team: Successfully working in a team for analytics projects. Interaction with team \n\nmembers and working in coordination with team lead to complete projects on time. \n\n \n\n \n\nEE Coverage Analysis: \n\n \n\n• Call drops were analyzed on the basis of variables such as call volumes, household numbers \noccupied, 2G, 3G & 4G data strength etc. \n\n• ANOVA used to find the significant variables effecting Service value. \n\n• Developed a single algorithm to assign a Service value and Service Quality based on call \n\nvolumes’. \n\n• 2.1 million Postcodes were scored against Service value. \n\n• Created MAD dashboard using Tableau to give real time drill down on investment priority \n\nbased on Service value. \n\nBT Global Service - Sentiment & Topic Modeling: \n\n \n\n• Cleaned the text and prepared the data set as per model requirement in R.  \n• Found the topic of discussion in different verbatim in the data containing customer \n\nfeedback or comments. \n\n• The customer sentiment around the topic of discussion was found. \n\nShivappa Gundlur \n\nMail:shivu.k380@gmail.com; Phone: 9035000223 \n\nin.linkedin.com/in/shivappa-gundlur \n\n \n\nProfessional Synopsis \n\nSignificant Solutions  - Example \n\n\n\n• For topic modelling Latent Dirichlet Allocation (LDA) and supervised machine \n\nlearning algorithms like Support Vector Machine (SVM) and Random Forest models \n\nwere used.   \n• Used sentiment analysis to get customer sentiment in the customer feedback data using R.  \n• Used Tableau to build Dashboards for Customer sentiment and topic of discussion. \n\n \n\n \n\nBT Global Service- Pattern Recognition and Fault prediction: \n\n \n\n• BT global service provides Machine logs file for particular server and we convert Log \n\nfiles to CSV using Python code.  \n• The Python code then converts Log files to CSV with Date and text columns. \n• Classified text column were trained to use Latent Dirchilet Allocation and name the topics \n\naccordingly. \n\n• Data had aggregated LDA classes in required time format after analysis.  \n• We used time series pattern recognition to find out Patterns in LDA output over the time. \n\nUsed time series clustering model in R to group similar kind of patterns. \n\n• Combined LDA lag data set and actual fault data then we trained attribution model by taking \nactual fault as target variable. \n\n• Predicted fault by seeing 5 previous days lag classes.  \n• Used Tableau to build Dashboards for Patterns and Fault prediction over the time. \n\n \n\nOrganization Name: \n\nHarman Connected \n\nServices. \n\n \n\nCurrent Role: Data \n\nScientist  \n\nSince May 2016 \n\n \n\nKRA: \n\n• Responsible for working in coordination with clients to check progress of work. \n\n• Worked on telecom projects under “British telecom” client such as churn calls, \n\ninternet connectivity issues region-wise. \n\n• Managing project from end to end, from descriptive analytics, model \n\ndevelopment and final solution deployment. \n\n• High performing team member with active role and involvement in projects. \n\n \n\nKey achievements: \n\n• Topic modelling was achieved with 73% accuracy to find out about topics \nwhich come up under calls to BT services. Then sentiment analysis was \n\napplied to the text on those calls where we recorder the following ratio of \n\nsentiments: negative- 19.05%, Positive- 47.69% and neutral-33.26%. \n\n• Out of the 2.1 million postcodes in EE service quality analysis, 13% of the post \ncodes need immediate investment as the service value is positive however \n\nsignal strength is not good and possible churn is expected. \n\n• Built time series pattern recognition for BT global service faults and also we \npredicted the faults for lag data i.e. tomorrow and day after tomorrow faults. \n\nPredicting the faults in advance helped them resolve the issues before they start \n\nand be prepared. \n\n• Published paper on “Driver Fatigue Detection using Deep Learning” \n\nCareer Graph \n\n\n\n▪ Internship as a data analyst working on data throughout the state about dairy products and cereals in \n\nvarious districts.  \n\n▪ Developed dynamic and statistical reports & charts using advanced formulas of Excel and pivot table. \n\n \n\n▪ Awarded certificate of achievement as a fresher in Concentrix Technologies. \n\n▪ Received award for my extra contribution under projects in Harman titled “extra mile award” \n\n▪ Rewarded as “Best contribution within team” in Harman for work under telecom projects. \n\n \n\nAcademic Vitae  \n \n\n \n\nOrganization Name: \n\nConcentrix \n\nTechnologies \n\n \n\nCurrent Role: Data \n\nAnalyst \n\nFrom Feb 2015 to May \n\n2016 \n\n \n\nKRA: \n\n \n\n      •     One of the point of contacts for various projects and played major roles in      \n\n            establishing process improvement programs and ensured client deliverables   \n\n            are adhered to at the highest standards.   \n\n• Cleansing & processing data using Excel, R, SQL and SFDC.  \n• Review and Document business requirements and also define its scope and \n\nobjectives.  \n• Developed dynamic and statistical reports & charts using advanced formulas \n\nof Excel and pivot table.  \n• Responsible for automating the dashboard, sales reporting and various other \n\nAd-hoc projects.  \n• Training new resources over the MDM process.  \n• Organizing review meetings with various stakeholders and \n\npreparing the Business Requirement Document. \n\n• Responsible for Generating Daily, Weekly, Monthly and Quarterly \n\nprocess Reports & Dashboards and sending across to clients, \n\nstakeholders and top management. \n\n• Coordinate with top management in understanding different \n\nprocess plans, business process, and functionality in depth.  \n \n \n\nData Analyst (Intern), Fiscal Policy Institute:                                                                    Sep 2014 to Nov 2014 \n\nKey Achievements in Career  \n\nDegree/certifications University             Specialization Year of Passing Percentage \n\nM.Sc. \nUniversity Of \n\nMysore \nStatistics 2014 70% \n\nB. Sc. \nKarnataka \n\nUniversity Dharwad \n\nStatistics, Physics, \n\nMathematics \n2012 82%","annotation":[{"label":["Education"],"points":[{"start":7046,"end":7051,"text":"B. Sc."}]},{"label":["Name"],"points":[{"start":2186,"end":2202,"text":"Shivappa Gundlur "}]},{"label":["Skills"],"points":[{"start":114,"end":131,"text":"Machine \n\nlearning"}]},{"label":["Skills"],"points":[{"start":103,"end":111,"text":"Analytics"}]},{"label":["Skills"],"points":[{"start":16,"end":24,"text":"Analytics"}]}],"extras":null,"metadata":{"first_done_at":1532672644000,"last_updated_at":1532672644000,"sec_taken":104,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "SHIVARAJA\n\nE-Mail: shivarajssalyan@gmail.com\t\t\t\t\t  Phone: +91-9741967643\n\n\n\n  \n“Versatile, high-energy professional, offering  4.11 years of dynamic career in Cognitive Technologies & Business Intelligence ; scaling new heights of success with hard work & dedication and leaving a mark of excellence on each step”\n\n\n\tSkill Set\nCognitive Solutions - Watson\nIBM Bluemix Services\nBusiness Intelligence - Cognos\nSQL\nData Warehousing\nClient Interaction\nTraining & Development\nAcademic Details\n· B.E. from Vivekananda College of Engineering & Technology, \nin 2010\nCourses & Badges\n· Data Science course from Collabera TACT\n· R 101 - Big Data University \n· Data Science 101 – Big Data University\n· NLP using Python – Udemy\nCertification\n· IBM Certified Designer – Cognos 10 BI Reports\n· IBM Cognos Analytics Reporting Essentials\nPersonal Details\nDate of Birth: 8th May 1987\nAddress: #10/303, Sharada Nivasam, \nMeenakshi Layout, Kalena Agrahara,\nBangalore - 560076\n\t\n\tProfile Summary\n\n· Extensive hands-on experience in diversified fields;specializes in Business Intelligence, data warehousing, web application development and Cognitive technologies.\n· Developed models in Text Analytics using Python/R\n· Extensively worked on BI Tools like–COGNOS, Watson Analytics, Hyperion-Intelligence Explorer, QMF, SPSS Modeler and Jaspersoft involving in Developing Reports/dashboards as per the business requirements\n· Extensive experience in writing and tuning complex SQL queries\n· Ability to drill-down and perform root-cause analysis on Data issues.\n· Last 10 months working as Cloud and Cognitive Developer at IBM.\n· Have inclination towards innovation and ability to absorb new technology fast.\n\nNotable Accomplishments Across The Career\n\n· IBM Manager’s Choice Award -2015: Show Personal Interest\n· IBM Manager’s Choice Award -Q2-2016: Share Expertise\n· IBM Manager’s Choice Award -Q4-2016: Put the Client First\n· Awarded innovator of the quarter for designining a Cognos Landing Page using HTML/Javascript/CSS\n· Implemented reporting & analytics solution product called COMPASS for banking sector. \n\n\n\n\nIT Skills\n\nCognitive Technologies:\tIBM Watson APIs – Natural Language Understanding, Natural Languauge Classifier , Watson Discivery, Watson Knowledge Studio, IBM Bluemix\nProgramming:\tPython, R, Apache Spark.\nWorkbench: \tJupyter Notebook, R studio, IBM Data Science Experience\nBusiness Intelligence:\tCognos Analytics, Watson Analytics, Cognos 10.2.2 BI, Framework Manager, Transformer, Jaspersoft, Hyperion/Brio, SPSS Modeler, QMF, R Studio.\nData Warehousing:\tPentaho Data Integration (Kettle) \nDatabases:\tCloudant,IBM Netezza, Oracle 11g, MySQL 5.5, & SQL Server 2008.\nDB Tools:\tAginity Workbench, SQL*Plus, SQL Developer, SQL Yog.\nLanguages: \tSQL, PL/SQL.\nScripting:\t\tHTML,CSS,Javascript\n\nOrganisational Experience\n\nCognitive Solutions Developer | IBM India Private Limited, Bangalore | Mar’15 – till date\n\nHighlights:\n· Working as a Cognitive Developer for Cognitive Team – Enterprise Services, Transformation & Operations BU of IBM\n· Responsible for develpoping new projects using cognitive / strategic technologies of IBM that can help transform IBM\n· Actively contribute on development(R, Python, FLASK) & leveraging Watson APIs\n\n\nOperations Analyst \nHighlights:\n\n· Data management of Sales Transaction Support HUB Globe.\n· Deliver periodic reports on key Performance Metrics for Sales units across the Globe.\n· Developing Framework Manager Models and publishing packages.\n· Independently developing and maintaining Cognos reports, Hyperion based reports and QMF query.\n· Interaction with stakeholders across the globe to understand metrics/reporting requirements to identify the reporting solution for the data requirements\n· Provide analytics on the reports, which help Leaders to know how the trends, projections and summary of the reports in short. The analytics would include business insights and actionable inputs.\n· Provide adhoc reporting support per business needs\n· Monitor and manage Cognos performance and tune as per end user requirement\n· Experience in all the phases of the Project Delivery Life Cycle right from requirement gathering to production support.\n\nSr. Software Engineer | Pinovus Consulting Pvt Ltd, Bangalore | Dec’12 - Mar’15\nHighlights:\n· Interacting extensively with end users to gather requirements.\n· Creating ETL transformations and jobs using Pentaho Kettle Spoon designer to Migrate data from Oracle to MySQL and scheduling them.\n· Creation of metadata model using Framework manager for Cognos and Data Extractor component for Jasperserver.\n· Creating Reports/Dashboards.\n· Modifying reports/queries as necessary and Troubleshooting operational/data issues\n· Performance tuning, report scheduling and report bursting.\n· Implemented Third Party Security with LDAP and creating Data Level, Object Securities.\n· Involved in creating Databases, Table structures.\n· Writing SQL Queries for DML operations on Database objects. \n· Creation of Procedures, Functions, Triggers, Cursors, Views etc.\n· Installed and configured Oracle 11g R2 & IBM Cognos 10.2 on WINDOWS\n· Documentation of business processes.\n· End User Training & Support.\n\n\nPlace:Bangalore\nDate:December 13, 2017\t\t\t\t\t\t\t\t\t\t\t Shivaraja","annotation":[{"label":["Location"],"points":[{"start":5173,"end":5181,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":4905,"end":4907,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":4441,"end":4443,"text":"SQL"}]},{"label":["Location"],"points":[{"start":4227,"end":4235,"text":"Bangalore"}]},{"label":["Location"],"points":[{"start":2871,"end":2879,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":2747,"end":2749,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":2739,"end":2741,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":2718,"end":2720,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":2703,"end":2705,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":2693,"end":2695,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":2647,"end":2649,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":2636,"end":2638,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":2347,"end":2358,"text":"Data Science"}]},{"label":["Skills"],"points":[{"start":1453,"end":1455,"text":"SQL"}]},{"label":["Location"],"points":[{"start":938,"end":946,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":650,"end":661,"text":"Data Science"}]},{"label":["Skills"],"points":[{"start":577,"end":588,"text":"Data Science"}]},{"label":["Education"],"points":[{"start":490,"end":493,"text":"B.E."}]},{"label":["Skills"],"points":[{"start":408,"end":410,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":377,"end":406,"text":"Business Intelligence - Cognos"}]},{"label":["Skills"],"points":[{"start":356,"end":375,"text":"IBM Bluemix Services"}]},{"label":["Skills"],"points":[{"start":327,"end":354,"text":"Cognitive Solutions - Watson"}]},{"label":["Name"],"points":[{"start":0,"end":8,"text":"SHIVARAJA"}]}],"extras":null,"metadata":{"first_done_at":1532685105000,"last_updated_at":1532685105000,"sec_taken":114,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Address:\n\n1161,Mig Flat, Opp. Tejas Vidyalaya, Ellora park,\n\nVADODARA\n\n+91- 09321606864\n\n+91- 09574006864\n\nshiv8_statistics@rediffmail.com\nshiv8.statistics@gmail.com\nwww.linkedin.com/in/shivesh-jha-56950835\nABOUT ME\n\nKnowledge of predictive modeling &developing statistical models, ANOVA, Machine Learning, testing hypothesis, sampling technique, universe estimation  with ownership quality & initiative driven approach\n\nSKILLS\n\nSoftware\n\nR\n\nPython\n\nSAS\n\nSPSS\n\nMinitab\n\nSQL\n\nExcel\n\nFoxpro\n\nPowerpoint\n\n   Domain Knowledge\n\nSector\n\nFMCG\n\nPharma\n\nCigarette\n\nSoft Drink\n\nOthers(Paint,\n\nHandset etc.)\n\nPERSONAL\n\nOWNERSHIP\n\nPROACTIVE\n\nINTIATIVE\n\nTEAM PLAYER\n\nSOCIAL\n\nDOB: 4th April 1988\n\nGENDER:MALE\n\nMARTIAL STATUS: SINGLE\n\nNATIONALITY: INDIAN\n\nLANGUAGE: ENGLISH,HINDI,MARATHI\n\nHOBBIES: PLAYING CRICKET,\n\nREADING\n\tShivesh Jha\nDATA SCIENTIST\n\nWhen was that – 6 Months \nTotal Years: 7 Yrs \n\nRelevant : 5 Yrs \n\nSME –  R 3.5 Yrs.\n\nPython- 1 Yrs \n\nMachine Learning – 4 Yrs.\n\nNP : 90 Days (60 days) \n\nEXPERIENCE\n\nLEAD DATA SCEIENTIST\n\nNielsen                                               (Apr 2013 – present)\n\n· Built Identification of classification variable using Machine learning techniques(Random Forest)for creating volume classes using R\n\n· Created regression Model for estimating store sales based on auxiliary variable in SPSS\n\n· Automated  in house estimation model in Python\n\n· Develop regression Models for Brand health scorecard in SAS\n\n· Created homogenous set of towns using clustering technique for providing replica for client requested towns to reduce operation cost in SAS\n\n· Performed ANOVA analysis for identification of homogenous set of classes in Excel\n\n· Performed Chi-square test for testing distribution of stores w.r.t. auxiliary variables in Excel\n\n· Built I regression  mode for identification of Outlier settlement in Excel\n\n· Worked on Discriminant analysis for identification of observable characteristic which will discriminate sales behavior in SPSS\n\n· Converted SAS/SPSS codes into R to reduce dependency on SAS using base R, data.table, sqldf, shiny packages\n\n· Perform Multiple correspondence analysis on India Census data\n\n· Automated logic checks & validation through SAS resulting in saving of time with better accuracy\n\n· Performed analysis on India Soft-drink market size estimation\n\n· Performed India Modern Trade Universe Estimation Project\n\n· Performed analysis on Bangladesh Retail market size estimation\n\n· Provided in house Base SAS training to all other peers\n\n· Completed in house BPI Green Belt Certification program \n\nAWARDS\n\n· Excellence in client centricity (Nielsen Data Science-Q2,2016)\n\n· Dream work through Team work ( Nielsen Data Science -Q1,2015)\n\n· Beyond the boundary Award ( Nielsen Data Science -Q4,2014)\n\n· Innovation Award (Nielsen Data Science -Q2,2014)\n\n· Best Team player award  (Nielsen Data Science -Q4,2013)\n\n· Bronze Award for turning fast output for Coca-Cola Company customized request(Nielsen Data Science -Q4,2013)\n\n· Nominated for “Emerging Young talent” for Nielsen India- Annual Awards 2015\n\nSTATS METHODLOGISTS\n\nIMS Health                                         (Jan 2011-Mar 2013)\n· Developing SAS Codes for various automation & Process Improvement\n\n· Sampling, Projection and Quality Control of Pharmacy data.\n\n· To perform Analysis for price change used for various Pharmacy Audits monthly\n\n· Perform quality checks of data-value additions for new introductions (Pharmacy Products) in Audits\n\n· Checking & Go ahead on Projection factors for Audits\n\n· Assisting in new Innovations\n\nEDUCATION\n\nMASTER OF SCEIENCE-STATISTICS (86%)\n\nAMRAVATI UNIVERSITY                                                 (2008 – 2010)\n\nMultivariate analysis, Sampling, Hypothesis Testing, Clinical Trial, Exploratory data analysis, Non-parametric test, Actuarial Statistics, Operation Research\n\nBACHELOR OF SCEIENCE-STATISTICS (72%)\n\nMUMBAI UNIVERSITY (2005 – 2008)   \n\nStatistics, Computer Programming( C, SQL)\n\n\t\n\tHSC (75%)\n\nMUMBAI BOARD                                         (2002 – 2004)   \n\nPhysics, Biology, Mathematics, Chemistry, Hindi, English\nSSC (84%)\n\nMUMBAI BOARD                                         (2001-2002)   \n\nMathematics, Science, English, Hindi, Social science, Marathi\n\nCERTIFICATES\n\n DATACAMP R CERTIFICATES\n\n\n\n\t\n\t· INTRODUCTION TO R\n\n· INTERMEDIATE R\n\n· IMPORTING DATA INTO R\n\n· Data manipulation in R with dplyr\n\n· Data Analysis in R, the data. table way\n\n· REPORTING WITH R MARKDOWN\n\nNielsen CERTIFICATES\n\n· BPI Green Belt","annotation":[{"label":["Skills"],"points":[{"start":4479,"end":4479,"text":"R"}]},{"label":["Skills"],"points":[{"start":4461,"end":4461,"text":"R"}]},{"label":["Skills"],"points":[{"start":4457,"end":4457,"text":"R"}]},{"label":["Skills"],"points":[{"start":4446,"end":4446,"text":"R"}]},{"label":["Skills"],"points":[{"start":4442,"end":4442,"text":"R"}]},{"label":["Skills"],"points":[{"start":4416,"end":4416,"text":"R"}]},{"label":["Skills"],"points":[{"start":4383,"end":4383,"text":"R"}]},{"label":["Skills"],"points":[{"start":4357,"end":4357,"text":"R"}]},{"label":["Skills"],"points":[{"start":4341,"end":4341,"text":"R"}]},{"label":["Skills"],"points":[{"start":4332,"end":4332,"text":"R"}]},{"label":["Skills"],"points":[{"start":4323,"end":4323,"text":"R"}]},{"label":["Skills"],"points":[{"start":4314,"end":4314,"text":"R"}]},{"label":["Skills"],"points":[{"start":4301,"end":4301,"text":"R"}]},{"label":["Skills"],"points":[{"start":4279,"end":4279,"text":"R"}]},{"label":["Skills"],"points":[{"start":4275,"end":4275,"text":"R"}]},{"label":["Skills"],"points":[{"start":4253,"end":4253,"text":"R"}]},{"label":["Skills"],"points":[{"start":4129,"end":4129,"text":"R"}]},{"label":["Skills"],"points":[{"start":3990,"end":3990,"text":"R"}]},{"label":["Skills"],"points":[{"start":3960,"end":3962,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":3899,"end":3899,"text":"R"}]},{"label":["Skills"],"points":[{"start":3855,"end":3855,"text":"R"}]},{"label":["Education"],"points":[{"start":3848,"end":3867,"text":"BACHELOR OF SCEIENCE"}]},{"label":["Skills"],"points":[{"start":3838,"end":3838,"text":"R"}]},{"label":["Skills"],"points":[{"start":3620,"end":3620,"text":"R"}]},{"label":["Skills"],"points":[{"start":3608,"end":3608,"text":"R"}]},{"label":["Skills"],"points":[{"start":3574,"end":3574,"text":"R"}]},{"label":["Skills"],"points":[{"start":3169,"end":3171,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":2564,"end":2564,"text":"R"}]},{"label":["Skills"],"points":[{"start":2468,"end":2470,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":2412,"end":2412,"text":"R"}]},{"label":["Skills"],"points":[{"start":2198,"end":2200,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":2049,"end":2049,"text":"R"}]},{"label":["Skills"],"points":[{"start":2034,"end":2036,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":2008,"end":2008,"text":"R"}]},{"label":["Skills"],"points":[{"start":1992,"end":1995,"text":"SPSS"}]},{"label":["Skills"],"points":[{"start":1988,"end":1990,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1970,"end":1973,"text":"SPSS"}]},{"label":["Skills"],"points":[{"start":1578,"end":1580,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1435,"end":1437,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1369,"end":1374,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1321,"end":1324,"text":"SPSS"}]},{"label":["Skills"],"points":[{"start":1233,"end":1233,"text":"R"}]},{"label":["Skills"],"points":[{"start":1185,"end":1185,"text":"R"}]},{"label":["Skills"],"points":[{"start":995,"end":995,"text":"R"}]},{"label":["Skills"],"points":[{"start":923,"end":928,"text":"Python"}]},{"label":["Skills"],"points":[{"start":911,"end":911,"text":"R"}]},{"label":["Skills"],"points":[{"start":885,"end":885,"text":"R"}]},{"label":["Skills"],"points":[{"start":801,"end":801,"text":"R"}]},{"label":["Skills"],"points":[{"start":792,"end":792,"text":"R"}]},{"label":["Skills"],"points":[{"start":767,"end":767,"text":"R"}]},{"label":["Skills"],"points":[{"start":698,"end":698,"text":"R"}]},{"label":["Skills"],"points":[{"start":688,"end":688,"text":"R"}]},{"label":["Skills"],"points":[{"start":651,"end":651,"text":"R"}]},{"label":["Skills"],"points":[{"start":620,"end":620,"text":"R"}]},{"label":["Skills"],"points":[{"start":612,"end":612,"text":"R"}]},{"label":["Skills"],"points":[{"start":600,"end":600,"text":"R"}]},{"label":["Skills"],"points":[{"start":470,"end":472,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":461,"end":467,"text":"Minitab"}]},{"label":["Skills"],"points":[{"start":455,"end":458,"text":"SPSS"}]},{"label":["Skills"],"points":[{"start":450,"end":452,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":442,"end":447,"text":"Python"}]},{"label":["Skills"],"points":[{"start":439,"end":439,"text":"R"}]},{"label":["Name"],"points":[{"start":186,"end":196,"text":"shivesh-jha"}]},{"label":["Skills"],"points":[{"start":67,"end":67,"text":"R"}]},{"label":["Location"],"points":[{"start":61,"end":68,"text":"VADODARA"}]}],"extras":null,"metadata":{"first_done_at":1532691610000,"last_updated_at":1532691610000,"sec_taken":104,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Shubam Kumar Sharma \nDOB : 04-Dec-1991 \nAddress: A17-303 MegaPolis Sunway, Hinjewadi Ph. 3 Pune-411057    \nPhone: 7028028058, 9049509476 \nE-mail:  shubamsharma1947@gmail.com \nGitHub URL - https://github.com/shubamsharma \n \n\nCareer Objective \n● A Machine Learning and Data Science Enthusiast who is seeking a challenging task in an organization that \n\nencourages continuous learning and exposure of new technologies. So as to achieve personal and professional \ngrowth in the field of Business Intelligence, Machine Learning and Data Science. \n\n \n\nSummary \n● 3.5 Years of programming experience in Cognizant as Application and Analytics Products developer. \n● Well versed with regression, classification and clustering algorithms and their application. \n● Proficient in RDBMS and able to implement complex business logic in SQL queries. \n● Good understanding of data-warehouse concept like dimensional Modeling, star & snowflake schema, Fact and \n\nDimension, and Slowly Changing Dimensions and BI etc. \n● Experience of working with multiple teams in Agile and SDLC. \n● Quick learner with strong working knowledge of software, hardware. \n\n \n\nSkills Summary: \n\n Key Skills \n • Machine Learning • Data Warehousing Concepts • NLP \n\n Languages \n• R Programming • C# • JavaScript • Perl • SQL • T/SQL • UNIX shell  \n\n Systems \n• Windows • Linux • UNIX  \n\n Technologies \n[Reporting]: • QlikView • SAP Business Objects \n[Database]: • Oracle • Sybase \n[Environment]: • Visual Studio • R Studio • QlikView Desktop • Control M • Vi Editor   \n[Platform/SDK]:  • .NET/ASP.NET   \n[Build/Release]: • SVN  \n[Misc.]:  • HP ALM • Photoshop CS4 • MS-Excel • Control–M • Tectia • Putty. \n \n\nEDUCATION \n \n\nB.E in Information Technology, Jammu University, J&K, India (2013) 74.2% \n12th JKBOSE, J&K, India (2009) 78.9% \n10th JKBOSE, J&K, India (2007) 77.8% \n\n \nEXPERIENCE \nCognizant Technology Solution, Pune, India Feb 2014 - Present \nAssociate - Projects \n \nProduct control IT (Credit Suisse): Aug 2014 - Present \nML PROJECTS : JazzFobo & SwissVat are classification models which executes daily through Control M Scheduler. Jazz Fobo \npredict whether the breaks reported are genuine or not and Swiss Vat predicts the tax category. The prediction done by \nboth the systems are used to create the reports. \n \nPOETS - Its is an APAC PNL calculation system that works for four MIS Entities Australia, Singapore, Hong Kong and \nJapan. This system is used by product controller for having check on trader’s activity for fraud. It is a back office system \nalso used for reconciliation purpose. \n\nmailto:shubamsharma1947@gmail.com\nhttps://github.com/shubamsharma\n\n\n \nRoles and Responsibilities: \n\n Worked on data cleaning and transformation using R and documented the process. \n Worked on noise reduction, feature scaling and dimensionality reduction on data set. \n Worked on hypothesis design and testing as per statistical models. \n Used different library to apply different machine learning algorithms like Linear/ Logistic Regression, \n\nDecision Tree, Random Forest, GBM, k-NN, etc. \n Created several Dashboards on QlikView for PNL reporting to Product Controllers.  \n Created Automation tool on WPF for eliminating repeated code change tasks and Database migration.  \n Written scripts for creating reports for down streams and Implemented changes in price waterfall model \n\nto incorporate new price sources.    \n To create jobs and schedule them using Control M.   \n\nEnvironment: \nR Programming, QlikView, C#, Perl, T/Sql, Sql, Unix Shell Scripting. \n\n \nCMC Ltd. Delhi Sep 2013 - Feb 2014 \nTraining on Oracle and Asp.Net \n\n Training on Oracle and Ap.Net Using C#. \n \nUtility Management System. Dec 2013 - Feb 2014 \n\nThis application is used to manage assets assigned employees of particular organization. Assets include books, \nhardware, network equipment etc. \n \nRoles and Responsibilities:  \n\n Created UI design on Asp.Net.   \n Wrote procedures on oracle.   \n Handled events and validation.  \n\nEnvironment:  \nVisual Studio, Oracle 10g. \n\n \nACADEMIC PROJECTS \n\n \nChess Master Club Jan 2013 - Apr 2014 \n\nOnline chess game where user can play chess and chat with their opponent. It has profile management feature \nthat allows user to manage their profile with forum where they can post questions and answer question for \nknowledge transfer. Video tutorials and articles about famous players are also maintained. \n \nRoles and Responsibilities:  \n\n GUI using Html, CSS, js and JQuery.  \n Database creation and back end programming.  \n Validation handling.  \n\nEnvironment: \nEclipse, RAD, Appache, IBM DB2.  \n\nLanguage: \nJava, JSP, Servlets, Ajax, JavaScript, Html. \n\n \n\nActivites and Achivements \n● Received appreciation from APAC Risk IT head (Credit Suisse). \n● Certified in IBM Certified Application Developer - Rational Developer for Web Sphere Software v6.0 and IBM DB2 \n\nAcademic Associate - DB2 Database and Application Fundamentals \n\n● Organized Code Debugging at College Fest. \n● IBM Student Ambassador for my class in 2012.  \n\n \nPlace: PUNE          Date: 13 Nov 2017","annotation":[{"label":["Location"],"points":[{"start":5035,"end":5038,"text":"PUNE"}]},{"label":["Education"],"points":[{"start":1687,"end":1689,"text":"B.E"}]}],"extras":null,"metadata":{"first_done_at":1532684307000,"last_updated_at":1532684307000,"sec_taken":56,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Sirisha N \n\n  Bangalore  \n\nMob:  8867008398\n  Mail: sirisha0689@gmail.com\nLead Analyst | Skoruz Technologies Pvt Ltd\nSummary\n\n \nSkilled Lead Analyst with 4+ years of experience in Data Science / Analytics and full Life Cycle of Software Testing.\nDeveloped Statistical models which involved Data Collection, Data Cleaning, Data Preparation and Modelling using R Studio.\nDesign, Build, Deploy Machine Learning applications to solve the business problems.\nData Science enthusiast with zeal to learn and passion for working with data and finding insights. Pursued post graduate program in data science technologies.\nEquipped with Excellent Analytical, and Problem Solving Skills .\nAn effective team player with exceptional planning and execution skills coupled with a systematic approach and quick adaptability.\nWell-versed in exploring new technologies and tools that can be leveraged for better solutions. Experienced working in agile methodology.\nEducation\n\tPGP in Big Data Analytics and Optimization\nINSOFE\n\t2017 - 2018\n\n\tProgram is certified by the LTI at Carnegie Mellon University\n\t\n\n\tM.C.A\nB V Raju Institute of Computer Education, Andhra University\n\t2009 - 2012\n\n\tMaster of Computer Applications, CGPA 7.9\n\t\n\n\nSkills\nStatistical Modeling,Machine\nLearning and AI\nLinear regression, Logistic Regression, Time Series.Clustering (Hclust, K- means), Rule Extraction (APRIORI), Decision Trees (CART, C5.0), K-NN,\nSVM, ANN, Ensembles, GA, SVD, CNN.\nR Studio\n\n\n SHAPE  \\* MERGEFORMAT \n\n\n\nHave hands on experience working with Statistical Modeling and ML packages\nIBM Cognos ICM/Varicent\n\n\n SHAPE  \\* MERGEFORMAT \n\n\n\nCognos ICM certified from IBM-IBM000063836\nPython\n\n\n SHAPE  \\* MERGEFORMAT \n\n\n\nExposure to the basics on Python\nHadoop and Spark Ecosystem\n\n\n SHAPE  \\* MERGEFORMAT \n\n\n\nExposure to the basics on HDFS,YARN,Spark,Map Reduce,Hive,Pig\n SHAPE  \\* MERGEFORMAT \n\n\n\n\nKEY ACHIEVEMENTS\n\tSecured 4th Rank in Data Science Hackathon\nINSOFE\n\t2017\n\n\tWon Scholarship worth 40,000 INR\n\t\n\n\tAwarded Best Employee for 3 Consecutive Years VMware\n\t2013 - 2017\n\n\tAlso received Client appreciations and accolades for going Extra Mile in Project Delivery.\n\t\n\n\tParticipated in Kaggle and Analytics Vidhya Competitions\n\t\n\n\tMercedes-Benz, Loan Prediction, Black Friday Problems solved through ML Algorithms\n\t\n\n\nWork experience\nConsultant\nVMware Software India Private Limited\n\nFeb 2016 - Now\nOrders Hold Prediction - Logistic Regression and Decision Tree Models for VMware’s business team which identifies highly significant variables in the model, which help in setting up the perfect marketing strategies.\nIt helped business in terms of orders processing to meet the quarter end targets.\nIt helped to identify at bill-to level to find out which partners are sending bad data, which causes the order to go on hold.\nDelivered Customer Cluster Model at GEO level (AMER, EMEA, APJ) Identified which GEO behave similarly in terms of orders booking. Clustering helped in identifying customers that can be targeted.\nPredicting IBM Cognos ICM/Varicent Calc Run Time.\nApplied Machine Learning algorithms (Random Forest, GBM and XGBoost) to predict next Calc run time based on historical data of booking transactions, credit filters, product, customers tables as an input and selecting  the best model by considering the error metric.\nCommissions Business team successfully communicate and provide the ETA to sales reps about the Calc Run and delay of environment due to long running calculations if any.\nEstimating the calc run time helped a lot during the Pay Roll activities Since Sales reps will access the report and check the commissions earnings and payments of the month which will be done mid week and weekend depends up on Business request.\nResponsible for validating the integration of Varicent System with other upstream systems (Order management / Bookings/workday) and check if the Order Data booked by Sales representative are flowing into Varicent System (ICM) and validating the authenticity of the Plan, Territory and Quota elements for Sales representatives of all the GEOs.\nConsultant\nVMware Software India Private Limited\n\nJul 2013 - Jan 2016\nUsing IBM ICM tool, validate whether the commission rates calculated for the Sales representatives are correct as per the booked orders for particular quarter (GEO Wise).\nSupport, co-ordination and responsibility of the testing activities which includes review of test cases and test conditions, walk through of test cases with Client and Requirements understanding and estimations.\nInvolved in Smoke testing, Functional testing, Regression testing and a ttend meetings with developers and managers for risk assessment of project.Test lead for Commissions Optimization Tier1 projects which successfully deployed with bug free report for sales team.\nPlayed a crucial role in testing cycles for successful deployment of archival projects which improves the Calc performance of IBM Cognos ICM tool, by avoiding the recalculation for all the previous half year data.\n\nhttps://� HYPERLINK \"http://www.visualcv.com/sirishaexperience\" \\h �www.visualcv.com/sirishaexperience�\n\n\n\nhttps://� HYPERLINK \"http://www.visualcv.com/sirishaexperience\" \\h �www.visualcv.com/sirishaexperience�","annotation":[{"label":["Skills"],"points":[{"start":1523,"end":1542,"text":"Statistical Modeling"}]},{"label":["Skills"],"points":[{"start":1264,"end":1265,"text":"AI"}]},{"label":["Skills"],"points":[{"start":1243,"end":1258,"text":"Machine\nLearning"}]},{"label":["Skills"],"points":[{"start":1222,"end":1241,"text":"Statistical Modeling"}]},{"label":["Education"],"points":[{"start":1088,"end":1092,"text":"M.C.A"}]},{"label":["Location"],"points":[{"start":14,"end":23,"text":"Bangalore "}]},{"label":["Name"],"points":[{"start":0,"end":8,"text":"Sirisha N"}]}],"extras":null,"metadata":{"first_done_at":1532670393000,"last_updated_at":1532670393000,"sec_taken":88,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "SIVA ADITYA MOGANTI\n\nADDRESS:\n\n\n\n\n                       Contact No.  : 8555967364,\nAnanda Reddy layout,                                                      \n                                    7411653323\nElectronic City, Phase 2,                                                      \n        Email: siva_adithya@yahoo.com\nBangalore.\n\nCareer Objective:\n\nSeeking a challenging position in Analytics & Insights industry to utilize my technical skills and analytical abilities that would uplift my professional growth while being resourceful and innovative.\n\nSummary:\n\n\nOver all 6 years of experience in Data Analytics and Modelling using various statistical and machine learning techniques.\n\n· Expertise in Regression and Clustering Algorithm.\n\n· Expertise in Text mining and web scraping, Topic Modeling.\n\n· MILP, Sampling Theory, Ratio Estimation.\n· Cost Effectiveness Analysis, Budget Impact Model and Sensitivity Analysis.\n\nTechnical Skills:\n\n· Analytics Tools                  : R, MS Excel, MS VBA, Python (Sklearn, Numpy,  Pandas)\n· Relational Data Base       :  SQL, MS Access.\n\nProfessional Experience:\n\nCompany\n: TATA CONSULTANCY SERVICES, Bangalore.\n\nWork Period\n: From August-3rd 2011 to till Date\nDesignation\n: Assistant Manager\n\nRole\n\n: Data Scientist\nRoles & Responsibility:\n· Currently working in Analytics & Insights functional unit.\n\n· Team lead for a team of 12 members.\n\n· Collaborating with different business functions, understand business and meet expectations of customer, Power point presentations and client co-ordination.\n\nProjects: \n· Soiling Intelligence Solution for Solar Plants: \n\n· Anomaly detection in real time to avoid production loss due to physical damage or soiling impact using Regression analysis.\n\n· Energy forecast to identify Demand vs. Supply gap and right time to identify washing schedule.\n\n· Optimum Water Treatment Solution for Oil & Gas Industry:\n· Built an Optimum Water Treatment solution tool which recommends best treatment option with minimum cost using Python.\n· Inventory Re-allocation for Transportation:\n· Inventory optimization by analysis existing on-hand and demand inventory and identify re-allocation opportunities. Java based tool with R as a background engine has been developed.\n·   Tickets Classification to Accelerate Resolution Time:\n· Using historical ticket solutions as a reference, identified critical factors that adversely impact ticket resolution time and did ticket classification into relevant categories using Naïve-Bayes algorithm.\n· Opportunity assessment using Text Mining for Aviation:\n\n· Text mining to identify key business opportunities for two major airlines customers by performing web scraping and Topic modeling.\n\n· Retail Market Study:\n\n· Establish Retail Universe and study market dynamics by executing retail survey, store classification, estimating universe and sampling stores.\n\n· Healthcare Industry:\n\n· Pricing Analytics for healthcare manufacturer to identify customers to focus and opportunities for pricing changes. \n\n· Social media analytics for top healthcare equipment manufacturer to monitor and analyze customer discussions on social media forums using R.\n\n· Built Budget Impact model and Cost Effectiveness analysis for an underdeveloped country using VBA Macros.\n\n· Worked extensively on R, Python and VBA to automate the business requirement by Data Manipulation and Modelling.\nEducational Qualifications:\n\n\tQUALIFICATION\n\tCOLLEGE/INSTITUTION\n\tUNIVERSITY/BOARD\n\tYEAR OF PASSING\n\tCGPA/%\n\n\tM.Sc\n(Computer science & Statistics)\n\tDEPARTMENT OF STATISTICS\n\tANDHRA UNIVERSITY\n\t2011\n\t8\n\n\tB.Sc.(M.S.CS)\n\tK.G.R.L DEGREE COLLEGE\n\tANDHRA UNIVERSITY\n\t2009\n\t71%\n\n\tINTERMEDIATE\n\tADITYA JUNIOR COLLEGE\n\tBOARD OF INTERMEDIATE EDUCATION\n\t2006\n\t84%\n\n\tS.S.C\n\tMONTESSORI PUBLIC SCHOOL\n\tBOARD OF SECONDARY EDUCATION\n\t2004\n\t74%\n\n\nProfessional Achievements:\n\n· Awarded as “Star Performer” 11 times for outstanding contribution to the organization.\n\n· Received “Certificate of Appreciation” for automating process which reduced TAT.\nAcademic Achievements:\n\n· Secured N.C.C ‘A’ certificate in army wing.\n· Secured second prize in Kabadi at school level.\n· Secured first prize in shuttle at Inaugural Celebrations- Games and Sports 2010-2011 of Department Of Statistics, Andhra University. \n· Received Merit Scholarship for outstanding performance in II B.Sc. from Sri Shiridi Sai Baba Charitable Trust.\nPersonal Details:\n\nDate of Birth\n\n:    22-08-1988\n\nFather name\n\n:    M.V.Krishna Rao (late)\n\nLanguages Known\n:    English and Telugu.\nPermanent Address\n:   Moganti vari street, \n                                                   Near Municipal Office, Bhimavaram-534201,\n                                                   West Godavari District(AP).\nDeclaration:\n\n\nI hereby declare that the information and facts furnished above are true to the best of my knowledge and belief.\n\n\nPlace:  Bangalore\n\n\n\n         \n                                  Siva Aditya Moganti\n                                                                                                                                                           (Signature)","annotation":[{"label":["Location"],"points":[{"start":4874,"end":4882,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":4467,"end":4467,"text":"R"}]},{"label":["Skills"],"points":[{"start":4275,"end":4275,"text":"R"}]},{"label":["Skills"],"points":[{"start":3936,"end":3936,"text":"R"}]},{"label":["Skills"],"points":[{"start":3790,"end":3790,"text":"R"}]},{"label":["Skills"],"points":[{"start":3777,"end":3777,"text":"R"}]},{"label":["Skills"],"points":[{"start":3756,"end":3756,"text":"R"}]},{"label":["Skills"],"points":[{"start":3709,"end":3709,"text":"R"}]},{"label":["Skills"],"points":[{"start":3699,"end":3699,"text":"R"}]},{"label":["Skills"],"points":[{"start":3685,"end":3685,"text":"R"}]},{"label":["Skills"],"points":[{"start":3663,"end":3663,"text":"R"}]},{"label":["Skills"],"points":[{"start":3640,"end":3640,"text":"R"}]},{"label":["Skills"],"points":[{"start":3632,"end":3632,"text":"R"}]},{"label":["Skills"],"points":[{"start":3615,"end":3615,"text":"R"}]},{"label":["Skills"],"points":[{"start":3608,"end":3608,"text":"R"}]},{"label":["Skills"],"points":[{"start":3572,"end":3572,"text":"R"}]},{"label":["Skills"],"points":[{"start":3564,"end":3564,"text":"R"}]},{"label":["Skills"],"points":[{"start":3538,"end":3538,"text":"R"}]},{"label":["Education"],"points":[{"start":3496,"end":3499,"text":"M.Sc"}]},{"label":["Skills"],"points":[{"start":3473,"end":3473,"text":"R"}]},{"label":["Skills"],"points":[{"start":3466,"end":3466,"text":"R"}]},{"label":["Skills"],"points":[{"start":3457,"end":3457,"text":"R"}]},{"label":["Skills"],"points":[{"start":3297,"end":3304,"text":" Python "}]},{"label":["Skills"],"points":[{"start":3295,"end":3295,"text":"R"}]},{"label":["Skills"],"points":[{"start":3158,"end":3158,"text":"R"}]},{"label":["Skills"],"points":[{"start":2740,"end":2740,"text":"R"}]},{"label":["Skills"],"points":[{"start":2706,"end":2706,"text":"R"}]},{"label":["Skills"],"points":[{"start":2286,"end":2286,"text":"R"}]},{"label":["Skills"],"points":[{"start":2200,"end":2200,"text":"R"}]},{"label":["Skills"],"points":[{"start":2028,"end":2028,"text":"R"}]},{"label":["Skills"],"points":[{"start":1717,"end":1717,"text":"R"}]},{"label":["Skills"],"points":[{"start":1273,"end":1273,"text":"R"}]},{"label":["Skills"],"points":[{"start":1265,"end":1265,"text":"R"}]},{"label":["Skills"],"points":[{"start":1242,"end":1242,"text":"R"}]},{"label":["Location"],"points":[{"start":1149,"end":1157,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":1141,"end":1141,"text":"R"}]},{"label":["Skills"],"points":[{"start":1074,"end":1082,"text":"MS Access"}]},{"label":["Skills"],"points":[{"start":1069,"end":1071,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1039,"end":1039,"text":"R"}]},{"label":["Skills"],"points":[{"start":1003,"end":1010,"text":" Python "}]},{"label":["Skills"],"points":[{"start":995,"end":1001,"text":" MS VBA"}]},{"label":["Skills"],"points":[{"start":986,"end":993,"text":"MS Excel"}]},{"label":["Skills"],"points":[{"start":983,"end":983,"text":"R"}]},{"label":["Skills"],"points":[{"start":831,"end":831,"text":"R"}]},{"label":["Skills"],"points":[{"start":706,"end":706,"text":"R"}]},{"label":["Location"],"points":[{"start":324,"end":332,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":91,"end":91,"text":"R"}]},{"label":["Skills"],"points":[{"start":24,"end":24,"text":"R"}]},{"label":["Name"],"points":[{"start":0,"end":18,"text":"SIVA ADITYA MOGANTI"}]}],"extras":null,"metadata":{"first_done_at":1532689950000,"last_updated_at":1532689950000,"sec_taken":126,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Sonia Vikas Rajput | soniarajput01@gmail.com |81697 35367\n\n\nSummary\nAnalyst with over 4 years of work experience in Data Analytics from Pentation Analytics, Capgemini and Patni Computers Systems; Post Graduate in Data Science\n• Strong client services expertise: Worked closely with direct client interactions for clients like Metlife and Guardian across various horizontals like HR, Insurance, IT, etc.\n• Strong expertise in R and Tableau which is a fast-growing interactive data analytics and visualization tool\n• Proficient at database management tools like IBM SPSS and languages like SQL, R etc.\n• Good grasping power to learn and master new tools/softwares quickly.\n\n\nSkills:\n· Programming Languages : R and Python\n· Frameworks: Anaconda and Jupyter \n· Databases:  SQL Server and HP Vertica\n· Machine Learning : Regression, Classification, Clustering, Time Series Analysis, Dimensionality Reduction and Recommender Systems\n· Visualization : ggplot2 (R) , Tableau, IBM SPSS, IBM Cognos and Qliksense\n\n\n\nEmployment History and Job Description\n\n· Pentation Analytics   \nAn Insurance Analytics company wherein large data is analyzed for decision making by discovering patterns by collecting, organizing and analyzing large sets of data.\n· Data Analyst (June 2017 – Sep 2017)\n· Handled project management responsibilities for various clients. Contributed as a Data Analyst to develop a motor claim insurance data model by using SQL Server, R language and HP Vertica for analyzing big data. Infrastructure set up included working on Azure Server, CentOS and Vertica Database Implemented Clustering algorithm on distributed R in Vertica Database. \n· To build a Customer Profile Segmentation model based on market segmentation. The objective of the project was to improve the process efficiency by accurately monitoring processing time, renewal behavior of claiming customers, first time vs repeat claimants.\n· Prepared dashboards and reports on Tableau \n\n· Capgemini\n· Associate (July 2015 – May 2016)\n· Responsibilities included HR Analytics using R language and Tableau and end to end recruitment for hiring candidates into BI domain for requirements such as Informatica, Teradata, Cognos, Cognos TM1, Tableau, Greenplum, Cassandra etc.\n· Developed a Tableau Dashboard to regulate the Human Resources off-boarding process. \n· Developed a Tableau Dashboard for Senior Management Team to track the Travel and Expenses reimbursements of each employee through a hierarchy, limiting necessary data based on user log-in.\n• This dashboard was directly consumed by 30 members of the Senior Management Team \nwhich helped them minimize the cost to company by identifying cost saving opportunities  \n\n\n\n· Patni Computers Systems Ltd.\n· Software Engineer (Oct 2006 – Jan 2010)  Metlife and Guardian Insurance Life\n· Involved in managing all facets of SDLC project lifecycle-requirements gathering, data cleaning and analysis, technical specification, data modelling, design, development, testing, deployment and post production support and maintenance.\n· Strong working knowledge in R, Mainframe languages & various tools.\n· Implemented a high end interactive statistical performance dashboard project end to end using R programming. \n· Developed Tableau Workbook and Dashboard for Guardian\n· Experienced in environments requiring direct Customer interaction during specifications, development and project implementation phases.\n\n\n______________________________________________________________________________________\n\nAcademic and Self-Learn Projects: \n\n· Cancer prediction (Benign or Malignant) : knn clustering algorithm\n· Customer Segmentation based on Age, Income and Spending Score: K-Means\n· Churn Prediction of a telecommunications company : Random Forest\n· Social Media Analysis \n· Predicting Customer Shopping Trends with Market Basket Analysis\n· Building a Product Recommendation System\n· Credit Risk Detection and Prediction\n· Segmentation based on frequently used words on Twitter : K-Means\n· Capstone Project: H1B Visa Petitions Analysis: https://sonia-rajput.shinyapps.io/shinyapp/\nObjective: To know which employers submit the most number of H1B visa applications, most common job titles applied by the high applicant employers, salary comparison for software jobs.\nTools used: R, Python (Scrapy Web Crawler), Shiny\n__________________________________________________________________________________________\n\nEducation\n\nPost Graduate Program (PGP) in Business Analytics, Big Data and Data Science \nAegis School of Business, Telecommunication and Data Science jointly certified with IBM \t(2016-2017)\n\nBachelor of Science in Information Technology\nSouth Indian Education Society College\t\t \t\t\t\t\t\t (2003-2006) \t\t\t(70%)\n\n\nSummary of Strengths \n\n· Good analytical and communication skills.\n· Self-motivated.\n· Assertive.\n· Adaptable to change.\n· Quick in identifying problems and providing best solutions.\n· High level of physical and mental endurance.","annotation":[{"label":["Education"],"points":[{"start":4423,"end":4449,"text":"Post Graduate Program (PGP)"}]},{"label":["Skills"],"points":[{"start":4285,"end":4290,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4282,"end":4282,"text":"R"}]},{"label":["Skills"],"points":[{"start":3895,"end":3895,"text":"R"}]},{"label":["Skills"],"points":[{"start":3864,"end":3864,"text":"R"}]},{"label":["Skills"],"points":[{"start":3738,"end":3738,"text":"R"}]},{"label":["Skills"],"points":[{"start":3207,"end":3207,"text":"R"}]},{"label":["Skills"],"points":[{"start":3074,"end":3092,"text":"Mainframe languages"}]},{"label":["Skills"],"points":[{"start":3071,"end":3071,"text":"R"}]},{"label":["Skills"],"points":[{"start":2291,"end":2291,"text":"R"}]},{"label":["Skills"],"points":[{"start":2047,"end":2047,"text":"R"}]},{"label":["Skills"],"points":[{"start":2029,"end":2029,"text":"R"}]},{"label":["Skills"],"points":[{"start":2002,"end":2002,"text":"R"}]},{"label":["Skills"],"points":[{"start":1622,"end":1622,"text":"R"}]},{"label":["Skills"],"points":[{"start":1440,"end":1440,"text":"R"}]},{"label":["Skills"],"points":[{"start":955,"end":955,"text":"R"}]},{"label":["Skills"],"points":[{"start":908,"end":908,"text":"R"}]},{"label":["Skills"],"points":[{"start":894,"end":894,"text":"R"}]},{"label":["Skills"],"points":[{"start":817,"end":817,"text":"R"}]},{"label":["Skills"],"points":[{"start":713,"end":718,"text":"Python"}]},{"label":["Skills"],"points":[{"start":707,"end":707,"text":"R"}]},{"label":["Skills"],"points":[{"start":593,"end":593,"text":"R"}]},{"label":["Skills"],"points":[{"start":425,"end":425,"text":"R"}]},{"label":["Skills"],"points":[{"start":380,"end":380,"text":"R"}]},{"label":["Skills"],"points":[{"start":12,"end":12,"text":"R"}]},{"label":["Name"],"points":[{"start":0,"end":17,"text":"Sonia Vikas Rajput"}]}],"extras":null,"metadata":{"first_done_at":1532676234000,"last_updated_at":1532676234000,"sec_taken":142,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Soumik Sarkar\n\n\n\tFlat 304, Orange Block, Kamal residency, Sonarpur station Road,\nKamalgazi, \n\tContact No.: (+91)9836059005\n\n\tKolkata -700103, West Bengal, India\n\t\n\n\t\n\tsoumikadams@outlook.com\n\n\t\nSenior Consultant, \nPricewaterhouse Coopers India\n\t\nExperience: 5 years\n\n\tProfessional Summary\n\t\n\n\tRole: Senior Developer\n\n\t· Currently working as Senior Consultant, playing a key role in implementation of project SDLC phases (Design, Coding and Unit testing).\n· Passionate about learning and implementing new technologies and creating solutions helping people and making their life easy.\n· Good awareness of processes executed in insurance domain.\n· Ability to learn quickly, good communication skill, highly motivated and result oriented.\n· Very much involved in different aspects of development and assimilate new concepts.\n\n\tExperience Summary\n\n\t\nWorking for Pricewaterhouse Coopers India, as a Senior Consultant from June 2017 to present, associated with development of a chat bot facilitating queries and performing actions for our client’s Human Resource communication. \nFormerly worked for Cognizant Technology Solutions as an Associate from January 2016 to May 2017 associated with developing a tool for data migration of our Banking and Financial Services client. Started career working for Tata Consultancy Services from October 2012 to January 2016, associated with Development of Producer Administration and Compensation calculation application batch processes and Testing PNL web application.\n\n\n\tEducation Summary\n\n\t\tDegree\n\tUniversity\n\tYear\n\tGrade\n\n\tB.Tech , Electronics & Communication Engineering\n\tWest Bengal University of Technology, WB\n\t2012\n\t7.9 (GPA)\n\n\t12th\n\tCBSE\n\t2008\n\t80%\n\n\t10th\n\tCBSE\n\t2006\n\t82%\n\n\n\n\n\tTechnical Skill\n\n\tOperating System\n\tMicrosoft  Windows\n\n\tLanguage\n\tCoreJava, JSP,JDBC,Servlets, J2EE(Spring, Hibernate), SQL\n\n\tSoftware Product\n\tOracle 11g, Eclipse, System-i-navigator(AS400 DB2 Interface), Apache Tomcat Server, TCS Mastercraft, SVN, VSS, JIRA, Jenkins\n\n\tTechnology\n\tREST Web Services (MVC framework), SpringBatch , SpringMVC, Framework, SpringData, Spring Boot, Spring Integration Spring Security, JPA, Hibernate, Maven, Gradle, JUnit, jQuery, Ajax, HTML, CSS, NodeJS, IBM Bluemix Technologies(IBM Watson Conversation, IBM Watson Natural Language Classifier, Node-Red, IBM CloudFoundry, IBM Cloudant NoSQL Database).\n\n\tProject Experience\n\n\tTitle\n\tDesign and Development of a middleware application for Order Processing System connecting multiple systems together.\n\n\tPeriod\n\tJune 2017 to Present\n\n\tProject\n\tDevelop an Order Processing middleware solution, using Spring Integration, connecting multiple systems together to process the order for our telecom client. The application takes the orders from a customer facing API and calls the related SOAP and REST services, processes the responses and returns the HTTP Response back to the customer facing API\n\n\tResponsibilities\n\tAs an Offshore Developer, responsible for \n· Interacting with the business clients to understand their requirements.\n· Involved in design and coding by Spring Integration, REST webservices\n· Involved in Unit testing and Integration testing of the developed code.\n· Involved in continuous integration using Jenkins.\n· Responsible for understanding the upgrade requirements and   making appropriate code changes, unit and system testing.\n\n\n\tEnvironment\n\tSpring Integration, SpringBoot, JDBC Template\n\n\tApplication Server\n\tTomcat Server, JBoss Wildfly 10 Application Server.\n\n\t\n\t\n\n\tTitle\n\tDesign and Development of a Chat Bot facilitating queries and performing actions for our client’s Human Resource Department\n\n\tPeriod\n\tJune 2017 to July 2017\n\n\tProject\n\tDesign and develop a chat bot integrated with Facebook messenger as the client, NodeJS as the server side technology and integrating with IBM Watson Conversation API. The bot is responsible for answering normal queries and also performing advanced tasks related to our client’s Human Resource Department.\n\n\tResponsibilities\n\tAs an Offshore Developer, responsible for \n· Interacting with the business clients to understand their requirements.\n· Involved in design and coding by using IBM Watson Conversation, Node-Red, NodeJS, Facebook APIs\n· Involved in Unit testing and Integration testing of the developed code.\n\n· Responsible for understanding the upgrade requirements and   making appropriate code changes, unit and system testing.\n\n\n\tEnvironment\n\tIBM Bluemix Technologies (Watson Conversation API, Node RED, Cloudfoundry) \n\n\tApplication Server\n\tNodeJS Express Server, IBM Cloudfoundry for hosting\n\n\t\n\n\tTitle\n\tDevelopment of an ETL tool for data migration\n\n\tPeriod\n\tJanuary 2016 to May 2017\n\n\tProject\n\tThe ETL tool is responsible for the data migration of our BFS client’s legacy system to an updated system. It ensures full flow of extraction, transformation or processing the data and loading the data to the destination database invoking client given Webservices. The tool is being developed using Springbatch framework, Spring data, JPA Hibernate, using build tools like Gradle, and is being used to migrate millions of data in a small amount of time.\n\n\tResponsibilities\n\tAs an Offshore Developer, responsible for \n· Interacting with the business clients to understand their requirements.\n· Involved in coding by using Java, Springbatch\n· Modification of the Spring batch admin UI into a customized client specific UI using jQuery,Ajax, Freemarker template(FTL),CSS.\n· Involved in Unit testing and Integration testing of the developed code using JUnit.\n· Led the technical team of 4 persons to achieve added features in the Migration Tool.\n· Responsible for understanding the upgrade requirements and   making appropriate code changes, unit and system testing, data configuration and maintaining repository.\n\n\n\tEnvironment\n\tJava, Spring Batch, SpringMVC, SpringData, Spring Boot, Spring Security, JPA Hibernate, Gradle\n\n\tApplication Server\n\tLiberty Server in UAT and Production, Tomcat Server in Local Dev Environment.\n\n\t\n\n\tTitle\n\tDevelopment of Web Services for a Claims and Policy Management System for an Insurance Client\n\n\tPeriod\n\tSeptember 2015 to December 2016\n\n\tProject\n\tThe System manages the existing policies and claims of the various distribution channels of our client such as agents, units, banks etc. It’s a web application whose users are agent managers, unit managers, bankers.\n\n\tResponsibilities\n\tAs an Offshore Developer, responsible for \n· Interacting with the business clients to understand their requirements.\n· Involved in coding by using Java, REST Webservices, JDBC Template\n· Involved in Unit testing and Integration testing of the developed code using Postman.\n· Responsible for understanding the upgrade requirements and   making appropriate code changes, unit and system testing, data configuration and maintaining repository.\n\n\n\tEnvironment\n\tJava, Spring MVC, REST Webservices, JDBC Template, Maven, JSON\n\n\tApplication Server\n\tWebsphere Application Server\n\n\t\n\n\tTitle\n\tDesign and Development on Batch Framework for a Compensation and Commission Calculation System’s Batch Process(named as iPAC Batch)\n\n\tPeriod\n\tJuly 2013 to August 2015\n\n\tProject\n\tiPAC Batch calculates the compensation and commissions, overrides, various types of bonuses of the various distribution channels of our client such as Agents, Unit Managers and Agency Managers by running a batch cycle every month for eleven different regions.\n\n\tPosition\n\tOffshore Developer\n\n\tResponsibilities\n\tAs an Offshore Developer, responsible for \n· Interacting with the business clients to understand their requirements.\n· Involved in the analysis phase of the project in code comparison. \n· Involved in coding by using Java, SpringBatch, Hibernate.\n· Involved in Unit testing and Integration testing of the developed code.\n· Responsible for understanding the upgrade requirements and   making appropriate code changes, unit and system testing, data configuration and maintaining repository.\n\n\tEnvironment\n\tJava, Spring, Hibernate, DB2\n\n\t\n\n\tTitle\n\tProfit and Loss calculation application\n\n\tPeriod\n\tMarch 2013 to July 2013\n\n\tProject\n\tProfit and Loss (abbreviated as PNL) application was to calculate the profits, commissions of our client in different parts of the world wherever there is a business of our client. A web application was developed by which users can login, upload csv files, and the system would process the data according to the clients requirements and display it and also generate the reports in spreadsheet format.\n\n\tPosition\n\tOffshore Tester\n\n\tResponsibilities\n\tAs part of an Offshore testing team, responsible for \n· Interacting with the business clients to understand their requirements.\n· Involved in testing the application.\n· Involved in Integration testing of the developed code.\n· Involved in regression testing.\n\n\tEnvironment\n\tJava, Spring 3 ,Hibernate 2, Web Services, TCS Mastercraft (a defect logging tool)\n\n\tApplication Server\n\tApache Tomcat Server  Version 6\n\n\tPersonal Detail\n\n\tFather’s Name\n\tBimal Sarkar\n\n\tDate of Birth\n\t01.02.1990\n\n\tLanguages known\n\tEnglish, Hindi, Bengali\n\n\tPassport Detail\n\tPassport  No K7615533, issued on 11/4/2013\n\n\tPAN Details\n\tPAN No. DTMPS6579E","annotation":[{"label":["Skills"],"points":[{"start":6882,"end":6885,"text":"JDBC"}]},{"label":["Skills"],"points":[{"start":6560,"end":6563,"text":"JDBC"}]},{"label":["Skills"],"points":[{"start":5406,"end":5409,"text":"Ajax"}]},{"label":["Skills"],"points":[{"start":4150,"end":4159,"text":"IBM Watson"}]},{"label":["Skills"],"points":[{"start":3805,"end":3814,"text":"IBM Watson"}]},{"label":["Skills"],"points":[{"start":3397,"end":3400,"text":"JDBC"}]},{"label":["Skills"],"points":[{"start":2340,"end":2342,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":2257,"end":2266,"text":"IBM Watson"}]},{"label":["Skills"],"points":[{"start":2232,"end":2241,"text":"IBM Watson"}]},{"label":["Skills"],"points":[{"start":2193,"end":2196,"text":" CSS"}]},{"label":["Skills"],"points":[{"start":2187,"end":2191,"text":" HTML"}]},{"label":["Skills"],"points":[{"start":2182,"end":2185,"text":"Ajax"}]},{"label":["Skills"],"points":[{"start":1841,"end":1843,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1816,"end":1838,"text":"J2EE(Spring, Hibernate)"}]},{"label":["Skills"],"points":[{"start":1806,"end":1813,"text":"Servlets"}]},{"label":["Skills"],"points":[{"start":1801,"end":1804,"text":"JDBC"}]},{"label":["Skills"],"points":[{"start":1797,"end":1799,"text":"JSP"}]},{"label":["Skills"],"points":[{"start":1787,"end":1794,"text":"CoreJava"}]},{"label":["Education"],"points":[{"start":1559,"end":1565,"text":"B.Tech "}]},{"label":["Location"],"points":[{"start":125,"end":131,"text":"Kolkata"}]},{"label":["Name"],"points":[{"start":0,"end":13,"text":"Soumik Sarkar\n"}]}],"extras":null,"metadata":{"first_done_at":1532683895000,"last_updated_at":1532683895000,"sec_taken":434,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "SOUMYAANSH ROY \n E-mail: royansh5555@gmail.com \n Mobile: +91-8861690442  \n\n \n\nProfessional Profile \nI am a data enthusiast, former Java programmer with newly acquired skills, an insatiable \nintellectual curiosity, and the ability to mine hidden gems located within datasets. Able to \nleverage a heavy dose of analytics and applied statistics with visualization and a healthy sense \nof exploration. \n \n\n● Having 2+ years of experience in machine learning, predictive modelling, statistical modelling. \n● Having 5+ years of Programming experience in Software Development. \n● Programming expertise in java, python. \n● Incorporate analysis of raw data in order to draw conclusions and make recommendations. \n\n \n\n \n\nWork Experience Academic Qualification  \n2015 June - 2017 Aug | Acrowit Technologies  B.E  from G.G.I.T.S  Computer Sci 2009 73.2% \n\n2014 Dec - 2015 May | Acuver Consulting  H.S.C from C.M.M 54.8% \n\n2012 July - 2014 Nov  | Megalon eConcepts India S.S.C from C.M.M 62.3% \n \n\nProgramming and Development Skills and Tools \nPackages: Pandas, Numpy, Scikit Learn, NLTK, Gensim, Matplotlib, PySpark, Anaconda3, Scipy \nTools: Jupyter Notebook on AWS Cloud, Zeppelin with Amazon EMR clusters using Spark on Hadoop \nYARN with Ganglia, Pycharm, Eclipse for Java \nAnalytical Techniques: Logistic and Linear Regression, Decision Trees, Random Forest, KNN, Naive \nBayes \nNLP: Text Classification , Word Embedding BOW, TF-IDF, LDA, Sentiment Analysis \n \n\nProject Details \nProject Title: Recommender System \nClient: Oracle, Citrix \nTeam Size: 2 \nTechnologies Used: Python, Machine Learning, Information Retrieval. \nAnalytical Tools: Python | Analytical Techniques: Cosine Similarity, Latent Dirichlet Allocation \nProject Description: Recommender systems suggest users the desired information through the analyses \nof their past preferences, we have used LDA as dimension reduction approaches to explore text content \nfeatures by revealing latent topics of each document from the document repository, with latent topics \nuncovered, we can derive document similarity more precisely using Cosine Similarity on the vectors of \n\n \n \n\n\n\n \n\ndocument topics to comprehend user’s requirements and make more relevant recommendation. \n \n\n \n\nProject Title: Predicting automobile price \nClient: Autovlan  \nTeam Size: 2 \nTechnologies Used: Python, Machine Learning  \nAnalytical Tools: Python | Analytical Techniques:  Predictive modelling, Random Forest Regressor \nProject Detail: This project has been dedicated to predict the used car pricing, building a predictive model \nfirst requires shaping the data into the right format to meet the mathematical assumptions of machine \nlearning algorithms and establishing an objective of a predictive model and preprocessing the data. \nPre-processing data includes munging heterogeneous data into a representation that is suitable for \nscikit-learn models which also includes handling anomalies like removing the outliers and taking care of \nmissing data and extrapolating the data using feature engineering to improve the model performance. \n \n \nProject Title: Email Activity Management  \nClient: Oracle, Hayzlett Groups \nTechnologies Used: Java, Information Retrieval and MongoDB. \nProject Description: It is a part of Campaign module of WittyParrot Project where everyday thousands \nof mails needs to be sent to the customers, prospects, new leads, to scale up the business we use different \nways of tracking the mails to personalize each and every mail for better customer engagement, to \nredefine the accessibility and approachability we capture the Read Rates, Forwards and Printing of each \nand every mails so that we can provide the personalized experience to users.","annotation":[{"label":["Education"],"points":[{"start":797,"end":799,"text":"B.E"}]},{"label":["Skills"],"points":[{"start":604,"end":609,"text":"python"}]},{"label":["Skills"],"points":[{"start":598,"end":601,"text":"java"}]},{"label":["Skills"],"points":[{"start":477,"end":497,"text":"statistical modelling"}]},{"label":["Skills"],"points":[{"start":455,"end":474,"text":"predictive modelling"}]},{"label":["Skills"],"points":[{"start":437,"end":452,"text":"machine learning"}]},{"label":["Name"],"points":[{"start":0,"end":13,"text":"SOUMYAANSH ROY"}]}],"extras":null,"metadata":{"first_done_at":1532679831000,"last_updated_at":1532679831000,"sec_taken":132,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Srinivas Sinbi Reddy\nData Scientist Consultant \nMail: srinudatascience@gmail.com\nPhone: +91 – 8867614436\n\n\tSummary\n\n\n       \n· Having 4+ Years of Experience in IT industry out of which 2+ yrs of experience as a Data Scientist Consultant. \n· Experience in statistical & quantitative analysis using R and data driven decision-making and have very good understanding of Data mining techniques. \n· Good exposure to Data Mining Techniques like clustering, market basket analysis and developing association rules etc, good knowledge on Deep Learning concepts. \n· Exposure to web extraction and text mining in R. \n· Worked on machine learning algorithms like Decision Tree, Random Forest, SVM. \n· Working knowledge in building Prediction Models using linear regression, multiple linear regression analysis, and logistic regression analysis techniques. \n· Experience in tools like R Scripting language, Visualizations in R and Basic Knowledge on Apache Spark.\n· Having very good experience on Statistics and Predictive Analysis. \n· Having good experience on creating Graphs by using ggplot.\n· Having good knowledge in SQL and PL/SQL.\n\nEducation: \n         \n1. B.Tech  from JNTU Hyderabad in 2013.\n\n\n\tPROFESSIONAL EXPERIENCE\n\n\n1. Working as a Data Scientist consultant for Syniverse from Bangalore  Jul‘2013 to till date.\n\tProjects\n\n\nProject#3\nClient: Syniverse\nOrganization: Syniverse\nRole: Junior Data Scientist \nDuration:  Nov‘ 2015  to till Date\nEnvironment:  R 3.4.3 \nProject Type: Data Analytics Out sourcing Projects\nResponsibilities:\n\n\n· Working knowledge in building Prediction Models using linear regression, multiple linear regression analysis, and logistic regression analysis techniques.  \n· Worked on various machine learning algorithams like Linear Regression,Logistic regression, Decision Trees and Random Forest Algorithams. \n· Worked on the Prediction of new Employee Salary according to company standards using Linear Regression Machine Learning Algoritham\n· Worked on the Prediction of One of the Startup company whether the comapny will get Profit or loss using Linear Regression Machine learning algorithams.\n· Worked for the analysis of one of the Social network comapny uisng Logistic regression method.\n· Experience in tools like R Scripting language, Visualizations in R and Basic Knowledge on Apache Spark.\n· Having very good knowledge on Statistics and Predictive Analysis. \n\nProject # 2\n\nClient: Wilson Geat batch Technologies.\nOrganization: Wipro Technologies.\nRole: Fusion HCM Technical Consultant.\nDuration:  Aug‘2014 to Nov‘2015\nEnvironment: R10\nProject Type: Implementation and Support \nDescription\nWilson Great batch Technologies, co-inventor of the ﬁrst successful implanted pacemaker, founded Greatbatch, Inc. in 1970 to develop long-lived primary batteries to fuel pacemakers. They manufacture to customer and best-practice speciﬁcations. They deliver comprehensive consulting expertise and assembly services. Every day, Greatbatch supports and empowers its customers in their pursuit of revolutionary technology solutions.\n\nRoles and Responsibilities:\n· Handling the security aspect in Core HR e.g. Role provisioning, assigning data roles and duty roles to various users and creating security profiles \n·  Managing user accounts and Approval workflows through BPM work list and Oracle Identity Management (IDM) \n· Set-up/Configuration and detailed design for Fusion HCM R10\n·  Uploaded configuration and set-up data using HCM Data Loader \n· Development of the reports as per the requirement.\n· Involved in the Development of the Personalization’s.\n· Involved in the Development of the Customizations.\n· Development of the Report by creating the Dash Boards.\n· Creation of the elements and user defined tables.\n· Worked on the Payroll Batch Loader for various requirements.\n·  Identification and handling of errors related to migration and configurations \n·  Prepared detailed functional design documents \n·  Worked with Business analysts to gather requirements and document them \n·  Conducted Conference Room pilots with overview of Fusion HCM \n\nProject #1\nClient: Merichem \nProject Type: Implementation \nRole: Technical Developer \nEnvironment: Oracle Applications R12 \nDuration: Jul‘2013 to Jul‘2014\nDescription: \nMerichem Company provides a diversified portfolio of products and services to a wide range of operations, including the refining and petrochemicals industries. With more than 1,000 licensed process units worldwide, Merichem is the leader in licensing patented process technologies and supplying proprietary equipment to provide hydrocarbon treating solutions and by-product management services that remove sulfur and other impurities from hydrocarbon liquids and gases in the upstream and downstream energy sectors.\n     Roles and Responsibilities: \n· Studying, understanding and analyzing the given Functional Documents and responsible to prepare Technical Documents\n· Development and Customization of the assigned RICE Components according to the requirement and development standards\n· Developed RFQ Report using XML Publisher\n· Developed the Purchase Order Report\n· Concurrent program definitions and Executable\n· Involved in Unit testing of RICE Components\n· Creating database Triggers\n· Writing SQL queries according to customer requirement\n· Understanding customer issues\n· Analyzing logs and providing remedy to customers\n· Preparing Unit test\n· Developing  Reports\n\n\n1","annotation":[{"label":["Skills"],"points":[{"start":5246,"end":5248,"text":"SQL"}]},{"label":["Education"],"points":[{"start":1152,"end":1157,"text":"B.Tech"}]},{"label":["Skills"],"points":[{"start":1121,"end":1123,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1117,"end":1124,"text":" PL/SQL."}]},{"label":["Skills"],"points":[{"start":1110,"end":1112,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":411,"end":432,"text":"Data Mining Techniques"}]},{"label":["Name"],"points":[{"start":0,"end":19,"text":"Srinivas Sinbi Reddy"}]}],"extras":null,"metadata":{"first_done_at":1532672009000,"last_updated_at":1532672009000,"sec_taken":151,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "SUBHASH SINGH\t\t\t\t\t\t\t\nEmail: subhash.rdev@yahoo.com\nMob: 7065569770, 9250764260\t\t\t\t\t     \t Address:  Delhi -84\n-------------------------------------------------------------------------------------------------------------------\nIntend to build a career with leading organization of Hi-Tech environment, which will help me to explore myself fully and realize my potential. \n\nEXPERIENCE:\n\n1. Having 5 year experience in developing application in ColdFusion.\n2. Having 4 year experience in R/Python programming, Data Mining, Statistical Modeling.\n3. Working experience in different software methodology like waterfall, Agile.\n4. Experience with databases like  Sql Server, MySQL.\n5. Good command on LINUX.\n6. Proficient in structured query language (SQL)\n\nProfessional Summary:\n\n1. Capable of processing large sets data through R and supporting systems application architecture.\n2. Having knowledge of installing, configuring, monitoring Hadoop (Map Reduce),PIG, HIVE, Python.\n\nProfessional Qualification:\n\tMCA (Regular) from U.P. Technical University.\n\tB Sc (M) from B. R. Ambedkar University Agra.\n\nTECHNICAL SKILL SETS:\n1. Machine Learning       : Supervised, Unsupervised\n1. IDE\t\t\t: R Studio ,Eclipse, HPQC, ATP\n1. Database\t\t: SQL Server , Oracle,  My-SQL\n1. Web Technologies\t: HTML, JavaScript, Cold Fusion , AJAX,CSS\n1. Version  Control\t: SVN, Jira, Lotus Notes\n1. Programming \t: R , Python, Core Java, Java Script, XML, XSLT, Excel 2013\n0. Algorithm\t\t:Decision Tree, Random Forest, SVM,  Linear Regression, KNN, Naïve \n                                                              Bayes, Logistic Regression ,Time Series Analysis,\n                                                              Normal Distribution\n0. Popular R Packages  \t: Party, Caret, Data Table, ggplot2, MICE, Misforest, json,  dplyr,  stats,      \n0.                                                rpart, randomforest, lm, glm, car, XML,Stringr,plyr, RCurl,xlsx\n0.                                                RMySQL and MASS\n0. Python Tools\t\t:  Numpy, Scipy, Pandas, Numba, matplotlib\n1. Techniques: \t\t: Principal Component Analysis, R Square, Confusion Matrix, \n0. \t\t\t  Hypothesis Testing, Machine Learning, Predictive Modeling\n\nCompany: Sapient Nitro\t\t\t                                  17-April-2017 to 26-Oct-2017\nProject Name: Lounge Key Pass\nDesignation/Role: Sr. Developer (Module Lead)\nDatabase:  SQL Server 2014\nTime Duration : 17-April-2017 to Till now\nIDE: Eclipse, Spyder\nLanguage:  Python\nAlgorithm : SVM- Classification\nDescription: LoungeKey Pass is an application which is used to generate the single use lounge passes for customer/clients for a specific period of time. There are total fore type of Key Passes managed by this application (Single Use Pass,Priority Pass,Lounge Key,Lounge Club).\nCreated Successful Model on the Dataset: [CardInformation] to identify the issued cards used maximum times by customer, So that company can provide an offer on the cards to the customer on behalf of their uses. By using the below steps developed the model on total \nFollowed Steps for creating Models are \n1. Collect the data from the source (CardInformation.csv file)\n2. Data preparation and missing/Outlier treatment\n3. Data Analysis and feature engineering.\n4. Train Algorithm on training and validation data.\n5. Test the algorithm on test data.\n6. Deploy the algorithm\nCompany: Sapient Nitro\t\t\t                                   17-April-2017 to 26-Oct-2017\nProject Name: Card Tokenizer\nDesignation/Role: Sr. Developer (Module Lead)\nDatabase:  SQL Server 2014\nTime Duration : 17-April-2017 to Till now\nIDE: Spyder, Eclipse, django\nLanguage: Python\nDescription: CardTokeniser is the concept of Banking and i have implemented the concept of card Tokenizer on existing system for following types of Cards(MasterCard, Visa, Visa Electronic), Every time when any given card will go for processing ,system will check the existence of that particular card information from the third Party data source then after that ,if the card does exists, then it will check the fingerprint for that card, if  card Fingerprint  is exist then it will allow to do the operation for that card(like-insert, Update, delete transaction),Card Fingerprint is basically used to add one more level of security to protect from the threats and hackers.\nCompany: Aon Hewitt (India) Pvt. Ltd                                                 Jan ’15 to 31-March-2017\nProject Name: Absence Management System\nDesignation/Role: Sr. Developer\nPackages: ggplot2, stats, lm, glm , XML,Stringr, plyr, RCurl, Party, Data.Table\nEnvironment: R,Python, Rstudio , SQL Server \nTechniques: Machine Learning, and Predictive Modeling\nAlgorithm : Decision Tree- Classification (Random Forest/XG Boosting)\n\nDescription:\tNucleus is a Web based application used to manage leave and Payroll for employees of an organization. Basically it is a disability management system. Client sends their employee’s data in text/xlsx files and then that data is imported into the system. Based on the data Claims are created and then approved. Based on the logic provided by clients, employees of the organization are being paid.\n\nRoles and Responsibilities:\n· Analysis of the requirements and creating Technical Design documents. \n· To develop code and preparation of Unit Test Cases.\n· Develop a model for calculation of Claims for employees \n· Plotting the out with respect to claims \n· Final Output in csv \n· To develop programs for Data analysis using R \n· Developed functions in R to do calculation for Employee Re-imbursements cycle\n· To do code reviews, Help to team members.\n· Involved in the fixing high priority defects and issues\n\nCompany: Aon Hewitt (India) Pvt. Ltd                                        22-July-2010 to 31-March, 2017\nProject Name: Claim Management System\nDesignation/Role: Coldfusion /Python/R-Developer\nDatabase:  SQL Server 2008\nTime Duration: 22-July-2010 to 31-March, 2017\nLanguage/Tools: Coldfusion 11, Python, JavaScript, Ajax, JQuery\nIDE: Spyder, Eclipse\nFramework:  Fusebox \nAlgorithm: Naïve Bayes {SMS Spam Collection}\n\nDescription:  \nThe Nucleus Claim Management System is a sophisticated and flexible, web-enabled application built with ColdFusion, the Fuse box framework and Microsoft SQL Server – and a core component of the Nucleus Solutions integrated management solution.\n\nNucleus believes the key to successful claim management is to simplify the entire process, by making it easier to manage the entire claim from beginning to end. The Nucleus Claim Management System can:\nIncrease claims management productivity Reduce operating costs Monitor claims performance, compliance and consistency Improve disability and return-to-work\nCommunications Strengthen employee relations\nAs a result, many Fortune 500 companies use the Nucleus Claim Management System to improve their operational efficiency.\nClaim management exists to track and manage large numbers of claims, so the entire process can be viewed as beginning with the creation of each individual claim. And claim creation begins with the claim intake process. The customization that Nucleus provides for its clients begins here too, since claim intake forms are tailored to the requirements of each client.\nWorked on Modules: Claim Intake, Email Management, IVR (Integrated Voice Response, Payroll, Case Management, Reporting Management \n\n\nEmployee Engagement Analysis\nCompany: Aon Hewitt (India) Pvt. Ltd.                                       \t\tOct 14’ to Aug 15’                     \nDesignation/Role: Sr. Developer\nPlatform & Skills: R, Excel, R Studio, Python\nPackages: ggplot2, stats, lm, glm , XML, Stringr, plyr, RCurl, Party, Data.Table, numpy\nAlgorithm: KNN\nIDE: Spyder,RStudio\nTechniques: Machine Learning, and Predictive Modeling\nBrief: Company is conducting Engagement survey of employees every year to see their engagement level. We have to analyze the comments written by employees on scale of Highly Satisfied, Satisfied, Neutral, Unsatisfied, and Highly Unsatisfied.\n-Major tasks involved in the project were:\n-Defining the problem statements.\n-Apply text mining to obtain relevant problem associate them with their actionable insights.\n-Dictionary creation of negative and positive words in addition to the dictionary used in \n  ‘qdap’ package. \n-Develop a model for calculating the polarity of each row in data frame.\n-Function to calculate the sentiments on scale of Highly Satisfied, Satisfied, Neutral, \n  Unsatisfied, and Highly Unsatisfied.\n-Some plotting.\n-The actionable insights obtained through my data science contribution in the project can be accessed from the fact that ROI is 6 months which amounts to significant year on year savings for the company. \n\nProject Name: LDW Shutdown for Data analysis                                       Feb 14’ to Oct 14’\nRole: R Developer\t\t\t\t\t\t\t\t\nEnvironment: R ,Sqoop,Hive \nProject Description :\nThe purpose of the project is to change the LDW platform to analyze the data stored in hadoop file system\n\nRoles and Responsibilities:\n· Involved in developing the R programs \n· Gathering requirements from the client and analyzing them. \n· Fetched data from existing SQL data base and dump on Hbase using sqoop and map-reduce\n· Bug fixing, Unit testing and assisting UAT.\n· Doing the data validation \n· Preparing test plan documents and testing the scripts accordingly.\n\n---------------------------------------------------------------------------------------------------------------------\n\nColdFusion Projects :\n\n\n· Organization\t\t:\tChetu India Pvt Ltd,(Noida)\n· Project title\t\t:\tCEBM (Collaborative Evidence-based Medicine)\n· Designation\t\t:\tSoftware Engineer\n· Team Members\t:\t4\n· Time Duration\t:\t22-Feb-2010 to 21-July-2010\n· Role\t\t\t:\tDevelopment\n· Languages/Tools\t:\tCold Fusion, Java Script, AJAX\n· Database\t\t:\tSQL-Server 2005.\n\n\nDescription: Evidence-Based Medicine (EBM) is rapidly becoming the gold-standard in how health care provider’s patients and make decision regarding diagnosis, treatment and care. EBM aims to apply the best available evidence gained from scientific method to medical decision-making.it seeks to access the quality of evidence of risks and benefits of treatments(including lack of treatment).\n\nEBM exists on two levels: the institutional level (for large healthcare groups, hospitals, etc) and the individual level. On the institutional level, guidelines and standards of care are established for members of the institution to follow according to evidence-based medicine. On the individual level, the health care provider (HCP) may rely more on the evidence of a collective group. The aim is to develop a program that allows individual HCPs to draw on the collective wisdom of thousands of other HCPs, thus allowing individual HCPs to practice EBM on the institutional level without actually being associated with an institution. it will also allow institution to establish best practice methods based on  the data we collect, instead of accumulating the data themselves.\n\nThe main aim of CEBM (Collaborative Evidence-Based Medicine) will collect data on a granular level for thousand of diseases. It will be an open platform for HCPs to input data based on their experience and wisdom. By consulting specialists on each disease we define, we will collect the best evidence for diagnosis and treatment of each disease in our database.\n \n\n· Organization\t\t:\tOmnie solutions India Pvt Ltd,(Noida)\n· Project title\t\t:\tUnleash Inc\n· Designation\t\t:\tWeb Developer\n· Team Members\t:\t4\n· Role\t\t\t:\tDevelopment\n· Languages/Tools\t:\tCold Fusion, Java Script, AJAX, aspEasyPDF\n· Database\t\t:\tSQL-Server 2000.\n· Time Duration\t:\t15 July 2008 to 19 Feb 2010\n· Module Worked\t:\tMarketing Plan, MSP, NEWACTION PLAN, and User                                           \nInformation.\n  \nDescription:\nUnleash main objective is to give customize solutions to their various client. For this we have various tools like collaboration tool, planning tool and Scorecard etc. In this Project I have design and develop Marketing Plan tool for Unisys. User Information for Rutgers University, Mentoring for Novartis in Unleash if client requirement does not match with our tools then we create a new tool from scratch or customize existing.\n\nRole\n· Involved in database designing.\n· Involved in making various forms (Employee personal information form, Employee details form, employees attendance, leave management information etc.)\n\n\n· Organization\t\t:\tSiderealdot, Faridabad (Haryana)\n· Project title\t\t:\tMRD (Material Receipt and Dispatch)  \n· Team Size\t\t:\t6\n· Environment\t\t:\tC#, Java-Script, SQL Server 2005\n· Role\t\t\t:\tDeveloper\n· Time Duration\t:\t10 July 2007 to 7 June 2008\n\nDescription:\nIt is an interactive web based software application for MRD. It will issue challans for vendors   (Supplier, who will supply material and the party who will perform a job on the material). It will receive the material after completion of the job that has been assigned for a particular task and will also receive fresh purchased materials. Several reports will be generated by the application for Management Information System (MIS). The report will show the information on materials viz. materials went outside for processing, and other movement of materials through graph.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDate:                                                           \t\t\t\t (Subhash Singh)","annotation":[{"label":["Skills"],"points":[{"start":12578,"end":12580,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":11595,"end":11597,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":9803,"end":9805,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":9481,"end":9490,"text":"ColdFusion"}]},{"label":["Skills"],"points":[{"start":9158,"end":9160,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":6251,"end":6253,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":6202,"end":6211,"text":"ColdFusion"}]},{"label":["Skills"],"points":[{"start":5869,"end":5871,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":4607,"end":4609,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":3535,"end":3537,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":2381,"end":2383,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1988,"end":1990,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1986,"end":1990,"text":"MySQL"}]},{"label":["Skills"],"points":[{"start":1251,"end":1253,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1226,"end":1228,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":745,"end":747,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":694,"end":698,"text":"LINUX"}]},{"label":["Skills"],"points":[{"start":670,"end":672,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":668,"end":672,"text":"MySQL"}]},{"label":["Skills"],"points":[{"start":485,"end":504,"text":"R/Python programming"}]},{"label":["Skills"],"points":[{"start":442,"end":451,"text":"ColdFusion"}]},{"label":["Location"],"points":[{"start":100,"end":108,"text":"Delhi -84"}]},{"label":["Name"],"points":[{"start":0,"end":12,"text":"SUBHASH SINGH"}]}],"extras":null,"metadata":{"first_done_at":1532669688000,"last_updated_at":1532669688000,"sec_taken":111,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Udaya Laxmi Ch\n\nEmail : laxmi.udaya@gmail.com\n\n\t\n\n\tPhone: -9740606990\n\t\n\n\n\tSummary\n\n\t· 9.5 years of experience in Software Development.\n· 3.5 years of experience in Machine Learning\n· Primary Skills – Machine Learning, R programming, Lotus Notes.\n· Presently working for Wipro Technologies, Bangalore.\n· Experience in planning, estimation, design, development, and testing object oriented applications.\n· Experience in preparing various technical documents like Functional Specs, HLD, LLD, Flowcharts and Test cases.\n· Sound Knowledge in Object Oriented Design Principles\n· Have Team Handling experience.\n· Domain experience of Manufacturing and Finance.\n· Have Experience in Scrum Agile Model\n· Understand business requirements from clients\n\n\n\n\tTechnical Skills\n\n\tKey skills: \n\tMachine Learning,R Programming, MySQL, PostgreSQL, Microsoft Access, SQL Server, FileMaker, Oracle, RDBMS, dBASE, Clipper, FoxPro, Firebase, Mongodb, Python,  ava, J2EE, Oracle Fusion,Oracle Cloud, Salesforce, Devops Android, Business Analyst, UI Developer, DBAs, Embedded Systems, .NET, Hadoop, SQL Developer, Big Data, Tableau, Networking, Etl, Informatica, Ios, Quality Analyst, Project Manager, Python, Data Science, Python, Machine Learning, SAS, Java, Scala, Hadoop, Hive, Bigdata, Programming, SQL server reporting, Msbi Ssis, Ssrs, Msbi, Sql Reporting, Artificial Intelligence, Pandas, Pyspark, Sklearn, Flask, Django, Map Reduce, Parametric Design, Modeling, Regression, Patterns, Data Mining, Text Mining, Oops, Deep Learning, Web Analytics, Time Series, Regression, Tensorflow, Azure, Linear Regression, Logistic Regression, Decision Tree, Random Forest, Data Structure, Computer Vision, IHS, WAS, Java EE, SQL Server, .NET core, C#, ASP.NET, Rdlc, Linq, Sql, Web Api, Mvc, Javascript, Web Services, Oracle, MS SQL, PHP, Laravel, CodeIgniter, Symfony, Zend, Phalcon, CakePHP, Yii, FuelPHP, React, Vue, Angular, Ember, Backbone, Lotus Notes\n\n\tAlgorithms:\n\tNaïve Bayes, K means clustering,Word Cloud\n\n\tDatabases: \n\tMicrosoft SQL, Mongo DB\n\n\tWeb Technologies: \n\tXML, XSLT, HTML,  JavaScript,  AJAX, JQuery\n\n\tIDE:\n\tR studio,Pycharm\n\n\n\tProfessional Experience\n\n\tCurrent Employer :\n\tWipro Technologies., Bangalore  – (Oct  2010  to till date) – Technical Lead/Data Scientist\n\n\tPrevious Employers :\n\tHSBC Software development , Hyderabad (June  2008  to Sep 2010)  - SE\n\n\n\tQualification\n\n\tDegree\n\tCollege\n\tUniversity/Board\n\tYear\n\tPercentage (%)\n\n\tMCA\n\tNizam College, Basheerbagh,Hyderabad\n\tOsmania University\n\t2008\n\t75\n\n\n\tProject Experience \n\n\tProject 1 : Exploratory Data Analysis:\n\nProject Description:   Performed EDA analysis to analyze the Purchase frequency of vehicles which occurred over past 3 years and try to predict the frequency occurring in the future.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Performed EDA analysis to find the insights of the data. Observed the summary of each and every variable to understand the variables.\n\n· Performed the feature selection using hypothesis testing.\n\n· Identified the outliers using box plot.\n\n· Identified the trend in the purchases using histogram.\n\n\n\n\tProject 2: Word Cloud Analysis:\n\nProject Description:   Performed Word cloud and Sentimental Analysis of the customer feedbacks. Graphically represented the most frequently occurred words through Word cloud. Through sentimental analysis we identified whether a user-generated text expresses positive, negative or neutral opinion.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Created a Corpus using TM package and performed pre-processing of data.\n\n· Removed the punctuations, stemming and stop words which are of no analytical value.\n\n· Built a Document term matrix and identified the most frequently occurring words\n\n· Graphically represented it using  RColorbrewer Package\n\n\n\tProject 3: Sentimental Analysis:\n\nProject Description: Performed Sentimental Analysis of customer feedbacks through Naïve Bayes. Used “e1071” Package for implementing naïve Bayes method.\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· The DTM created using TM package was an input to the Naive Bayes Model.\n\n· As Naive Bayes classifier is typically trained on data with categorical features. We have converted the count of the words into a factor variable that indicates Yes or No whether the word is present or not.\n\n\tProject 4: Clustering Analysis:\n\nProject Description: Classified the customers on the basis of their purchases whether they have purchased low variant or high variant trucks. It in turn helped in building the right customer strategies.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Performed data preparation and Normalization of data using min-max method.\n\n· As K-means algorithm groups a dataset into a user-specified number (k) of clusters. Identified the initial cluster centroids as 3.\n\n· K clusters are creating by associating every observation with the nearest mean.\n\n· Used elbow method to validate the number of clusters such that within-cluster sum of square(wss) is minimized.\n\n\n\n\tProject 5 : Inter Connection Management Tool\nProject Description: Inter-connection Management (IMT) is prototype being developed for Engineering and Sales department to handle customizations of an existing product based on the customer's requirement. Users from engineering department will identify the items, which need to be customized out of the entire product design.\nRole\n\n       : Module Lead\n\nEnvironment\n       : Python, Mongo DB, jQuery\n\nTasks handled:\n\n· Gathering Requirements and providing Project Plan and Effort Estimation details.\n\n· Understanding business requirements and preparing SoU (Statement of Understanding) and Functional/Technical Specification documents.\n\n· Providing Effort & Resource estimations\n\n· Planning for application development and deployment\n\n· Writing and executing Test Cases and Test scenarios\n\n· Creating design elements using Technical Specification.\n\n· Performing Unit testing & Peer Reviews\n\n· Work Allocation and mentoring the team\n\n· Providing Technical guidance to the team. \n\n\tProject 6\n: cvdAEI Application\n\nProject Description\n     : CVDAEI is a web based multilingual application developed for handling the Change Management process in Truck division of Daimler. The change request flows through different phases mainly Initialization, Evaluation, Decision and Conclusion. This application has a configurable workflow where the request flow and the responsible persons can be configured easily at any point of time. \n\nRole\n\n    : Developer/Tester\n\nEnvironment\n     : Lotus Notes, Java, HTML, XML, Java Script, JQuery\n\nTasks handled:\n\n· Gathering Requirements and providing Project Plan and Effort Estimation details.\n\n· Understanding business requirements and preparing SoU (Statement of Understanding) and Functional/Technical Specification documents.\n\n· Providing Effort & Resource estimations\n\n· Planning for application development and deployment\n\n· Writing and executing Test Cases and Test scenarios\n\n· Creating design elements using Technical Specification.\n\n· Performing Unit testing & Peer Reviews\n\n· Work Allocation and mentoring the team\n\n· Providing Technical guidance to the team. \n\n\n\n\tProject Title: Project Management Office \nProject Description: The purpose of this system is to enable the Project Management Office to manage and execute the IT Applications and Operations driven project tasks in  more systematic manner. It will also enable them to efficiently perform a role as a facilitator to coordinate various IT Operations teams and to ensure that project activity enters the department through one common interface. The project tasks will subsequently be dealt with in a common format and in a consistent and appropriate manner, ensuring open and regular communication between all involved parties.\n\nRole\n\n    : Developer/Tester\n\nEnvironment\n     : Lotus Notes, Java, HTML, XML, Java Script, JQuery\n\nTasks Handled :\n\n· Writing and Executing Test cases in client server based environment\n· Individually provided application support","annotation":[{"label":["Skills"],"points":[{"start":7951,"end":7956,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":7938,"end":7948,"text":"Java Script"}]},{"label":["Skills"],"points":[{"start":7933,"end":7935,"text":"XML"}]},{"label":["Skills"],"points":[{"start":7927,"end":7930,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":7921,"end":7924,"text":"Java"}]},{"label":["Skills"],"points":[{"start":7908,"end":7918,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":6645,"end":6650,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":6632,"end":6642,"text":"Java Script"}]},{"label":["Skills"],"points":[{"start":6627,"end":6629,"text":"XML"}]},{"label":["Skills"],"points":[{"start":6621,"end":6624,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":6615,"end":6618,"text":"Java"}]},{"label":["Skills"],"points":[{"start":6602,"end":6612,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":5522,"end":5527,"text":"jQuery"}]},{"label":["Skills"],"points":[{"start":5512,"end":5519,"text":"Mongo DB"}]},{"label":["Skills"],"points":[{"start":5504,"end":5509,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4645,"end":4652,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":4054,"end":4061,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":3941,"end":3951,"text":"Naïve Bayes"}]},{"label":["Skills"],"points":[{"start":3494,"end":3501,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":3132,"end":3141,"text":"Word Cloud"}]},{"label":["Skills"],"points":[{"start":2793,"end":2800,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":2110,"end":2116,"text":"Pycharm"}]},{"label":["Skills"],"points":[{"start":2101,"end":2108,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":2086,"end":2091,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":2080,"end":2083,"text":"AJAX"}]},{"label":["Skills"],"points":[{"start":2067,"end":2076,"text":"JavaScript"}]},{"label":["Skills"],"points":[{"start":2060,"end":2063,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":2054,"end":2057,"text":"XSLT"}]},{"label":["Skills"],"points":[{"start":2049,"end":2051,"text":"XML"}]},{"label":["Skills"],"points":[{"start":2018,"end":2025,"text":"Mongo DB"}]},{"label":["Skills"],"points":[{"start":2003,"end":2015,"text":"Microsoft SQL"}]},{"label":["Skills"],"points":[{"start":1977,"end":1986,"text":"Word Cloud"}]},{"label":["Skills"],"points":[{"start":1958,"end":1975,"text":"K means clustering"}]},{"label":["Skills"],"points":[{"start":1945,"end":1955,"text":"Naïve Bayes"}]},{"label":["Skills"],"points":[{"start":1918,"end":1928,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":1908,"end":1915,"text":"Backbone"}]},{"label":["Skills"],"points":[{"start":1901,"end":1905,"text":"Ember"}]},{"label":["Skills"],"points":[{"start":1892,"end":1898,"text":"Angular"}]},{"label":["Skills"],"points":[{"start":1887,"end":1889,"text":"Vue"}]},{"label":["Skills"],"points":[{"start":1880,"end":1884,"text":"React"}]},{"label":["Skills"],"points":[{"start":1871,"end":1877,"text":"FuelPHP"}]},{"label":["Skills"],"points":[{"start":1866,"end":1868,"text":"Yii"}]},{"label":["Skills"],"points":[{"start":1857,"end":1863,"text":"CakePHP"}]},{"label":["Skills"],"points":[{"start":1848,"end":1854,"text":"Phalcon"}]},{"label":["Skills"],"points":[{"start":1842,"end":1845,"text":"Zend"}]},{"label":["Skills"],"points":[{"start":1833,"end":1839,"text":"Symfony"}]},{"label":["Skills"],"points":[{"start":1820,"end":1830,"text":"CodeIgniter"}]},{"label":["Skills"],"points":[{"start":1811,"end":1817,"text":"Laravel"}]},{"label":["Skills"],"points":[{"start":1806,"end":1808,"text":"PHP"}]},{"label":["Skills"],"points":[{"start":1798,"end":1803,"text":"MS SQL"}]},{"label":["Skills"],"points":[{"start":1790,"end":1795,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":1776,"end":1787,"text":"Web Services"}]},{"label":["Skills"],"points":[{"start":1764,"end":1773,"text":"Javascript"}]},{"label":["Skills"],"points":[{"start":1759,"end":1761,"text":"Mvc"}]},{"label":["Skills"],"points":[{"start":1750,"end":1756,"text":"Web Api"}]},{"label":["Skills"],"points":[{"start":1745,"end":1747,"text":"Sql"}]},{"label":["Skills"],"points":[{"start":1739,"end":1742,"text":"Linq"}]},{"label":["Skills"],"points":[{"start":1733,"end":1736,"text":"Rdlc"}]},{"label":["Skills"],"points":[{"start":1724,"end":1730,"text":"ASP.NET"}]},{"label":["Skills"],"points":[{"start":1720,"end":1721,"text":"C#"}]},{"label":["Skills"],"points":[{"start":1709,"end":1717,"text":".NET core"}]},{"label":["Skills"],"points":[{"start":1697,"end":1706,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":1688,"end":1694,"text":"Java EE"}]},{"label":["Skills"],"points":[{"start":1683,"end":1685,"text":"WAS"}]},{"label":["Skills"],"points":[{"start":1678,"end":1680,"text":"IHS"}]},{"label":["Skills"],"points":[{"start":1661,"end":1675,"text":"Computer Vision"}]},{"label":["Skills"],"points":[{"start":1645,"end":1658,"text":"Data Structure"}]},{"label":["Skills"],"points":[{"start":1630,"end":1642,"text":"Random Forest"}]},{"label":["Skills"],"points":[{"start":1615,"end":1627,"text":"Decision Tree"}]},{"label":["Skills"],"points":[{"start":1594,"end":1612,"text":"Logistic Regression"}]},{"label":["Skills"],"points":[{"start":1575,"end":1591,"text":"Linear Regression"}]},{"label":["Skills"],"points":[{"start":1568,"end":1572,"text":"Azure"}]},{"label":["Skills"],"points":[{"start":1556,"end":1565,"text":"Tensorflow"}]},{"label":["Skills"],"points":[{"start":1544,"end":1553,"text":"Regression"}]},{"label":["Skills"],"points":[{"start":1531,"end":1541,"text":"Time Series"}]},{"label":["Skills"],"points":[{"start":1516,"end":1528,"text":"Web Analytics"}]},{"label":["Skills"],"points":[{"start":1501,"end":1513,"text":"Deep Learning"}]},{"label":["Skills"],"points":[{"start":1495,"end":1498,"text":"Oops"}]},{"label":["Skills"],"points":[{"start":1482,"end":1492,"text":"Text Mining"}]},{"label":["Skills"],"points":[{"start":1469,"end":1479,"text":"Data Mining"}]},{"label":["Skills"],"points":[{"start":1459,"end":1466,"text":"Patterns"}]},{"label":["Skills"],"points":[{"start":1447,"end":1456,"text":"Regression"}]},{"label":["Skills"],"points":[{"start":1437,"end":1444,"text":"Modeling"}]},{"label":["Skills"],"points":[{"start":1418,"end":1434,"text":"Parametric Design"}]},{"label":["Skills"],"points":[{"start":1406,"end":1415,"text":"Map Reduce"}]},{"label":["Skills"],"points":[{"start":1398,"end":1403,"text":"Django"}]},{"label":["Skills"],"points":[{"start":1391,"end":1395,"text":"Flask"}]},{"label":["Skills"],"points":[{"start":1382,"end":1388,"text":"Sklearn"}]},{"label":["Skills"],"points":[{"start":1373,"end":1379,"text":"Pyspark"}]},{"label":["Skills"],"points":[{"start":1365,"end":1370,"text":"Pandas"}]},{"label":["Skills"],"points":[{"start":1340,"end":1362,"text":"Artificial Intelligence"}]},{"label":["Skills"],"points":[{"start":1325,"end":1337,"text":"Sql Reporting"}]},{"label":["Skills"],"points":[{"start":1325,"end":1327,"text":"Sql"}]},{"label":["Skills"],"points":[{"start":1319,"end":1322,"text":"Msbi"}]},{"label":["Skills"],"points":[{"start":1313,"end":1316,"text":"Ssrs"}]},{"label":["Skills"],"points":[{"start":1302,"end":1310,"text":"Msbi Ssis"}]},{"label":["Skills"],"points":[{"start":1302,"end":1305,"text":"Msbi"}]},{"label":["Skills"],"points":[{"start":1280,"end":1299,"text":"SQL server reporting"}]},{"label":["Skills"],"points":[{"start":1267,"end":1277,"text":"Programming"}]},{"label":["Skills"],"points":[{"start":1258,"end":1264,"text":"Bigdata"}]},{"label":["Skills"],"points":[{"start":1252,"end":1255,"text":"Hive"}]},{"label":["Skills"],"points":[{"start":1244,"end":1249,"text":"Hadoop"}]},{"label":["Skills"],"points":[{"start":1237,"end":1241,"text":"Scala"}]},{"label":["Skills"],"points":[{"start":1231,"end":1234,"text":"Java"}]},{"label":["Skills"],"points":[{"start":1226,"end":1228,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1208,"end":1223,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1200,"end":1205,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1186,"end":1197,"text":"Data Science"}]},{"label":["Skills"],"points":[{"start":1178,"end":1183,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1161,"end":1175,"text":"Project Manager"}]},{"label":["Skills"],"points":[{"start":1144,"end":1158,"text":"Quality Analyst"}]},{"label":["Skills"],"points":[{"start":1139,"end":1141,"text":"Ios"}]},{"label":["Skills"],"points":[{"start":1126,"end":1136,"text":"Informatica"}]},{"label":["Skills"],"points":[{"start":1121,"end":1123,"text":"Etl"}]},{"label":["Skills"],"points":[{"start":1109,"end":1118,"text":"Networking"}]},{"label":["Skills"],"points":[{"start":1100,"end":1106,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":1090,"end":1097,"text":"Big Data"}]},{"label":["Skills"],"points":[{"start":1075,"end":1087,"text":"SQL Developer"}]},{"label":["Skills"],"points":[{"start":1067,"end":1072,"text":"Hadoop"}]},{"label":["Skills"],"points":[{"start":1061,"end":1064,"text":".NET"}]},{"label":["Skills"],"points":[{"start":1043,"end":1058,"text":"Embedded Systems"}]},{"label":["Skills"],"points":[{"start":1037,"end":1040,"text":"DBAs"}]},{"label":["Skills"],"points":[{"start":1023,"end":1034,"text":"UI Developer"}]},{"label":["Skills"],"points":[{"start":1005,"end":1020,"text":"Business Analyst"}]},{"label":["Skills"],"points":[{"start":989,"end":1002,"text":"Devops Android"}]},{"label":["Skills"],"points":[{"start":977,"end":986,"text":"Salesforce"}]},{"label":["Skills"],"points":[{"start":963,"end":974,"text":"Oracle Cloud"}]},{"label":["Skills"],"points":[{"start":949,"end":961,"text":"Oracle Fusion"}]},{"label":["Skills"],"points":[{"start":943,"end":946,"text":"J2EE"}]},{"label":["Skills"],"points":[{"start":929,"end":934,"text":"Python"}]},{"label":["Skills"],"points":[{"start":920,"end":926,"text":"Mongodb"}]},{"label":["Skills"],"points":[{"start":910,"end":917,"text":"Firebase"}]},{"label":["Skills"],"points":[{"start":902,"end":907,"text":"FoxPro"}]},{"label":["Skills"],"points":[{"start":893,"end":899,"text":"Clipper"}]},{"label":["Skills"],"points":[{"start":886,"end":890,"text":"dBASE"}]},{"label":["Skills"],"points":[{"start":879,"end":883,"text":"RDBMS"}]},{"label":["Skills"],"points":[{"start":871,"end":876,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":860,"end":868,"text":"FileMaker"}]},{"label":["Skills"],"points":[{"start":848,"end":857,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":830,"end":845,"text":"Microsoft Access"}]},{"label":["Skills"],"points":[{"start":818,"end":827,"text":"PostgreSQL"}]},{"label":["Skills"],"points":[{"start":811,"end":815,"text":"MySQL"}]},{"label":["Skills"],"points":[{"start":798,"end":808,"text":"Programming"}]},{"label":["Skills"],"points":[{"start":796,"end":808,"text":"R Programming"}]},{"label":["Skills"],"points":[{"start":779,"end":794,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":234,"end":244,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":219,"end":231,"text":"R programming"}]},{"label":["Skills"],"points":[{"start":201,"end":216,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":165,"end":180,"text":"Machine Learning"}]},{"label":["Name"],"points":[{"start":0,"end":13,"text":"Udaya Laxmi Ch"}]}],"extras":null,"metadata":{"first_done_at":1579625576000,"last_updated_at":1579626369000,"sec_taken":0,"last_updated_by":"aJOmJy1lvpOYFetVNuqLvFo9Vx42","status":"done","evaluation":"NONE"}}
{"content": "Sudeep Ghosh\nData Scientist | Machine Learning\n\n� Data Scientist at Datafoundry a Jaitra Software Solutions Pvt\n� http://dfoundry.io\nB sudeepgh09@gmail.com\nÏ Contact No: +91-9685315467\n\nProfile Summary\nI am currently working as a Data Scientist with Datafoundry a Jaitra Software Solutions Pvt\nLtd, Bangalore, India since August 2017. I worked as a research scholar from Discipline of\nPhysics at Indian Institute of Technology Indore (IITI), India. I have an immense passion\nfor technology, science, and innovation. I have been in a joint project at IITI with Jefferson\nLab, USA and Forschungszentrum Juelich, Germany, from July 2012 - July 2017. During this\ntenure of the project I worked at different locations in India, USA and Germany. My contri-\nbutions to the project include experimental data management, developing analysis framework\nand performing data analysis, establishing suitable background subtraction techniques, Monte\nCarlo Simulations, modeling and testing, interpreting data, preparing scientific documentation\nand presenting it to conferences and publishing it to journals. I worked on different operating\nsystems like Linux/UNIX, Scientific Linux, Windows, MAC-OS and MS-DOS and I\nposses advanced level programming skills in C, C++, Python etc. Additionally, I learned\nand worked for development and implementation of Machine Learning tools, Mathematical\nand Statistical Models. I have special interest and expertise in Mathematics, which includes\nApplied Mathematics, solving higher order differential equations with Analytical and Numerical\nmethods etc.\n\nRelevant Experience\n• Data Scientist at Datafoundry a Jaitra Software Solutions Pvt. since 01 August 2017.\n\n• Research scholar at a joint project between Indian Institute of Technology Indore, India\nwith Jefferson Lab, USA and Forschungszentrum Juelich, Germany, from July 2012 - July\n2017.\n\nSkills\nPrimary Skills\n\n• Data analytics and modelling with Python (NumPy, Pandas, Scikit-learn, Ten-\nsorFlow, StatsModels, NLTK etc.) and Data visualisation with Matplotlib,\nSeaborn, Tableau, ROOT etc. experience of more than 4 years .\n\n• High volume Data Analysis (Unstructured, Structured and Semi-structured data),\nPredictive Analysis, Multivariate analysis, Planning and Documenting Problem\nstatement with numerical, text and image data.\n\n• Classification, Regression and Clustering projects with Machine Learning algo-\nrithms. (with Neural Networks, Support Vector Machine, Logistic regression,\nDecision trees etc.)\n\nmailto:sudeepgh09@gmail.com\n\n\n• Applied Mathematics, Statistics and Data Science experience of more than 5 years.\n\n• Advanced level C, C++ programming experience of more than 4 years.\n\nAdditional Skills\n\n• Designed Node.js Python application, micro-services and written API through Express\nand deployed using Docker.\n\n• Knowledge of Structured Query Language (SQL) and NoSQL (MongoDB) databases.\n\n• Active participant in various online data science and coding challenges and workshop.\n\n• Skilled in interpreting end results to derive meaningful conclusions for data analytics.\n\n• Extremely quick learner and adaptable to new data analysis platforms, working environ-\nment and programming languages as well as to data varying in terms of dimension as well\nas complexity and comfortable doing Multi tasking in several projects/tasks.\n\n• Developed data structures and algorithms.\n\n• Familiar to key concepts of Agile software development, Scrum framework, Cloud\nPlatforms and preparing Strategic Data Warehousing.\n\n• Modern scientific experimental packages (ROOT, MATLAB, Mathematica) for data\nhandling, Monte Carlo tools (PLUTO) & techniques and simulating experimental sce-\nnario.\n\n• Strong communication skills, a team player, and collaborated with other scientists, out-\nlining objectives, methodology conclusions, actively listening to people and stimulating\ninterest discussion.\n\n• Maintained group Wiki and Website using HTML, maintaining a common server and\nproficiency in preparing scientific documentation using LaTeX packages.\n\n• Experienced in handling intricate computational problems pertaining to Physics and Math-\nematics.\n\n• Enterprising professional with a documented record of success in scientific studies publi-\ncations over multiple locations.\n\nActive Public Profiles:\n\n• Linkedin: https://www.linkedin.com/in/sudeep-ghosh-9109b1136/\n\n• Kaggle: https://www.kaggle.com/sudeep88\n\n• Github: https://github.com/Sudeep09\n\n• HackerRank: https://www.hackerrank.com/sudeepgh09\n\n\n\nProfessional Experience\nData science product development team - Present\n\n• Description: Analysis of business process data from health care domain, and to come up\nwith data driven processes and products which could lead to faster and efficient flow of\nbusiness.\n\n• Tools/Packages: Python, Pandas, Flask, Statistics, Mathematics, NodeJS, Rest API, IOT,\nMachine Learning, Apache Tika, ElasticSearch, Kafka etc.\n\nApplication of machine learning techniques to decode structures of proteins,\nJanuary 2017 - July 2017\n\n• Description: Every protein has a sequence of amino acids, some proteins can be synthesized\nin the lab while others can not, depending on the structure and many other complexities.\nIn this project, a predictive analysis is carried out with machine learning techniques like\nNeural Networks and Support Vector Machine, which can give a probability of replication\nof any protein sequence. In order to prepare an environment to use the machine learning\ntools, the system is first trained with a history of all the successful and failed instances\nof replication trials to any protein sequence. Once the training is achieved with enough\nstatistics in the phase space of the observed variables, the Neural Network of the protein\nstructures is studied and the overall behavior of the system is predicted by this machine\nlearning tool. Another machine learning tool, the Support Vector Machine which can\nseparate complex phase-space of proteins using optimal boundary is also used in this\nproject, and the two tools are compared separately.\n\n• Tools/Packages: C++, TMVA Package, Root, Machine Learning with Neural Networks\nand Support Vector Machine.\n\nDeveloped double q-factor multivariate technique, January 2016 - December\n2016\n\n• Description: In this project, a unique multivariate analysis technique to separate noise\nfrom the signal is developed. In this technique, a multi-dimensional hyperspace with un-\ncorrelated variables is made for a system and the nearest neighbor approach is used to\nseparate events with an event based weights called the q-factor. We have also developed,\ncompiled and tested the codes and the work is presented at various national and interna-\ntional scientific conferences.\n\n• Tools/Packages: C++, RooFit, Root.\n\n\n\nDeveloped data analysis framework for Dalitz plot study of g11 and g12 runs\nof CLAS data from Jefferson Lab experiment, September 2014 - February\n2017 (Senior Research Fellow)\n\n• Description: It is the Ph.D. project and the experimental data is analysed for g11 and\ng12 runs to extract empirical parameters, using Numerical techniques, fitting, models and\nMonte Carlo integration. The selection, cuts, calibration of detectors for preselection\nof data set is done. To analyse the preselected data a framework is developed, using the\nframework the subtraction of background and calculation of Dalitz plot parameters is done.\nA simulation framework is also developed for the analysis to understand the inefficiencies\nin the detectors. The simulation framework requires the generation of events and modeling\nenvironment of the experiment. The data is then analysed using the framework, and series\nof Machine learning techniques, statistical and mathematical models is used to subtract\nthe background and to obtain the channel of interest. Finally, the parameters are reported\nwith statistical and systematic errors at various national and international conferences.\nThe scientific documentation is also prepared and the work is under review for publication.\n\n• Tools/Packages: Pluto, Perl, MINUIT, FUMILI, C++, RooFit, Root.\n\nCoatjava data analysis framework development for future Jefferson Lab ex-\nperiment, September 2012 - December 2014\n\n• Description: In this project, a robust data handling analysis framework was developed for\nthe users of future experiments. My duty in this project was to make data samples for\ntesting and analyzing it with Coatjava framework, and reporting bugs.\n\n• Tools/Packages: Jython, Python, and C++.\n\nList of Publications\n1. Sudeep Ghosh and Ankhi Roy, “An improvement to the measurement of Dalitz\n\nplot parameters”, Papers in Physics\n\n2. Hans-Peter Morsch and Sudeep Ghosh, “Chiral Structure of Particles Bound by\nMagnetic Forces”, Journal of Advances in Mathematics and Computer Science,\nISSN: 2456-9968, ISSN: 2231-0851 (Past),Vol.: 24, Issue.: 4\n\n3. “Dalitz plot of η′ → η π+ π−”\nS. Ghosh, A. Roy, EPJ Web Conf., 130, 03002 (2016).\n\n4. “Dalitz plot analysis of η′ → η π+ π−”\nS. Ghosh, AIP Conference Proceedings, 1735, 030018 (2016).\n\n5. “Calculation of the matrix element for the hadronic decay ω → π0 π+ π−”\nS. Ghosh, A. Roy, Proceedings of the DAE Symp. On Nucl. Phys, 59, 648 (2014).\n\n6. “Dalitz plot of the hadronic decay η′ → η π+ π−”\nS. Ghosh, A. Roy, Proceedings of the DAE International Symp. On Nucl. Phys, 58, 242\n(2013).\n\n\n\nPublications Under Review\n1. “Dalitz Plot Analysis of η′ → η π+ π− from CLAS G12 Data Set”\n\nS. Ghosh, A. Roy et al. Physical Review Letters (Under Preparation)\n\n2. “Machine learning to predict the solubility of proteins”\nS. Ghosh (Under Preparation)\n\nAnalysis Note\n1. “Dalitz Plot Analysis of η′ → η π+ π− from CLAS G12 Data Set”\n\nSudeep Ghosh, Ankhi Roy & Moskov Amaryan\n\nAssignments\n1. Visiting Guest Scientist at IKP-1, Forschungszentrum Jülich 52428, Germany\n\nNovember 1, 2016 – January 27, 2017.\nfunded by service agreement between Forschungszentrum Jülich and Indian Institute of\nTechnology Indore, India\n\n2. Visiting Guest Scientist at IKP-1, Forschungszentrum Jülich 52428, Germany\nMarch 22, 2016 – June 17, 2016.\nfunded by IKP-1, Forschungszentrum Jülich\n\n3. Visiting Researcher at Old Dominion University, Physics Department, 5115\nHampton Blvd, Norfolk, VA 23529, USA\nSeptember 12, 2015 – December 11, 2015.\nfunded by Jefferson Lab & Old Dominion University\n\n4. Visiting Researcher at Jefferson Lab, Newport News, VA 23606, USA\nDecember 27, 2013 – March 15, 2014.\nfunded by APS-IUSSTF, Jefferson Lab & Old Dominion University\n\nConferences, Workshops and Talks\n1. Invited Talk: CANU/FEE/CBAC #5 Meeting Physikzentrum Bad Honnef, Germany,\n\nDecember 20, 2016\n\n2. Invited Talk: IKP-1, Forschungszentrum Jülich 52428, Germany, August 18, 2016\n\n3. Talk: 14th International Workshop on Meson Production, Properties and Interaction (2nd\n- 7th June 2016), Cracow, Poland, June 3, 2016\n\n4. Invited Talk: Old Dominion University, Physics Department, 5115 Hampton Blvd, Nor-\nfolk, VA 23529, USA, November 19, 2015\n\n5. Talk: XVI International Conference on Hadron Spectroscopy (September 13-18, 2015),\nUSA, September 18, 2015\n\n6. Presented a Poster at 59th DAE Symposium on Nuclear Physics at Banaras Hindu\nUniversity, Varanasi, Uttar Pradesh, India, 8 - 12 Dec, 2014\n\n7. Talk and School Attended: IX SERC SCHOOL ON EXPERIMENTAL HIGH EN-\nERGY PHYSICS, Indian Institute of Technology Madras, Tamil Nadu, India, 2nd - 21st\nDecember, 2013\n\n\n\nResearch Interests\n• Experimental Data Analysis\n• Monte Carlo Simulation, Detector Development and Development of Multi-\n\nvariate Analysis Methods\n\nEducation\n2012 - 2017 Doctor of Philosophy in Physics (pursuing) (Ph.D. (pursuing))\n\nIndian Institute of Technology Indore, Indore, India\nTitle: Dalitz Plot Analysis of η′ → η π+ π− from CLAS G12 Data Set\nwork under review and presented at international conferences.\n\n2009 - 2011 Master of Science (M.Sc.)\nPhysics with IstClass\n(Specialization in Condensed matter physics)\nAssam (Central) University, Assam, India\n\n2006 - 2009 Bachelor of Science (B.Sc.)\nPhysics (Hons.), Computer Sc. & Mathematics with IInd Class\nSt Joseph’s College, Darjeeling (University of North Bengal), West Bengal, India\n\n2006 Senior Secondary Examination (XIIth)\nMathematics, Physics, Chemistry, Biology & English with Ist Class\nCBSE Board, Kendriya Vidyalaya Alipurduar Jn., West Bengal, India\n\n2004 Secondary School Examination (Xth)\nGeneral with Ist Class\nCBSE Board, Kendriya Vidyalaya Alipurduar Jn., West Bengal, India\n\nAwards\n2014 APS-IUSSTF Physics Ph.D. Student Visitation Program awardee\n2012 CSIR Eligibility for Lectureship (NET) in Physical Sciences - 184\n2012 Qualified GATE with All India Rank- 932\n2011 Ranked 2nd in M.Sc. (Physics) in 2011\n\nPersonal Details\nDate of Birth September 20, 1988\n\nAddress H2-905, Alpine Eco Appartment,\nDoddanekundi Village,\nKR Puram, Hobli, Bengaluru,\nKarnataka 560037\n\nNationality: Indian\nPassport No: K7796524\nValid VISA: Schengen VISA\nLanguages: English, Hindi, Bengali, Nepali & Assamese\n\nHobbies: Sports, Reading, Cooking & Music\n\n\n\tProfile Summary\n\tRelevant Experience\n\tSkills\n\tProfessional Experience\n\tList of Publications\n\tPublications Under Review\n\tAnalysis Note\n\tAssignments\n\tConferences, Workshops and Talks\n\tResearch Interests\n\tEducation\n\tAwards\n\tPersonal Details","annotation":[{"label":["Skills"],"points":[{"start":13099,"end":13099,"text":"C"}]},{"label":["Skills"],"points":[{"start":12932,"end":12932,"text":"C"}]},{"label":["Location"],"points":[{"start":12754,"end":12762,"text":"Bengaluru"}]},{"label":["Skills"],"points":[{"start":12470,"end":12470,"text":"C"}]},{"label":["Skills"],"points":[{"start":12326,"end":12326,"text":"C"}]},{"label":["Skills"],"points":[{"start":12320,"end":12320,"text":"C"}]},{"label":["Skills"],"points":[{"start":12196,"end":12196,"text":"C"}]},{"label":["Skills"],"points":[{"start":12190,"end":12190,"text":"C"}]},{"label":["Skills"],"points":[{"start":12152,"end":12152,"text":"C"}]},{"label":["Skills"],"points":[{"start":12018,"end":12018,"text":"C"}]},{"label":["Skills"],"points":[{"start":12000,"end":12000,"text":"C"}]},{"label":["Skills"],"points":[{"start":11963,"end":11963,"text":"C"}]},{"label":["Skills"],"points":[{"start":11871,"end":11871,"text":"C"}]},{"label":["Skills"],"points":[{"start":11838,"end":11838,"text":"C"}]},{"label":["Skills"],"points":[{"start":11813,"end":11813,"text":"C"}]},{"label":["Skills"],"points":[{"start":11678,"end":11678,"text":"C"}]},{"label":["Education"],"points":[{"start":11513,"end":11543,"text":"Doctor of Philosophy in Physics"}]},{"label":["Skills"],"points":[{"start":11399,"end":11399,"text":"C"}]},{"label":["Skills"],"points":[{"start":11252,"end":11252,"text":"C"}]},{"label":["Skills"],"points":[{"start":11211,"end":11211,"text":"C"}]},{"label":["Skills"],"points":[{"start":11208,"end":11208,"text":"C"}]},{"label":["Skills"],"points":[{"start":10947,"end":10947,"text":"C"}]},{"label":["Skills"],"points":[{"start":10764,"end":10764,"text":"C"}]},{"label":["Skills"],"points":[{"start":10506,"end":10506,"text":"C"}]},{"label":["Skills"],"points":[{"start":10503,"end":10503,"text":"C"}]},{"label":["Skills"],"points":[{"start":10494,"end":10494,"text":"C"}]},{"label":["Skills"],"points":[{"start":10444,"end":10444,"text":"C"}]},{"label":["Name"],"points":[{"start":9638,"end":9649,"text":"Sudeep Ghosh"}]},{"label":["Skills"],"points":[{"start":9618,"end":9618,"text":"C"}]},{"label":["Skills"],"points":[{"start":9379,"end":9379,"text":"C"}]},{"label":["Skills"],"points":[{"start":9010,"end":9010,"text":"C"}]},{"label":["Skills"],"points":[{"start":8960,"end":8960,"text":"C"}]},{"label":["Skills"],"points":[{"start":8877,"end":8877,"text":"C"}]},{"label":["Skills"],"points":[{"start":8739,"end":8739,"text":"C"}]},{"label":["Skills"],"points":[{"start":8643,"end":8643,"text":"C"}]},{"label":["Name"],"points":[{"start":8628,"end":8639,"text":"Sudeep Ghosh"}]},{"label":["Name"],"points":[{"start":8492,"end":8503,"text":"Sudeep Ghosh"}]},{"label":["Skills"],"points":[{"start":8462,"end":8464,"text":"C++"}]},{"label":["Skills"],"points":[{"start":8462,"end":8462,"text":"C"}]},{"label":["Skills"],"points":[{"start":8450,"end":8455,"text":"Python"}]},{"label":["Skills"],"points":[{"start":8383,"end":8383,"text":"C"}]},{"label":["Skills"],"points":[{"start":8059,"end":8059,"text":"C"}]},{"label":["Skills"],"points":[{"start":8039,"end":8041,"text":"C++"}]},{"label":["Skills"],"points":[{"start":8039,"end":8039,"text":"C"}]},{"label":["Skills"],"points":[{"start":7098,"end":7098,"text":"C"}]},{"label":["Skills"],"points":[{"start":6815,"end":6815,"text":"C"}]},{"label":["Skills"],"points":[{"start":6714,"end":6716,"text":"C++"}]},{"label":["Skills"],"points":[{"start":6714,"end":6714,"text":"C"}]},{"label":["Skills"],"points":[{"start":6047,"end":6049,"text":"C++"}]},{"label":["Skills"],"points":[{"start":6047,"end":6047,"text":"C"}]},{"label":["Skills"],"points":[{"start":4763,"end":4768,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3599,"end":3599,"text":"C"}]},{"label":["Skills"],"points":[{"start":3445,"end":3445,"text":"C"}]},{"label":["Skills"],"points":[{"start":2860,"end":2876,"text":" NoSQL (MongoDB) "}]},{"label":["Skills"],"points":[{"start":2825,"end":2856,"text":"Structured Query Language (SQL) "}]},{"label":["Skills"],"points":[{"start":2735,"end":2748,"text":"micro-services"}]},{"label":["Skills"],"points":[{"start":2715,"end":2720,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2707,"end":2713,"text":"Node.js"}]},{"label":["Skills"],"points":[{"start":2627,"end":2629,"text":"C++"}]},{"label":["Skills"],"points":[{"start":2627,"end":2627,"text":"C"}]},{"label":["Skills"],"points":[{"start":2624,"end":2624,"text":"C"}]},{"label":["Skills"],"points":[{"start":2346,"end":2346,"text":"C"}]},{"label":["Skills"],"points":[{"start":2315,"end":2315,"text":"C"}]},{"label":["Skills"],"points":[{"start":2108,"end":2185,"text":" High volume Data Analysis (Unstructured, Structured and Semi-structured data)"}]},{"label":["Skills"],"points":[{"start":1929,"end":1934,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1895,"end":1922,"text":"Data analytics and modelling"}]},{"label":["Skills"],"points":[{"start":1254,"end":1259,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1249,"end":1251,"text":"C++"}]},{"label":["Skills"],"points":[{"start":1249,"end":1249,"text":"C"}]},{"label":["Skills"],"points":[{"start":1246,"end":1246,"text":"C"}]},{"label":["Skills"],"points":[{"start":1180,"end":1180,"text":"C"}]},{"label":["Skills"],"points":[{"start":935,"end":935,"text":"C"}]},{"label":["Skills"],"points":[{"start":158,"end":158,"text":"C"}]},{"label":["Name"],"points":[{"start":0,"end":11,"text":"Sudeep Ghosh"}]}],"extras":null,"metadata":{"first_done_at":1532686259000,"last_updated_at":1532686259000,"sec_taken":363,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Has 3.5 yrs. of relevant exp in ML and Python currently in Lead role but started his carirer with Python and has good familier Under standing on Python with ML concepts.\nSuhas Jk           \n\n\n\n                              Mobile:   9036810804\n\n\n\n\n                          Email: suhas.datascience@gmail.com\n\n\n\n\nObjective:\n\nTo seek challenging assignment and responsibility, with an opportunity for growth and career advancement as successful achievements.\n\nProfessional Skill Set:\n\n· Competent and techno-savvy IT professional, having 6+ Years of experience in IT industry. \n· Experience in using Machine learning techniques(Regression): Simple Linear Regression,Multiple Linear Regression ,Polynomial Regression ,Support Vector Regression (SVR) ,Decision Tree Regression ,Random Forest Regression  using Python.\n· Experience in using Machine learning techniques (Classification): Logistic Regression, K-Nearest Neighbors (K-NN), Support Vector Machine (SVM), Kernel SVM ,Naive Bayes ,Random Forest Classification using Python.\n· Evaluating Regression Models Performance \n· R-Squared Intuition \n\n· Adjusted R-Squared Intuition \n\n· Evaluating Regression Models Performance \n\n· Interpreting Linear Regression Coefficients\n\n· Experience in working with Text Analytics, Predictions with Python NLTK and Scikit -Learn modules.\n· Evaluating Classification Models Performance \n· False Positives & False Negatives \n\n· Confusion Matrix \n\n· Accuracy Paradox \n\n· CAP Curve\n· Experience in Machine learning and its libraries like Pandas,Matplotlib, Scikit-Learn, Numpy, NLTK etc.\n\n· Experience in Tableau (involved in the complete lifecycle implementation and Analytics)\n· Experience in Clustering techniques(K-Means and Hierarchical), Association Rule learning(Apriori),Reinforcement Learning(UCB and Thompson sampling).\n· Experience in Deep Learning(Neural Networks and Convolutional Neural Networks)\n· Experience in Natural Language Processing(Text Classification and Sentimental Analysis)\n· Experience in PCA,LDA(Principal Component Analysis and Linear Discriminant Analysis) and Kernel PCA.\n· Experience in Model Selection and Boosting(K-Fold Cross Validation,Grid Search,XGBoost)\n· Have good Knowledge in Apache Spark,R- programming.\n\n\nHighlights:\nData Preprocessing for Algorithm , Regression , Classification , Clustering , Association Rule Learning , Reinforcement Learning , Natural Language Processing , Deep Learning , Dimensionality Reduction , Model Selection & Boosting , Machine Learning on Big Data ,Data mining, cleaning, and imputing, principal component analysis, statistical data modeling,Pattern recognition,forecasting,classification,clustering,regression/fitting,Greedy algorithms, efficient data structures, dynamic programming,Parallel computing, High-Throughput Computing, computing clusters and grids.\n\nEducation Summary:\n\nBachelor Of Engineering in Computer Science from Sapthagiri College Of Engineering(2006-2010),Bangalore.\n\n\n\nTechnical Skills:\n\n· Python :numpy, pandas,scikit-learn \n\n· Unix shell scripts \n\n· Cloud,Tableau\nFamiliar:\n\n· PostgreSql,MySql,NewSql(Voltdb),Apache Quarks,Hbase\n\nExperience Summary:\n\nCompany 1: (Current company)\nTerra Blue PvtLtd, Bangalore\n\nTime Period: November 2016 to till now\n\nDesignation: Member of Technical Staff II\n\nProject Title:\n\nTJay is the Healthcare IOT device building for pre prediction of Neurological disorders.With this wearable device , the doctors can monitor the patients data/history remotely, so that doctors can guide the way to create the wellness and happiness in the patients life.\n\nJob Responsibilities:\n\n\t· Research and implement classification algorithms for detection of epileptic seizures using physiological time-series datacollected from wearable sensors.\n\n· Improved upon the accuracy of existing algorithms by incorporating non-linear and chaotic features\n\n· Implemented algorithms for peak detection and artifact removal.\n\n· As a part of a team, designed and implemented a real-time machine-learning framework for human emotional state/activityrecognition.\n\n· Mentor budding data scientists.\n\n\n\t\n\n\nCompany 2: \n\nAegis Global PvtLtd,Bangalore\n\nTime Period: March 2016 to September 2016.\n\nDesignation: Assistant Manager Technology\n\nProject Title:\n\nPredicting Customer behavior for Industry Leading Automobile Company. Service is a series of maintenance procedures carried out at a set time interval or after the vehicle has traveled a certain distance. The service intervals are specified by the vehicle manufacturer in a service schedule and some modern cars display the due date for the next service electronically on the instrument panel. We need to predict whether customer will come to next service or not and also what are the problems most likely vehicle might have.\n\nJob Responsibilities:\n\n\t· Acquire data from primary or secondary data sources and maintain databases/data systems\n\n· Work closely with management to prioritize business and information needs\n\n· Identify, analyze, and interpret trends or patterns in complex data sets\n\n\n\t\n\t\n\n\nCompany 3: \n\nIPSoft Global Services PvtLtd,Bangalore\n\nTime Period:\nJuly 2015 to March 2016\n\nDesignation:\nSystems Engineer\n\nProject Title:\n\nPredicting  Customer behavior of Courier Service.Customer Analytics have become a vital tool for success used to glean important information,anticipate customer behavior , and drive loyalty. With growing competition in shipping market companies needs to focus on Customer behavior to understand customer requirements and needs.\n\n\nJob Responsibilities:\n\n\t· Interpret data, analyze results using statistical techniques and provide ongoing reports\n\n· Develop and implement data collection systems and other strategies that optimize statistical efficiency and data quality\n\n· Identify, analyze, and interpret trends or patterns in complex data sets\n\n· Filter and “clean” data, and review computer reports, printouts, and performance indicators to locate and correct code problems\n\n\n\t\n\n\nCompany 4:\n\nOptime Info Services Pvt Ltd, Bangalore\n\nTime Period: \nJuly 2011 to July 2015\n\nDesignation:  Senior Software Engineer\n\nProject Title:\n\nWork closely with various teams across the company to identify and solve business challenges utilizing large structured, semi-structured, and unstructured data in a distributed processing environment. Develop a new pricing strategy for Total Jeans that boosted margins by 2 percent and analyzed customer buying habits which correctly predicated the resurgence of dark blue denim giving us a jump on the competition\nJob Responsibilities:\n\n\t\n\t\n\n\t· Analyze large datasets to provide strategic direction to the company.\n· Perform quantitative analysis of product sales trends to recommend pricing decisions.\n\n· Conduct cost and benefit analysis on new ideas.\n· Scrutinize and track customer behavior to identify trends and unmet needs.\n\n· Develop statistical models to forecast inventory and procurement cycles.\n\n· Assist in developing internal tools for data analysis\n\n\n\tProject Title:\n\nCitrix Cloud \nJob Responsibilities:\n\n\n· Supporting and troubleshooting Customer issues.\n\n· Installing, publishing, configuring business applications as per customer requirement.\n· Involved in Upgradation activities from Xenserver 6.0/6.2 to 6.5.\n\n· Involved in Live migration of VMs between the Hosts without affecting VMS during production hours.\n\n· Upgradation of firmware for dell and hp servers using ILO(Integrated Lights Out)  and IDRAC.(Integrated Dell Remote Access Controller)\n\n· Analysing the Customer issues in depth, when the VMs went to Unregistered state.\n\n· Installing Hotfixes, Rollup Pack Updates on the Servers.\n\n\nDate  : JAN 03 2018\nPlace : Bangalore                                                                                                    SUHAS JK","annotation":[{"label":["Location"],"points":[{"start":7647,"end":7655,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":6994,"end":6998,"text":"Cloud"}]},{"label":["Location"],"points":[{"start":5998,"end":6006,"text":"Bangalore"}]},{"label":["Location"],"points":[{"start":5078,"end":5086,"text":"Bangalore"}]},{"label":["Location"],"points":[{"start":4119,"end":4127,"text":"Bangalore"}]},{"label":["Location"],"points":[{"start":3181,"end":3189,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":3059,"end":3068,"text":"PostgreSql"}]},{"label":["Skills"],"points":[{"start":3038,"end":3044,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":3009,"end":3013,"text":"Unix "}]},{"label":["Skills"],"points":[{"start":2970,"end":2975,"text":"Python"}]},{"label":["Location"],"points":[{"start":2935,"end":2943,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":1587,"end":1593,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":1285,"end":1290,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1022,"end":1027,"text":"Python"}]},{"label":["Skills"],"points":[{"start":807,"end":812,"text":"Python"}]},{"label":["Name"],"points":[{"start":170,"end":177,"text":"Suhas Jk"}]},{"label":["Skills"],"points":[{"start":157,"end":158,"text":"ML"}]},{"label":["Skills"],"points":[{"start":145,"end":150,"text":"Python"}]},{"label":["Skills"],"points":[{"start":98,"end":103,"text":"Python"}]},{"label":["Skills"],"points":[{"start":39,"end":44,"text":"Python"}]},{"label":["Skills"],"points":[{"start":32,"end":33,"text":"ML"}]}],"extras":null,"metadata":{"first_done_at":1532668984000,"last_updated_at":1532668984000,"sec_taken":114,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "SUMIT RANJAN        \n                                                                                                                  \n                                                                                                                     Email: sumit.ranjan819@gmail.com\n                                                                                                                     Phone Number: +91-8197199347\n\n\n SUMMARY:\n\n· An experienced, disciplined, and highly-motivated Data Analyst with 3.5 years of experience with an organization of repute in IT field. An accomplished and fluent communicator with strong investigation, problem-solving and decision-making skills, combined with a pragmatic approach. \n· Expertise includes abstracting and quantifying the computational aspects of the problems, designing and applying new statistical algorithms as well as system-level software design and implementation in different platform e.g. R, Python, PySpark, SparkR and Oracle SQL.\n· Excellent mathematical, statistical and calculation skills with ability to apply to real world situations.\n· Experience in applying Machine Learning and Statistical Modeling techniques to solve business problem.\n· Working knowledge on Supervised Learning and Unsupervised Learning.\n· Implemented bootstrapping methods such as Random Forests (Classification), K-Mean Clustering, KNN (K-Nearest Neighbors), SVM (Support Vector Machines), Decision Tree, PCA (Principal Component Analysis), Recommender systems, NLP (Natural Language Processing) Linear and Logistic Regression Methods.\n· Working knowledge of neural network library such as tensor flow.\n· Working knowledge on tools such as Microsoft Azure ML, R-Studio, Anaconda and IBM Data Science tool.\n· Experience of working in different domains i.e. Semiconductor, Health Care & Telecom domain.\n· Worked as System Analysis for an Application for client Lam Research. Responsible for performance and throughput analysis using logs, before deployment across releases for various customers like INTEL, SAMSUNG, TSMC, Global Foundries, etc.\n· Worked as a Test Analyst for client NOKIA. \n\n\nTECHNICAL SKILLS: \n\n\n\tOperating Systems\n\tWindows, Linux, Mac\n\n\tLanguages\n\tR, Python, SQL\n\n\tTools Used\n\tMicrosoft Azure ML, R-Studio, Anaconda, IBM Data Science tool, Jupyter Notebook, Apache Spark & SQL Developer.\n\n\tMathematical Skills\n\tStatistics, Mathematics ( Linear Algebra, Calculus & Probability)\n\n\tDatabases\n\tSQL Developer\n\n\tData Analysis \n\tIBM Clear Quest, ECR\n\n\t\n\nMachine Learning Algorithms\n\tRandom Forests (Classification), K-Mean Clustering, KNN (K-Nearest Neighbors), SVM (Support Vector Machines), Decision Tree, PCA (Principal Component Analysis), Recommender systems, NLP (Natural Language Processing) Linear and Logistic Regression Methods, Neural Network Theory\n\n\tLibrary used\n\tNumpy, Pandas, Matplotlib, Seaborn, Plotly and Cufflinks, Scikit     and Tensorflow.\n\n\n\n\n\n\n\nEXPERIENCE SUMMARY: \n\n· KPIT Technologies\t\t\t\t\t\t\tMarch 2017- Present\n· OAK Systems Pvt Ltd., Software Test Engineer\t\t\t\tJuly 2014– Dec 2016\n\nONSITE EXPOSURE: \n\n· NOKIA(ALU Unit), Silver Oak, Manyata Tech Park, Bangalore.\n· Lam Research Corporation, Maruthi Tech Park, Bangalore.\n· Baxter India, Prestige Shantinekatan, Whitefield, Bangalore.\n\n\nOpen Source Project: \n\n· Data Capstone project on 911 Calls using Python & R.\n· LINEAR REGRESSION project on USA Housing using Python & R.\n· LOGISTIC REGRESSION project on Titanic Data ( www.kaggle.com) using python & R.\n· Natural Language Processing project on Yelp (www.kaggle.com ) using python & R.\n· Recommended System project on movie date (www.kaggle.com ) using python & R.\n· Deep Learning project using tensor flow on Bank data ( www.kaggle.com ) using python & R.\n\nPROJECT EXPERIENCE:\n\n\tProject 1#\n\tNEXUS\n\n\tRole\n\tSoftware Test Engineer\n\n\tClient\n\tLam Research Corporation (INTEL, SAMSUNG, TSMC, Global Foundries, etc.)\n\n\tTools used\n\tNexus Simulator, Eclipse, IBM Clear Quest web, TRACK, CyberSim.\n\n\tSDLC \n\t Iterative Model\n\n\n\nProject Overview:\n\nLam Research Corporation is an American corporation that engages in the design, manufacture, marketing, and service of semiconductor processing equipment used in the fabrication of integrated circuits. The Testing involves testing the functionality of the product like right film deposited in right proportion for the right duration. The real complex features like multi film types handling, consistency of the different deposition program execution and performance monitoring are handled through the automation scripts.\n\nResponsibilities:\n\n· Extensively involved in Throughput Analysis & Performance Analysis.\n· Extensive exposure in analysis the data using Excel.\n· Working as test analyst for an Application for client Lam Research. Responsible for testing if the Machine Learning algorithms are working fine, before deployment across releases for various customers like INTEL, SAMSUNG, TSMC, Global Foundries, etc.\n· Work closely with the delivery functions and ensure compliance with testing, configuration and release management processes for the projects responsible.\n\n\n\n\tProject 2#\n\tTS Portal\n\n\tRole\n\tSoftware Engineer Consultant\n\n\tClient\n\tBaxter International\n\n\tEnvironment\n\tJAVA, XML, SOAP Webservices, SQL, Oracle 10g, Sales force, JD Edwards\n\n\tTool Used\n\tSOAP 5.0.0, JIRA, XML Marker, Oxygen, SQL Developer\n\n\tSDLC \n\tAGILE Software Development\n\n\n\n\nProject Overview:\n\nAT&T is the global leader in the market for the telecom products. The purpose of AT&T Indirect eCommerce application is to provide online service to the customers. AT&T Indirect eCommerce application allows user to order for a new product & request service for the existing product for upgrading additional features. This application acts as a tool between customers & Service provider, wherein customer can request the service using this application.\n\nResponsibilities:\n\n· Involved in review and analysis of the requirements as stated in the Business document.\n· Preparing Functional Test cases against the requirements.\n· Involved in peer reviews, Stand up Meetings regular basis.\n· Involved in reviewing and executing test cases, reporting defect and retesting defects and follow up with the development team. \n· Sending clarification emails to BA’s in order to make the Business document perfect.\n· Updating weekly status and daily status report and attending calls regularly.\n· Involved in Sprint review meetings and Sprint retrospect meeting.\n· Performed Functional, Database testing, Regression Testing, Smoke, Adhoc and System Testing.\n\nEDUCATIONAL QUALIFICATION: \n\n· Professional Qualification (B.TECH ELECTRONICS & TELECOMMUNICATION):- From Dr. MGR Educational & Research Institute, Chennai with 89.99%\n· CLASS XII 2008 (Intermediate): From ST Columba’s College, Hazaribag with 61.02 %\n· CLASS X 2006: From ST Stephen’s School, Hazaribag with 84.06%\n\n\nTRAINING & CERTIFICATION: \n\n· “Data Science, Deep Learning & Machine Learning with Python” certification from Sundog Education, Florida.\n· “Data Science & Machine Learning Bootcamp with R” certification from Pearson Inc.\n· “Microsoft Azure ML” Bootcamp at Microsoft, EGL Bangalore.\n· “Statistics for Data Science” certification from Udacity.\n\n\n\n\nACHIEVMENTS: \n\n· “Silver Medalist” in Electronic & Telecommunication Engineering of the University.\n· Got “Active mind of the year award (EINSTEIN AWARD)” 2011 by “Institute of Engineering & Technology, United Kingdom”.\n· Got “BEST START-UP “of the year award 2011 for “MICROSOFT TECHNOLOGY CLUB”, by “Institute of Engineering & Technology, United Kingdom”.\n· Received the “ABOVE & BEYOND” award on Dec’15 by LAM Research India for outstanding contribution towards project.\n· Received the “SPOT AWARD” award on Oct’17 by Baxter India for outstanding contribution towards project.\n\nPERSONAL DETAILS:\n\n· Date of Birth\t\t\t20 Jan 1991\n· Languages Known\t\tEnglish, Hindi \n· Marital Status\t\t\tSingle","annotation":[{"label":["Skills"],"points":[{"start":7794,"end":7794,"text":"R"}]},{"label":["Skills"],"points":[{"start":7709,"end":7709,"text":"R"}]},{"label":["Skills"],"points":[{"start":7687,"end":7687,"text":"R"}]},{"label":["Skills"],"points":[{"start":7624,"end":7624,"text":"R"}]},{"label":["Skills"],"points":[{"start":7571,"end":7571,"text":"R"}]},{"label":["Skills"],"points":[{"start":7484,"end":7484,"text":"R"}]},{"label":["Skills"],"points":[{"start":7446,"end":7446,"text":"R"}]},{"label":["Skills"],"points":[{"start":7361,"end":7361,"text":"R"}]},{"label":["Skills"],"points":[{"start":7051,"end":7051,"text":"R"}]},{"label":["Skills"],"points":[{"start":6948,"end":6953,"text":"Python"}]},{"label":["Skills"],"points":[{"start":6878,"end":6878,"text":"R"}]},{"label":["Skills"],"points":[{"start":6866,"end":6866,"text":"R"}]},{"label":["Skills"],"points":[{"start":6676,"end":6676,"text":"R"}]},{"label":["Skills"],"points":[{"start":6660,"end":6660,"text":"R"}]},{"label":["Skills"],"points":[{"start":6619,"end":6619,"text":"R"}]},{"label":["Education"],"points":[{"start":6607,"end":6644,"text":"B.TECH ELECTRONICS & TELECOMMUNICATION"}]},{"label":["Skills"],"points":[{"start":6531,"end":6544,"text":"System Testing"}]},{"label":["Skills"],"points":[{"start":6521,"end":6525,"text":"Adhoc"}]},{"label":["Skills"],"points":[{"start":6514,"end":6518,"text":"Smoke"}]},{"label":["Skills"],"points":[{"start":6494,"end":6511,"text":"Regression Testing"}]},{"label":["Skills"],"points":[{"start":6494,"end":6494,"text":"R"}]},{"label":["Skills"],"points":[{"start":6476,"end":6491,"text":"Database testing"}]},{"label":["Skills"],"points":[{"start":6464,"end":6473,"text":"Functional"}]},{"label":["Skills"],"points":[{"start":5977,"end":5986,"text":"Functional"}]},{"label":["Skills"],"points":[{"start":5856,"end":5856,"text":"R"}]},{"label":["Skills"],"points":[{"start":5306,"end":5306,"text":"R"}]},{"label":["Skills"],"points":[{"start":5128,"end":5128,"text":"R"}]},{"label":["Skills"],"points":[{"start":4761,"end":4761,"text":"R"}]},{"label":["Skills"],"points":[{"start":4751,"end":4751,"text":"R"}]},{"label":["Skills"],"points":[{"start":4547,"end":4547,"text":"R"}]},{"label":["Skills"],"points":[{"start":4029,"end":4029,"text":"R"}]},{"label":["Skills"],"points":[{"start":3961,"end":3961,"text":"R"}]},{"label":["Skills"],"points":[{"start":3831,"end":3831,"text":"R"}]},{"label":["Skills"],"points":[{"start":3788,"end":3788,"text":"R"}]},{"label":["Skills"],"points":[{"start":3758,"end":3758,"text":"R"}]},{"label":["Skills"],"points":[{"start":3747,"end":3747,"text":"R"}]},{"label":["Skills"],"points":[{"start":3742,"end":3742,"text":"R"}]},{"label":["Skills"],"points":[{"start":3650,"end":3650,"text":"R"}]},{"label":["Skills"],"points":[{"start":3576,"end":3576,"text":"R"}]},{"label":["Skills"],"points":[{"start":3571,"end":3571,"text":"R"}]},{"label":["Skills"],"points":[{"start":3489,"end":3489,"text":"R"}]},{"label":["Skills"],"points":[{"start":3424,"end":3424,"text":"R"}]},{"label":["Skills"],"points":[{"start":3421,"end":3421,"text":"R"}]},{"label":["Skills"],"points":[{"start":3407,"end":3407,"text":"R"}]},{"label":["Skills"],"points":[{"start":3398,"end":3403,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3361,"end":3361,"text":"R"}]},{"label":["Skills"],"points":[{"start":3358,"end":3358,"text":"R"}]},{"label":["Skills"],"points":[{"start":3356,"end":3356,"text":"R"}]},{"label":["Skills"],"points":[{"start":3346,"end":3346,"text":"R"}]},{"label":["Skills"],"points":[{"start":3337,"end":3342,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3154,"end":3154,"text":"R"}]},{"label":["Skills"],"points":[{"start":3081,"end":3081,"text":"R"}]},{"label":["Skills"],"points":[{"start":2945,"end":2945,"text":"R"}]},{"label":["Skills"],"points":[{"start":2933,"end":2933,"text":"R"}]},{"label":["Skills"],"points":[{"start":2779,"end":2779,"text":"R"}]},{"label":["Skills"],"points":[{"start":2704,"end":2704,"text":"R"}]},{"label":["Skills"],"points":[{"start":2543,"end":2543,"text":"R"}]},{"label":["Skills"],"points":[{"start":2508,"end":2508,"text":"R"}]},{"label":["Skills"],"points":[{"start":2264,"end":2264,"text":"R"}]},{"label":["Skills"],"points":[{"start":2218,"end":2223,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2215,"end":2215,"text":"R"}]},{"label":["Skills"],"points":[{"start":1923,"end":1923,"text":"R"}]},{"label":["Skills"],"points":[{"start":1913,"end":1913,"text":"R"}]},{"label":["Skills"],"points":[{"start":1710,"end":1710,"text":"R"}]},{"label":["Skills"],"points":[{"start":1566,"end":1566,"text":"R"}]},{"label":["Skills"],"points":[{"start":1491,"end":1491,"text":"R"}]},{"label":["Skills"],"points":[{"start":1330,"end":1330,"text":"R"}]},{"label":["Skills"],"points":[{"start":990,"end":999,"text":"Oracle SQL"}]},{"label":["Skills"],"points":[{"start":984,"end":984,"text":"R"}]},{"label":["Skills"],"points":[{"start":979,"end":984,"text":"SparkR"}]},{"label":["Skills"],"points":[{"start":969,"end":976,"text":" PySpark"}]},{"label":["Skills"],"points":[{"start":962,"end":967,"text":"Python"}]},{"label":["Skills"],"points":[{"start":959,"end":959,"text":"R"}]},{"label":["Skills"],"points":[{"start":440,"end":440,"text":"R"}]},{"label":["Skills"],"points":[{"start":6,"end":6,"text":"R"}]},{"label":["Name"],"points":[{"start":0,"end":11,"text":"SUMIT RANJAN"}]}],"extras":null,"metadata":{"first_done_at":1532677073000,"last_updated_at":1532677073000,"sec_taken":204,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Résumé\nName: Sunil MS\n\nContact info: sunil.inxs@gmail.com; +91 99001 58376\nCTC: 26.5 L \n\nECTC: 30 %\n\nProfessional Summary: A Black Belt Certified Professional with over 17 years of vibrant and rich experience in Customer Centric Operations, Client Relationship Management, Technology Lead Project Planning, Execution and Delivery.  Developed and deployed some of the Industry Leading solutions that are patented to Infosys.\nQualifications: Bachelor of Science – Computer Technology and Graduate NIIT, Professional Certifications in Mortgage Banking, Retail Banking, Business Analysis and Business Management\nProfessional Profile:\nHexaware Experience (Oct 2016 – Till date)\n1) Currently as General Manager of Automation Initiatives I am responsible of a Team of 140 people spread across 4 locations globally – Bengaluru, Mumbai, Chennai, New York, Amterdam and Singapore for deployment of Automation Robots based on multiple platforms - Automation Anywhere, UiPath, Blue Prism and Work Fussion\n2) This team is solely responsible for bringing about the required Automation across Business lines and locations across the Globe\n3) Timeliness, Quality Compliant delivery is the mantra of the team and we live up to it – consistently up to Six Sigma levels using the best of practices in Project Management and Quality tools\nInfosys experience (Feb 2006 – Aug 2016):\n1) Part a team of spirited individuals who is responsible for Identification, Development and Deployment of Technology led Process Automation Transformation Solutions as Head with the following responsibilities: \na) Delivering value to Customers by driving Process Improvements through innovative and appropriate use of Talent and Technology Solutions including but, not limited to Automation Anywhere, Blue Prism, UiPath, in-house solutions etc.,\nb) Creating an environment that is conducive for generation of ideas to improve Service Delivery.\nc) Oversee implementation and ensure delivery quality and timeline compliance.\nd) Manage Vendors to implement new requirements for support and governance models.\ne) Manage Resources, Projects and P&L.\n2) Prior to the above role I have played multiple roles and respective responsibilities:\na) I joined Infosys BPO as Assistant Manager was part of back office operations for a Leading US Mortgage company handling a team of 42 team members, 3 Team Leads.  The process outsourced to Infosys BPO required all staff to have a strong knowledge of Mortgage banking (Inclusive of Securitization and Secondary Marketing).  The client sponsored my MBA101 certification for being a good performer.\nb) Was promoted to Operations Manager and assigned 2 new teams with the following responsibilities:\ni) Ensure seamless operations by monitoring periodical reports & MIS on various parameters & controlling SLAs.\nii) Building strong effective relationships with clients to ensure alignment with client business needs and leverage business opportunities.\niii) Framing work direction and plan for associates after assessment of their capabilities.\niv) Monitoring overall functioning of processes, identifying improvement areas and implementing measures to maximize customer satisfaction level; responsible to process and guidelines.\nc) Was promoted as Senior Project Manager and took additional responsibilities:\ni) P&L and Overall process delivery of the entire engagement\nii) Large scale project planning, deployment including new process transition and setup.\niii) Client Relationship Management while looking out for opportunities for further additions to the existing processes outsourced to Infosys.\nPrior to Infosys (in chronological order – bottom up):\na. Ocwen Financial Services (Jan 2005 – Dec 2005):\nWorked as Senior Team Leader for Fulfillment Services – was required to understand the fundamentals of securities and the way these securities are handled.  This knowledge was used to ensure that all investments Ocwen made in mortgage securities met the stringent company guidelines and the portfolio Ocwen had.\nb. AXA Business Services (Oct 2001 – Dec 2004):\nJoined as a Junior Team Member worked in multiple processes – Medical Insurance claims management, Claims adjudication, Policy Underwriting, Vehicle Insurance claims processing and management.  Good performance, knowledge and Leadership qualities helped me get promoted twice. After a span of 3+ years I quit as a Process Leader.\nc. Hindustan Unilever Limited (June 2000 – Oct 2001):\nWorked as Implementation Engineer; ensuring a noiseless implementation and data transition from a native MFG Pro to a customized version across C&FA (carrying and forwarding agents) locations.  As part of a team of 20+ implementation staff I was required to understand ERP functionalities from a Technology and business standpoints.\nTechnologies and Solutions:\nBusiness Analysis and Project Management enabling technology skills – IBM Rational RequisitePro, MS Visio, MS Office and MS Project\nApp Development Technologies worked on – C, C++, .Net, VC, MS SQL\nDatabases used as backend – MFG Pro, MS SQL and MS Access\nRPA Solutions – Blue Prism, UiPath, Automation Anywhere\nEducation:\nBachelor of Science (Computer Science) from Alagappa University – Department of Distance Education passed in May 2000\nBlack Belt Certified\nPursuing MBA from Alagappa University","annotation":[{"label":["Education"],"points":[{"start":5131,"end":5149,"text":"Bachelor of Science"}]},{"label":["Skills"],"points":[{"start":5099,"end":5118,"text":" Automation Anywhere"}]},{"label":["Skills"],"points":[{"start":5092,"end":5097,"text":"UiPath"}]},{"label":["Skills"],"points":[{"start":5079,"end":5089,"text":" Blue Prism"}]},{"label":["Skills"],"points":[{"start":4905,"end":4912,"text":"MS Visio"}]},{"label":["Skills"],"points":[{"start":4878,"end":4902,"text":"IBM Rational RequisitePro"}]},{"label":["Skills"],"points":[{"start":1776,"end":1781,"text":"UiPath"}]},{"label":["Skills"],"points":[{"start":1763,"end":1773,"text":" Blue Prism"}]},{"label":["Skills"],"points":[{"start":1742,"end":1761,"text":" Automation Anywhere"}]},{"label":["Skills"],"points":[{"start":1139,"end":1164,"text":"Quality Compliant delivery"}]},{"label":["Skills"],"points":[{"start":964,"end":974,"text":" Blue Prism"}]},{"label":["Skills"],"points":[{"start":957,"end":962,"text":"UiPath"}]},{"label":["Skills"],"points":[{"start":935,"end":954,"text":" Automation Anywhere"}]},{"label":["Skills"],"points":[{"start":689,"end":703,"text":"General Manager"}]},{"label":["Education"],"points":[{"start":440,"end":458,"text":"Bachelor of Science"}]},{"label":["Name"],"points":[{"start":13,"end":20,"text":"Sunil MS"}]}],"extras":null,"metadata":{"first_done_at":1532693071000,"last_updated_at":1532693071000,"sec_taken":203,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Sunil S                                                                                                   \nPh: 7204026231\nEmail Id: kanealways@gmail.com\n____________________________________________________________________________\nExperience: 10+ Years\nPROFESSIONAL SUMMARY:  \nElectronics and Communication Engineer with Masters in Digital Electronics & Communication Engineering from Visweswarays Technological University. \nDiverse work experience in IT industry for more than 10+ years with Capgemini as Senior Consultant. Equipped with sound technical background along with management skills. Passionate about software development and aspires to be a successful software developer with sound technical knowledge. \nCore competencies include:Python,Machine Learning (Scikit Learn),  Pandas, PySpark\nEducation:\nM.Tech in digital electronics and communication systems (VTU) [2005-2007]\nB.E in ECE \n[2000-2004]\n\nProfessional Experience:\n· Working as Senior consultant at Capgemini Technological Services India Pvt Ltd\n\n· Currently working as Data Scientist (Python technology) 5 Years of experience\n· Earlier worked as software developer for Mainframe Technology, 5 Years of experience\nTechnical Skills:\n\tProgramming Language\n\tPython, Pyspark, Scala (basic)\n\n\tPackages\n\tPandas, SCIKIT Learn, Flask\n\n\tPlatform\n\tSpark\n\n\tTools\n\tAirflow, Jenkins, Lambda(AWS)\n\n\tDatabase\n\tPostgreSQL, MongoDB, MySQL\n\n\nProject Details:\nRole: Data Scientist                                                                                           Jun 2016 – Present\nCapgemini Technological Services India Pvt Ltd. (Bengaluru, KA)\nClient: GE Digital\nSkills: Python, PySpark, Airflow, Genie, Jenkins, Postgresql \nProject Description:  Project is about Migrating analytics running on legacy system (MnD – Monitoring and Diagnostics) written in Matlab and CCAP to AWS platform.The new platform in AWS is designed to build and run analytics with ease using airflow, genie, jenkins tools\nContributions:\n· Developed Python analytics using SCIKIT\n· Developed Python programs to fetch Data from database PostgreSQL for analytics using SQLAlchemy\n· Developed orchestration part of running the analytics, using Python\n· Written DAGs in Python extensively for Airflow (workflow engine)\n· Developed and designed an API (RESTful Web Service) for the company’s website to display Airflow status\n· Working at clients location (JFWTC GE’s Research and Development center Bengaluru)\n· My responsibilities included, Propose solutions to problems, coordinate and discuss with onsite client counterpart\n· Set-up the project artifacts for perfect analytic execution\n· Written numerous adhoc Python scripts for data handling \n· Performed all responsibilities exceptionally, as a result was assigned to completely manage and complete 2 new projects.\nRole: Team Lead                                                                  Jun 2013 – May 2016                                                                                                                   Capgemini Technological Services India Pvt Ltd. (Bengaluru, KA)\nClient: GE Aviation\nSkills: Python, Pandas\nProject Description: The project was to create a catalog of analytics. Also to write Python scripts that do data cleansing which were later uploaded to legacy system. \nContributions:\n· Developed Python programs to visualize all analytics alarm data using  matplotlib\n· Developed Python based program to store analytic’s alarm data in PostgreSQL database, using SQLAlchemy\n· Developed Python based RESTFul API  to access alarm data for the analytics using Flask, SQLAlchemy and PostgreSQL.\nRole: Onsite CoOrdinator                                                                                                    Aug 2010 – May 2013\nPatni Americas Inc. (Shelton, CT USA)\nClient: GEXPRO support\nSkills: Mainframe\nProject Description: Developing new functionalities related to SCM (Supply Chain Management) with Mainframe as  main technology. The project primarily involves the maintenance of mainframe applications belonging to gexpro system. Here I have worked at clients location in Shelton Connecticut US. \nContributions:\n· My responsibilities included working with Clients to discuss requirement, various ideas/solutions, road blockers, and timelines\n· Reviewing work-product created by my team offshore before delivering them to the clients.\nRole: Team Member                                                                                                                 Aug 2007 – July 2010\nPatni Computers Systems Ltd. (Mumbai, MH)\nClient: IESC development and support\nSkills: Mainframe\nProject Description: Develop mainframe applications according to specification provided. \nContributions:\n· My responsibilities included working with Onsite coordinator to discuss requirement, various ideas/solutions, road blockers, and timelines\n· Do testing of the code changes done with suitable test cases\n· Reviewing my work-product before delivering them to onsite coordinator.\nPage 1 of 3","annotation":[{"label":["Skills"],"points":[{"start":4606,"end":4614,"text":"Mainframe"}]},{"label":["Skills"],"points":[{"start":3932,"end":3940,"text":"Mainframe"}]},{"label":["Skills"],"points":[{"start":3824,"end":3832,"text":"Mainframe"}]},{"label":["Skills"],"points":[{"start":3506,"end":3511,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3401,"end":3406,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3317,"end":3322,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3207,"end":3212,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3107,"end":3112,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2643,"end":2648,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2199,"end":2204,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2174,"end":2179,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2025,"end":2030,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1983,"end":1988,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1631,"end":1636,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1224,"end":1229,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1139,"end":1147,"text":"Mainframe"}]},{"label":["Skills"],"points":[{"start":1055,"end":1060,"text":"Python"}]},{"label":["Education"],"points":[{"start":810,"end":815,"text":"M.Tech"}]},{"label":["Skills"],"points":[{"start":749,"end":764,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":742,"end":747,"text":"Python"}]},{"label":["Name"],"points":[{"start":0,"end":7,"text":"Sunil S "}]}],"extras":null,"metadata":{"first_done_at":1532691822000,"last_updated_at":1532691822000,"sec_taken":76,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Suranjan Malik\nCurrent –Bangalore \n\nE-mail: suranjanmalik@gmail.com\n\nMobile: +91- 8880037735/8073324475\nEXPERIENCE SUMMARY\n\n· 4+years experience in Production-Application-Maintenance-Enhancement in Transportation and Investment Banking.\n· Monitoring of the application jobs,creating and droping of databases.\n· Involved in application issue and fixing it accoring to priority.\n· Analyzing the issue and finding the root cause\n\n· Hands on experience in Oracle(sql,pl/sql),Unix(shell scripting),Python.\n\n· Modifying the Sql and PL/sql code as per the client requirement.\n· Good exposure to analytical and problems resolving skills.\n\n· Managed continous maintenance and troubleshooting of Python Django projects.\n\n· Having basic knowledge of Core Java and HTML.\n\n· Hands on experience in Handling and resolving the escalations.\n· Involved in System maintenance and database Support activities\n\n· Trouble shooting various errors in Applications\n· Involved in various releases and code level changes as per the CR’s.\n\n· Involved in the analysis of the recurring issue and Enhancing the performance of the existing system.\n\n· Attending the calls with team members with clients for understanding the requirements.\n\n· Involved in creation and modification of various Pl/sql code (procedure, function, Package, Trigger etc).\n\n· Involved in  performance tuning activities.\n\n· Experience in creating the RFC and MOP for sev2 Issues. \n· Hands on experience in Monitoring the servers and make sure server should  up and running.\n· Hands on experience of automating the system to avoid the manual job.\n\nACADEMICS \n\n· B.Tech in Computer Science from Biju Pattnaik University of technology, Rourkela, Orissa 2009.\nPERSONAL SKILLS\n\n· Working as a team player with strong analytical and problem-solving skills.\n\n· Aspiring to work with a growing organization that offers a challenging environment to carve a nice and effectively deliver towards contributing to the organization’s target & aspirations.\n\nTECHNICAL SUMMARY\n\n\tSKILLS\n\tTOOLS\n\n\tLanguages\n\tSQL,PL/SQL,Shell Scripting,Python\n\n\tCase Tools\n\tToad,Sql Developper,SQL Server managements FTP, Remedy 7.1,Putty,Mputty,mRemoteNG,Service Center,SNOW,JIRA, Winscp,SSH,IDLE,Django\n\n\tScheduling Tools\n\tCA Workload,ESP Series,COSmanager,Autosys.\n\n\tOperating Systems\n\tWindows 2008 Server, Windows 7\nUnix,LINUX\n\n\tDatabase\n\tOracle(9i/10g/11g/12c),Sql server managements\n\n\nWORK EXPERIENCE\n\n\tDuration\n\n\n\tOrganization\n\tDesignation\n\n\tApr 2013 to till date\n\tXerox India(Conduent), Bangalore\n\tSystem Dev. Specialist\n\n\nPROJECT EXPERIENCE\n\nProject #1 : Electronic Toll Collection Systems(E-ZPass)            \nClient\n\n           \n: US Government(NY,NJ,NH,NC,MD,BATA,SC,TXDOT)\nEnvironment \n\n: Oracle 10g, shell scripting,Linux,Unix,Python\nTeam Size\n           \n: 15\nMethodologies           : Oracle and Unix\n\nRole\n\n           \n: Production support\nOrganization \n\n:Xerox India(Conduent),Bangalore\n\nDescription: \nElectronic Toll Collection Systems has become a technically feasible and financially attractive alternative to finance and maintain highway construction projects and their ongoing maintenance operations. VECTOR is a large and complex system, consisting of a number of different components. Beyond replacing cash collections to improve revenue accountability,ETC has evolved to support the digital age with technologies that safeguard toll revenues. It provides an improved patron experience by mobility, safety,convenience and even support for a “greener”world by reducing pollution. ETC is now a necessity and a daily part of many commuters lives as indicated by the popular use in congested urban areas of New York and New Jersey. Demands for faster and greater vehicle throughput technologies are now providing the basis for another tolling evolution which Xerox is leading. This includes new concepts ywhere toll booths give way to all-electronic non-stop openhighway tolling or AET.VECTOR systems operate in a 24x7 production environment.  \n\n\tROLES AND RESPONSIBILITIES\n\n\n\n\t· Involved in code lable investigation of the jobs(UNIX, Shell Scripting,Python,\n     Oracle 9i, SQL,PL/SQL).\n· Monitoring of the application batch jobs.\n· Involved in application issue and taking the proper action.\n· Analyzing the issue and finding the root cause.\n· Fixing the job failure issue.\n· Trouble shooting various errors in Applications.\n· Providing work around in the form of data fix .\n· Involved in resolving production problems for the applications and Ensure all support service level agreements are meet. \n· Documenting the cause, resolution of the issue.\n\n· Running some shell scripts to make support work easier.\n· In OUTAGE condition taking the necessary steps to resolve the issue with Helpdesk/LAN/Network team\n\n· Involed on diffenent issue depending on priority basis.\n· Providing the support in L2/L3 level depending on  the Priority of the issues to meet client’s SLA.\n\n· Providing support to client on 24*7 basis.\n\n\n\n\nProject #2\n      Margin and Risk      \nClient\n\n            : Bank of America\nEnvironment \n            : Oracle 9i, Unix,shell scripting\nTeam Size\n           \n: 5\nRole\n\n           \n: Production Support/Application support.\nOrganization \n             : Xerox India\nDescription: \n\n\nServing individual consumers.small and large market business and large corporations  with\n\nRange of banking ,investing ,asset management and other financial risk management product and services.\n\nROLES AND RESPONSIBILITIES :- \n\n· Monitoring Daily production Scheduling Jobs.\n\n· Resolving the application issue.\n\n· Developed stored procedures and complex packages extensively using PL/SQL and shell programs.\n\n· Coding for the required components.\n\n· Involved in L1/L2/L3 support depending on the Priority of the issues to meet client’s SLA.\n\n· Interaction with customers for production issues.\n\n· Resolving production issues\n\n· Writing high quality and well documented code according to standards.\n\n· Extensive experience in developing UNIX Shell scripts, SQL and PL/SQL (Coding Procedures, Functions, Database Packages and Triggers).\n\n· Developed reports using complex queries as per client request as a part of production support.\n\n· Handling trouble tickets.\n\n· Application Support 24/7.\n\nProject #3\n     PSS(Public Safty Systems)\nClient\n\n           \n: US Govt.\nEnvironment \n\n: Unix,Linux,Sql server managements,\nTeam Size\n           \n: 5\nRole\n\n           \n: Application support\nOrganization \n\n: Xerox India\n\nDescription: \n\nPublic safety is a major concern—especially as budgets are cut and populations continue to grow. Every community deserves safe streets. With data analytics tools, automated photo enforcement, and other public road safety solutions, every community can have safer streets. Photo enforcement systems and solutions, including red light, speed and school bus cameras. No matter how large or small your jurisdiction, there is a photo enforcement system that can help you maximize resources, deter careless driving and keep people safe.\nROLES AND RESPONSIBILITIES :-\n\n· Monitoring the application\n· Handling the application ussue raised by customer\n· Developed stored procedures and complex packages extensively using PL/SQL and shell programs.\n\n· Coding for the required components.\n\n· Involved in importing the production data to lower environments for testing purpose.\n\n· Resolving Production severity Issues in time and meeting the SLA.\n\n· Involved in L1/L2/L3 support depending on the Priority of the issues to meet client’s SLA.\n\n· Interaction with customers for production issues.\n\n· Handling trouble tickets.\n\n· Prepared root cause analysis for problems occurred.\n\n· Monitoring Daily production Scheduling Jobs.\n\n· Application Support 24/7.","annotation":[{"label":["Skills"],"points":[{"start":4078,"end":4083,"text":"Python"}]},{"label":["Location"],"points":[{"start":2901,"end":2909,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":2747,"end":2752,"text":"Python"}]},{"label":["Location"],"points":[{"start":2501,"end":2509,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":2059,"end":2064,"text":"Python"}]},{"label":["Skills"],"points":[{"start":753,"end":756,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":739,"end":747,"text":"Core Java"}]},{"label":["Skills"],"points":[{"start":493,"end":498,"text":"Python"}]},{"label":["Skills"],"points":[{"start":471,"end":491,"text":"Unix(shell scripting)"}]},{"label":["Skills"],"points":[{"start":452,"end":469,"text":"Oracle(sql,pl/sql)"}]},{"label":["Location"],"points":[{"start":24,"end":32,"text":"Bangalore"}]},{"label":["Name"],"points":[{"start":0,"end":13,"text":"Suranjan Malik"}]}],"extras":null,"metadata":{"first_done_at":1532672539000,"last_updated_at":1532672539000,"sec_taken":111,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Surya Kiran Bende\nFlat 403, A06, Singapore Township,Pocharam,Hyderabad,500088\nTelephone: + 91 9666612520\nEmail: Surya.bende@gmail.com\nExperience Relevant to the Role:\n· Software  professional with 3.5 years of experience in Java Development and Data Scientist. \n· I have been working with Infosys Ltd, India as Senior Systems Engineer since 3rd Mar 2014 to till now.\n· Industry expertise – Banking, Manufacturing.\n· Strong skills include Python, Machine Learning, NLP, R, Java/J2EE\n\n· Good knowledge in Statistics and very strong in math concepts\n\n· Worked on finding solutions to various problems with data analytics (Regression, Classification, Clustering)\n\n· Worked extensively on Web based applications.\n· Worked in Waterfall model and having exposure to Agile methodology.\n· Good knowledge and proven experience in Java/J2EE.\n· Very good knowledge and hands on experience in SQL\n· Worked on stored procedures.\nProfessional Profile:\nAn ambitious and experienced Java Developer and ML Engineer with a strong technical background. I possess self-discipline\nand the ability to work with the minimum supervision. Having proven ability to carry out the assigned tasks, appropriate\nimplementation of requirements and communicate the outcome to work colleagues and clients.\nObjective:\nI am seeking a challenging opportunity in a leading organization to utilize my technical expertise and problem solving skills for the organization’s growth and success.\nEducation:\n\nBachelor of Technology in Electronics & Communication from Jawaharlal Nehru Technological University, Hyderabad, India\nKey Skills & Core Competencies:\n\t· IDE: Eclipse, Spyder, RStudio, Jupyter\n· Framework : Spring MVC \n· Database: Oracle\n· Tools:SQLDeveloper\n· Programming Language: Java/J2EE, Python, R\n\n· Querying Language : SQL\n\n· Basic commands of UNIX\n\n\t· Platform: Windows-7/XP/98, Unix \n· Cloud: Amazon Web Services (AWS)\n· Machine Learning (ML)\n\n· AWS Machine Learning\n\n· Natural Language Processing (NLP)\n\n· Scikit-Learn, Pandas, Matplotlib, Numpy, NLTK\n\n\n\n\nCertifications:\n· Edureka certified Data Science Professional\n\n· Udemy certified Python programmer\n· Oracle certified Professional Java SE 6 programmer (OCPJP 1.6).\n· Oracle certified Web component developer (OCEWCD 1.6)\nCareer Summary:\n\nMar 2014 to till now : Java Developer  &  ML, Infosys Pvt. Ltd.\n\nNotable Projects:\n· SRP:\nSupplier Risk Profiling. It deals with identification of supplier operational risk items, assessing risk impact, calculating   \nsupplier operational risk score, giving high risk notification and triggering risk mitigation in transactional system.\nI was involved in following activities: \n· Accountable for Data Extraction, Cleansing data and Deployment from multiple channels [Blogs, Supplier website,  Social network, News, Financial data]\n· Worked on supervised learning like regression and classification models. \n\n· Analyzed data by considering various supplier's operational parameters and calculated the supplier risk score\n· Predicted the suppliers goodwill with sentiment analysis\n· Deriving the insights on the market analysis using python.\n\n· Creating Monthly dashboards consisting of product analysis, Sentimental score card and region wise key products.\n\n· FBIT:\nFBIT application deals with tracking of expenditure (Forecast/Budget) related to headcount flow of employees which allows functionalities such as Creation of Budget/Forecast, managing the headcount flow, View historical budgeted/forecasted data and its comparison with current year forecast/budget data, Mismatch reports, summary reports. The phase 3 of the application aims to improve the Administrative and Performance Manager functions of the tool.   \n        I was involved in following activities:\n· worked closely with onsite folks for effective requirement analysis\n· Dealt with minor and major enhancements\n· Actively involved in implementation of core modules\n· Worked on Stored Procedures as part of the requirement\n· Code optimization\n· Unit tested the code\n· worked on bug fixing as part of maintaining activities\n\n· Helped team members to achieve target\n\t· Access Online :\nAccess Online is a web-based solutions, integrated robust online payments, balance and transaction reporting catering to the Front-office of Global Electronic Banking domain of ABN AMRO. Corporate customers mainly use this application for initiating manual/ file upload, online generation of reports, administration, track and trace of the status of payments and reports. \n        I was involved in following activities:\n· Understanding the Functional Specification Document\n· Developed and enhanced the code\n· Involved in UI development\n· Prepared and executed unit test cases\n· Building and deploying the new builds using Cascade version manager.\n· Maintaining the code quality by generating SONAR reports\nRewards and Achievements :\n· Insta Award in the year 2015\n\n· Award for Excellence for the year 2016\n\nSelf Interest :\n\n· Participated in various Kaggle/Analytics Vidhya Competitions and solved datasets on Predictive analytics.\n\n· Completed Self paced courses in Machine Learning from Udemy.\n\n· Part of the chrysalis group (ML club) in Infosys.\n· Participated in various Tech-Quiz's in Infosys\n\n\t\n\n\nPersonal Details:\n\n· Date of Birth: 23 December 1991\n· Languages known:English, Hindi, Telugu.\n· Hobbies:Cricket, Badminton, Photography.\n· Strengths:Dedication towards work, ability to work in Team, good presentation and verbal skills.\nDeclaration:I hereby declare that all the details furnished above are true to the best of my knowledge and belief.\nSURYA KIRAN B.","annotation":[{"label":["Skills"],"points":[{"start":1894,"end":1914,"text":"Machine Learning (ML)"}]},{"label":["Skills"],"points":[{"start":1865,"end":1890,"text":" Amazon Web Services (AWS)"}]},{"label":["Skills"],"points":[{"start":1790,"end":1792,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1746,"end":1754,"text":"Java/J2EE"}]},{"label":["Skills"],"points":[{"start":1709,"end":1711,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":880,"end":882,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":820,"end":828,"text":"Java/J2EE"}]},{"label":["Skills"],"points":[{"start":472,"end":480,"text":"Java/J2EE"}]},{"label":["Name"],"points":[{"start":0,"end":16,"text":"Surya Kiran Bende"}]}],"extras":null,"metadata":{"first_done_at":1532672740000,"last_updated_at":1532672740000,"sec_taken":94,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "SUSHMITA GOGOI \n(+91) 80886-95913/86603-07190                                                                                                         \n\nsushmita.gogoi12@gmail.com \n\nWork Experience: \nTrans Neuron Technologies                                                                                                                                                                          (Nov’16 – Present) \nProduct Manager       \n                    Developed India’s first admission and counselling Chatbot for UPES University and Karnataka Government’s cognitive counsellor \n\n UPES Counselling chatbot was used by 40K+ candidates in 6 days counselling across India, with an increase of 13%   in admission \n\n Enhanced the chatbot’s performance by tracking various metrics like Active and engagement rates, confusion triggers, conversion steps, \naverage conversation per day, Drop off rate of conversation in middle \n\n Developed a standard and ranked Apache SOLAR search engine for UPES university \nWeb Apps  \n\n Launched two websites named as iTrack and eKaushal/YuvaYuga  \n\n Build API products for clients, to sell their courses and training partners on our platforms \n\n  Monitoring the development of eLearning Kit for education platform ensuring Quality, Cost and Delivery Targets through \ncollaborative project planning and execution \n\n Handled 100+ business users both internal & external \n\n Managing a team of developers and analysts   \n\n \n\nReliance Jio Money Private Ltd. - Mumbai                                                                                                                                                    (Oct’15 – Oct’16) \nProduct Manager - Payments \n\nLed business Strategy and Product planning \n Led and executed the customer acquisition strategy and cost of acquisition for first 10,000 users and currently devised the strategy for 1 \n\nlakh Users \nMerchant App & Credit Score Engine  \n\n Designed the MC scoring Engine, which resulted in fraud reduction during pilot phase by 1.8 cr.  in 45 days.  \n Performed an Ethnographic Research in remote places of Rajasthan, Arunachal, J&K and many other states of India \n Designed the business requirement document (PRD) to outline the functionality of Jio money merchant application \n\n Merchant App: Responsible for onboarding of Merchants, and monitoring their transactions \n       Product Analytics  \n\n Developed different business cases on improving the drop off rates of new customers \n Process design for various functions of the company including micro loan, operations; effectively managed scale \n Developed a one view dashboard for top management covering key L1 corporate metrics for customer experience \n\n \n\nFlipkart Internet Private Ltd.                                                                                                                                                                                (Sep’13– Oct’15) \nSenior Business Analyst (Customer Experience Analytics) \n\n       NPS Drivers \n Developed a multi-linear regression model using Minitab for explaining and predicting Flipkart NPS \n\n Identified top 7 drivers of Flipkart NPS using the model, which lead to increase NPS by roughly 5% \n Performed sentiment analysis by modeling a boosted decision tree. It helped identify a customer’s propensity to be a Promoter / Demoter \n\n       Smart Check Implementation \n\n Designed the Smart Check metric to understand the inside out view of returns for Mobiles and Tablets \n Implemented the Smart Check process for reducing return rate of Mobiles and Tablets, resulting in reduction of return rate by ~4.5%, which \n\nresulted in savings of ~2.5 cr. \n\n       Returns and Refunds Platform Implementation Analytics \n\n Planned, implemented and executed an inside out metric for CEO, COO and the key holders to review the company’s performance \n\n        Refund Analytics Platform Implementation \n\n Instrumented the key performance metrics for continuous measurement of IMPS effectiveness on refunds process efficiency and TAT, \nwhich resulted in refunds NPS improved by ~30% \n\n       Customer Experience evaluation and Policies \n\n Performed Analytical work on various policies to remove bottlenecks from customer’s journey ed. Speedy refund in case of fake \nproduct \n\nBusiness Analyst (Payments Ops - Payzippy)                                                                                                                                                                                            \n   Merchant Effort Improvement \n\n Assisted in coordinating and developing the L1, L2 metrics for 11 functions in 4 clusters, i.e. Onboarding, Risk, Tech and Sales clusters across \nthe organization \n\n Business engagements and external stakeholder management (including large banks and payment gateways) and cross functional \ncollaboration for setting up payment aggregation services for PayZippy  \n\n       Wallet \n\n Built case studies to identify process and quality improvements in integration with the various banks \n\n Meet Stakeholders requirements and contributing towards process improvement \n Coordinated with different teams to increase the partnering with payment gateways, ~14 PG’s were live during Pilot \n\n \nSkills and Tools: \n\n        R, Python (Intermediate) , MySQL, Data Crawling, Custom scoring , Machine learning, Text Mining, C, C++, Android \n\n \n      Business Strategy, Project management, Fin Tech          IBM Watson, AWS, Graphana, Qlikview, Tableau \n\n \n\nEducation: \nB. Tech, (2009-13) – Electronics and Communication, Assam University   (CGPA 7.9) \n\n  \n\nmailto:gogoi12@gmail.com\n\n\n \n.","annotation":[{"label":["Education"],"points":[{"start":5518,"end":5524,"text":"B. Tech"}]},{"label":["Skills"],"points":[{"start":5456,"end":5465,"text":"IBM Watson"}]},{"label":["Skills"],"points":[{"start":5417,"end":5435,"text":" Project management"}]},{"label":["Skills"],"points":[{"start":5381,"end":5387,"text":"Android"}]},{"label":["Skills"],"points":[{"start":5310,"end":5322,"text":"Data Crawling"}]},{"label":["Skills"],"points":[{"start":5279,"end":5299,"text":"Python (Intermediate)"}]},{"label":["Skills"],"points":[{"start":5276,"end":5276,"text":"R"}]},{"label":["Skills"],"points":[{"start":4669,"end":4669,"text":"R"}]},{"label":["Skills"],"points":[{"start":3879,"end":3879,"text":"R"}]},{"label":["Skills"],"points":[{"start":3699,"end":3699,"text":"R"}]},{"label":["Skills"],"points":[{"start":3687,"end":3687,"text":"R"}]},{"label":["Skills"],"points":[{"start":2295,"end":2295,"text":"R"}]},{"label":["Skills"],"points":[{"start":2210,"end":2210,"text":"R"}]},{"label":["Skills"],"points":[{"start":2105,"end":2105,"text":"R"}]},{"label":["Skills"],"points":[{"start":2076,"end":2076,"text":"R"}]},{"label":["Skills"],"points":[{"start":1462,"end":1462,"text":"R"}]},{"label":["Skills"],"points":[{"start":972,"end":972,"text":"R"}]},{"label":["Name"],"points":[{"start":0,"end":14,"text":"SUSHMITA GOGOI "}]}],"extras":null,"metadata":{"first_done_at":1532681709000,"last_updated_at":1532681709000,"sec_taken":609,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "SYED FARAZ ALI ,  B. Tech - M.Tech, IIT Kharagpur \nHSR Layout, Bangalore 560102 I +91-9535566770| faraz.ali.2702@gmail.com \n\n \nData Scientist I    Qua ntitative Analyst \n\n \n \nData scientist from IIT Kharagpur with expertise in various Machine Learning and Deep Learning \nAlgorithms using Python and R. \n\n \n \n\nPROFESSIONAL EXPERIENCE \n\n \nCentum Academy, Bangalore                                         Data Scientist  [Jan 2017 – Present] \n \nHelping leadership team at Centum build best in class offering for students to crack national level \nengineering entrance examinations. I have also developed a tool to pinpoint the areas where students \nneed improvements on the basis of their performance related data.  \n\n \nSimplilearn, Bangalore                                                     Category Manager [May 2015 – December 2016] \n \nResponsible for building new offerings and scaling existing categories to ensure consistent recurring \nrevenues, while ensuring customer delight and maintain high NPS for the services/products availed by \ncustomers \n \nKey Achievements: \n\n Improved core offerings in Data Science and Analytics categories after doing competitive analysis, \nthis helped in scaling monthly revenue to $100K from $17K, and NPS from 27 to 70 \n\n Devised Simplilearn Influential Board Program to onboard influential professionals from across the \nglobe and help Simplilearn gain market leadership in specific domains. Partnered with Lilian \nPearson – “big data girl” for Big Data Analytic category \n\n \nFEM Consulting, New Delhi                                                                  Co-Founder [June 2012 – May 2015] \n \nFounded FEM Consulting to change the engineering consultancy landscape in India. Responsible for \ndelivering technical aspects of engineering and design projects undertaken.  \n \nKey Achievements: \n\n Identified & proposed most economical feasible alternate route after studying Chandil reservoir \nwatershed falling in influence area of project for TATA Power \n\n Completed DPR of 86 secondary roads including technical report & bid document while complying \nwith requirement for World Bank funding for Ministry of Rural Development, Govt. of India \n\n Investigated data & proposed change in data acquisition, thereby instrumental in saving the \nrehabilitation cost of 200 km of highway with faulty assumptions on existing condition \n\n \n\n \n\nAarvee Associates, New Delhi                                              Structural Engineer [July 2011 – April 2012 ]  12] \n \n\nKey Achievements:  \n\n Designed the substructure (Piles, Pile Caps, Piers and Pier Caps) of Sasaram Road Over Bridge \nas part of the Dedicated Freight Corridor Corporation of India Limited Project  \n\n Designed and performed quality control of stress analysis spreadsheets. \n\n Created Bridge models and evaluated construction stages using STAAD Pro. \n\n Project lead for design of minor bridges \n \n \n \n\n \n\n\n\n \nACADEMIC QUALIFICATION\n\n \n \n\nYear Examination Institution Marks Obtained \n\n2011 M.Tech(Structural Engineering) IIT Kharagpur 6.83/10 \n\n2010 B.Tech(Civil Engineering) IIT Kharagpur 6.83/10 \n\n2005 Class XII, CBSE Jawaharlal Nehru School, Bhopal 92.2% \n\n2003 Class X, CBSE Jawaharlal Nehru School, Bhopal 94.2% \n\n \n\n \nTRAINING AND CERTIFICATIONS\n\n \n\n Data Science : Jigsaw Academy \n\n Data Analysis and Statistical Inference : Coursera \n\n Python For Everybody – Coursera  \n\n Python Data Structures – Coursera  \n\n Intro to Python for Data Science – edX \n\n Machine Learning – Coursera   \n\n \n\nData Science Related Projects  \n\nProfit Predictor  \nImplemented Linear Regression to predict profits for a restaurant \n\nfranchise based on the population of different cities. (Github Link) \n\nHouse Price Predictor  \n\nImplemented Multivariate Linear Regression to predict house prices in \n\nPortland, Oregon, based on the number of bedrooms and size of the \n\nhouse. (Github Link) \n\nUniversity Admission \n\nProbability   \n\nBuilt a classification model using Logistic Regression that estimates an \n\napplicant’s probability of admission based on their results on two \n\nexams. (Github Link)  \n\nMicrochip Quality \n\nAssessment  \n\nImplemented regularized logistic regression to predict whether \n\nmicrochips from a fabrication plant pass quality assurance. (Github \n\nLink) \n\nImage Recognition - I \nImplemented logistic regression(One Vs All Classification) to recognize \n\nhandwritten digits(0-9). (Github Link) \n\nImage Recognition - II \nImplemented Neural Networks to recognize handwritten digits(0-9). \n\n(Github Link) \n\nPredicting the amount \n\nof water flowing out \n\nof a dam  \n\nImplemented regularized linear regression to predict the amount of \n\nwater flowing out of a dam using the change of water level in a \n\nreservoir. (Github Link ) \n\nPredicting the species \n\nof iris flowers   \n\nImplemented the k- nearest neighbors algorithm to identify the species \n\nof iris flower based on different measurements. (Github Link) \n\n \n \n \n \n \n\nhttps://github.com/farru46/Profit-Predictor-\nhttps://github.com/farru46/Portland-House-Price-Prediction\nhttps://github.com/farru46/University-Admission-Probability-\nhttps://github.com/farru46/Microchip-Quality-Assessment-\nhttps://github.com/farru46/Microchip-Quality-Assessment-\nhttps://github.com/farru46/Image-Recognition-\nhttps://github.com/farru46/Image-Recognition-using-Neural-Networks-\nhttps://github.com/farru46/Predicting-the-amount-of-water-flowing-out-of-a-dam-\nhttps://github.com/farru46/Classification-using-kNN-algorithm-/blob/master/Scikit%20learn%20classification%20with%20the%20Iris%20dataset%20.ipynb\n\n\n \n \n\n \nSCHOLASTIC ACHIEVEMENTS\n\n \n \n\n Recipient of President’s Silver Medal for best performance in class 10th Board exams \n\n Scored 100% marks in Mathematics in both class 10th and 12th Board examinations \n\n Awarded NTSE Scholarship based on National Talent Search Examination , conducted by NCERT in \n\n2003. \n\n Ranked within top 1.5% in IIT-JEE 2006 \n\n Ranked within top 1.7% in AIEEE 2006 \n\n Secured 99 percentile (AIR 215 out of 20000 candidates )in GATE 2010  \n\n Qualified CSIR JRF-NET with an All India Rank of 66 in National Eligibility Test (NET ) 2013 conducted \n\nby CSIR.","annotation":[{"label":["Skills"],"points":[{"start":6150,"end":6150,"text":"R"}]},{"label":["Skills"],"points":[{"start":6080,"end":6080,"text":"R"}]},{"label":["Skills"],"points":[{"start":6055,"end":6055,"text":"R"}]},{"label":["Skills"],"points":[{"start":6052,"end":6052,"text":"R"}]},{"label":["Skills"],"points":[{"start":5990,"end":5990,"text":"R"}]},{"label":["Skills"],"points":[{"start":5924,"end":5924,"text":"R"}]},{"label":["Skills"],"points":[{"start":5881,"end":5881,"text":"R"}]},{"label":["Skills"],"points":[{"start":5863,"end":5863,"text":"R"}]},{"label":["Skills"],"points":[{"start":5603,"end":5603,"text":"R"}]},{"label":["Skills"],"points":[{"start":5301,"end":5301,"text":"R"}]},{"label":["Skills"],"points":[{"start":5255,"end":5255,"text":"R"}]},{"label":["Skills"],"points":[{"start":4426,"end":4426,"text":"R"}]},{"label":["Skills"],"points":[{"start":4288,"end":4288,"text":"R"}]},{"label":["Skills"],"points":[{"start":3981,"end":3981,"text":"R"}]},{"label":["Skills"],"points":[{"start":3767,"end":3767,"text":"R"}]},{"label":["Skills"],"points":[{"start":3590,"end":3590,"text":"R"}]},{"label":["Skills"],"points":[{"start":3532,"end":3532,"text":"R"}]},{"label":["Skills"],"points":[{"start":3484,"end":3499,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":3450,"end":3455,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3402,"end":3407,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3365,"end":3370,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3257,"end":3257,"text":"R"}]},{"label":["Skills"],"points":[{"start":3243,"end":3243,"text":"R"}]},{"label":["Education"],"points":[{"start":3007,"end":3012,"text":"M.Tech"}]},{"label":["Skills"],"points":[{"start":2616,"end":2616,"text":"R"}]},{"label":["Skills"],"points":[{"start":2161,"end":2161,"text":"R"}]},{"label":["Skills"],"points":[{"start":2022,"end":2022,"text":"R"}]},{"label":["Skills"],"points":[{"start":1728,"end":1728,"text":"R"}]},{"label":["Skills"],"points":[{"start":839,"end":839,"text":"R"}]},{"label":["Location"],"points":[{"start":730,"end":738,"text":"Bangalore"}]},{"label":["Location"],"points":[{"start":353,"end":361,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":326,"end":326,"text":"R"}]},{"label":["Skills"],"points":[{"start":310,"end":310,"text":"R"}]},{"label":["Skills"],"points":[{"start":299,"end":299,"text":"R"}]},{"label":["Skills"],"points":[{"start":288,"end":293,"text":"Python"}]},{"label":["Skills"],"points":[{"start":256,"end":268,"text":"Deep Learning"}]},{"label":["Skills"],"points":[{"start":235,"end":250,"text":"Machine Learning"}]},{"label":["Location"],"points":[{"start":63,"end":71,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":53,"end":53,"text":"R"}]},{"label":["Education"],"points":[{"start":28,"end":33,"text":"M.Tech"}]},{"label":["Skills"],"points":[{"start":7,"end":7,"text":"R"}]},{"label":["Name"],"points":[{"start":0,"end":13,"text":"SYED FARAZ ALI"}]}],"extras":null,"metadata":{"first_done_at":1532690546000,"last_updated_at":1532690546000,"sec_taken":110,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Hno 29,Shree Ganesh, \nSurabhi Nagar, Gokul Road \nHubli - 580030                                                    \n\n    TTaannuusshhrreeee  WWaannddkkaarr    \n8105796756 \n\ntanu.wandkar@gmail.com  \n\n \n  \n\nEMPLOYMENT \n Systems Engineer (4 years) Tata Consultancy Services  \n \n\nA  System Engineer with Tata Consultancy Services, Bangalore, with a total of 4 years of industry experience. \nCurrently working in Analytics and Insights team, and carrying out POCs and projects on various domains. \nExperience in Data Analysis, cleaning, manipulation, build models and optimizing for better accuracy on larger \ndatasets using R. An enthusiast for Data Science and exploring new techniques and technologies. \n \n\nBusiness Domain: Healthcare, Energy, Banking and Finance \nTechnical Domain: Machine Learning, Linear Regression, Kmeans , NLP, Topic Modelling, Sentiment Analysis, Text \nClassification, Basics of Time series forecasting                    \nProgramming Languages: R, SQL, Python , Java, JCL \nTools: Rstudio, Anaconda,Excel, IBM RAD, QWS Secure  \nDatabases: IBM DB2,Postgresql,Presto,SparkSQL \n\n \nTECHNICAL EXPERIENCE \nProjects \n\n \n\n \n1. Travel and Living Cockpit (Financial Data and Insights) \n\n Description: This cockpit holds all the travel and leisure expense statistics in each of categories \nlike Flights, Hotels, Car/Ride, Meals etc. Also provides the executive users of company to take \nsome strategic and Tactical actions when the expenses are over the budget. \n\n Tools and Techniques: Python, Postgresql,Presto,SparkSQL \n\n Domain:  Travel \n \n\n2. Solar Energy forecasting \n\n Description: Initial analysis of the power produced from the cleaned and uncleaned solar panels \nin order to automatically determine when the panels have to undergo maintenance. \n\n Tools and Techniques: RStudio, Linear Regression, Time series forecasting, R \n\n Domain : Energy \n \n\n3. Service Request Classification \n\n Description : To analyze the comments provided for each service request and come up with the \nSR classification categories. SRs are Preventive maintenance, Installation-deinstallation of medical \nequipments etc requests.  \n\n Tools and Techniques : RStudio, NLP, Topic modeling, Hierarchical and Kmeans clustering, R \n\n Domain : Healthcare \n \n\n4. Billing Disputes Classification \n\n Description: The data is regarding the disputes in billing information of various healthcare \nproducts. The objective was to analyze the disputes comments and categorize the bills into \nvarious different sections like PO issues, price discrepancies etc. \n\n Tools and Techniques: RStudio, Topic modeling, Log likelihood method to find no of topics, R \n\n Domain : Healthcare \n \n\n\n\n5. Net Promoter Score dashboard \n\n Description : Here we performed sentiment analysis on the comments/recommendations \nprovided by the Promoters/Passive/Detractor customers  and understand what are the loopholes \nin terms of services, products, Engineers etc. \n\n Tools and Techniques : RStudio, NLP, Sentiment analysis, R \n\n Domain :  Healthcare \n\n  \n6. General Ledger Application support \n\n Description : Supporting the mainframes legacy system. \n\n Tools and Techniques : Mainframes, QWS Secure \n\n Domain : Banking and Finance \n \n\n7. 24x7 Medisurance \n\n Description : Objective of this project is to leverage  hospital services where patient need not do \nany paper work while getting admitted to the hospital by providing seamless application that \nhandles thousands of patient information and provides efficient health care services. \n\n Tools and Techniques : IBM RAD, IBM WAS, IBM RSA, IBM DB2, JavaScript, JSP, SQL, \nXML&XQUERY, Servlets \n\n Domain : Healthcare \n \n\nEDUCATION \n \n\n   \n\nCOURSE NAME SCHOOL/COLLEGE \nNAME \n\nBOARD/UNIVERSITY NAME PERCENTAGE/ \nAGGREGATE \n\nYEAR OF PASSING \n\nB E \n(Computer \n\nScience) \n\nBapuji Institute of \nEngineering and \n\ntechnology,         \nDavangere \n\nVisvesvaraya \nTechnological University \n\n \n79.32 \n\n \n2013 \n\nII PUC Alva's PU college, \nMoodbidri \n\nKarnataka PU Board 88.17 2009 \n\nSSLC JVS English Medium \nHigh School, \n\nChickmagalur \n\nKarnataka Secondary    \nEducation  Examination \n\nBoard \n\n95.36  \n2007 \n\n \n\n \n\n \n\nADDITIONAL EXPERIENCE AND AWARDS \n \n\n Part of team who won first place in “The Great Mind Challenge 2012-2013” , a National level software \ndevelopment competition by IBM for 24*7 Medisurance Project. \n\n Competing in various Hackathons on Analytics Vidhya, Kaggle and following other data science portals. \n\n Receiver of \"Star of the quarter\" (Q3 2016) and \"Star Performer\" for (December 2017) at TCS. \n Received team on the spot award while supporting project. \n\n Honoured for actively participating in one of the initiatives of teaching students in Government School \nat Whitefield. \n\n Certified from Edureka training institute in Data Science with R.  \n\n Completed MOOCs like The Analytics Edge from EDX and Machine Learning on Coursera. \n\n Attended Softskills and Hardskills trainings under Infosys Campus Connect. \n\n IBM DB2, IBM RAD, IBM TIVOLI Certification Course under IBM Academic Initiative.","annotation":[{"label":["Skills"],"points":[{"start":4986,"end":4986,"text":"R"}]},{"label":["Skills"],"points":[{"start":4799,"end":4799,"text":"R"}]},{"label":["Skills"],"points":[{"start":4550,"end":4550,"text":"R"}]},{"label":["Skills"],"points":[{"start":4454,"end":4454,"text":"R"}]},{"label":["Skills"],"points":[{"start":4171,"end":4171,"text":"R"}]},{"label":["Skills"],"points":[{"start":4157,"end":4157,"text":"R"}]},{"label":["Education"],"points":[{"start":3775,"end":3777,"text":"B E"}]},{"label":["Skills"],"points":[{"start":3760,"end":3760,"text":"R"}]},{"label":["Skills"],"points":[{"start":3748,"end":3748,"text":"R"}]},{"label":["Skills"],"points":[{"start":3734,"end":3734,"text":"R"}]},{"label":["Skills"],"points":[{"start":3721,"end":3721,"text":"R"}]},{"label":["Skills"],"points":[{"start":3713,"end":3713,"text":"R"}]},{"label":["Skills"],"points":[{"start":3678,"end":3678,"text":"R"}]},{"label":["Skills"],"points":[{"start":3615,"end":3615,"text":"R"}]},{"label":["Skills"],"points":[{"start":3601,"end":3603,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":3584,"end":3587,"text":"Java"}]},{"label":["Skills"],"points":[{"start":3570,"end":3570,"text":"R"}]},{"label":["Skills"],"points":[{"start":3552,"end":3552,"text":"R"}]},{"label":["Skills"],"points":[{"start":2999,"end":2999,"text":"R"}]},{"label":["Skills"],"points":[{"start":2965,"end":2965,"text":"R"}]},{"label":["Skills"],"points":[{"start":2645,"end":2645,"text":"R"}]},{"label":["Skills"],"points":[{"start":2576,"end":2576,"text":"R"}]},{"label":["Skills"],"points":[{"start":2227,"end":2227,"text":"R"}]},{"label":["Skills"],"points":[{"start":2161,"end":2161,"text":"R"}]},{"label":["Skills"],"points":[{"start":2037,"end":2037,"text":"R"}]},{"label":["Skills"],"points":[{"start":2007,"end":2007,"text":"R"}]},{"label":["Skills"],"points":[{"start":1885,"end":1885,"text":"R"}]},{"label":["Skills"],"points":[{"start":1848,"end":1848,"text":"R"}]},{"label":["Skills"],"points":[{"start":1811,"end":1811,"text":"R"}]},{"label":["Skills"],"points":[{"start":1795,"end":1795,"text":"R"}]},{"label":["Skills"],"points":[{"start":1531,"end":1533,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1500,"end":1505,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1328,"end":1328,"text":"R"}]},{"label":["Skills"],"points":[{"start":1114,"end":1114,"text":"R"}]},{"label":["Skills"],"points":[{"start":1092,"end":1094,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1032,"end":1032,"text":"R"}]},{"label":["Skills"],"points":[{"start":1003,"end":1003,"text":"R"}]},{"label":["Skills"],"points":[{"start":991,"end":994,"text":"JCL "}]},{"label":["Skills"],"points":[{"start":985,"end":988,"text":"Java"}]},{"label":["Skills"],"points":[{"start":976,"end":981,"text":"Python"}]},{"label":["Skills"],"points":[{"start":971,"end":973,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":968,"end":968,"text":"R"}]},{"label":["Skills"],"points":[{"start":806,"end":806,"text":"R"}]},{"label":["Skills"],"points":[{"start":620,"end":620,"text":"R"}]},{"label":["Location"],"points":[{"start":327,"end":335,"text":"Bangalore"}]},{"label":["Name"],"points":[{"start":121,"end":154,"text":"TTaannuusshhrreeee  WWaannddkkaarr"}]},{"label":["Skills"],"points":[{"start":43,"end":43,"text":"R"}]}],"extras":null,"metadata":{"first_done_at":1532689175000,"last_updated_at":1532689175000,"sec_taken":164,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Introduction  \n\nA Full-Stack Developer , having good exposure to various Digital Technologies.  \n\n7+  years of programming experience in areas like – Java, J2EE, Webservices, Messaging \n\nSystem in Big Data, Artificial Intelligence( IBM Watson) and IBM Bluemix. \n\n➢ Experience in different phases of SDLC including understanding Customer Requirements, preparing \n\nTechnical Design Documents, developing programs from specifications, in-depth system analysis for both \n\ndevelopment projects & Production Support partnering with Quality Assurance for test considerations, \n\nresults verification and code deployment on server \n\n \n \n\nTechnical Skills \n\nProgramming \n\nLanguages \n\nCore Java, Java script,    JSP,    J2EE,     Springboot Framework,     Angular JS,    \n\nNode JS,     Cordova Framework \n\nDatabases Oracle 10g, MongoDB, Postgres, PL/SQL \n\nSpecial Tools \n\nOracle Jdeveloper 10g , Oracle Report Builder , PL/SQL  Developer,  IBM Bluemix,  \n\nAndroid Emulator, Apache SOLAR, KAFKA Messaging system, IBM Watson \n\nAPIs \n\nProcess CMM Level5 Quality Procedure \n\nProfessional Experience \n\nAssociate                                                                   CGI Information Systems & Management Consultant \n\nAug. 2017 to Present \n\nRoles & \n\nResponsibilities \n\n \n\nIntelligent Automation Platform \n \n\n• Responsible for creation of the Knowledge Base( Storing, Searching, Indexing, Quering) for \nAutomating Tickets raised in various ITSM tools using Apache Solar \n\n• Responsible for Creation & Maintenance of the Messaging Hub using Apache Kafka  \n• Team-Lead to create the RBAC module for the CGI in-house Intelligent Automation \n\nPlatform. \n \n\nAssociate                                                                   Cognizant Technology Solutions \n\nApr. 2014 to Aug . 2017  \n\nTapaswinee Jena \nFemale | email : tapaswinee.jena@gmail.com | \nDOB: 31 July 1987 \nMobile: +919686695556 \n\n\n\nRoles & \n\nResponsibilities \n\n \n\nGlobal Technology Office (IBM Watson – AI )  \n  \n\n• Creation of APIs in the areas of Conversation, Dialog, Natural Language Classifier, \nPersonality Insights, Retrieve & Rank and Visual Recognition. \n\n• Creation of a Search Application using Open-source ( Apache Solr – built on top of \nLucene). \n\n• Design and Development of the entire UI for the Search Engine using HTML & \nAngularJS \n\n• Creation of webservices to call instances of Apache Solr running in the server \n\n• Responsible for creation of the Search Application Module for Web-Search using web \ncrawler \n\n• Developed a Mobile Application leveraging Visual Recognition API of IBM Watson \nto reduce manual intervention in Vehicle Insurance claim processing.  \n\n \n\nAssociate                                                                   Cognizant Technology Solutions                                                                     \n\nMay,2014 to Mar 2015 \n\nRoles & \n\nResponsibilities \n\n \n\nCLIENT: THE HARTFORD(CUE)  \nProject Description: \n \nCUE(Consolidated Underwriter environment) delivered end to end processing of a \nCommercial Auto and Worker Compensation Quote Proposal.  \nGenerate quote proposal builder for data input.  \nFull integration of all services to support quote generation using java/j2ee. \n \nGeneration of professional formatted Quote Proposal including coverage \n\nforms(optional and Automatically Generated), subjective, application coverage \n\nexplanation and flyers.  \nQuote Proposal builder is designed for fully supported, partially supported and manual policy \n\ntypes. \n \n \nProject Role: \n\n \n\n➢ Development of applications and solution as per customer requirement. \n\n\n➢ Propose solution based on Adobe Marketing Solutions and Adobe LiveCycle \nusing Java, J2EE platform. \n\n➢ Worked as a key member in Development of project \n\n\n➢ Possesses good technical and communication skills with the ability to learn \nquickly and implement. \n\n➢ Expertise in Requirement gathering and transforming into Business process . \n➢ Has worked on Insurance Domain. \n➢ Internal certification in General Insurance. \n \n\nProgrammer Analyst                                                               TCS  Limited                                                                                                                   \n\nJan ,2011 to May, 2014    \n\n \n\nRoles & \n\nResponsibilities \n\n \n\nCLIENT: KERALA Government Commercial Department(KVAT)  \nProject Description: \n \n \n\n KVAT is a web-based application, which is hosted on Oracle 10G Application server and \nOracle10g database, provides rich web front end to users to file the tax through online \nsystem. The end user is the commercial tax employee and he / she is also provided with an \nonline facility for filling their returns and payment monthly. It also provides additional \n\n\n\nprivileges to the commercial tax employee can also generate reports daily basis. \n\n \nProject Role: \n \n \n\n➢ Analyze the Requirements obtained from the client using J2EE and formulates \ntechnical design specifications and Estimating the time required to incorporate the \nrequirement in the system. \n\n\n➢ Prepare high level design, low level design, coding and unit testing and deployment \n\nof the code at client side server. \n➢ Performing Impact testing, if the new code affects objects other than its parent objects. \n\nPlay key role on reviewing the code changes, preparing the Test Plans. \n➢ Coordinate with testing team for Integration / User Acceptance Test execution and \n\nvalidation \n➢ Taking part in UAT and implementing UAT comments \n\nHighlights \n• Appreciated by the Commissioner of Income Tax for the development of SMS sending \n\napplication \n\nProgrammer Analyst                                                   TCS Limited  \n\nJan 2011  to May ,2011    \n\n \n\nRoles & \n\nResponsibilities \n\n \n\nCLIENT: KERALA Government Commercial Department(KVAT)  \nProject Description: \n\nDevelopment of Online PAN verification - a web based application to check end-user’s \n\nregistered PAN in the NSDL database \n\n \n\nProject Role: \n\n \n\n➢ Created a web service and hosted in Apache Tomcat server to connect with NSDL \ndatabase for verification of PAN \n\n➢ Created a Java Function from existing KVAT application to call Web service created for \nPAN verification \n\n➢ Supporting & Monitoring the application for better quality and performance  \n \n\n \n\nEDUCATION BACKGROUND \n\nM.Tech 2016 BITS, Pilani \n\nB.Tech 2010 Government Engineering College ( IGIT), Sarang, Orissa \n\nXII (C.B.S.E.) 2005 Godavarish Mahavidyalaya \n\nX (H.S.C) 2003 Balugaon High School \n\n\n\n \n\nPERSONAL DETAILS \n\nDate of Birth 31st July 1987 \n\nLanguages Known Hindi, English, Oriya \n\nPassport G6213208 \n\nPAN No. AJPPJ1946G \n\nMarital Status Married \n\nAddress \n3rd Floor, House no. -6, Greenwood Regency, Sarjapur Road, \n\nBangalore- 560035","annotation":[{"label":["Location"],"points":[{"start":6714,"end":6722,"text":"Bangalore"}]},{"label":["Education"],"points":[{"start":6302,"end":6307,"text":"M.Tech"}]},{"label":["Skills"],"points":[{"start":6097,"end":6100,"text":"Java"}]},{"label":["Skills"],"points":[{"start":4905,"end":4908,"text":"J2EE"}]},{"label":["Skills"],"points":[{"start":3670,"end":3673,"text":"J2EE"}]},{"label":["Skills"],"points":[{"start":3664,"end":3667,"text":"Java"}]},{"label":["Skills"],"points":[{"start":929,"end":939,"text":"IBM Bluemix"}]},{"label":["Skills"],"points":[{"start":709,"end":712,"text":"J2EE"}]},{"label":["Skills"],"points":[{"start":685,"end":688,"text":"Java"}]},{"label":["Skills"],"points":[{"start":679,"end":682,"text":"Java"}]},{"label":["Skills"],"points":[{"start":248,"end":258,"text":"IBM Bluemix"}]},{"label":["Skills"],"points":[{"start":207,"end":242,"text":"Artificial Intelligence( IBM Watson)"}]},{"label":["Skills"],"points":[{"start":197,"end":204,"text":"Big Data"}]},{"label":["Skills"],"points":[{"start":156,"end":159,"text":"J2EE"}]},{"label":["Skills"],"points":[{"start":150,"end":153,"text":"Java"}]}],"extras":null,"metadata":{"first_done_at":1532668447000,"last_updated_at":1532668447000,"sec_taken":11,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Udaya Laxmi Ch\n\nEmail : laxmi.udaya@gmail.com\n\n\t\n\n\tPhone: -9740606990\n\t\n\n\n\tSummary\n\n\t· 9.5 years of experience in Software Development.\n· 3.5 years of experience in Machine Learning\n· Primary Skills – Machine Learning, R programming, Lotus Notes.\n· Presently working for Wipro Technologies, Bangalore.\n· Experience in planning, estimation, design, development, and testing object oriented applications.\n· Experience in preparing various technical documents like Functional Specs, HLD, LLD, Flowcharts and Test cases.\n· Sound Knowledge in Object Oriented Design Principles\n· Have Team Handling experience.\n· Domain experience of Manufacturing and Finance.\n· Have Experience in Scrum Agile Model\n· Understand business requirements from clients\n\n\n\n\tTechnical Skills\n\n\tKey skills: \n\tMachine Learning,R Programming, Python,  Lotus Notes\n\n\tAlgorithms:\n\tNaïve Bayes, K means clustering,Word Cloud\n\n\tDatabases: \n\tMicrosoft SQL, Mongo DB\n\n\tWeb Technologies: \n\tXML, XSLT, HTML,  JavaScript,  AJAX, JQuery\n\n\tIDE:\n\tR studio,Pycharm\n\n\n\tProfessional Experience\n\n\tCurrent Employer :\n\tWipro Technologies., Bangalore  – (Oct  2010  to till date) – Technical Lead/Data Scientist\n\n\tPrevious Employers :\n\tHSBC Software development , Hyderabad (June  2008  to Sep 2010)  - SE\n\n\n\tQualification\n\n\tDegree\n\tCollege\n\tUniversity/Board\n\tYear\n\tPercentage (%)\n\n\tMCA\n\tNizam College, Basheerbagh,Hyderabad\n\tOsmania University\n\t2008\n\t75\n\n\n\tProject Experience \n\n\tProject 1 : Exploratory Data Analysis:\n\nProject Description:   Performed EDA analysis to analyze the Purchase frequency of vehicles which occurred over past 3 years and try to predict the frequency occurring in the future.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Performed EDA analysis to find the insights of the data. Observed the summary of each and every variable to understand the variables.\n\n· Performed the feature selection using hypothesis testing.\n\n· Identified the outliers using box plot.\n\n· Identified the trend in the purchases using histogram.\n\n\n\n\tProject 2: Word Cloud Analysis:\n\nProject Description:   Performed Word cloud and Sentimental Analysis of the customer feedbacks. Graphically represented the most frequently occurred words through Word cloud. Through sentimental analysis we identified whether a user-generated text expresses positive, negative or neutral opinion.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Created a Corpus using TM package and performed pre-processing of data.\n\n· Removed the punctuations, stemming and stop words which are of no analytical value.\n\n· Built a Document term matrix and identified the most frequently occurring words\n\n· Graphically represented it using  RColorbrewer Package\n\n\n\tProject 3: Sentimental Analysis:\n\nProject Description: Performed Sentimental Analysis of customer feedbacks through Naïve Bayes. Used “e1071” Package for implementing naïve Bayes method.\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· The DTM created using TM package was an input to the Naive Bayes Model.\n\n· As Naive Bayes classifier is typically trained on data with categorical features. We have converted the count of the words into a factor variable that indicates Yes or No whether the word is present or not.\n\n\tProject 4: Clustering Analysis:\n\nProject Description: Classified the customers on the basis of their purchases whether they have purchased low variant or high variant trucks. It in turn helped in building the right customer strategies.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Performed data preparation and Normalization of data using min-max method.\n\n· As K-means algorithm groups a dataset into a user-specified number (k) of clusters. Identified the initial cluster centroids as 3.\n\n· K clusters are creating by associating every observation with the nearest mean.\n\n· Used elbow method to validate the number of clusters such that within-cluster sum of square(wss) is minimized.\n\n\n\n\tProject 5 : Inter Connection Management Tool\nProject Description: Inter-connection Management (IMT) is prototype being developed for Engineering and Sales department to handle customizations of an existing product based on the customer's requirement. Users from engineering department will identify the items, which need to be customized out of the entire product design.\nRole\n\n       : Module Lead\n\nEnvironment\n       : Python, Mongo DB, jQuery\n\nTasks handled:\n\n· Gathering Requirements and providing Project Plan and Effort Estimation details.\n\n· Understanding business requirements and preparing SoU (Statement of Understanding) and Functional/Technical Specification documents.\n\n· Providing Effort & Resource estimations\n\n· Planning for application development and deployment\n\n· Writing and executing Test Cases and Test scenarios\n\n· Creating design elements using Technical Specification.\n\n· Performing Unit testing & Peer Reviews\n\n· Work Allocation and mentoring the team\n\n· Providing Technical guidance to the team. \n\n\tProject 6\n: cvdAEI Application\n\nProject Description\n     : CVDAEI is a web based multilingual application developed for handling the Change Management process in Truck division of Daimler. The change request flows through different phases mainly Initialization, Evaluation, Decision and Conclusion. This application has a configurable workflow where the request flow and the responsible persons can be configured easily at any point of time. \n\nRole\n\n    : Developer/Tester\n\nEnvironment\n     : Lotus Notes, Java, HTML, XML, Java Script, JQuery\n\nTasks handled:\n\n· Gathering Requirements and providing Project Plan and Effort Estimation details.\n\n· Understanding business requirements and preparing SoU (Statement of Understanding) and Functional/Technical Specification documents.\n\n· Providing Effort & Resource estimations\n\n· Planning for application development and deployment\n\n· Writing and executing Test Cases and Test scenarios\n\n· Creating design elements using Technical Specification.\n\n· Performing Unit testing & Peer Reviews\n\n· Work Allocation and mentoring the team\n\n· Providing Technical guidance to the team. \n\n\n\n\tProject Title: Project Management Office \nProject Description: The purpose of this system is to enable the Project Management Office to manage and execute the IT Applications and Operations driven project tasks in  more systematic manner. It will also enable them to efficiently perform a role as a facilitator to coordinate various IT Operations teams and to ensure that project activity enters the department through one common interface. The project tasks will subsequently be dealt with in a common format and in a consistent and appropriate manner, ensuring open and regular communication between all involved parties.\n\nRole\n\n    : Developer/Tester\n\nEnvironment\n     : Lotus Notes, Java, HTML, XML, Java Script, JQuery\n\nTasks Handled :\n\n· Writing and Executing Test cases in client server based environment\n· Individually provided application support","annotation":[{"label":["Skills"],"points":[{"start":6810,"end":6820,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":5504,"end":5514,"text":"Lotus Notes"}]},{"label":["Education"],"points":[{"start":1332,"end":1334,"text":"MCA"}]},{"label":["Location"],"points":[{"start":1090,"end":1099,"text":"Bangalore "}]},{"label":["Skills"],"points":[{"start":820,"end":830,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":779,"end":794,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":676,"end":692,"text":"Scrum Agile Model"}]},{"label":["Skills"],"points":[{"start":538,"end":559,"text":"Object Oriented Design"}]},{"label":["Skills"],"points":[{"start":234,"end":244,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":219,"end":231,"text":"R programming"}]},{"label":["Skills"],"points":[{"start":201,"end":216,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":165,"end":180,"text":"Machine Learning"}]},{"label":["Name"],"points":[{"start":0,"end":13,"text":"Udaya Laxmi Ch"}]}],"extras":null,"metadata":{"first_done_at":1532689822000,"last_updated_at":1532689822000,"sec_taken":97,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Utkarsh Chaturvedi\nEmail id: 113.utkarsh@gmail.com\nContact No. +919789863263\n  Address: House 143, 3rd cross\n20th main, BTM Stage 1\n Bangalore-68\nCareer Objective: \nSeeking opportunities as Data Scientist with three years and seven months of experience and to unleash my potential as solution finder for organization goals and business development. \nTechnical Skill:\nArea of Interest: Data Analytics, R, SQL, Machine Learning Algorithms\n\nLanguages known: R, SQL, Python\nProfessional Skills:\n· 3.7 years of professional experience (February 2014 - till date) as Senior Systems Engineer with Infosys in Data Analytics, SQL.\n· Used concepts of Data Analytics to prevent loss of Revenue to client.\n\n· Used classification techniques to determine the sales/return patterns of merchandise.\n· Performed exploratory analysis to segment the customers for proactive retention strategy.  \n\n· Good ability to Understand Functional Requirements and Design documents\n\n· Excellent verbal and written communication skills\n\nProjects:\n1. Understanding the churn behavior of customers of a Telecom Company:\n   Description:\n\nA telecom giant wanted to understand the churn behavior of customers from its network and to minimize the revenue loss due to it. The data provided to us had customer details, usage behavior, billing details etc. The objective was to conduct the exploratory analysis on the data and to segment the customers such that the organization can come up with proactive retention programs to minimize this rate.\n\nTech Skills: \n\nR Studio, SQL, Excel, Classification Algorithms\n2. Increasing the Customer Life Time Value of customers of a Retail Client:\nDescription:\n\nA retail giant wanted to increase the Customer Life Time Value by identifying the Customer Sales. The client wanted to run a promotional event for specific section of customers. The data provided included the customer information and their past sales records. The objective was to segment the customer based on their sales data.\nTech Skills: \n\nR Studio, SQL, Excel, Machine Learning Algorithms\n3. RMS (PFI-Perpetual and Financial Inventory):\n   Description:\n\nPFI is a comparatively new system of record in Gap’s IT infrastructure that integrates perpetual and financial\n inventory i.e. a centralized place to view inventory data and to track movement of inventory throughout the supply chain. It exploits RMS’ (Retek Merchandizing System) stock ledger to account inventory. All other functionalities like Purchase Orders, Transfers, Inventory adjustments, etc. are provided by various legacy systems which interact with PFI, which is center of transactional information. As it is a central database, the inventory in this system must be in sync with the other systems. \n\nTech Skills: \n\nRetek Merchandizing Systems (RMS 10.1), ORACLE 10G, R \n\nResponsibilities\n\n· Involved in performing various data analysis to improve application performance and prevent Revenue loss.\n\n· Conducted exploratory analysis on the data set provided to identify potential ways to prevent revenue loss during inventory movement. \n\n Achievements:\n· Won first Prize in national level Treasure Hunt competition.\n· Received numerous appreciations from the Managers for the great effort and coordination towards the project work. \n\n· Was part of NGO working for women’s welfare, education and empowerment. \n\n· Organized various Client visits and Unit/Team level festivals\nEducational Qualification:\n\n\tMTech(CSE)\n\tSRM University\n\t2011-2013\n\t8.64 CGPA\n\n\tB.E. (Information Technology)\n\tRGTU, Bhopal\n\t2006-2010\n\t75.03%\n\n\tXII\n\tCBSE\n\t2006\n\t75%\n\n\tX\n\tCBSE\n\t2004\n\t81%\n\n\nPersonal Information:\n\n    Father’s Name               : Mr. U.B. CHATURVEDI\n\n\nMother’s Name             : Mrs. GYANENDRY CHATURVEDI  \n\n\nLanguage\n              : English & Hindi\n\n\nPermanent Address      : C-3 Premy Colony GUNA (M.P.) 473001\nDeclaration\n\nI hereby declare that the above furnished Information is true to best of my knowledge & belief.\n\nDate:\n\n\n\n\n\n        \n\n\n\n  Utkarsh Chaturvedi  \n\n                                                                                                                            Signature","annotation":[{"label":["Name"],"points":[{"start":3970,"end":3987,"text":"Utkarsh Chaturvedi"}]},{"label":["Skills"],"points":[{"start":3721,"end":3721,"text":"R"}]},{"label":["Skills"],"points":[{"start":3713,"end":3713,"text":"R"}]},{"label":["Skills"],"points":[{"start":3665,"end":3665,"text":"R"}]},{"label":["Skills"],"points":[{"start":3516,"end":3516,"text":"R"}]},{"label":["Skills"],"points":[{"start":3447,"end":3447,"text":"R"}]},{"label":["Education"],"points":[{"start":3434,"end":3443,"text":"MTech(CSE)"}]},{"label":["Skills"],"points":[{"start":3149,"end":3149,"text":"R"}]},{"label":["Skills"],"points":[{"start":2916,"end":2916,"text":"R"}]},{"label":["Skills"],"points":[{"start":2804,"end":2804,"text":"R"}]},{"label":["Skills"],"points":[{"start":2800,"end":2800,"text":"R"}]},{"label":["Skills"],"points":[{"start":2789,"end":2789,"text":"R"}]},{"label":["Skills"],"points":[{"start":2777,"end":2777,"text":"R"}]},{"label":["Skills"],"points":[{"start":2748,"end":2748,"text":"R"}]},{"label":["Skills"],"points":[{"start":2373,"end":2373,"text":"R"}]},{"label":["Skills"],"points":[{"start":2367,"end":2367,"text":"R"}]},{"label":["Skills"],"points":[{"start":2059,"end":2059,"text":"R"}]},{"label":["Skills"],"points":[{"start":2028,"end":2043,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":2015,"end":2018,"text":" SQL"}]},{"label":["Skills"],"points":[{"start":2006,"end":2006,"text":"R"}]},{"label":["Skills"],"points":[{"start":1633,"end":1633,"text":"R"}]},{"label":["Skills"],"points":[{"start":1533,"end":1536,"text":" SQL"}]},{"label":["Skills"],"points":[{"start":1524,"end":1524,"text":"R"}]},{"label":["Skills"],"points":[{"start":918,"end":918,"text":"R"}]},{"label":["Skills"],"points":[{"start":675,"end":675,"text":"R"}]},{"label":["Skills"],"points":[{"start":616,"end":619,"text":" SQL"}]},{"label":["Skills"],"points":[{"start":463,"end":468,"text":"Python"}]},{"label":["Skills"],"points":[{"start":457,"end":460,"text":" SQL"}]},{"label":["Skills"],"points":[{"start":455,"end":455,"text":"R"}]},{"label":["Skills"],"points":[{"start":409,"end":424,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":403,"end":406,"text":" SQL"}]},{"label":["Skills"],"points":[{"start":401,"end":401,"text":"R"}]},{"label":["Location"],"points":[{"start":133,"end":141,"text":"Bangalore"}]},{"label":["Name"],"points":[{"start":0,"end":17,"text":"Utkarsh Chaturvedi"}]}],"extras":null,"metadata":{"first_done_at":1532679930000,"last_updated_at":1532679930000,"sec_taken":97,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Udaya Laxmi Ch\n\nEmail : laxmi.udaya@gmail.com\n\n\t\n\n\tPhone: -9740606990\n\t\n\n\n\tSummary\n\n\t· 9.5 years of experience in Software Development.\n· 3.5 years of experience in Machine Learning\n· Primary Skills – Machine Learning, R programming, Lotus Notes.\n· Presently working for Wipro Technologies, Bangalore.\n· Experience in planning, estimation, design, development, and testing object oriented applications.\n· Experience in preparing various technical documents like Functional Specs, HLD, LLD, Flowcharts and Test cases.\n· Sound Knowledge in Object Oriented Design Principles\n· Have Team Handling experience.\n· Domain experience of Manufacturing and Finance.\n· Have Experience in Scrum Agile Model\n· Understand business requirements from clients\n\n\n\n\tTechnical Skills\n\n\tKey skills: \n\tMachine Learning,R Programming, MySQL, PostgreSQL, Microsoft Access, SQL Server, FileMaker, Oracle, RDBMS, dBASE, Clipper, FoxPro, Firebase, Mongodb, Python,  ava, J2EE, Oracle Fusion,Oracle Cloud, Salesforce, Devops Android, Business Analyst, UI Developer, DBAs, Embedded Systems, .NET, Hadoop, SQL Developer, Big Data, Tableau, Networking, Etl, Informatica, Ios, Quality Analyst, Project Manager, Python, Data Science, Python, Machine Learning, SAS, Java, Scala, Hadoop, Hive, Bigdata, Programming, SQL server reporting, Msbi Ssis, Ssrs, Msbi, Sql Reporting, Artificial Intelligence, Pandas, Pyspark, Sklearn, Flask, Django, Map Reduce, Parametric Design, Modeling, Regression, Patterns, Data Mining, Text Mining, Oops, Deep Learning, Web Analytics, Time Series, Regression, Tensorflow, Azure, Linear Regression, Logistic Regression, Decision Tree, Random Forest, Data Structure, Computer Vision, IHS, WAS, Java EE, SQL Server, .NET core, C#, ASP.NET, Rdlc, Linq, Sql, Web Api, Mvc, Javascript, Web Services, Oracle, MS SQL, PHP, Laravel, CodeIgniter, Symfony, Zend, Phalcon, CakePHP, Yii, FuelPHP, React, Vue, Angular, Ember, Backbone, Lotus Notes\n\n\tAlgorithms:\n\tNaïve Bayes, K means clustering,Word Cloud\n\n\tDatabases: \n\tMicrosoft SQL, Mongo DB\n\n\tWeb Technologies: \n\tXML, XSLT, HTML,  JavaScript,  AJAX, JQuery\n\n\tIDE:\n\tR studio,Pycharm\n\n\n\tProfessional Experience\n\n\tCurrent Employer :\n\tWipro Technologies., Bangalore  – (Oct  2010  to till date) – Technical Lead/Data Scientist\n\n\tPrevious Employers :\n\tHSBC Software development , Hyderabad (June  2008  to Sep 2010)  - SE\n\n\n\tQualification\n\n\tDegree\n\tCollege\n\tUniversity/Board\n\tYear\n\tPercentage (%)\n\n\tMCA\n\tNizam College, Basheerbagh,Hyderabad\n\tOsmania University\n\t2008\n\t75\n\n\n\tProject Experience \n\n\tProject 1 : Exploratory Data Analysis:\n\nProject Description:   Performed EDA analysis to analyze the Purchase frequency of vehicles which occurred over past 3 years and try to predict the frequency occurring in the future.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Performed EDA analysis to find the insights of the data. Observed the summary of each and every variable to understand the variables.\n\n· Performed the feature selection using hypothesis testing.\n\n· Identified the outliers using box plot.\n\n· Identified the trend in the purchases using histogram.\n\n\n\n\tProject 2: Word Cloud Analysis:\n\nProject Description:   Performed Word cloud and Sentimental Analysis of the customer feedbacks. Graphically represented the most frequently occurred words through Word cloud. Through sentimental analysis we identified whether a user-generated text expresses positive, negative or neutral opinion.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Created a Corpus using TM package and performed pre-processing of data.\n\n· Removed the punctuations, stemming and stop words which are of no analytical value.\n\n· Built a Document term matrix and identified the most frequently occurring words\n\n· Graphically represented it using  RColorbrewer Package\n\n\n\tProject 3: Sentimental Analysis:\n\nProject Description: Performed Sentimental Analysis of customer feedbacks through Naïve Bayes. Used “e1071” Package for implementing naïve Bayes method.\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· The DTM created using TM package was an input to the Naive Bayes Model.\n\n· As Naive Bayes classifier is typically trained on data with categorical features. We have converted the count of the words into a factor variable that indicates Yes or No whether the word is present or not.\n\n\tProject 4: Clustering Analysis:\n\nProject Description: Classified the customers on the basis of their purchases whether they have purchased low variant or high variant trucks. It in turn helped in building the right customer strategies.\n\nRole\n\n    : Developer\n\nEnvironment\n     : R studio\n\nTasks handled:\n\n· Performed data preparation and Normalization of data using min-max method.\n\n· As K-means algorithm groups a dataset into a user-specified number (k) of clusters. Identified the initial cluster centroids as 3.\n\n· K clusters are creating by associating every observation with the nearest mean.\n\n· Used elbow method to validate the number of clusters such that within-cluster sum of square(wss) is minimized.\n\n\n\n\tProject 5 : Inter Connection Management Tool\nProject Description: Inter-connection Management (IMT) is prototype being developed for Engineering and Sales department to handle customizations of an existing product based on the customer's requirement. Users from engineering department will identify the items, which need to be customized out of the entire product design.\nRole\n\n       : Module Lead\n\nEnvironment\n       : Python, Mongo DB, jQuery\n\nTasks handled:\n\n· Gathering Requirements and providing Project Plan and Effort Estimation details.\n\n· Understanding business requirements and preparing SoU (Statement of Understanding) and Functional/Technical Specification documents.\n\n· Providing Effort & Resource estimations\n\n· Planning for application development and deployment\n\n· Writing and executing Test Cases and Test scenarios\n\n· Creating design elements using Technical Specification.\n\n· Performing Unit testing & Peer Reviews\n\n· Work Allocation and mentoring the team\n\n· Providing Technical guidance to the team. \n\n\tProject 6\n: cvdAEI Application\n\nProject Description\n     : CVDAEI is a web based multilingual application developed for handling the Change Management process in Truck division of Daimler. The change request flows through different phases mainly Initialization, Evaluation, Decision and Conclusion. This application has a configurable workflow where the request flow and the responsible persons can be configured easily at any point of time. \n\nRole\n\n    : Developer/Tester\n\nEnvironment\n     : Lotus Notes, Java, HTML, XML, Java Script, JQuery\n\nTasks handled:\n\n· Gathering Requirements and providing Project Plan and Effort Estimation details.\n\n· Understanding business requirements and preparing SoU (Statement of Understanding) and Functional/Technical Specification documents.\n\n· Providing Effort & Resource estimations\n\n· Planning for application development and deployment\n\n· Writing and executing Test Cases and Test scenarios\n\n· Creating design elements using Technical Specification.\n\n· Performing Unit testing & Peer Reviews\n\n· Work Allocation and mentoring the team\n\n· Providing Technical guidance to the team. \n\n\n\n\tProject Title: Project Management Office \nProject Description: The purpose of this system is to enable the Project Management Office to manage and execute the IT Applications and Operations driven project tasks in  more systematic manner. It will also enable them to efficiently perform a role as a facilitator to coordinate various IT Operations teams and to ensure that project activity enters the department through one common interface. The project tasks will subsequently be dealt with in a common format and in a consistent and appropriate manner, ensuring open and regular communication between all involved parties.\n\nRole\n\n    : Developer/Tester\n\nEnvironment\n     : Lotus Notes, Java, HTML, XML, Java Script, JQuery\n\nTasks Handled :\n\n· Writing and Executing Test cases in client server based environment\n· Individually provided application support","annotation":[{"label":["Skills"],"points":[{"start":7951,"end":7956,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":7938,"end":7948,"text":"Java Script"}]},{"label":["Skills"],"points":[{"start":7933,"end":7935,"text":"XML"}]},{"label":["Skills"],"points":[{"start":7927,"end":7930,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":7921,"end":7924,"text":"Java"}]},{"label":["Skills"],"points":[{"start":7908,"end":7918,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":6645,"end":6650,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":6632,"end":6642,"text":"Java Script"}]},{"label":["Skills"],"points":[{"start":6627,"end":6629,"text":"XML"}]},{"label":["Skills"],"points":[{"start":6621,"end":6624,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":6615,"end":6618,"text":"Java"}]},{"label":["Skills"],"points":[{"start":6602,"end":6612,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":5522,"end":5527,"text":"jQuery"}]},{"label":["Skills"],"points":[{"start":5512,"end":5519,"text":"Mongo DB"}]},{"label":["Skills"],"points":[{"start":5504,"end":5509,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4645,"end":4652,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":4054,"end":4061,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":3941,"end":3951,"text":"Naïve Bayes"}]},{"label":["Skills"],"points":[{"start":3494,"end":3501,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":3132,"end":3141,"text":"Word Cloud"}]},{"label":["Skills"],"points":[{"start":2793,"end":2800,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":2110,"end":2116,"text":"Pycharm"}]},{"label":["Skills"],"points":[{"start":2101,"end":2108,"text":"R studio"}]},{"label":["Skills"],"points":[{"start":2086,"end":2091,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":2080,"end":2083,"text":"AJAX"}]},{"label":["Skills"],"points":[{"start":2067,"end":2076,"text":"JavaScript"}]},{"label":["Skills"],"points":[{"start":2060,"end":2063,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":2054,"end":2057,"text":"XSLT"}]},{"label":["Skills"],"points":[{"start":2049,"end":2051,"text":"XML"}]},{"label":["Skills"],"points":[{"start":2018,"end":2025,"text":"Mongo DB"}]},{"label":["Skills"],"points":[{"start":2003,"end":2015,"text":"Microsoft SQL"}]},{"label":["Skills"],"points":[{"start":1977,"end":1986,"text":"Word Cloud"}]},{"label":["Skills"],"points":[{"start":1958,"end":1975,"text":"K means clustering"}]},{"label":["Skills"],"points":[{"start":1945,"end":1955,"text":"Naïve Bayes"}]},{"label":["Skills"],"points":[{"start":1918,"end":1928,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":1908,"end":1915,"text":"Backbone"}]},{"label":["Skills"],"points":[{"start":1901,"end":1905,"text":"Ember"}]},{"label":["Skills"],"points":[{"start":1892,"end":1898,"text":"Angular"}]},{"label":["Skills"],"points":[{"start":1887,"end":1889,"text":"Vue"}]},{"label":["Skills"],"points":[{"start":1880,"end":1884,"text":"React"}]},{"label":["Skills"],"points":[{"start":1871,"end":1877,"text":"FuelPHP"}]},{"label":["Skills"],"points":[{"start":1866,"end":1868,"text":"Yii"}]},{"label":["Skills"],"points":[{"start":1857,"end":1863,"text":"CakePHP"}]},{"label":["Skills"],"points":[{"start":1848,"end":1854,"text":"Phalcon"}]},{"label":["Skills"],"points":[{"start":1842,"end":1845,"text":"Zend"}]},{"label":["Skills"],"points":[{"start":1833,"end":1839,"text":"Symfony"}]},{"label":["Skills"],"points":[{"start":1820,"end":1830,"text":"CodeIgniter"}]},{"label":["Skills"],"points":[{"start":1811,"end":1817,"text":"Laravel"}]},{"label":["Skills"],"points":[{"start":1806,"end":1808,"text":"PHP"}]},{"label":["Skills"],"points":[{"start":1798,"end":1803,"text":"MS SQL"}]},{"label":["Skills"],"points":[{"start":1790,"end":1795,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":1776,"end":1787,"text":"Web Services"}]},{"label":["Skills"],"points":[{"start":1764,"end":1773,"text":"Javascript"}]},{"label":["Skills"],"points":[{"start":1759,"end":1761,"text":"Mvc"}]},{"label":["Skills"],"points":[{"start":1750,"end":1756,"text":"Web Api"}]},{"label":["Skills"],"points":[{"start":1745,"end":1747,"text":"Sql"}]},{"label":["Skills"],"points":[{"start":1739,"end":1742,"text":"Linq"}]},{"label":["Skills"],"points":[{"start":1733,"end":1736,"text":"Rdlc"}]},{"label":["Skills"],"points":[{"start":1724,"end":1730,"text":"ASP.NET"}]},{"label":["Skills"],"points":[{"start":1720,"end":1721,"text":"C#"}]},{"label":["Skills"],"points":[{"start":1709,"end":1717,"text":".NET core"}]},{"label":["Skills"],"points":[{"start":1697,"end":1706,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":1688,"end":1694,"text":"Java EE"}]},{"label":["Skills"],"points":[{"start":1683,"end":1685,"text":"WAS"}]},{"label":["Skills"],"points":[{"start":1678,"end":1680,"text":"IHS"}]},{"label":["Skills"],"points":[{"start":1661,"end":1675,"text":"Computer Vision"}]},{"label":["Skills"],"points":[{"start":1645,"end":1658,"text":"Data Structure"}]},{"label":["Skills"],"points":[{"start":1630,"end":1642,"text":"Random Forest"}]},{"label":["Skills"],"points":[{"start":1615,"end":1627,"text":"Decision Tree"}]},{"label":["Skills"],"points":[{"start":1594,"end":1612,"text":"Logistic Regression"}]},{"label":["Skills"],"points":[{"start":1575,"end":1591,"text":"Linear Regression"}]},{"label":["Skills"],"points":[{"start":1568,"end":1572,"text":"Azure"}]},{"label":["Skills"],"points":[{"start":1556,"end":1565,"text":"Tensorflow"}]},{"label":["Skills"],"points":[{"start":1544,"end":1553,"text":"Regression"}]},{"label":["Skills"],"points":[{"start":1531,"end":1541,"text":"Time Series"}]},{"label":["Skills"],"points":[{"start":1516,"end":1528,"text":"Web Analytics"}]},{"label":["Skills"],"points":[{"start":1501,"end":1513,"text":"Deep Learning"}]},{"label":["Skills"],"points":[{"start":1495,"end":1498,"text":"Oops"}]},{"label":["Skills"],"points":[{"start":1482,"end":1492,"text":"Text Mining"}]},{"label":["Skills"],"points":[{"start":1469,"end":1479,"text":"Data Mining"}]},{"label":["Skills"],"points":[{"start":1459,"end":1466,"text":"Patterns"}]},{"label":["Skills"],"points":[{"start":1447,"end":1456,"text":"Regression"}]},{"label":["Skills"],"points":[{"start":1437,"end":1444,"text":"Modeling"}]},{"label":["Skills"],"points":[{"start":1418,"end":1434,"text":"Parametric Design"}]},{"label":["Skills"],"points":[{"start":1406,"end":1415,"text":"Map Reduce"}]},{"label":["Skills"],"points":[{"start":1398,"end":1403,"text":"Django"}]},{"label":["Skills"],"points":[{"start":1391,"end":1395,"text":"Flask"}]},{"label":["Skills"],"points":[{"start":1382,"end":1388,"text":"Sklearn"}]},{"label":["Skills"],"points":[{"start":1373,"end":1379,"text":"Pyspark"}]},{"label":["Skills"],"points":[{"start":1365,"end":1370,"text":"Pandas"}]},{"label":["Skills"],"points":[{"start":1340,"end":1362,"text":"Artificial Intelligence"}]},{"label":["Skills"],"points":[{"start":1325,"end":1337,"text":"Sql Reporting"}]},{"label":["Skills"],"points":[{"start":1325,"end":1327,"text":"Sql"}]},{"label":["Skills"],"points":[{"start":1319,"end":1322,"text":"Msbi"}]},{"label":["Skills"],"points":[{"start":1313,"end":1316,"text":"Ssrs"}]},{"label":["Skills"],"points":[{"start":1302,"end":1310,"text":"Msbi Ssis"}]},{"label":["Skills"],"points":[{"start":1302,"end":1305,"text":"Msbi"}]},{"label":["Skills"],"points":[{"start":1280,"end":1299,"text":"SQL server reporting"}]},{"label":["Skills"],"points":[{"start":1267,"end":1277,"text":"Programming"}]},{"label":["Skills"],"points":[{"start":1258,"end":1264,"text":"Bigdata"}]},{"label":["Skills"],"points":[{"start":1252,"end":1255,"text":"Hive"}]},{"label":["Skills"],"points":[{"start":1244,"end":1249,"text":"Hadoop"}]},{"label":["Skills"],"points":[{"start":1237,"end":1241,"text":"Scala"}]},{"label":["Skills"],"points":[{"start":1231,"end":1234,"text":"Java"}]},{"label":["Skills"],"points":[{"start":1226,"end":1228,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1208,"end":1223,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1200,"end":1205,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1186,"end":1197,"text":"Data Science"}]},{"label":["Skills"],"points":[{"start":1178,"end":1183,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1161,"end":1175,"text":"Project Manager"}]},{"label":["Skills"],"points":[{"start":1144,"end":1158,"text":"Quality Analyst"}]},{"label":["Skills"],"points":[{"start":1139,"end":1141,"text":"Ios"}]},{"label":["Skills"],"points":[{"start":1126,"end":1136,"text":"Informatica"}]},{"label":["Skills"],"points":[{"start":1121,"end":1123,"text":"Etl"}]},{"label":["Skills"],"points":[{"start":1109,"end":1118,"text":"Networking"}]},{"label":["Skills"],"points":[{"start":1100,"end":1106,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":1090,"end":1097,"text":"Big Data"}]},{"label":["Skills"],"points":[{"start":1075,"end":1087,"text":"SQL Developer"}]},{"label":["Skills"],"points":[{"start":1067,"end":1072,"text":"Hadoop"}]},{"label":["Skills"],"points":[{"start":1061,"end":1064,"text":".NET"}]},{"label":["Skills"],"points":[{"start":1043,"end":1058,"text":"Embedded Systems"}]},{"label":["Skills"],"points":[{"start":1037,"end":1040,"text":"DBAs"}]},{"label":["Skills"],"points":[{"start":1023,"end":1034,"text":"UI Developer"}]},{"label":["Skills"],"points":[{"start":1005,"end":1020,"text":"Business Analyst"}]},{"label":["Skills"],"points":[{"start":989,"end":1002,"text":"Devops Android"}]},{"label":["Skills"],"points":[{"start":977,"end":986,"text":"Salesforce"}]},{"label":["Skills"],"points":[{"start":963,"end":974,"text":"Oracle Cloud"}]},{"label":["Skills"],"points":[{"start":949,"end":961,"text":"Oracle Fusion"}]},{"label":["Skills"],"points":[{"start":943,"end":946,"text":"J2EE"}]},{"label":["Skills"],"points":[{"start":929,"end":934,"text":"Python"}]},{"label":["Skills"],"points":[{"start":920,"end":926,"text":"Mongodb"}]},{"label":["Skills"],"points":[{"start":910,"end":917,"text":"Firebase"}]},{"label":["Skills"],"points":[{"start":902,"end":907,"text":"FoxPro"}]},{"label":["Skills"],"points":[{"start":893,"end":899,"text":"Clipper"}]},{"label":["Skills"],"points":[{"start":886,"end":890,"text":"dBASE"}]},{"label":["Skills"],"points":[{"start":879,"end":883,"text":"RDBMS"}]},{"label":["Skills"],"points":[{"start":871,"end":876,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":860,"end":868,"text":"FileMaker"}]},{"label":["Skills"],"points":[{"start":848,"end":857,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":830,"end":845,"text":"Microsoft Access"}]},{"label":["Skills"],"points":[{"start":818,"end":827,"text":"PostgreSQL"}]},{"label":["Skills"],"points":[{"start":811,"end":815,"text":"MySQL"}]},{"label":["Skills"],"points":[{"start":798,"end":808,"text":"Programming"}]},{"label":["Skills"],"points":[{"start":796,"end":808,"text":"R Programming"}]},{"label":["Skills"],"points":[{"start":779,"end":794,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":234,"end":244,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":219,"end":231,"text":"R programming"}]},{"label":["Skills"],"points":[{"start":201,"end":216,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":165,"end":180,"text":"Machine Learning"}]},{"label":["Name"],"points":[{"start":0,"end":13,"text":"Udaya Laxmi Ch"}]}],"extras":null,"metadata":{"first_done_at":1579625576000,"last_updated_at":1579626369000,"sec_taken":0,"last_updated_by":"aJOmJy1lvpOYFetVNuqLvFo9Vx42","status":"done","evaluation":"NONE"}}